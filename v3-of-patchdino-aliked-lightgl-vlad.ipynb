{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e84b560c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.006868,
     "end_time": "2025-05-28T22:23:19.646229",
     "exception": false,
     "start_time": "2025-05-28T22:23:19.639361",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Example submission\n",
    "\n",
    "Image Matching Challenge 2025: https://www.kaggle.com/competitions/image-matching-challenge-2025\n",
    "\n",
    "This notebook creates a simple submission using ALIKED and LightGlue, plus DINO for shortlisting, on GPU. Adapted from [last year](https://www.kaggle.com/code/oldufo/imc-2024-submission-example).\n",
    "\n",
    "Remember to select an accelerator on the sidebar to the right, and to disable internet access when submitting a notebook to the competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4d5fb62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T22:23:19.659685Z",
     "iopub.status.busy": "2025-05-28T22:23:19.659288Z",
     "iopub.status.idle": "2025-05-28T22:23:26.715173Z",
     "shell.execute_reply": "2025-05-28T22:23:26.714141Z"
    },
    "papermill": {
     "duration": 7.064523,
     "end_time": "2025-05-28T22:23:26.716992",
     "exception": false,
     "start_time": "2025-05-28T22:23:19.652469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/imc2024-packages-lightglue-rerun-kornia/kornia-0.7.2-py2.py3-none-any.whl\r\n",
      "Processing /kaggle/input/imc2024-packages-lightglue-rerun-kornia/kornia_moons-0.2.9-py3-none-any.whl\r\n",
      "Processing /kaggle/input/imc2024-packages-lightglue-rerun-kornia/kornia_rs-0.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Processing /kaggle/input/imc2024-packages-lightglue-rerun-kornia/lightglue-0.0-py3-none-any.whl\r\n",
      "Processing /kaggle/input/imc2024-packages-lightglue-rerun-kornia/pycolmap-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Processing /kaggle/input/imc2024-packages-lightglue-rerun-kornia/rerun_sdk-0.15.0a2-cp38-abi3-manylinux_2_31_x86_64.whl\r\n",
      "Installing collected packages: rerun-sdk, pycolmap, lightglue, kornia-rs, kornia-moons, kornia\r\n",
      "  Attempting uninstall: kornia-rs\r\n",
      "    Found existing installation: kornia_rs 0.1.8\r\n",
      "    Uninstalling kornia_rs-0.1.8:\r\n",
      "      Successfully uninstalled kornia_rs-0.1.8\r\n",
      "  Attempting uninstall: kornia\r\n",
      "    Found existing installation: kornia 0.8.0\r\n",
      "    Uninstalling kornia-0.8.0:\r\n",
      "      Successfully uninstalled kornia-0.8.0\r\n",
      "Successfully installed kornia-0.7.2 kornia-moons-0.2.9 kornia-rs-0.1.2 lightglue-0.0 pycolmap-0.6.1 rerun-sdk-0.15.0a2\r\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT \n",
    "#Install dependencies and copy model weights to run the notebook without internet access when submitting to the competition.\n",
    "\n",
    "!pip install --no-index /kaggle/input/imc2024-packages-lightglue-rerun-kornia/* --no-deps\n",
    "!mkdir -p /root/.cache/torch/hub/checkpoints\n",
    "!cp /kaggle/input/aliked/pytorch/aliked-n16/1/aliked-n16.pth /root/.cache/torch/hub/checkpoints/\n",
    "!cp /kaggle/input/lightglue/pytorch/aliked/1/aliked_lightglue.pth /root/.cache/torch/hub/checkpoints/\n",
    "!cp /kaggle/input/lightglue/pytorch/aliked/1/aliked_lightglue.pth /root/.cache/torch/hub/checkpoints/aliked_lightglue_v0-1_arxiv-pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23582cb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T22:23:26.731617Z",
     "iopub.status.busy": "2025-05-28T22:23:26.731338Z",
     "iopub.status.idle": "2025-05-28T22:23:28.067261Z",
     "shell.execute_reply": "2025-05-28T22:23:28.065708Z"
    },
    "papermill": {
     "duration": 1.345628,
     "end_time": "2025-05-28T22:23:28.069683",
     "exception": false,
     "start_time": "2025-05-28T22:23:26.724055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp /kaggle/input/disk-depth/disk_lightglue.pth /root/.cache/torch/hub/checkpoints/\n",
    "!cp /kaggle/input/disk-depth/disk_lightglue.pth /root/.cache/torch/hub/checkpoints/disk_lightglue_v0-1_arxiv-pth\n",
    "!cp /kaggle/input/disk-depth/depth-save.pth /root/.cache/torch/hub/checkpoints/depth-save.pth\n",
    "!cp /kaggle/input/disk-depth/depth-save.pth /root/.cache/torch/hub/checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10014ec5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T22:23:28.091421Z",
     "iopub.status.busy": "2025-05-28T22:23:28.091148Z",
     "iopub.status.idle": "2025-05-28T22:23:28.095385Z",
     "shell.execute_reply": "2025-05-28T22:23:28.094536Z"
    },
    "papermill": {
     "duration": 0.0144,
     "end_time": "2025-05-28T22:23:28.096620",
     "exception": false,
     "start_time": "2025-05-28T22:23:28.082220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.path.exists(\"/root/.cache/torch/hub/checkpoints/depth-save.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74002f39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T22:23:28.111022Z",
     "iopub.status.busy": "2025-05-28T22:23:28.110806Z",
     "iopub.status.idle": "2025-05-28T22:24:04.872042Z",
     "shell.execute_reply": "2025-05-28T22:24:04.871168Z"
    },
    "papermill": {
     "duration": 36.770228,
     "end_time": "2025-05-28T22:24:04.873615",
     "exception": false,
     "start_time": "2025-05-28T22:23:28.103387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/kornia/feature/lightglue.py:44: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n",
      "/usr/local/lib/python3.10/dist-packages/lightglue/lightglue.py:24: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from time import time, sleep\n",
    "import gc\n",
    "import numpy as np\n",
    "import h5py\n",
    "import dataclasses\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import kornia as K\n",
    "import kornia.feature as KF\n",
    "\n",
    "import torch\n",
    "from lightglue import match_pair\n",
    "from lightglue import ALIKED, LightGlue\n",
    "from lightglue.utils import load_image, rbd\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "\n",
    "# from lightglue import DISK\n",
    "from kornia.feature import LightGlueMatcher as KF_LightGlueMatcher\n",
    "from scipy.spatial import cKDTree # For efficient nearest neighbor search to remove duplicate keypoints\n",
    "\n",
    "# IMPORTANT Utilities: importing data into colmap and competition metric\n",
    "import pycolmap\n",
    "sys.path.append('/kaggle/input/imc25-utils')\n",
    "from database import *\n",
    "from h5_to_db import *\n",
    "import metric\n",
    "\n",
    "\n",
    "# LightGlue\n",
    "from lightglue import match_pair\n",
    "from lightglue import ALIKED, SuperPoint,DISK, DoGHardNet, LightGlue, SIFT\n",
    "from fastprogress import progress_bar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74bfef23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T22:24:04.888214Z",
     "iopub.status.busy": "2025-05-28T22:24:04.887716Z",
     "iopub.status.idle": "2025-05-28T22:24:04.891398Z",
     "shell.execute_reply": "2025-05-28T22:24:04.890610Z"
    },
    "papermill": {
     "duration": 0.012171,
     "end_time": "2025-05-28T22:24:04.892889",
     "exception": false,
     "start_time": "2025-05-28T22:24:04.880718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "import concurrent.futures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dad7248",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T22:24:04.915112Z",
     "iopub.status.busy": "2025-05-28T22:24:04.914874Z",
     "iopub.status.idle": "2025-05-28T22:24:05.041441Z",
     "shell.execute_reply": "2025-05-28T22:24:05.040492Z"
    },
    "papermill": {
     "duration": 0.137928,
     "end_time": "2025-05-28T22:24:05.043082",
     "exception": false,
     "start_time": "2025-05-28T22:24:04.905154",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu121\n",
      "Python version: 3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]\n",
      "CUDA available: True\n",
      "CUDA version: 12.1\n",
      "Device count: 2\n",
      "Current device: 0\n",
      "Device name: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "import sys\n",
    "print(\"Python version:\", sys.version)\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"Device count:\", torch.cuda.device_count())\n",
    "print(\"Current device:\", torch.cuda.current_device())\n",
    "print(\"Device name:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4373bbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T22:24:05.063778Z",
     "iopub.status.busy": "2025-05-28T22:24:05.063452Z",
     "iopub.status.idle": "2025-05-28T22:24:05.068162Z",
     "shell.execute_reply": "2025-05-28T22:24:05.067296Z"
    },
    "papermill": {
     "duration": 0.013713,
     "end_time": "2025-05-28T22:24:05.069600",
     "exception": false,
     "start_time": "2025-05-28T22:24:05.055887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device=device(type='cuda', index=0)\n"
     ]
    }
   ],
   "source": [
    "# Do not forget to select an accelerator on the sidebar to the right.\n",
    "device = K.utils.get_cuda_device_if_available(0)\n",
    "print(f'{device=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37b44dd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T22:24:05.083795Z",
     "iopub.status.busy": "2025-05-28T22:24:05.083496Z",
     "iopub.status.idle": "2025-05-28T22:24:05.086961Z",
     "shell.execute_reply": "2025-05-28T22:24:05.086176Z"
    },
    "papermill": {
     "duration": 0.012172,
     "end_time": "2025-05-28T22:24:05.088496",
     "exception": false,
     "start_time": "2025-05-28T22:24:05.076324",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "VERBOSE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9dd0230",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T22:24:05.111336Z",
     "iopub.status.busy": "2025-05-28T22:24:05.111130Z",
     "iopub.status.idle": "2025-05-28T22:24:05.119039Z",
     "shell.execute_reply": "2025-05-28T22:24:05.118299Z"
    },
    "papermill": {
     "duration": 0.019007,
     "end_time": "2025-05-28T22:24:05.120377",
     "exception": false,
     "start_time": "2025-05-28T22:24:05.101370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CONFIG:\n",
    "    # DEBUG Settings\n",
    "    DRY_RUN = False\n",
    "    DRY_RUN_MAX_IMAGES = 10\n",
    "\n",
    "    # Pipeline settings\n",
    "    NUM_CORES = 2\n",
    "    \n",
    "    # COLMAP Reconstruction\n",
    "    CAMERA_MODEL = \"simple-radial\"\n",
    "    \n",
    "    # Rotation correction\n",
    "    ROTATION_CORRECTION = False\n",
    "    \n",
    "    # Keypoints handling\n",
    "    MERGE_PARAMS = {\n",
    "        \"min_matches\" : 15,\n",
    "        # When merging keypoints, it is enable to filtering matches with cv2.findFundamentalMatrix.\n",
    "        \"filter_FundamentalMatrix\" : True,\n",
    "        \"filter_iterations\" : 4,\n",
    "        \"filter_threshold\" : 2,\n",
    "    }\n",
    "    \n",
    "    # Keypoints Extraction\n",
    "    use_aliked_lightglue = True\n",
    "    use_doghardnet_lightglue = False\n",
    "    use_superpoint_lightglue = False\n",
    "    use_disk_lightglue = True\n",
    "    use_sift_lightglue = False\n",
    "    use_loftr = False\n",
    "    use_dkm = False\n",
    "    use_superglue = False\n",
    "    use_matchformer = False\n",
    "        \n",
    "    # Keypoints Extraction Parameters\n",
    "    params_aliked_lightglue = {\n",
    "        \"num_features\" : 4096,\n",
    "        \"detection_threshold\" : 0.2,\n",
    "        \"min_matches\" : 200,\n",
    "        \"resize_to\" : 2048,\n",
    "        \"match_confidence_threshold\":1.0\n",
    "    }\n",
    "    \n",
    "    params_doghardnet_lightglue = {\n",
    "        \"num_features\" : 8192,\n",
    "        \"detection_threshold\" : 0.001,\n",
    "        \"min_matches\" : 15,\n",
    "        \"resize_to\" : 1024,\n",
    "    }\n",
    "    \n",
    "    params_superpoint_lightglue = {\n",
    "        \"num_features\" : 4096,\n",
    "        \"detection_threshold\" : 0.005,\n",
    "        \"min_matches\" : 15,\n",
    "        \"resize_to\" : 1024,\n",
    "    }\n",
    "    \n",
    "    params_disk_lightglue = {\n",
    "        \"num_features\" : 4096,\n",
    "        \"detection_threshold\" : 0.2,\n",
    "        \"min_matches\" : 200,\n",
    "        \"resize_to\" : 2048,\n",
    "        \"match_confidence_threshold\":1.0\n",
    "    }\n",
    "\n",
    "    params_sift_lightglue = {\n",
    "        \"num_features\" : 8192,\n",
    "        \"detection_threshold\" : 0.001,\n",
    "        \"min_matches\" : 15,\n",
    "        \"resize_to\" : 1024,\n",
    "    }\n",
    "\n",
    "    params_loftr = {\n",
    "        \"resize_small_edge_to\" : 750,\n",
    "        \"min_matches\" : 15,\n",
    "    }\n",
    "    \n",
    "    params_dkm = {\n",
    "        \"num_features\" : 2048,\n",
    "        \"detection_threshold\" : 0.4,\n",
    "        \"min_matches\" : 15,\n",
    "        \"resize_to\" : (540, 720),    \n",
    "    }\n",
    "    \n",
    "    # superpoint + superglue  ...  https://www.kaggle.com/competitions/image-matching-challenge-2023/discussion/416873\n",
    "    params_sg1 = {\n",
    "        \"sg_config\" : \n",
    "        {\n",
    "            \"superpoint\": {\n",
    "                \"nms_radius\": 4, \n",
    "                \"keypoint_threshold\": 0.005,\n",
    "                \"max_keypoints\": -1,\n",
    "            },\n",
    "            \"superglue\": {\n",
    "                \"weights\": \"outdoor\",\n",
    "                \"sinkhorn_iterations\": 20,\n",
    "                \"match_threshold\": 0.2,\n",
    "            },\n",
    "        },\n",
    "        \"resize_to\": 1088,\n",
    "        \"min_matches\": 15,\n",
    "    }\n",
    "    params_sg2 = {\n",
    "        \"sg_config\" : \n",
    "        {\n",
    "            \"superpoint\": {\n",
    "                \"nms_radius\": 4, \n",
    "                \"keypoint_threshold\": 0.005,\n",
    "                \"max_keypoints\": -1,\n",
    "            },\n",
    "            \"superglue\": {\n",
    "                \"weights\": \"outdoor\",\n",
    "                \"sinkhorn_iterations\": 20,\n",
    "                \"match_threshold\": 0.2,\n",
    "            },\n",
    "        },\n",
    "        \"resize_to\": 1280,\n",
    "        \"min_matches\": 15,\n",
    "    }\n",
    "    params_sg3 = {\n",
    "        \"sg_config\" : \n",
    "        {\n",
    "            \"superpoint\": {\n",
    "                \"nms_radius\": 4, \n",
    "                \"keypoint_threshold\": 0.005,\n",
    "                \"max_keypoints\": -1,\n",
    "            },\n",
    "            \"superglue\": {\n",
    "                \"weights\": \"outdoor\",\n",
    "                \"sinkhorn_iterations\": 20,\n",
    "                \"match_threshold\": 0.2,\n",
    "            },\n",
    "        },\n",
    "        \"resize_to\": 1376,\n",
    "        \"min_matches\": 15,\n",
    "    }\n",
    "    params_sgs = [params_sg1, params_sg2, params_sg3]\n",
    "    \n",
    "    params_matchformer = {\n",
    "        \"detection_threshold\" : 0.15,\n",
    "        \"resize_to\" : (560, 750),\n",
    "        \"num_features\" : 2000,\n",
    "        \"min_matches\" : 15, \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82fa9fdb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T22:24:05.135916Z",
     "iopub.status.busy": "2025-05-28T22:24:05.135624Z",
     "iopub.status.idle": "2025-05-28T22:24:05.164068Z",
     "shell.execute_reply": "2025-05-28T22:24:05.163304Z"
    },
    "papermill": {
     "duration": 0.037829,
     "end_time": "2025-05-28T22:24:05.165626",
     "exception": false,
     "start_time": "2025-05-28T22:24:05.127797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assume these are available from your environment or previous code\n",
    "# from .utils import load_torch_image # Assuming load_torch_image is defined elsewhere\n",
    "# from kornia.feature import ALIKED # Already in your detect_aliked\n",
    "# from kornia.feature import LightGlueMatcher as KF_LightGlueMatcher # Already in your match_with_lightglue\n",
    "# from kornia.geometry import laf_from_center_scale_ori # Already in your match_with_lightglue\n",
    "# from colmap_database import COLMAPDatabase, add_keypoints, add_matches # Already in your colmap_import\n",
    "\n",
    "# --- Helper function for image loading (if not already defined) ---\n",
    "def load_torch_image(fname, device=torch.device('cpu')):\n",
    "    img = K.io.load_image(fname, K.io.ImageLoadType.RGB32, device=device)[None, ...]\n",
    "    return img\n",
    "def get_dino_patch_features_for_keypoints(img_path, keypoints_xy, dino_processor, dino_model, patch_size=16, device=torch.device('cpu')):\n",
    "    \"\"\"\n",
    "    Extracts DINO patch features corresponding to given ALIKED keypoint locations.\n",
    "    It correctly infers the DINO patch grid dimensions from the processed input.\n",
    "\n",
    "    Args:\n",
    "        img_path (str): Path to the image file.\n",
    "        keypoints_xy (torch.Tensor): Nx2 tensor of (x, y) keypoint coordinates in image pixel space.\n",
    "                                     These keypoints are assumed to be in the original image's coordinate system.\n",
    "        dino_processor: HuggingFace AutoImageProcessor for DINO.\n",
    "        dino_model: HuggingFace AutoModel for DINO.\n",
    "        patch_size (int): The patch size used by the DINO model (e.g., 14 or 16).\n",
    "        device (torch.device): Device to run the models on.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: NxD_dino tensor of DINO patch features for each keypoint.\n",
    "                      Returns None if no keypoints or image loading fails.\n",
    "    \"\"\"\n",
    "    if len(keypoints_xy) == 0:\n",
    "        dino_feature_dim = dino_model.config.hidden_size # Get actual DINO hidden size\n",
    "        return torch.empty((0, dino_feature_dim), device=device)\n",
    "\n",
    "    # 1. Load the original image (ALIKED processed this size)\n",
    "    original_img = load_torch_image(img_path, device=device)\n",
    "    original_h, original_w = original_img.shape[-2], original_img.shape[-1]\n",
    "\n",
    "\n",
    "    # 2. Process the image with DINO's processor\n",
    "    #    This step performs resizing, padding, etc., as needed by the DINO model\n",
    "    with torch.inference_mode():\n",
    "        # dino_processor returns a BatchFeature object which includes pixel_values\n",
    "        # and potentially other information like `pixel_mask`\n",
    "        inputs = dino_processor(images=original_img, return_tensors=\"pt\", do_rescale=False).to(device)\n",
    "        outputs = dino_model(**inputs)\n",
    "\n",
    "        # Get the actual dimensions of the image as processed by the DINO model\n",
    "        # This is the crucial part: the actual H and W that produced `patch_tokens`\n",
    "        # We can infer this from the `pixel_values` shape\n",
    "        processed_h = inputs['pixel_values'].shape[-2]\n",
    "        processed_w = inputs['pixel_values'].shape[-1]\n",
    "\n",
    "        # Extract patch tokens (excluding the CLS token)\n",
    "        patch_tokens = outputs.last_hidden_state[:, 1:].squeeze(0) # Shape: (num_patches, hidden_size)\n",
    "\n",
    "        # Calculate the actual grid dimensions based on the *processed* image size\n",
    "        # and the model's patch size.\n",
    "        # This should perfectly match the number of patch_tokens if the model is well-behaved.\n",
    "        num_patches_h = processed_h // patch_size\n",
    "        num_patches_w = processed_w // patch_size\n",
    "\n",
    "        # Safety check: ensure calculated grid matches actual token count\n",
    "        expected_token_count = num_patches_h * num_patches_w\n",
    "        if patch_tokens.shape[0] != expected_token_count:\n",
    "            # This indicates a deeper issue with how the model's output tokens\n",
    "            # map to the spatial grid, or an unexpected patch size/model behavior.\n",
    "            # Some models might have slightly different patch token arrangements.\n",
    "            # DINOv2 typically aligns well.\n",
    "            raise ValueError(\n",
    "                f\"DINO patch token count ({patch_tokens.shape[0]}) does not match \"\n",
    "                f\"expected grid dimensions ({num_patches_h}x{num_patches_w} = {expected_token_count}) \"\n",
    "                f\"for processed image size {processed_w}x{processed_h} with patch size {patch_size}. \"\n",
    "                f\"Please verify DINO model and processor configuration.\"\n",
    "            )\n",
    "\n",
    "        # Reshape patch tokens into a 2D grid\n",
    "        patch_features_grid = patch_tokens.reshape(num_patches_h, num_patches_w, -1)\n",
    "        dino_feature_dim = patch_features_grid.shape[-1] # Actual feature dimension\n",
    "\n",
    "\n",
    "    dino_features_for_kpts = torch.zeros((len(keypoints_xy), dino_feature_dim), device=device)\n",
    "\n",
    "    # 3. Rescale ALIKED keypoints to the DINO *processed* image dimensions\n",
    "    #    ALIKED keypoints are in original_w x original_h coordinates.\n",
    "    #    DINO patches correspond to processed_w x processed_h coordinates.\n",
    "    scale_x = processed_w / original_w\n",
    "    scale_y = processed_h / original_h\n",
    "\n",
    "    scaled_keypoints_xy = keypoints_xy.clone()\n",
    "    scaled_keypoints_xy[:, 0] *= scale_x\n",
    "    scaled_keypoints_xy[:, 1] *= scale_y\n",
    "\n",
    "    # 4. Map scaled keypoints to DINO patch grid indices\n",
    "    keypoint_cols = (scaled_keypoints_xy[:, 0] / patch_size).long()\n",
    "    keypoint_rows = (scaled_keypoints_xy[:, 1] / patch_size).long()\n",
    "\n",
    "    # Clip indices to ensure they are within bounds of the patch grid\n",
    "    keypoint_rows = torch.clamp(keypoint_rows, 0, num_patches_h - 1)\n",
    "    keypoint_cols = torch.clamp(keypoint_cols, 0, num_patches_w - 1)\n",
    "\n",
    "    # Gather DINO features for each keypoint's corresponding patch\n",
    "    dino_features_for_kpts = patch_features_grid[keypoint_rows, keypoint_cols]\n",
    "\n",
    "    return dino_features_for_kpts\n",
    "\n",
    "\n",
    "def convert_coord(r, w, h, rotk):\n",
    "    if rotk == 0:\n",
    "        return r\n",
    "    elif rotk == 1:\n",
    "        rx = w-1-r[:, 1]\n",
    "        ry = r[:, 0]\n",
    "        return torch.concat([rx[None], ry[None]], dim=0).T\n",
    "    elif rotk == 2:\n",
    "        rx = w-1-r[:, 0]\n",
    "        ry = h-1-r[:, 1]\n",
    "        return torch.concat([rx[None], ry[None]], dim=0).T\n",
    "    elif rotk == 3:\n",
    "        rx = r[:, 1]\n",
    "        ry = h-1-r[:, 0]\n",
    "        return torch.concat([rx[None], ry[None]], dim=0).T\n",
    "\n",
    "def detect_common(img_fnames,\n",
    "                  model_name,\n",
    "                  rots,\n",
    "                  file_keypoints,\n",
    "                  feature_dir = '.featureout',\n",
    "                  num_features = 4096,\n",
    "                  resize_to = 1024,\n",
    "                  detection_threshold = 0.01,\n",
    "                  device=torch.device('cpu'),\n",
    "                  min_matches=15,\n",
    "                  match_confidence_threshold = 0.0,\n",
    "                  verbose=VERBOSE\n",
    "                 ):\n",
    "    if not os.path.isdir(feature_dir):\n",
    "        os.makedirs(feature_dir)\n",
    "\n",
    "    #####################################################\n",
    "    # Extract keypoints and descriptions\n",
    "    #####################################################\n",
    "    dict_model = {\n",
    "        \"aliked\" : ALIKED,\n",
    "        \"superpoint\" : SuperPoint,\n",
    "        \"doghardnet\" : DoGHardNet,\n",
    "        \"disk\" : DISK,\n",
    "        \"sift\" : SIFT,\n",
    "    }\n",
    "    extractor_class = dict_model[model_name]\n",
    "    dtype = torch.float32 # ALIKED has issues with float16\n",
    "    # extractor = extractor_class(max_num_keypoints=num_features, detection_threshold=detection_threshold, \n",
    "    #                             resize=resize_to).eval().to(device, dtype)\n",
    "    # if model_name == 'disk':\n",
    "    #     extractor = DISK(\n",
    "    #         max_num_keypoints=num_features,\n",
    "    #         detection_threshold=detection_threshold,\n",
    "    #         resize=resize_to\n",
    "    #     ).to(device).eval()\n",
    "    #     checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "    #     extractor.load_state_dict(checkpoint['model'])\n",
    "    # else:\n",
    "    #     extractor_class = dict_model[model_name]\n",
    "    #     extractor = extractor_class(\n",
    "    #         max_num_keypoints=num_features,\n",
    "    #         detection_threshold=detection_threshold,\n",
    "    #         resize=resize_to\n",
    "    #     ).to(device, dtype).eval()\n",
    "\n",
    "    extractor_class = dict_model[model_name]\n",
    "    extractor = extractor_class(\n",
    "        max_num_keypoints=num_features,\n",
    "        detection_threshold=detection_threshold,\n",
    "        resize=resize_to\n",
    "    ).to(device, dtype).eval()\n",
    "    dict_kpts_cuda = {}\n",
    "    dict_descs_cuda = {}\n",
    "    for (img_path, rot_k) in zip(img_fnames, rots):\n",
    "        img_fname = img_path.split('/')[-1]\n",
    "        key = img_fname\n",
    "        with torch.inference_mode():\n",
    "            image0 = load_torch_image(img_path, device=device).to(dtype)\n",
    "            h, w = image0.shape[2], image0.shape[3]\n",
    "            image1 = torch.rot90(image0, rot_k, [2, 3])\n",
    "            feats0 = extractor.extract(image1)  # auto-resize the image, disable with resize=None\n",
    "            kpts = feats0['keypoints'].reshape(-1, 2).detach()\n",
    "            descs = feats0['descriptors'].reshape(len(kpts), -1).detach()\n",
    "            kpts = convert_coord(kpts, w, h, rot_k)\n",
    "            dict_kpts_cuda[f\"{key}\"] = kpts\n",
    "            dict_descs_cuda[f\"{key}\"] = descs\n",
    "            if verbose:\n",
    "                print(f\"{model_name} > rot_k={rot_k}, kpts.shape={kpts.shape}, descs.shape={descs.shape}\")\n",
    "    del extractor\n",
    "    gc.collect()\n",
    "\n",
    "    #####################################################\n",
    "    # Matching keypoints\n",
    "    #####################################################\n",
    "    lg_matcher = KF.LightGlueMatcher(model_name, {\"width_confidence\": -1,\n",
    "                                            \"depth_confidence\": -1,\n",
    "                                             \"mp\": True if 'cuda' in str(device) else False}).eval().to(device)\n",
    "    \n",
    "    cnt_pairs = 0\n",
    "    with h5py.File(file_keypoints, mode='w') as f_match:\n",
    "        for pair_idx in tqdm(index_pairs):\n",
    "            idx1, idx2 = pair_idx\n",
    "            fname1, fname2 = img_fnames[idx1], img_fnames[idx2]\n",
    "            \n",
    "            key1, key2 = fname1.split('/')[-1], fname2.split('/')[-1]\n",
    "            \n",
    "            kp1 = dict_kpts_cuda[key1]\n",
    "            kp2 = dict_kpts_cuda[key2]\n",
    "            desc1 = dict_descs_cuda[key1]\n",
    "            desc2 = dict_descs_cuda[key2]\n",
    "            with torch.inference_mode():\n",
    "                dists, idxs = lg_matcher(desc1,\n",
    "                                     desc2,\n",
    "                                     KF.laf_from_center_scale_ori(kp1[None]),\n",
    "                                     KF.laf_from_center_scale_ori(kp2[None]))\n",
    "            if len(idxs)  == 0:\n",
    "                continue\n",
    "            len1 = len(idxs)\n",
    "            n_matches = len1\n",
    "            # if len(idxs) >= min_matches:                \n",
    "            #     conf = dists.cpu().numpy()  # lower is better\n",
    "            #     if conf.ndim == 2:\n",
    "            #         conf = conf[:, 0]  # force (N,)\n",
    "            #     conf_mask = conf <= match_confidence_threshold\n",
    "            #     if not np.any(conf_mask):\n",
    "            #         continue\n",
    "            #     idxs = idxs[conf_mask]\n",
    "            #     conf = conf[conf_mask]\n",
    "            #     n_matches = len(idxs)\n",
    "            #     if verbose:\n",
    "            #         print(f\"match after conf threshold: {key1}-{key2}: {len1}->{n_matches}\")\n",
    "            kp1 = kp1[idxs[:,0], :].cpu().numpy().reshape(-1, 2).astype(np.float32)\n",
    "            kp2 = kp2[idxs[:,1], :].cpu().numpy().reshape(-1, 2).astype(np.float32)\n",
    "            group  = f_match.require_group(key1)\n",
    "            if n_matches >= min_matches:\n",
    "                group.create_dataset(key2, data=np.concatenate([kp1, kp2], axis=1))\n",
    "                cnt_pairs+=1\n",
    "                if verbose:\n",
    "                    print (f'{model_name}> {key1}-{key2}: {n_matches} matches @ {cnt_pairs}th pair({model_name}+lightglue)')            \n",
    "            else:\n",
    "                pass\n",
    "                # if verbose:\n",
    "                #     print (f'{model_name}> {key1}-{key2}: {n_matches} matches --> skipped')\n",
    "    del lg_matcher\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    return\n",
    "\n",
    "def detect_lightglue_common(\n",
    "    img_fnames, model_name, index_pairs, feature_dir, device, file_keypoints, rots,\n",
    "    resize_to=1024,\n",
    "    detection_threshold=0.01, \n",
    "    num_features=4096, \n",
    "    min_matches=15,\n",
    "    match_confidence_threshold = 0.0\n",
    "):\n",
    "    t=time()\n",
    "    detect_common(\n",
    "        img_fnames, model_name, rots, file_keypoints, feature_dir, \n",
    "        resize_to=resize_to,\n",
    "        num_features=num_features, \n",
    "        detection_threshold=detection_threshold, \n",
    "        device=device,\n",
    "        min_matches=min_matches,\n",
    "        match_confidence_threshold = match_confidence_threshold\n",
    "    )\n",
    "    gc.collect()\n",
    "    t=time() -t \n",
    "    print(f'Features matched in  {t:.4f} sec ({model_name}+LightGlue)')\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0961876a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T22:24:05.187691Z",
     "iopub.status.busy": "2025-05-28T22:24:05.187378Z",
     "iopub.status.idle": "2025-05-28T22:24:05.222507Z",
     "shell.execute_reply": "2025-05-28T22:24:05.221734Z"
    },
    "papermill": {
     "duration": 0.046067,
     "end_time": "2025-05-28T22:24:05.223989",
     "exception": false,
     "start_time": "2025-05-28T22:24:05.177922",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_unique_idxs(A, dim=0):\n",
    "    # https://stackoverflow.com/questions/72001505/how-to-get-unique-elements-and-their-firstly-appeared-indices-of-a-pytorch-tenso\n",
    "    unique, idx, counts = torch.unique(A, dim=dim, sorted=True, return_inverse=True, return_counts=True)\n",
    "    _, ind_sorted = torch.sort(idx, stable=True)\n",
    "    cum_sum = counts.cumsum(0)\n",
    "    cum_sum = torch.cat((torch.tensor([0],device=cum_sum.device), cum_sum[:-1]))\n",
    "    first_indices = ind_sorted[cum_sum]\n",
    "    return first_indices\n",
    "\n",
    "def get_keypoint_from_h5(fp, key1, key2):\n",
    "    rc = -1\n",
    "    try:\n",
    "        kpts = np.array(fp[key1][key2])\n",
    "        rc = 0\n",
    "        return (rc, kpts)\n",
    "    except:\n",
    "        return (rc, None)\n",
    "\n",
    "def get_keypoint_from_multi_h5(fps, key1, key2):\n",
    "    list_mkpts = []\n",
    "    for fp in fps:\n",
    "        rc, mkpts = get_keypoint_from_h5(fp, key1, key2)\n",
    "        if rc == 0:\n",
    "            list_mkpts.append(mkpts)\n",
    "    if len(list_mkpts) > 0:\n",
    "        list_mkpts = np.concatenate(list_mkpts, axis=0)\n",
    "    else:\n",
    "        list_mkpts = None\n",
    "    return list_mkpts\n",
    "\n",
    "def matches_merger(\n",
    "    img_fnames,\n",
    "    index_pairs,\n",
    "    files_keypoints,\n",
    "    save_file,\n",
    "    feature_dir = 'featureout',\n",
    "    filter_FundamentalMatrix = False,\n",
    "    filter_iterations = 10,\n",
    "    filter_threshold = 8,\n",
    "    verbose = VERBOSE\n",
    "):\n",
    "    # open h5 files\n",
    "    fps = [ h5py.File(file, mode=\"r\") for file in files_keypoints ]\n",
    "\n",
    "    with h5py.File(save_file, mode='w') as f_match:\n",
    "        counter = 0\n",
    "        for pair_idx in progress_bar(index_pairs):\n",
    "            idx1, idx2 = pair_idx\n",
    "            fname1, fname2 = img_fnames[idx1], img_fnames[idx2]\n",
    "            key1, key2 = fname1.split('/')[-1], fname2.split('/')[-1]\n",
    "\n",
    "            # extract keypoints\n",
    "            mkpts = get_keypoint_from_multi_h5(fps, key1, key2)\n",
    "            if mkpts is None:\n",
    "                # if verbose:\n",
    "                #     print(f\"skipped key1={key1}, key2={key2}\")\n",
    "                continue\n",
    "\n",
    "            ori_size = mkpts.shape[0]\n",
    "            if mkpts.shape[0] < CONFIG.MERGE_PARAMS[\"min_matches\"]:\n",
    "                continue\n",
    "            \n",
    "            if filter_FundamentalMatrix:\n",
    "                store_inliers = { idx:0 for idx in range(mkpts.shape[0]) }\n",
    "                idxs = np.array(range(mkpts.shape[0]))\n",
    "                for iter in range(filter_iterations):\n",
    "                    try:\n",
    "                        Fm, inliers = cv2.findFundamentalMat(\n",
    "                            mkpts[:,:2], mkpts[:,2:4], cv2.USAC_MAGSAC, 0.15, 0.9999, 20000)\n",
    "                        if Fm is not None:\n",
    "                            inliers = inliers > 0\n",
    "                            inlier_idxs = idxs[inliers[:, 0]]\n",
    "                            #print(inliers.shape, inlier_idxs[:5])\n",
    "                            for idx in inlier_idxs:\n",
    "                                store_inliers[idx] += 1\n",
    "                    except:\n",
    "                        print(f\"Failed to cv2.findFundamentalMat. mkpts.shape={mkpts.shape}\")\n",
    "                inliers = np.array([ count for (idx, count) in store_inliers.items() ]) >= filter_threshold\n",
    "                mkpts = mkpts[inliers]\n",
    "                if mkpts.shape[0] < 15:\n",
    "                    if verbose:\n",
    "                        print(f\"skipped key1={key1}, key2={key2}: mkpts.shape={mkpts.shape} after filtered.\")\n",
    "                    continue\n",
    "                print(f\"filter_FundamentalMatrix: {len(store_inliers)} matches --> {mkpts.shape[0]} matches\")\n",
    "            \n",
    "            if verbose:\n",
    "                print (f'{key1}-{key2}: {ori_size} --> {mkpts.shape[0]} matches')            \n",
    "            # regist tmp file\n",
    "            group  = f_match.require_group(key1)\n",
    "            group.create_dataset(key2, data=mkpts)\n",
    "            counter += 1\n",
    "    print( f\"Ensembled pairs : {counter} pairs\" )\n",
    "    for fp in fps:\n",
    "        fp.close()\n",
    "\n",
    "def keypoints_merger(\n",
    "    img_fnames,\n",
    "    index_pairs,\n",
    "    files_keypoints,\n",
    "    feature_dir = 'featureout',\n",
    "    filter_FundamentalMatrix = False,\n",
    "    filter_iterations = 10,\n",
    "    filter_threshold = 8,\n",
    "):\n",
    "    save_file = f'{feature_dir}/merge_tmp.h5'\n",
    "    !rm -rf {save_file}\n",
    "    matches_merger(\n",
    "        img_fnames,\n",
    "        index_pairs,\n",
    "        files_keypoints,\n",
    "        save_file,\n",
    "        feature_dir = feature_dir,\n",
    "        filter_FundamentalMatrix = filter_FundamentalMatrix,\n",
    "        filter_iterations = filter_iterations,\n",
    "        filter_threshold = filter_threshold,\n",
    "    )\n",
    "        \n",
    "    # Let's find unique loftr pixels and group them together.\n",
    "    kpts = defaultdict(list)\n",
    "    match_indexes = defaultdict(dict)\n",
    "    total_kpts=defaultdict(int)\n",
    "    with h5py.File(save_file, mode='r') as f_match:\n",
    "        for k1 in f_match.keys():\n",
    "            group  = f_match[k1]\n",
    "            for k2 in group.keys():\n",
    "                matches = group[k2][...]\n",
    "                total_kpts[k1]\n",
    "                kpts[k1].append(matches[:, :2])\n",
    "                kpts[k2].append(matches[:, 2:])\n",
    "                current_match = torch.arange(len(matches)).reshape(-1, 1).repeat(1, 2)\n",
    "                current_match[:, 0]+=total_kpts[k1]\n",
    "                current_match[:, 1]+=total_kpts[k2]\n",
    "                total_kpts[k1]+=len(matches)\n",
    "                total_kpts[k2]+=len(matches)\n",
    "                match_indexes[k1][k2]=current_match\n",
    "\n",
    "    for k in kpts.keys():\n",
    "        kpts[k] = np.round(np.concatenate(kpts[k], axis=0))\n",
    "    unique_kpts = {}\n",
    "    unique_match_idxs = {}\n",
    "    out_match = defaultdict(dict)\n",
    "    for k in kpts.keys():\n",
    "        uniq_kps, uniq_reverse_idxs = torch.unique(torch.from_numpy(kpts[k]),dim=0, return_inverse=True)\n",
    "        unique_match_idxs[k] = uniq_reverse_idxs\n",
    "        unique_kpts[k] = uniq_kps.numpy()\n",
    "    for k1, group in match_indexes.items():\n",
    "        for k2, m in group.items():\n",
    "            m2 = deepcopy(m)\n",
    "            m2[:,0] = unique_match_idxs[k1][m2[:,0]]\n",
    "            m2[:,1] = unique_match_idxs[k2][m2[:,1]]\n",
    "            mkpts = np.concatenate([unique_kpts[k1][ m2[:,0]],\n",
    "                                    unique_kpts[k2][  m2[:,1]],\n",
    "                                   ],\n",
    "                                   axis=1)\n",
    "            unique_idxs_current = get_unique_idxs(torch.from_numpy(mkpts), dim=0)\n",
    "            m2_semiclean = m2[unique_idxs_current]\n",
    "            unique_idxs_current1 = get_unique_idxs(m2_semiclean[:, 0], dim=0)\n",
    "            m2_semiclean = m2_semiclean[unique_idxs_current1]\n",
    "            unique_idxs_current2 = get_unique_idxs(m2_semiclean[:, 1], dim=0)\n",
    "            m2_semiclean2 = m2_semiclean[unique_idxs_current2]\n",
    "            out_match[k1][k2] = m2_semiclean2.numpy()\n",
    "    with h5py.File(f'{feature_dir}/keypoints.h5', mode='w') as f_kp:\n",
    "        for k, kpts1 in unique_kpts.items():\n",
    "            f_kp[k] = kpts1\n",
    "    \n",
    "    with h5py.File(f'{feature_dir}/matches.h5', mode='w') as f_match:\n",
    "        for k1, gr in out_match.items():\n",
    "            group  = f_match.require_group(k1)\n",
    "            for k2, match in gr.items():\n",
    "                group[k2] = match\n",
    "                # print(f\"KKKKKKK KKKKKK {k1} - {k2}: {len(match)} matches\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3dc55942",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T22:24:05.243860Z",
     "iopub.status.busy": "2025-05-28T22:24:05.243571Z",
     "iopub.status.idle": "2025-05-28T22:24:05.246811Z",
     "shell.execute_reply": "2025-05-28T22:24:05.246054Z"
    },
    "papermill": {
     "duration": 0.011585,
     "end_time": "2025-05-28T22:24:05.247949",
     "exception": false,
     "start_time": "2025-05-28T22:24:05.236364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !rm -rf /kaggle/working/result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff2f4ede",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T22:24:05.262166Z",
     "iopub.status.busy": "2025-05-28T22:24:05.261878Z",
     "iopub.status.idle": "2025-05-28T22:24:05.272993Z",
     "shell.execute_reply": "2025-05-28T22:24:05.272317Z"
    },
    "papermill": {
     "duration": 0.019631,
     "end_time": "2025-05-28T22:24:05.274237",
     "exception": false,
     "start_time": "2025-05-28T22:24:05.254606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- MODIFIED: Detect ALIKED and Combine with DINO Patch Features ---\n",
    "def detect_aliked_and_combine_with_dino(img_fnames,\n",
    "                                        feature_dir='.featureout',\n",
    "                                        num_features=4096,\n",
    "                                        resize_to=1024,\n",
    "                                        dino_processor=None,\n",
    "                                        dino_model=None,\n",
    "                                        dino_patch_size=16, # Typically 14 or 16 for DINO\n",
    "                                        device=torch.device('cpu')):\n",
    "    dtype = torch.float32 # ALIKED has issues with float16\n",
    "    aliked_extractor = ALIKED(max_num_keypoints=num_features, detection_threshold=0.1).eval().to(device, dtype)\n",
    "    aliked_extractor.preprocess_conf[\"resize\"] = resize_to\n",
    "    if not os.path.isdir(feature_dir):\n",
    "        os.makedirs(feature_dir)\n",
    "\n",
    "    with h5py.File(f'{feature_dir}/keypoints.h5', mode='w') as f_kp, \\\n",
    "         h5py.File(f'{feature_dir}/descriptors_aliked.h5', mode='w') as f_desc_aliked, \\\n",
    "         h5py.File(f'{feature_dir}/descriptors_combined.h5', mode='w') as f_desc_combined: # New HDF5 for combined features\n",
    "        for img_path in tqdm(img_fnames):\n",
    "            img_fname = img_path.split('/')[-1]\n",
    "            key = img_fname\n",
    "\n",
    "            with torch.inference_mode():\n",
    "                image0 = load_torch_image(img_path, device=device).to(dtype)\n",
    "                feats0 = aliked_extractor.extract(image0)\n",
    "                kpts = feats0['keypoints'].reshape(-1, 2).detach().cpu().numpy() # ALIKED keypoints (x,y)\n",
    "                descs_aliked = feats0['descriptors'].reshape(len(kpts), -1).detach().cpu().numpy() # ALIKED descriptors\n",
    "\n",
    "                # Get DINO patch features for these keypoints\n",
    "                kpts_torch = torch.from_numpy(kpts).to(device)\n",
    "                descs_dino_patch = get_dino_patch_features_for_keypoints(\n",
    "                    img_path, kpts_torch, dino_processor, dino_model, dino_patch_size, device\n",
    "                ).detach().cpu().numpy()\n",
    "\n",
    "                # Concatenate ALIKED and DINO features\n",
    "                if len(descs_aliked) > 0 and len(descs_dino_patch) > 0:\n",
    "                    combined_descs = np.concatenate((descs_aliked, descs_dino_patch), axis=1)\n",
    "                elif len(descs_aliked) > 0: # Only ALIKED if no DINO features (shouldn't happen often)\n",
    "                    combined_descs = descs_aliked\n",
    "                else: # No features found\n",
    "                    combined_descs = np.array([]) # Empty array\n",
    "\n",
    "                f_kp[key] = kpts\n",
    "                f_desc_aliked[key] = descs_aliked # Keep ALIKED descriptors for debugging or other uses\n",
    "                f_desc_combined[key] = combined_descs # Store the new combined descriptors\n",
    "    print(f\"Combined features saved to {feature_dir}/descriptors_combined.h5\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "661c86f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T22:24:05.288740Z",
     "iopub.status.busy": "2025-05-28T22:24:05.288402Z",
     "iopub.status.idle": "2025-05-28T22:24:05.840072Z",
     "shell.execute_reply": "2025-05-28T22:24:05.839133Z"
    },
    "papermill": {
     "duration": 0.560295,
     "end_time": "2025-05-28T22:24:05.841665",
     "exception": false,
     "start_time": "2025-05-28T22:24:05.281370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans # MiniBatchKMeans is faster for large datasets\n",
    "\n",
    "# --- VLAD Aggregation Function ---\n",
    "def vlad_encode(descriptors, centroids):\n",
    "    \"\"\"\n",
    "    Performs VLAD encoding.\n",
    "\n",
    "    Args:\n",
    "        descriptors (np.ndarray): NxM array of local descriptors.\n",
    "        centroids (np.ndarray): KxM array of K-Means cluster centroids.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: 1x(K*M) VLAD descriptor.\n",
    "    \"\"\"\n",
    "    if descriptors.shape[0] == 0:\n",
    "        return np.zeros(centroids.shape[0] * centroids.shape[1], dtype=np.float32)\n",
    "\n",
    "    num_descriptors, desc_dim = descriptors.shape\n",
    "    num_centroids, _ = centroids.shape\n",
    "\n",
    "    # Assign each descriptor to its nearest centroid\n",
    "    # Using cdist for efficiency\n",
    "    distances = np.sqrt(np.sum((descriptors[:, None, :] - centroids[None, :, :])**2, axis=2))\n",
    "    # distances = cdist(descriptors, centroids, 'sqeuclidean') # Could use cdist for sqeuclidean\n",
    "    cluster_assignments = np.argmin(distances, axis=1)\n",
    "\n",
    "    # Initialize VLAD accumulator\n",
    "    vlad_accumulator = np.zeros((num_centroids, desc_dim), dtype=np.float32)\n",
    "\n",
    "    # Accumulate residuals\n",
    "    for i in range(num_descriptors):\n",
    "        cluster_idx = cluster_assignments[i]\n",
    "        residual = descriptors[i] - centroids[cluster_idx]\n",
    "        vlad_accumulator[cluster_idx] += residual\n",
    "\n",
    "    # Flatten and L2 normalize\n",
    "    vlad_descriptor = vlad_accumulator.flatten()\n",
    "    vlad_descriptor = F.normalize(torch.from_numpy(vlad_descriptor).unsqueeze(0), dim=1, p=2).squeeze(0).numpy()\n",
    "\n",
    "    return vlad_descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8851bb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T22:24:05.856200Z",
     "iopub.status.busy": "2025-05-28T22:24:05.855975Z",
     "iopub.status.idle": "2025-05-28T22:24:05.864082Z",
     "shell.execute_reply": "2025-05-28T22:24:05.863299Z"
    },
    "papermill": {
     "duration": 0.016751,
     "end_time": "2025-05-28T22:24:05.865425",
     "exception": false,
     "start_time": "2025-05-28T22:24:05.848674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- NEW: Get Global Descriptors using K-Means + VLAD ---\n",
    "def get_global_desc_vlad(fnames, feature_dir='.featureout', num_clusters=64, device=torch.device('cpu')):\n",
    "    \"\"\"\n",
    "    Generates global descriptors for images using K-Means + VLAD on combined ALIKED+DINO features.\n",
    "\n",
    "    Args:\n",
    "        fnames (list): List of image file paths.\n",
    "        feature_dir (str): Directory where combined descriptors are stored.\n",
    "        num_clusters (int): Number of clusters for K-Means (K in VLAD).\n",
    "        device (torch.device): Not directly used for VLAD computation, but passed for consistency.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Nx(K*M) tensor of global VLAD descriptors.\n",
    "    \"\"\"\n",
    "    all_local_descs = []\n",
    "    keys_order = [] # To maintain order of descriptors with respect to fnames\n",
    "\n",
    "    # 1. Load all combined local descriptors\n",
    "    with h5py.File(f'{feature_dir}/descriptors_combined.h5', mode='r') as f_desc_combined:\n",
    "        for img_path in tqdm(fnames, desc=\"Loading combined local descriptors for K-Means\"):\n",
    "            key = img_path.split('/')[-1]\n",
    "            if key in f_desc_combined:\n",
    "                descs = f_desc_combined[key][...]\n",
    "                if descs.shape[0] > 0:\n",
    "                    all_local_descs.append(descs)\n",
    "                    keys_order.append(key)\n",
    "\n",
    "    if not all_local_descs:\n",
    "        print(\"No combined local descriptors found. Cannot train K-Means or compute VLAD.\")\n",
    "        return torch.empty((0, num_clusters * 0), dtype=torch.float32) # Return empty tensor\n",
    "\n",
    "    # Concatenate all descriptors for K-Means training\n",
    "    all_local_descs_flat = np.concatenate(all_local_descs, axis=0)\n",
    "\n",
    "    # 2. Train K-Means on a subset of descriptors if the dataset is too large\n",
    "    # Or directly on all_local_descs_flat if memory permits\n",
    "    print(f\"Training K-Means with {num_clusters} clusters on {all_local_descs_flat.shape[0]} descriptors...\")\n",
    "    # Use MiniBatchKMeans for efficiency\n",
    "    kmeans = MiniBatchKMeans(n_clusters=num_clusters, random_state=0, n_init='auto', batch_size=256).fit(all_local_descs_flat)\n",
    "    centroids = kmeans.cluster_centers_\n",
    "    print(\"K-Means training complete.\")\n",
    "\n",
    "    # 3. Compute VLAD descriptor for each image\n",
    "    global_descs_vlad = []\n",
    "    # Re-iterate through original fnames to match the output order\n",
    "    with h5py.File(f'{feature_dir}/descriptors_combined.h5', mode='r') as f_desc_combined:\n",
    "        for img_path in tqdm(fnames, desc=\"Computing VLAD descriptors\"):\n",
    "            key = img_path.split('/')[-1]\n",
    "            if key in f_desc_combined:\n",
    "                descs = f_desc_combined[key][...]\n",
    "                vlad_desc = vlad_encode(descs, centroids)\n",
    "                global_descs_vlad.append(torch.from_numpy(vlad_desc).unsqueeze(0))\n",
    "            else:\n",
    "                # Handle cases where an image might not have any combined descriptors\n",
    "                # (e.g., no ALIKED keypoints detected). Append a zero vector of correct size.\n",
    "                print(f\"Warning: No combined descriptors for {key}. Appending zero VLAD descriptor.\")\n",
    "                # Determine descriptor dimension from centroids\n",
    "                desc_dim_per_cluster = centroids.shape[1] if centroids.shape[1] > 0 else 0 # Should not be 0 normally\n",
    "                zero_vlad = np.zeros(num_clusters * desc_dim_per_cluster, dtype=np.float32)\n",
    "                global_descs_vlad.append(torch.from_numpy(zero_vlad).unsqueeze(0))\n",
    "\n",
    "\n",
    "    if not global_descs_vlad:\n",
    "        return torch.empty((0, num_clusters * centroids.shape[1] if centroids.shape[1] > 0 else 0), dtype=torch.float32)\n",
    "\n",
    "    global_descs_vlad = torch.cat(global_descs_vlad, dim=0)\n",
    "    return global_descs_vlad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1630c427",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T22:24:05.879388Z",
     "iopub.status.busy": "2025-05-28T22:24:05.879144Z",
     "iopub.status.idle": "2025-05-28T22:24:05.887256Z",
     "shell.execute_reply": "2025-05-28T22:24:05.886516Z"
    },
    "papermill": {
     "duration": 0.016304,
     "end_time": "2025-05-28T22:24:05.888448",
     "exception": false,
     "start_time": "2025-05-28T22:24:05.872144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- RE-DEFINED: get_image_pairs_shortlist to use the new VLAD global descriptor ---\n",
    "def get_image_pairs_shortlist_vlad(fnames,\n",
    "                                   sim_th=0.6, # should be strict\n",
    "                                   min_pairs=30,\n",
    "                                   exhaustive_if_less=20,\n",
    "                                   feature_dir='.featureout', # Pass feature_dir\n",
    "                                   num_clusters_vlad=64, # New parameter for VLAD\n",
    "                                   device=torch.device('cpu')):\n",
    "    num_imgs = len(fnames)\n",
    "    if num_imgs <= exhaustive_if_less:\n",
    "        return get_img_pairs_exhaustive(fnames) # You need to define get_img_pairs_exhaustive if not done.\n",
    "\n",
    "    # Use the new VLAD-based global descriptor\n",
    "    descs = get_global_desc_vlad(fnames, feature_dir=feature_dir, num_clusters=num_clusters_vlad, device=device)\n",
    "\n",
    "    if descs.shape[0] == 0:\n",
    "        print(\"No global descriptors generated. Returning empty matching list.\")\n",
    "        return []\n",
    "\n",
    "    dm = torch.cdist(descs, descs, p=2).detach().cpu().numpy()\n",
    "\n",
    "    # \n",
    "    triu_indices = np.triu_indices_from(dm, k=1)\n",
    "    dm_flat = dm[triu_indices]\n",
    "    \n",
    "    # \n",
    "    print(\"Distance Matrix Statistics:\")\n",
    "    print(f\"Min:  {dm_flat.min():.4f}\")\n",
    "    print(f\"Max:  {dm_flat.max():.4f}\")\n",
    "    print(f\"Mean: {dm_flat.mean():.4f}\")\n",
    "    print(f\"Std:  {dm_flat.std():.4f}\")\n",
    "    print(f\"20%:  {np.percentile(dm_flat, 20):.4f}\")\n",
    "    print(f\"25%:  {np.percentile(dm_flat, 25):.4f}\")\n",
    "    print(f\"USED 60%:  {np.percentile(dm_flat, 60):.4f}\")\n",
    "    print(f\"75%:  {np.percentile(dm_flat, 75):.4f}\")\n",
    "    threshold = np.percentile(dm_flat, 60) + np.sqrt(3) * dm_flat.std()\n",
    "\n",
    "    # removing half\n",
    "    mask = dm <= np.percentile(dm_flat, 60)\n",
    "    total = 0\n",
    "    matching_list = []\n",
    "    ar = np.arange(num_imgs)\n",
    "    already_there_set = set() # Use a set for faster lookup of already added pairs\n",
    "\n",
    "    for st_idx in range(num_imgs - 1):\n",
    "        mask_idx = mask[st_idx]\n",
    "        to_match = ar[mask_idx]\n",
    "        if len(to_match) < min_pairs:\n",
    "            to_match = np.argsort(dm[st_idx])[:min_pairs]\n",
    "\n",
    "        for idx in to_match:\n",
    "            if st_idx == idx:\n",
    "                continue\n",
    "            if dm[st_idx, idx] < threshold: # Ensure distance is not effectively infinite\n",
    "                pair = tuple(sorted((st_idx, idx.item())))\n",
    "                if pair not in already_there_set:\n",
    "                    matching_list.append(pair)\n",
    "                    already_there_set.add(pair)\n",
    "                    total += 1\n",
    "    matching_list = sorted(list(matching_list)) # Sort the list of tuples\n",
    "    return matching_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9714987e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T22:24:05.902118Z",
     "iopub.status.busy": "2025-05-28T22:24:05.901877Z",
     "iopub.status.idle": "2025-05-28T22:24:05.905350Z",
     "shell.execute_reply": "2025-05-28T22:24:05.904605Z"
    },
    "papermill": {
     "duration": 0.011628,
     "end_time": "2025-05-28T22:24:05.906644",
     "exception": false,
     "start_time": "2025-05-28T22:24:05.895016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_img_pairs_exhaustive(img_fnames):\n",
    "    index_pairs = []\n",
    "    for i in range(len(img_fnames)):\n",
    "        for j in range(i+1, len(img_fnames)):\n",
    "            index_pairs.append((i,j))\n",
    "    return index_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8cc4716",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T22:24:05.920712Z",
     "iopub.status.busy": "2025-05-28T22:24:05.920464Z",
     "iopub.status.idle": "2025-05-28T22:24:05.930311Z",
     "shell.execute_reply": "2025-05-28T22:24:05.929545Z"
    },
    "papermill": {
     "duration": 0.018319,
     "end_time": "2025-05-28T22:24:05.931559",
     "exception": false,
     "start_time": "2025-05-28T22:24:05.913240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Must Use efficientnet global descriptor to get matching shortlists.\n",
    "def get_global_desc(fnames, device = torch.device('cpu')):\n",
    "    processor = AutoImageProcessor.from_pretrained('/kaggle/input/dinov2/pytorch/base/1')\n",
    "    model = AutoModel.from_pretrained('/kaggle/input/dinov2/pytorch/base/1')\n",
    "    model = model.eval()\n",
    "    model = model.to(device)\n",
    "    global_descs_dinov2 = []\n",
    "    for i, img_fname_full in tqdm(enumerate(fnames),total= len(fnames)):\n",
    "        key = os.path.splitext(os.path.basename(img_fname_full))[0]\n",
    "        timg = load_torch_image(img_fname_full)\n",
    "        with torch.inference_mode():\n",
    "            inputs = processor(images=timg, return_tensors=\"pt\", do_rescale=False).to(device)\n",
    "            outputs = model(**inputs)\n",
    "            dino_mac = F.normalize(outputs.last_hidden_state[:,1:].max(dim=1)[0], dim=1, p=2)\n",
    "        global_descs_dinov2.append(dino_mac.detach().cpu())\n",
    "    global_descs_dinov2 = torch.cat(global_descs_dinov2, dim=0)\n",
    "    return global_descs_dinov2\n",
    "\n",
    "\n",
    "def get_img_pairs_exhaustive(img_fnames):\n",
    "    index_pairs = []\n",
    "    for i in range(len(img_fnames)):\n",
    "        for j in range(i+1, len(img_fnames)):\n",
    "            index_pairs.append((i,j))\n",
    "    return index_pairs\n",
    "\n",
    "\n",
    "def get_image_pairs_shortlist(fnames,\n",
    "                              sim_th=0.6,\n",
    "                              min_pairs=30,\n",
    "                              max_pairs=100,  #  max_pairs \n",
    "                              exhaustive_if_less=20,\n",
    "                              device=torch.device('cpu')):\n",
    "    num_imgs = len(fnames)\n",
    "    if num_imgs <= exhaustive_if_less:\n",
    "        return get_img_pairs_exhaustive(fnames)\n",
    "\n",
    "    descs = get_global_desc(fnames, device=device)\n",
    "    dm = torch.cdist(descs, descs, p=2).detach().cpu().numpy()\n",
    "\n",
    "    # \n",
    "    triu_indices = np.triu_indices_from(dm, k=1)\n",
    "    dm_flat = dm[triu_indices]\n",
    "\n",
    "    print(\"Distance Matrix Statistics:\")\n",
    "    print(f\"Min:  {dm_flat.min():.4f}\")\n",
    "    print(f\"Max:  {dm_flat.max():.4f}\")\n",
    "    print(f\"Mean: {dm_flat.mean():.4f}\")\n",
    "    print(f\"Std:  {dm_flat.std():.4f}\")\n",
    "    print(f\"20%:  {np.percentile(dm_flat, 20):.4f}\")\n",
    "    print(f\"25%:  {np.percentile(dm_flat, 25):.4f}\")\n",
    "    print(f\"60%:  {np.percentile(dm_flat, 60):.4f}\")\n",
    "    print(f\"75%:  {np.percentile(dm_flat, 75):.4f}\")\n",
    "\n",
    "    threshold = np.percentile(dm_flat, 50) + np.sqrt(3) * dm_flat.std()\n",
    "    mask = dm <= np.percentile(dm_flat, 30)\n",
    "\n",
    "    ar = np.arange(num_imgs)\n",
    "    matching_set = set()\n",
    "\n",
    "    for st_idx in range(num_imgs):\n",
    "        mask_idx = mask[st_idx]\n",
    "        to_match = ar[mask_idx]\n",
    "\n",
    "        #  min_pairs \n",
    "        if len(to_match) < min_pairs:\n",
    "            to_match = np.argsort(dm[st_idx])[:min_pairs]\n",
    "\n",
    "        #  max_pairs\n",
    "        sorted_matches = sorted(\n",
    "            [(idx, dm[st_idx, idx]) for idx in to_match if idx != st_idx and dm[st_idx, idx] < threshold],\n",
    "            key=lambda x: x[1]\n",
    "        )\n",
    "        for idx, _ in sorted_matches[:max_pairs]:\n",
    "            pair = tuple(sorted((st_idx, idx)))\n",
    "            matching_set.add(pair)\n",
    "\n",
    "    matching_list = sorted(list(matching_set))\n",
    "    return matching_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79bf63e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T22:24:05.945076Z",
     "iopub.status.busy": "2025-05-28T22:24:05.944852Z",
     "iopub.status.idle": "2025-05-28T22:24:05.963921Z",
     "shell.execute_reply": "2025-05-28T22:24:05.963162Z"
    },
    "papermill": {
     "duration": 0.027235,
     "end_time": "2025-05-28T22:24:05.965147",
     "exception": false,
     "start_time": "2025-05-28T22:24:05.937912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def wrapper_keypoints(\n",
    "    img_fnames, index_pairs, feature_dir, device, timings, rots\n",
    "):\n",
    "    #############################################################\n",
    "    # get keypoints\n",
    "    #############################################################\n",
    "    files_keypoints = []\n",
    "    \n",
    "    if CONFIG.use_superglue:\n",
    "        for params_sg in CONFIG.params_sgs:\n",
    "            resize_to = params_sg[\"resize_to\"]\n",
    "            file_keypoints = f\"{feature_dir}/matches_superglue_{resize_to}pix.h5\"\n",
    "            !rm -rf {file_keypoints}\n",
    "            t = detect_superglue(\n",
    "                img_fnames, index_pairs, feature_dir, device, \n",
    "                params_sg[\"sg_config\"], file_keypoints, \n",
    "                resize_to=params_sg[\"resize_to\"], \n",
    "                min_matches=params_sg[\"min_matches\"],\n",
    "            )\n",
    "            gc.collect()\n",
    "            files_keypoints.append( file_keypoints )\n",
    "            timings['feature_matching'].append(t)\n",
    "\n",
    "    if CONFIG.use_aliked_lightglue:\n",
    "        model_name = \"aliked\"\n",
    "        file_keypoints = f'{feature_dir}/matches_lightglue_{model_name}.h5'\n",
    "        t = detect_lightglue_common(\n",
    "            img_fnames, model_name, index_pairs, feature_dir, device, file_keypoints, rots,\n",
    "            resize_to=CONFIG.params_aliked_lightglue[\"resize_to\"],\n",
    "            detection_threshold=CONFIG.params_aliked_lightglue[\"detection_threshold\"],\n",
    "            num_features=CONFIG.params_aliked_lightglue[\"num_features\"],\n",
    "            min_matches=CONFIG.params_aliked_lightglue[\"min_matches\"],\n",
    "            match_confidence_threshold=CONFIG.params_aliked_lightglue[\"match_confidence_threshold\"]\n",
    "        )\n",
    "        gc.collect()\n",
    "        files_keypoints.append(file_keypoints)\n",
    "        timings['feature_matching'].append(t)\n",
    "\n",
    "    if CONFIG.use_doghardnet_lightglue:\n",
    "        model_name = \"doghardnet\"\n",
    "        file_keypoints = f'{feature_dir}/matches_lightglue_{model_name}.h5'\n",
    "        t = detect_lightglue_common(\n",
    "            img_fnames, model_name, index_pairs, feature_dir, device, file_keypoints, rots,\n",
    "            resize_to=CONFIG.params_doghardnet_lightglue[\"resize_to\"],\n",
    "            detection_threshold=CONFIG.params_doghardnet_lightglue[\"detection_threshold\"],\n",
    "            num_features=CONFIG.params_doghardnet_lightglue[\"num_features\"],\n",
    "            min_matches=CONFIG.params_doghardnet_lightglue[\"min_matches\"],\n",
    "        )\n",
    "        gc.collect()\n",
    "        files_keypoints.append(file_keypoints)\n",
    "        timings['feature_matching'].append(t)\n",
    "\n",
    "    if CONFIG.use_superpoint_lightglue:\n",
    "        model_name = \"superpoint\"\n",
    "        file_keypoints = f'{feature_dir}/matches_lightglue_{model_name}.h5'\n",
    "        t = detect_lightglue_common(\n",
    "            img_fnames, model_name, index_pairs, feature_dir, device, file_keypoints, rots,\n",
    "            resize_to=CONFIG.params_superpoint_lightglue[\"resize_to\"],\n",
    "            detection_threshold=CONFIG.params_superpoint_lightglue[\"detection_threshold\"],\n",
    "            num_features=CONFIG.params_superpoint_lightglue[\"num_features\"],\n",
    "            min_matches=CONFIG.params_superpoint_lightglue[\"min_matches\"],\n",
    "        )\n",
    "        gc.collect()\n",
    "        files_keypoints.append(file_keypoints)\n",
    "        timings['feature_matching'].append(t)\n",
    "\n",
    "    if CONFIG.use_disk_lightglue:\n",
    "        model_name = \"disk\"\n",
    "        file_keypoints = f'{feature_dir}/matches_lightglue_{model_name}.h5'\n",
    "        t = detect_lightglue_common(\n",
    "            img_fnames, model_name, index_pairs, feature_dir, device, file_keypoints, rots,\n",
    "            resize_to=CONFIG.params_disk_lightglue[\"resize_to\"],\n",
    "            detection_threshold=CONFIG.params_disk_lightglue[\"detection_threshold\"],\n",
    "            num_features=CONFIG.params_disk_lightglue[\"num_features\"],\n",
    "            min_matches=CONFIG.params_disk_lightglue[\"min_matches\"],\n",
    "            match_confidence_threshold=CONFIG.params_disk_lightglue[\"match_confidence_threshold\"]\n",
    "        )\n",
    "        gc.collect()\n",
    "        files_keypoints.append(file_keypoints)\n",
    "        timings['feature_matching'].append(t)\n",
    "\n",
    "    if CONFIG.use_sift_lightglue:\n",
    "        model_name = \"sift\"\n",
    "        file_keypoints = f'{feature_dir}/matches_lightglue_{model_name}.h5'\n",
    "        t = detect_lightglue_common(\n",
    "            img_fnames, model_name, index_pairs, feature_dir, device, file_keypoints, rots,\n",
    "            resize_to=CONFIG.params_sift_lightglue[\"resize_to\"],\n",
    "            detection_threshold=CONFIG.params_sift_lightglue[\"detection_threshold\"],\n",
    "            num_features=CONFIG.params_sift_lightglue[\"num_features\"],\n",
    "            min_matches=CONFIG.params_sift_lightglue[\"min_matches\"],\n",
    "        )\n",
    "        gc.collect()\n",
    "        files_keypoints.append(file_keypoints)\n",
    "        timings['feature_matching'].append(t)\n",
    "\n",
    "    if CONFIG.use_loftr:\n",
    "        file_keypoints = f'{feature_dir}/matches_loftr_{CONFIG.params_loftr[\"resize_small_edge_to\"]}pix.h5'\n",
    "        t = detect_loftr(\n",
    "            img_fnames, index_pairs, feature_dir, device, file_keypoints,\n",
    "            resize_small_edge_to=CONFIG.params_loftr[\"resize_small_edge_to\"],\n",
    "            min_matches=CONFIG.params_loftr[\"min_matches\"],\n",
    "        )\n",
    "        gc.collect()\n",
    "        files_keypoints.append( file_keypoints )\n",
    "        timings['feature_matching'].append(t)\n",
    "\n",
    "    if CONFIG.use_dkm:\n",
    "        file_keypoints = f'{feature_dir}/matches_dkm.h5'\n",
    "        t = detect_dkm(\n",
    "            img_fnames, index_pairs, feature_dir, device, file_keypoints,\n",
    "            resize_to=CONFIG.params_dkm[\"resize_to\"], \n",
    "            detection_threshold=CONFIG.params_dkm[\"detection_threshold\"], \n",
    "            num_features=CONFIG.params_dkm[\"num_features\"], \n",
    "            min_matches=CONFIG.params_dkm[\"min_matches\"]\n",
    "        )\n",
    "        gc.collect()\n",
    "        files_keypoints.append(file_keypoints)\n",
    "        timings['feature_matching'].append(t)\n",
    "\n",
    "    if CONFIG.use_matchformer:\n",
    "        file_keypoints = f'{feature_dir}/matches_matchformer_{CONFIG.params_matchformer[\"resize_to\"]}pix.h5'\n",
    "        t = detect_matchformer(\n",
    "            img_fnames, index_pairs, feature_dir, device, file_keypoints,\n",
    "            resize_to=CONFIG.params_matchformer[\"resize_to\"],\n",
    "            num_features=CONFIG.params_matchformer[\"num_features\"], \n",
    "            min_matches=CONFIG.params_matchformer[\"min_matches\"]\n",
    "        )\n",
    "        gc.collect()\n",
    "        files_keypoints.append( file_keypoints )\n",
    "        timings['feature_matching'].append(t)\n",
    "\n",
    "    #############################################################\n",
    "    # merge keypoints\n",
    "    #############################################################\n",
    "    keypoints_merger(\n",
    "        img_fnames,\n",
    "        index_pairs,\n",
    "        files_keypoints,\n",
    "        feature_dir = feature_dir,\n",
    "        filter_FundamentalMatrix = CONFIG.MERGE_PARAMS[\"filter_FundamentalMatrix\"],\n",
    "        filter_iterations = CONFIG.MERGE_PARAMS[\"filter_iterations\"],\n",
    "        filter_threshold = CONFIG.MERGE_PARAMS[\"filter_threshold\"],\n",
    "    )    \n",
    "    return timings\n",
    "\n",
    "\n",
    "def import_into_colmap(img_dir, feature_dir ='.featureout', database_path = 'colmap.db'):\n",
    "    db = COLMAPDatabase.connect(database_path)\n",
    "    db.create_tables()\n",
    "    single_camera = False\n",
    "    fname_to_id = add_keypoints(db, feature_dir, img_dir, '', 'simple-pinhole', single_camera)\n",
    "    add_matches(\n",
    "        db,\n",
    "        feature_dir,\n",
    "        fname_to_id,\n",
    "    )\n",
    "    db.commit()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c0c1b52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T22:24:05.978740Z",
     "iopub.status.busy": "2025-05-28T22:24:05.978503Z",
     "iopub.status.idle": "2025-05-28T22:24:05.984834Z",
     "shell.execute_reply": "2025-05-28T22:24:05.984195Z"
    },
    "papermill": {
     "duration": 0.014363,
     "end_time": "2025-05-28T22:24:05.986071",
     "exception": false,
     "start_time": "2025-05-28T22:24:05.971708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reconstruct_from_db(feature_dir, img_dir):\n",
    "    result = {}\n",
    "    local_timings = {'RANSAC': [], 'Reconstruction': []}\n",
    "    #############################################################\n",
    "    # regist keypoints from h5 into colmap db\n",
    "    #############################################################\n",
    "    database_path = f'{feature_dir}/colmap.db'\n",
    "    if os.path.isfile(database_path):\n",
    "        os.remove(database_path)\n",
    "    gc.collect()\n",
    "    import_into_colmap(img_dir, feature_dir=feature_dir, database_path=database_path)\n",
    "    output_path = f'{feature_dir}/colmap_rec'\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    print(\"colmap database\")\n",
    "    #############################################################\n",
    "    # Calculate fundamental matrix with colmap api\n",
    "    #############################################################\n",
    "    t=time()\n",
    "    # options = pycolmap.SiftMatchingOptions()\n",
    "    # options.confidence = 0.9999\n",
    "    # options.max_num_trials = 20000\n",
    "    # pycolmap.match_exhaustive(database_path, sift_options=options)\n",
    "    pycolmap.match_exhaustive(database_path)\n",
    "    print(\"matching done!!!!\")\n",
    "    local_timings['RANSAC'].append(time() - t)\n",
    "    print(f'RANSAC in {local_timings[\"RANSAC\"][-1]:.4f} sec')\n",
    "\n",
    "    #############################################################\n",
    "    # Execute bundle adjustmnet with colmap api\n",
    "    # --> Bundle adjustment Calcs Camera matrix, R and t\n",
    "    #############################################################\n",
    "    t=time()\n",
    "    # By default colmap does not generate a reconstruction if less than 10 images are registered. Lower it to 3.\n",
    "    mapper_options = pycolmap.IncrementalPipelineOptions()\n",
    "    # mapper_options.mapper.filter_max_reproj_error\t = 1.0\n",
    "    # mapper_options.mapper.init_max_error = 2.0\n",
    "    mapper_options.min_model_size = 5\n",
    "    mapper_options.max_num_models = 25\n",
    "    mapper_options.ba_global_images_freq = 5\n",
    "    mapper_options.ba_local_num_images = 8\n",
    "    mapper_options.mapper.abs_pose_min_inlier_ratio = 0.4\n",
    "    mapper_options.ba_global_max_num_iterations = 100\n",
    "    # mapper_options.mapper.filter_max_reproj_error = 6.0\n",
    "    mapper_options.mapper.max_reg_trials = 10\n",
    "    # mapper_options.mapper.init_min_num_inliers = 50\n",
    "    # mapper_options.mapper.abs_pose_min_num_inliers = 15\n",
    "    \n",
    "\n",
    "    \n",
    "    maps = pycolmap.incremental_mapping(database_path=database_path, image_path=img_dir, \n",
    "                                        output_path=output_path, options=mapper_options)\n",
    "    print(maps)\n",
    "    for map_index, rec in maps.items():\n",
    "        result[map_index] = {}\n",
    "        for img_id, image in rec.images.items():\n",
    "            result[map_index][image.name] = {\n",
    "                'R': image.cam_from_world.rotation.matrix().tolist(),\n",
    "                't': image.cam_from_world.translation.tolist()\n",
    "            }\n",
    "    # clear_output(wait=False)\n",
    "    local_timings['Reconstruction'].append(time() - t)\n",
    "    print(f'Reconstruction done in {local_timings[\"Reconstruction\"][-1]:.4f} sec')\n",
    "\n",
    "    #############################################################\n",
    "    # Extract R,t from maps \n",
    "    #############################################################            \n",
    "    return result, local_timings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "453478fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T22:24:05.999599Z",
     "iopub.status.busy": "2025-05-28T22:24:05.999316Z",
     "iopub.status.idle": "2025-05-28T22:24:06.158365Z",
     "shell.execute_reply": "2025-05-28T22:24:06.157350Z"
    },
    "papermill": {
     "duration": 0.167265,
     "end_time": "2025-05-28T22:24:06.159822",
     "exception": false,
     "start_time": "2025-05-28T22:24:05.992557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset \"imc2023_haiper\" -> num_images=54\n",
      "Dataset \"imc2023_heritage\" -> num_images=209\n",
      "Dataset \"imc2023_theather_imc2024_church\" -> num_images=76\n",
      "Dataset \"imc2024_dioscuri_baalshamin\" -> num_images=138\n",
      "Dataset \"imc2024_lizard_pond\" -> num_images=214\n",
      "Dataset \"pt_brandenburg_british_buckingham\" -> num_images=225\n",
      "Dataset \"pt_piazzasanmarco_grandplace\" -> num_images=168\n",
      "Dataset \"pt_sacrecoeur_trevi_tajmahal\" -> num_images=225\n",
      "Dataset \"pt_stpeters_stpauls\" -> num_images=200\n",
      "Dataset \"amy_gardens\" -> num_images=200\n",
      "Dataset \"fbk_vineyard\" -> num_images=163\n",
      "Dataset \"ETs\" -> num_images=22\n",
      "Dataset \"stairs\" -> num_images=51\n"
     ]
    }
   ],
   "source": [
    "# Collect vital info from the dataset\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class Prediction:\n",
    "    image_id: str | None  # A unique identifier for the row -- unused otherwise. Used only on the hidden test set.\n",
    "    dataset: str\n",
    "    filename: str\n",
    "    cluster_index: int | None = None\n",
    "    rotation: np.ndarray | None = None\n",
    "    translation: np.ndarray | None = None\n",
    "\n",
    "# Set is_train=True to run the notebook on the training data.\n",
    "# Set is_train=False if submitting an entry to the competition (test data is hidden, and different from what you see on the \"test\" folder).\n",
    "is_train = True\n",
    "data_dir = '/kaggle/input/image-matching-challenge-2025'\n",
    "workdir = '/kaggle/working/result/'\n",
    "os.makedirs(workdir, exist_ok=True)\n",
    "\n",
    "if is_train:\n",
    "    sample_submission_csv = os.path.join(data_dir, 'train_labels.csv')\n",
    "else:\n",
    "    sample_submission_csv = os.path.join(data_dir, 'sample_submission.csv')\n",
    "\n",
    "samples = {}\n",
    "competition_data = pd.read_csv(sample_submission_csv)\n",
    "for _, row in competition_data.iterrows():\n",
    "    # Note: For the test data, the \"scene\" column has no meaning, and the rotation_matrix and translation_vector columns are random.\n",
    "    if row.dataset not in samples:\n",
    "        samples[row.dataset] = []\n",
    "    samples[row.dataset].append(\n",
    "        Prediction(\n",
    "            image_id=None if is_train else row.image_id,\n",
    "            dataset=row.dataset,\n",
    "            filename=row.image\n",
    "        )\n",
    "    )\n",
    "\n",
    "for dataset in samples:\n",
    "    print(f'Dataset \"{dataset}\" -> num_images={len(samples[dataset])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "485c3e3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T22:24:06.174818Z",
     "iopub.status.busy": "2025-05-28T22:24:06.174574Z",
     "iopub.status.idle": "2025-05-28T22:24:06.188876Z",
     "shell.execute_reply": "2025-05-28T22:24:06.188247Z"
    },
    "papermill": {
     "duration": 0.023242,
     "end_time": "2025-05-28T22:24:06.190173",
     "exception": false,
     "start_time": "2025-05-28T22:24:06.166931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "\n",
    "def draw_keypoints_and_matches(images_input, unified_kp_path, remapped_matches_path, feature_dir='visualization_output'):\n",
    "    output_dir = os.path.join(feature_dir, 'visualization_output')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Load images and determine image_keys for HDF5 lookup\n",
    "    if isinstance(images_input[0], str):\n",
    "        loaded_images = [cv2.imread(img_path) for img_path in images_input]\n",
    "        image_keys = [os.path.basename(img_path) for img_path in images_input]\n",
    "    else:\n",
    "        loaded_images = images_input\n",
    "        # If images_input are already arrays, you need to provide the corresponding keys\n",
    "        # This part is crucial: image_keys MUST align with the HDF5 keys\n",
    "        image_keys = image_keys_in_h5 # Use the predefined list for the dummy case\n",
    "\n",
    "    # Load unified keypoints\n",
    "    keypoints_data = {}\n",
    "    with h5py.File(unified_kp_path, 'r') as f_kp:\n",
    "        for img_name_raw in f_kp.keys():\n",
    "            img_name = img_name_raw.decode('utf-8') if isinstance(img_name_raw, bytes) else img_name_raw\n",
    "            keypoints_data[img_name] = f_kp[img_name_raw][()] # Access with raw key if bytes\n",
    "\n",
    "    # Load remapped matches - CORRECTED LOGIC\n",
    "    # Store (img1_key, img2_key) directly with matches for robust iteration\n",
    "    matches_data_pairs = [] # Will store (img1_key, img2_key, matches_array)\n",
    "    with h5py.File(remapped_matches_path, 'r') as f_matches:\n",
    "        print(\"\\n--- Loading remapped matches from HDF5 ---\")\n",
    "        for img1_group_key_candidate in tqdm(f_matches.keys(), desc=\"Loading matches\"):\n",
    "            img1_key = img1_group_key_candidate.decode('utf-8') if isinstance(img1_group_key_candidate, bytes) else img1_group_key_candidate\n",
    "\n",
    "            img1_group = f_matches[img1_group_key_candidate] # Access with raw key\n",
    "\n",
    "            if isinstance(img1_group, h5py.Group):\n",
    "                for img2_dataset_key_candidate in img1_group.keys():\n",
    "                    img2_key = img2_dataset_key_candidate.decode('utf-8') if isinstance(img2_dataset_key_candidate, bytes) else img2_dataset_key_candidate\n",
    "\n",
    "                    try:\n",
    "                        matches_array = img1_group[img2_dataset_key_candidate][()]\n",
    "                        matches_data_pairs.append((img1_key, img2_key, matches_array))\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error loading matches for pair ({img1_key}, {img2_key}): {e}\")\n",
    "            else:\n",
    "                print(f\"Warning: Expected '{img1_key}' to be a group, but found {type(img1_group)}. Skipping its contents.\")\n",
    "\n",
    "\n",
    "    # --- Drawing Keypoints ---\n",
    "    print(\"\\n--- Drawing Keypoints ---\")\n",
    "    for i, img_key in enumerate(image_keys):\n",
    "        if img_key in keypoints_data:\n",
    "            img = loaded_images[i].copy()\n",
    "            kpts = keypoints_data[img_key]\n",
    "\n",
    "            for kp in kpts:\n",
    "                x, y = int(kp[0]), int(kp[1])\n",
    "                cv2.circle(img, (x, y), 3, (0, 255, 0), -1) # Green circle for keypoint\n",
    "\n",
    "            output_kp_path = os.path.join(output_dir, f\"keypoints_{img_key}\")\n",
    "            if len(img.shape) == 2:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "            cv2.imwrite(output_kp_path, img)\n",
    "            print(f\"Keypoints drawn on {img_key}, saved to {output_kp_path}\")\n",
    "        else:\n",
    "            print(f\"No keypoints found for {img_key} in unified keypoints file.\")\n",
    "\n",
    "    # --- Drawing Matches ---\n",
    "    print(\"\\n--- Drawing Matches ---\")\n",
    "    # Iterate through the (img1_key, img2_key, matches) tuples directly\n",
    "    for img_name1, img_name2, matches in matches_data_pairs:\n",
    "        # We no longer need to split img_pair_key, as we have img_name1 and img_name2 directly\n",
    "\n",
    "        # Find the actual image objects and their keypoints using image_keys list\n",
    "        try:\n",
    "            img1_idx = image_keys.index(img_name1)\n",
    "            img2_idx = image_keys.index(img_name2)\n",
    "        except ValueError:\n",
    "            print(f\"Skipping matches for {img_name1}-{img_name2}: One or both image names not found in the provided 'images' list/keys.\")\n",
    "            continue\n",
    "\n",
    "        img1 = loaded_images[img1_idx].copy()\n",
    "        img2 = loaded_images[img2_idx].copy()\n",
    "\n",
    "        kpts1 = keypoints_data.get(img_name1)\n",
    "        kpts2 = keypoints_data.get(img_name2)\n",
    "\n",
    "        if kpts1 is None or kpts2 is None:\n",
    "            print(f\"Skipping matches for {img_name1}-{img_name2}: keypoints not found for one or both images in unified keypoints.\")\n",
    "            continue\n",
    "        if len(matches) == 0:\n",
    "            print(f\"No matches to draw for {img_name1}-{img_name2}.\")\n",
    "            continue\n",
    "\n",
    "        # Ensure images are 3 channels for drawing lines\n",
    "        if len(img1.shape) == 2:\n",
    "            img1 = cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR)\n",
    "        if len(img2.shape) == 2:\n",
    "            img2 = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        # Create a concatenated image for drawing matches\n",
    "        h1, w1 = img1.shape[:2]\n",
    "        h2, w2 = img2.shape[:2]\n",
    "        max_h = max(h1, h2)\n",
    "        matched_img = np.zeros((max_h, w1 + w2, 3), dtype=np.uint8)\n",
    "        matched_img[0:h1, 0:w1] = img1\n",
    "        matched_img[0:h2, w1:w1+w2] = img2\n",
    "\n",
    "        num_matches_to_draw = min(len(matches), 200) # Draw up to 200 matches to avoid clutter, adjust as needed\n",
    "\n",
    "        for i in range(num_matches_to_draw):\n",
    "            match = matches[i]\n",
    "            kp1_idx, kp2_idx = int(match[0]), int(match[1])\n",
    "\n",
    "            # Bounds check for keypoint indices\n",
    "            if kp1_idx >= len(kpts1) or kp2_idx >= len(kpts2):\n",
    "                # print(f\"Warning: Match index out of bounds for {img_name1}-{img_name2}. Skipping match {kp1_idx}-{kp2_idx}.\")\n",
    "                continue\n",
    "\n",
    "            pt1 = tuple(map(int, kpts1[kp1_idx][:2]))\n",
    "            pt2 = tuple(map(int, kpts2[kp2_idx][:2]))\n",
    "\n",
    "            # Draw circles on the concatenated image\n",
    "            cv2.circle(matched_img, pt1, 5, (0, 0, 255), 2) # Red circle on img1 side\n",
    "            cv2.circle(matched_img, (pt2[0] + w1, pt2[1]), 5, (255, 0, 0), 2) # Blue circle on img2 side\n",
    "\n",
    "            # Draw a line connecting the matched keypoints\n",
    "            color = tuple(np.random.randint(0, 255, 3).tolist())\n",
    "            cv2.line(matched_img, pt1, (pt2[0] + w1, pt2[1]), color, 1)\n",
    "\n",
    "        output_match_path = os.path.join(output_dir, f\"matches_{img_name1}_{img_name2}.png\")\n",
    "        cv2.imwrite(output_match_path, matched_img)\n",
    "        print(f\"Matches drawn between {img_name1} and {img_name2}, saved to {output_match_path}\")\n",
    "\n",
    "\n",
    "# Example call (replace with your actual 'images' list)\n",
    "# If your 'images' are file paths:\n",
    "# images_file_paths = ['path/to/your/image1.jpg', 'path/to/your/image2.jpg', ...]\n",
    "# draw_keypoints_and_matches(images_file_paths, unified_kp_path, remapped_matches_path)\n",
    "\n",
    "# If your 'images' are loaded numpy arrays (as in the dummy example above):\n",
    "# draw_keypoints_and_matches(images, unified_kp_path, remapped_matches_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90f84fa8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T22:24:06.204065Z",
     "iopub.status.busy": "2025-05-28T22:24:06.203846Z",
     "iopub.status.idle": "2025-05-28T22:40:59.204722Z",
     "shell.execute_reply": "2025-05-28T22:40:59.203599Z"
    },
    "papermill": {
     "duration": 1013.009385,
     "end_time": "2025-05-28T22:40:59.206118",
     "exception": false,
     "start_time": "2025-05-28T22:24:06.196733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DINOv2 model for patch feature extraction...\n",
      "DINOv2 model loaded.\n",
      "Skipping \"imc2023_haiper\"\n",
      "Skipping \"imc2023_heritage\"\n",
      "Skipping \"imc2023_theather_imc2024_church\"\n",
      "Skipping \"imc2024_dioscuri_baalshamin\"\n",
      "Skipping \"imc2024_lizard_pond\"\n",
      "Skipping \"pt_brandenburg_british_buckingham\"\n",
      "Skipping \"pt_piazzasanmarco_grandplace\"\n",
      "Skipping \"pt_sacrecoeur_trevi_tajmahal\"\n",
      "Skipping \"pt_stpeters_stpauls\"\n",
      "\n",
      "Processing dataset \"amy_gardens\": 200 images\n",
      "rotation_detection for 200 images : 0.0000 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 200/200 [00:29<00:00,  6.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance Matrix Statistics:\n",
      "Min:  0.1448\n",
      "Max:  0.4239\n",
      "Mean: 0.2737\n",
      "Std:  0.0388\n",
      "20%:  0.2375\n",
      "25%:  0.2439\n",
      "60%:  0.2863\n",
      "75%:  0.3017\n",
      "Shortlisting. Number of pairs to match: 3256. Done in 29.9590 sec\n",
      "Generated 3256 image pairs using VLAD global descriptor.\n",
      "Shortlisting. Number of pairs to match: 3256. Done in 30.2718 sec\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([3975, 2]), descs.shape=torch.Size([3975, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([3601, 2]), descs.shape=torch.Size([3601, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4037, 2]), descs.shape=torch.Size([4037, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4042, 2]), descs.shape=torch.Size([4042, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4070, 2]), descs.shape=torch.Size([4070, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([3970, 2]), descs.shape=torch.Size([3970, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([3880, 2]), descs.shape=torch.Size([3880, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([3560, 2]), descs.shape=torch.Size([3560, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([3806, 2]), descs.shape=torch.Size([3806, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([3827, 2]), descs.shape=torch.Size([3827, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([2805, 2]), descs.shape=torch.Size([2805, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([3621, 2]), descs.shape=torch.Size([3621, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4049, 2]), descs.shape=torch.Size([4049, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([3989, 2]), descs.shape=torch.Size([3989, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([3855, 2]), descs.shape=torch.Size([3855, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([1559, 2]), descs.shape=torch.Size([1559, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([3848, 2]), descs.shape=torch.Size([3848, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([3611, 2]), descs.shape=torch.Size([3611, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([3616, 2]), descs.shape=torch.Size([3616, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([3877, 2]), descs.shape=torch.Size([3877, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([3948, 2]), descs.shape=torch.Size([3948, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([3955, 2]), descs.shape=torch.Size([3955, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([3838, 2]), descs.shape=torch.Size([3838, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([3956, 2]), descs.shape=torch.Size([3956, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([3683, 2]), descs.shape=torch.Size([3683, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([3869, 2]), descs.shape=torch.Size([3869, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4019, 2]), descs.shape=torch.Size([4019, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([3983, 2]), descs.shape=torch.Size([3983, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([3870, 2]), descs.shape=torch.Size([3870, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([3948, 2]), descs.shape=torch.Size([3948, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([3623, 2]), descs.shape=torch.Size([3623, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([3919, 2]), descs.shape=torch.Size([3919, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([3952, 2]), descs.shape=torch.Size([3952, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([959, 2]), descs.shape=torch.Size([959, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([3916, 2]), descs.shape=torch.Size([3916, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([3834, 2]), descs.shape=torch.Size([3834, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([3418, 2]), descs.shape=torch.Size([3418, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4060, 2]), descs.shape=torch.Size([4060, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([3916, 2]), descs.shape=torch.Size([3916, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([3856, 2]), descs.shape=torch.Size([3856, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([1711, 2]), descs.shape=torch.Size([1711, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([3927, 2]), descs.shape=torch.Size([3927, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([3862, 2]), descs.shape=torch.Size([3862, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4020, 2]), descs.shape=torch.Size([4020, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([3988, 2]), descs.shape=torch.Size([3988, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([3930, 2]), descs.shape=torch.Size([3930, 128])\n",
      "Loaded LightGlue model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/3256 [00:00<09:58,  5.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0100.png-peach_0091.png: 991 matches @ 1th pair(aliked+lightglue)\n",
      "aliked> peach_0100.png-peach_0075.png: 471 matches @ 2th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 19/3256 [00:02<04:48, 11.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0100.png-peach_0128.png: 752 matches @ 3th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 31/3256 [00:03<04:45, 11.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0091.png-peach_0075.png: 1191 matches @ 4th pair(aliked+lightglue)\n",
      "aliked> peach_0091.png-peach_0087.png: 218 matches @ 5th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 35/3256 [00:03<04:43, 11.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0091.png-peach_0143.png: 835 matches @ 6th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 41/3256 [00:03<04:43, 11.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0091.png-peach_0081.png: 1010 matches @ 7th pair(aliked+lightglue)\n",
      "aliked> peach_0091.png-peach_0104.png: 809 matches @ 8th pair(aliked+lightglue)\n",
      "aliked> peach_0091.png-peach_0141.png: 787 matches @ 9th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 49/3256 [00:04<04:43, 11.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0091.png-peach_0128.png: 1374 matches @ 10th pair(aliked+lightglue)\n",
      "aliked> peach_0091.png-peach_0199.png: 815 matches @ 11th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 53/3256 [00:05<04:43, 11.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0091.png-peach_0044.png: 475 matches @ 12th pair(aliked+lightglue)\n",
      "aliked> peach_0091.png-peach_0076.png: 712 matches @ 13th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 57/3256 [00:05<04:42, 11.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0075.png-peach_0087.png: 1247 matches @ 14th pair(aliked+lightglue)\n",
      "aliked> peach_0075.png-peach_0143.png: 1121 matches @ 15th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 73/3256 [00:06<04:33, 11.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0075.png-peach_0033.png: 257 matches @ 16th pair(aliked+lightglue)\n",
      "aliked> peach_0075.png-peach_0081.png: 1049 matches @ 17th pair(aliked+lightglue)\n",
      "aliked> peach_0075.png-peach_0104.png: 1109 matches @ 18th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 77/3256 [00:07<04:38, 11.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0075.png-peach_0141.png: 655 matches @ 19th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 79/3256 [00:07<04:36, 11.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0075.png-peach_0073.png: 245 matches @ 20th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 85/3256 [00:07<04:37, 11.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0075.png-peach_0128.png: 1486 matches @ 21th pair(aliked+lightglue)\n",
      "aliked> peach_0075.png-peach_0146.png: 678 matches @ 22th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 93/3256 [00:08<04:22, 12.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0075.png-peach_0134.png: 277 matches @ 23th pair(aliked+lightglue)\n",
      "aliked> peach_0075.png-peach_0044.png: 321 matches @ 24th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 99/3256 [00:08<04:34, 11.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0075.png-peach_0004.png: 383 matches @ 25th pair(aliked+lightglue)\n",
      "aliked> peach_0075.png-peach_0037.png: 769 matches @ 26th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 103/3256 [00:09<04:36, 11.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0087.png-peach_0089.png: 224 matches @ 27th pair(aliked+lightglue)\n",
      "aliked> peach_0087.png-peach_0143.png: 469 matches @ 28th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 109/3256 [00:09<04:13, 12.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0087.png-peach_0183.png: 252 matches @ 29th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 117/3256 [00:10<04:30, 11.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0087.png-peach_0033.png: 1017 matches @ 30th pair(aliked+lightglue)\n",
      "aliked> peach_0087.png-peach_0081.png: 569 matches @ 31th pair(aliked+lightglue)\n",
      "aliked> peach_0087.png-peach_0104.png: 1148 matches @ 32th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 127/3256 [00:11<04:32, 11.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0087.png-peach_0128.png: 852 matches @ 33th pair(aliked+lightglue)\n",
      "aliked> peach_0087.png-peach_0146.png: 1219 matches @ 34th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 135/3256 [00:12<04:34, 11.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0087.png-peach_0044.png: 271 matches @ 35th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 143/3256 [00:12<04:38, 11.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0089.png-peach_0183.png: 1894 matches @ 36th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 147/3256 [00:13<04:37, 11.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0089.png-peach_0185.png: 271 matches @ 37th pair(aliked+lightglue)\n",
      "aliked> peach_0089.png-peach_0033.png: 1254 matches @ 38th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 155/3256 [00:13<04:36, 11.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0089.png-peach_0146.png: 522 matches @ 39th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 157/3256 [00:14<04:36, 11.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0089.png-peach_0160.png: 325 matches @ 40th pair(aliked+lightglue)\n",
      "aliked> peach_0089.png-peach_0197.png: 354 matches @ 41th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 163/3256 [00:14<04:35, 11.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0089.png-peach_0182.png: 385 matches @ 42th pair(aliked+lightglue)\n",
      "aliked> peach_0089.png-peach_0065.png: 1647 matches @ 43th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 167/3256 [00:14<04:35, 11.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0028.png-peach_0161.png: 1487 matches @ 44th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 179/3256 [00:16<04:35, 11.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0028.png-peach_0088.png: 1093 matches @ 45th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|         | 183/3256 [00:16<04:35, 11.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0028.png-peach_0016.png: 519 matches @ 46th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|         | 197/3256 [00:17<04:34, 11.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0161.png-peach_0189.png: 459 matches @ 47th pair(aliked+lightglue)\n",
      "aliked> peach_0161.png-peach_0155.png: 332 matches @ 48th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 221/3256 [00:19<04:32, 11.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0161.png-peach_0088.png: 770 matches @ 49th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 235/3256 [00:21<04:31, 11.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0189.png-peach_0155.png: 434 matches @ 50th pair(aliked+lightglue)\n",
      "aliked> peach_0189.png-peach_0042.png: 257 matches @ 51th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|         | 259/3256 [00:23<04:27, 11.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0155.png-peach_0042.png: 561 matches @ 52th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|         | 277/3256 [00:24<04:25, 11.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0155.png-peach_0025.png: 204 matches @ 53th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|         | 281/3256 [00:25<04:25, 11.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0155.png-peach_0103.png: 205 matches @ 54th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|         | 287/3256 [00:25<04:26, 11.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0042.png-peach_0188.png: 416 matches @ 55th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|         | 299/3256 [00:26<04:27, 11.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0042.png-peach_0086.png: 1279 matches @ 56th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|         | 305/3256 [00:27<04:25, 11.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0042.png-peach_0025.png: 722 matches @ 57th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|         | 309/3256 [00:27<04:26, 11.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0042.png-peach_0016.png: 615 matches @ 58th pair(aliked+lightglue)\n",
      "aliked> peach_0042.png-peach_0103.png: 968 matches @ 59th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 329/3256 [00:29<04:25, 11.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0188.png-peach_0025.png: 659 matches @ 60th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 335/3256 [00:30<04:24, 11.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0188.png-peach_0103.png: 778 matches @ 61th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|        | 409/3256 [00:36<04:19, 10.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0121.png-peach_0126.png: 1743 matches @ 62th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|        | 423/3256 [00:37<04:17, 11.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0121.png-peach_0180.png: 522 matches @ 63th pair(aliked+lightglue)\n",
      "aliked> peach_0121.png-peach_0107.png: 621 matches @ 64th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 449/3256 [00:40<04:15, 10.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0045.png-peach_0080.png: 1137 matches @ 65th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 469/3256 [00:42<04:14, 10.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0045.png-peach_0107.png: 858 matches @ 66th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|        | 501/3256 [00:45<04:11, 10.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0080.png-peach_0107.png: 562 matches @ 67th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|        | 523/3256 [00:47<04:08, 10.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0043.png-peach_0145.png: 281 matches @ 68th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|        | 583/3256 [00:52<04:00, 11.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0136.png-peach_0029.png: 663 matches @ 69th pair(aliked+lightglue)\n",
      "aliked> peach_0136.png-peach_0050.png: 499 matches @ 70th pair(aliked+lightglue)\n",
      "aliked> peach_0136.png-peach_0001.png: 385 matches @ 71th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|        | 601/3256 [00:54<04:01, 11.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0136.png-peach_0159.png: 513 matches @ 72th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|        | 605/3256 [00:54<04:02, 10.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0136.png-peach_0113.png: 1747 matches @ 73th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|        | 631/3256 [00:56<04:01, 10.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0135.png-peach_0032.png: 383 matches @ 74th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 659/3256 [00:59<03:59, 10.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0158.png-peach_0133.png: 1619 matches @ 75th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 665/3256 [01:00<03:57, 10.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0158.png-peach_0168.png: 527 matches @ 76th pair(aliked+lightglue)\n",
      "aliked> peach_0151.png-peach_0154.png: 651 matches @ 77th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|        | 679/3256 [01:01<03:57, 10.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0151.png-peach_0169.png: 594 matches @ 78th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|        | 683/3256 [01:01<03:57, 10.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0151.png-peach_0171.png: 688 matches @ 79th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|       | 701/3256 [01:03<03:56, 10.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0154.png-peach_0169.png: 400 matches @ 80th pair(aliked+lightglue)\n",
      "aliked> peach_0154.png-peach_0171.png: 1762 matches @ 81th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|       | 715/3256 [01:04<03:53, 10.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0097.png-peach_0061.png: 1473 matches @ 82th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|       | 719/3256 [01:05<03:54, 10.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0097.png-peach_0051.png: 248 matches @ 83th pair(aliked+lightglue)\n",
      "aliked> peach_0097.png-peach_0035.png: 622 matches @ 84th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|       | 727/3256 [01:05<03:47, 11.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0024.png-peach_0084.png: 2476 matches @ 85th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|       | 735/3256 [01:06<03:48, 11.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0024.png-peach_0118.png: 219 matches @ 86th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|       | 743/3256 [01:07<03:50, 10.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0116.png-peach_0006.png: 1689 matches @ 87th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|       | 757/3256 [01:08<03:50, 10.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0116.png-peach_0118.png: 862 matches @ 88th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|       | 773/3256 [01:09<03:50, 10.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0006.png-peach_0118.png: 617 matches @ 89th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|       | 877/3256 [01:19<03:38, 10.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0132.png-peach_0181.png: 361 matches @ 90th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 977/3256 [01:28<03:29, 10.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0057.png-peach_0095.png: 2309 matches @ 91th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 985/3256 [01:29<03:30, 10.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0057.png-peach_0090.png: 420 matches @ 92th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 991/3256 [01:30<03:31, 10.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0057.png-peach_0063.png: 327 matches @ 93th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|      | 1019/3256 [01:32<03:05, 12.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0002.png-peach_0010.png: 348 matches @ 94th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|      | 1041/3256 [01:34<03:20, 11.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0086.png-peach_0025.png: 776 matches @ 95th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|      | 1047/3256 [01:34<03:22, 10.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0086.png-peach_0103.png: 1048 matches @ 96th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|      | 1071/3256 [01:37<03:23, 10.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0064.png-peach_0145.png: 949 matches @ 97th pair(aliked+lightglue)\n",
      "aliked> peach_0064.png-peach_0007.png: 945 matches @ 98th pair(aliked+lightglue)\n",
      "aliked> peach_0064.png-peach_0177.png: 476 matches @ 99th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|      | 1081/3256 [01:37<03:19, 10.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0064.png-peach_0131.png: 274 matches @ 100th pair(aliked+lightglue)\n",
      "aliked> peach_0064.png-peach_0196.png: 410 matches @ 101th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|      | 1101/3256 [01:39<03:20, 10.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0064.png-peach_0034.png: 526 matches @ 102th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|      | 1105/3256 [01:40<03:20, 10.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0064.png-peach_0117.png: 708 matches @ 103th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|      | 1119/3256 [01:41<03:19, 10.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0145.png-peach_0007.png: 3046 matches @ 104th pair(aliked+lightglue)\n",
      "aliked> peach_0145.png-peach_0177.png: 1466 matches @ 105th pair(aliked+lightglue)\n",
      "aliked> peach_0145.png-peach_0174.png: 639 matches @ 106th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|      | 1153/3256 [01:44<03:18, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0007.png-peach_0177.png: 1574 matches @ 107th pair(aliked+lightglue)\n",
      "aliked> peach_0007.png-peach_0174.png: 741 matches @ 108th pair(aliked+lightglue)\n",
      "aliked> peach_0007.png-peach_0083.png: 281 matches @ 109th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|      | 1159/3256 [01:45<03:14, 10.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0007.png-peach_0131.png: 1127 matches @ 110th pair(aliked+lightglue)\n",
      "aliked> peach_0007.png-peach_0196.png: 1085 matches @ 111th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|      | 1201/3256 [01:49<03:12, 10.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0177.png-peach_0174.png: 1489 matches @ 112th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|      | 1207/3256 [01:49<03:10, 10.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0177.png-peach_0131.png: 847 matches @ 113th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|      | 1243/3256 [01:53<03:05, 10.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0174.png-peach_0102.png: 464 matches @ 114th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 1293/3256 [01:57<03:06, 10.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0083.png-peach_0093.png: 230 matches @ 115th pair(aliked+lightglue)\n",
      "aliked> peach_0083.png-peach_0129.png: 210 matches @ 116th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|      | 1323/3256 [02:00<02:55, 11.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0029.png-peach_0115.png: 328 matches @ 117th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|      | 1331/3256 [02:01<02:55, 10.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0029.png-peach_0129.png: 226 matches @ 118th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|     | 1349/3256 [02:02<03:01, 10.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0050.png-peach_0159.png: 2012 matches @ 119th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|     | 1353/3256 [02:03<03:02, 10.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0050.png-peach_0113.png: 792 matches @ 120th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|     | 1361/3256 [02:04<02:50, 11.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0001.png-peach_0172.png: 1032 matches @ 121th pair(aliked+lightglue)\n",
      "aliked> peach_0001.png-peach_0041.png: 837 matches @ 122th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|     | 1371/3256 [02:04<02:39, 11.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0001.png-peach_0013.png: 456 matches @ 123th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|     | 1375/3256 [02:05<02:38, 11.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0001.png-peach_0085.png: 521 matches @ 124th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|     | 1403/3256 [02:07<02:36, 11.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0068.png-peach_0142.png: 420 matches @ 125th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|     | 1421/3256 [02:09<02:39, 11.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0068.png-peach_0186.png: 1150 matches @ 126th pair(aliked+lightglue)\n",
      "aliked> peach_0068.png-peach_0147.png: 929 matches @ 127th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|     | 1427/3256 [02:09<02:45, 11.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0068.png-peach_0168.png: 2665 matches @ 128th pair(aliked+lightglue)\n",
      "aliked> peach_0172.png-peach_0041.png: 926 matches @ 129th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|     | 1437/3256 [02:10<02:50, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0172.png-peach_0013.png: 445 matches @ 130th pair(aliked+lightglue)\n",
      "aliked> peach_0172.png-peach_0085.png: 916 matches @ 131th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|     | 1463/3256 [02:13<02:51, 10.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0143.png-peach_0081.png: 2327 matches @ 132th pair(aliked+lightglue)\n",
      "aliked> peach_0143.png-peach_0141.png: 1355 matches @ 133th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|     | 1467/3256 [02:13<02:38, 11.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0143.png-peach_0199.png: 1425 matches @ 134th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|     | 1475/3256 [02:14<02:39, 11.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0143.png-peach_0044.png: 358 matches @ 135th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|     | 1479/3256 [02:14<02:45, 10.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0143.png-peach_0037.png: 1492 matches @ 136th pair(aliked+lightglue)\n",
      "aliked> peach_0143.png-peach_0076.png: 494 matches @ 137th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|     | 1493/3256 [02:15<02:48, 10.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0041.png-peach_0085.png: 1836 matches @ 138th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 1519/3256 [02:18<02:40, 10.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0106.png-peach_0167.png: 2863 matches @ 139th pair(aliked+lightglue)\n",
      "aliked> peach_0106.png-peach_0031.png: 308 matches @ 140th pair(aliked+lightglue)\n",
      "aliked> peach_0106.png-peach_0148.png: 1085 matches @ 141th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 1527/3256 [02:19<02:40, 10.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0106.png-peach_0112.png: 2073 matches @ 142th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 1533/3256 [02:19<02:43, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0106.png-peach_0111.png: 214 matches @ 143th pair(aliked+lightglue)\n",
      "aliked> peach_0106.png-peach_0073.png: 662 matches @ 144th pair(aliked+lightglue)\n",
      "aliked> peach_0106.png-peach_0099.png: 1403 matches @ 145th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 1537/3256 [02:20<02:31, 11.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0106.png-peach_0055.png: 258 matches @ 146th pair(aliked+lightglue)\n",
      "aliked> peach_0106.png-peach_0058.png: 201 matches @ 147th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 1539/3256 [02:20<02:35, 11.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0106.png-peach_0166.png: 279 matches @ 148th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 1543/3256 [02:20<02:29, 11.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0106.png-peach_0134.png: 728 matches @ 149th pair(aliked+lightglue)\n",
      "aliked> peach_0106.png-peach_0003.png: 206 matches @ 150th pair(aliked+lightglue)\n",
      "aliked> peach_0106.png-peach_0019.png: 218 matches @ 151th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 1551/3256 [02:21<02:39, 10.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0102.png-peach_0131.png: 564 matches @ 152th pair(aliked+lightglue)\n",
      "aliked> peach_0102.png-peach_0196.png: 294 matches @ 153th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 1559/3256 [02:22<02:41, 10.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0102.png-peach_0060.png: 1273 matches @ 154th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 1567/3256 [02:22<02:42, 10.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0167.png-peach_0031.png: 222 matches @ 155th pair(aliked+lightglue)\n",
      "aliked> peach_0167.png-peach_0148.png: 1347 matches @ 156th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 1573/3256 [02:23<02:32, 11.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0167.png-peach_0112.png: 2249 matches @ 157th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 1577/3256 [02:23<02:36, 10.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0167.png-peach_0111.png: 270 matches @ 158th pair(aliked+lightglue)\n",
      "aliked> peach_0167.png-peach_0073.png: 494 matches @ 159th pair(aliked+lightglue)\n",
      "aliked> peach_0167.png-peach_0099.png: 1360 matches @ 160th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|     | 1589/3256 [02:24<02:35, 10.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0167.png-peach_0019.png: 205 matches @ 161th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|     | 1593/3256 [02:25<02:37, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0131.png-peach_0196.png: 2151 matches @ 162th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|     | 1605/3256 [02:26<02:38, 10.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0131.png-peach_0060.png: 1465 matches @ 163th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|     | 1649/3256 [02:30<02:34, 10.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0184.png-peach_0031.png: 917 matches @ 164th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|     | 1659/3256 [02:31<02:33, 10.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0184.png-peach_0059.png: 255 matches @ 165th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|    | 1683/3256 [02:33<02:31, 10.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0196.png-peach_0060.png: 1205 matches @ 166th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|    | 1713/3256 [02:36<02:29, 10.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0156.png-peach_0191.png: 503 matches @ 167th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|    | 1763/3256 [02:41<02:23, 10.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0074.png-peach_0053.png: 231 matches @ 168th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|    | 1771/3256 [02:42<02:22, 10.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0074.png-peach_0014.png: 737 matches @ 169th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|    | 1773/3256 [02:42<02:22, 10.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0074.png-peach_0195.png: 1466 matches @ 170th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|    | 1787/3256 [02:43<02:21, 10.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0056.png-peach_0141.png: 243 matches @ 171th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|    | 1791/3256 [02:44<02:21, 10.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0056.png-peach_0149.png: 655 matches @ 172th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|    | 1795/3256 [02:44<02:21, 10.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0056.png-peach_0044.png: 1128 matches @ 173th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|    | 1799/3256 [02:44<02:22, 10.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0053.png-peach_0152.png: 995 matches @ 174th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|    | 1807/3256 [02:45<02:21, 10.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0053.png-peach_0014.png: 1478 matches @ 175th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|    | 1817/3256 [02:46<02:14, 10.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0124.png-peach_0071.png: 948 matches @ 176th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|    | 1821/3256 [02:47<02:10, 10.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0124.png-peach_0093.png: 349 matches @ 177th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|    | 1827/3256 [02:47<02:07, 11.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0124.png-peach_0018.png: 712 matches @ 178th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|    | 1845/3256 [02:49<02:14, 10.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0084.png-peach_0118.png: 256 matches @ 179th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|    | 1859/3256 [02:50<02:15, 10.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0032.png-peach_0013.png: 350 matches @ 180th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|    | 1869/3256 [02:51<02:16, 10.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0032.png-peach_0069.png: 764 matches @ 181th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|    | 1911/3256 [02:55<02:10, 10.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0098.png-peach_0152.png: 2540 matches @ 182th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|    | 1917/3256 [02:56<02:10, 10.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0098.png-peach_0072.png: 314 matches @ 183th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|    | 1923/3256 [02:56<02:09, 10.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0098.png-peach_0014.png: 324 matches @ 184th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 1941/3256 [02:58<01:36, 13.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0148.png-peach_0111.png: 250 matches @ 185th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 1949/3256 [02:58<01:50, 11.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0110.png-peach_0125.png: 1643 matches @ 186th pair(aliked+lightglue)\n",
      "aliked> peach_0110.png-peach_0185.png: 1114 matches @ 187th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 1957/3256 [02:59<02:02, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0110.png-peach_0108.png: 1618 matches @ 188th pair(aliked+lightglue)\n",
      "aliked> peach_0110.png-peach_0160.png: 1094 matches @ 189th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 1959/3256 [02:59<02:03, 10.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0110.png-peach_0197.png: 1198 matches @ 190th pair(aliked+lightglue)\n",
      "aliked> peach_0110.png-peach_0179.png: 1415 matches @ 191th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 1963/3256 [03:00<02:04, 10.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0110.png-peach_0005.png: 1431 matches @ 192th pair(aliked+lightglue)\n",
      "aliked> peach_0110.png-peach_0094.png: 1831 matches @ 193th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 1967/3256 [03:00<02:04, 10.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0110.png-peach_0182.png: 2847 matches @ 194th pair(aliked+lightglue)\n",
      "aliked> peach_0110.png-peach_0009.png: 2363 matches @ 195th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 1969/3256 [03:00<02:05, 10.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0110.png-peach_0176.png: 1171 matches @ 196th pair(aliked+lightglue)\n",
      "aliked> peach_0110.png-peach_0065.png: 803 matches @ 197th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|    | 1985/3256 [03:02<01:50, 11.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0071.png-peach_0101.png: 276 matches @ 198th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|    | 1989/3256 [03:02<01:49, 11.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0071.png-peach_0061.png: 797 matches @ 199th pair(aliked+lightglue)\n",
      "aliked> peach_0071.png-peach_0018.png: 636 matches @ 200th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|    | 1993/3256 [03:02<01:48, 11.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0071.png-peach_0194.png: 784 matches @ 201th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|   | 2005/3256 [03:04<01:57, 10.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0025.png-peach_0016.png: 271 matches @ 202th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|   | 2007/3256 [03:04<01:58, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0025.png-peach_0103.png: 1133 matches @ 203th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|   | 2021/3256 [03:05<01:59, 10.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0138.png-peach_0021.png: 1107 matches @ 204th pair(aliked+lightglue)\n",
      "aliked> peach_0138.png-peach_0072.png: 548 matches @ 205th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|   | 2023/3256 [03:05<02:00, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0138.png-peach_0077.png: 1897 matches @ 206th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|   | 2045/3256 [03:07<01:53, 10.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0070.png-peach_0198.png: 221 matches @ 207th pair(aliked+lightglue)\n",
      "aliked> peach_0070.png-peach_0190.png: 1963 matches @ 208th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|   | 2079/3256 [03:11<01:51, 10.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0047.png-peach_0115.png: 371 matches @ 209th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|   | 2101/3256 [03:13<01:51, 10.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0119.png-peach_0157.png: 299 matches @ 210th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|   | 2151/3256 [03:18<01:42, 10.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0115.png-peach_0015.png: 915 matches @ 211th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|   | 2169/3256 [03:19<01:45, 10.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0152.png-peach_0072.png: 245 matches @ 212th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|   | 2173/3256 [03:20<01:46, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0152.png-peach_0014.png: 451 matches @ 213th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|   | 2197/3256 [03:22<01:41, 10.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0127.png-peach_0149.png: 640 matches @ 214th pair(aliked+lightglue)\n",
      "aliked> peach_0127.png-peach_0139.png: 688 matches @ 215th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|   | 2207/3256 [03:23<01:42, 10.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0183.png-peach_0033.png: 1701 matches @ 216th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|   | 2215/3256 [03:24<01:41, 10.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0183.png-peach_0146.png: 944 matches @ 217th pair(aliked+lightglue)\n",
      "aliked> peach_0183.png-peach_0046.png: 279 matches @ 218th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|   | 2219/3256 [03:24<01:41, 10.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0183.png-peach_0079.png: 229 matches @ 219th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|   | 2225/3256 [03:25<01:40, 10.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0183.png-peach_0065.png: 1316 matches @ 220th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|   | 2233/3256 [03:25<01:37, 10.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0062.png-peach_0122.png: 250 matches @ 221th pair(aliked+lightglue)\n",
      "aliked> peach_0062.png-peach_0090.png: 595 matches @ 222th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|   | 2237/3256 [03:26<01:32, 10.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0062.png-peach_0063.png: 495 matches @ 223th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|   | 2247/3256 [03:27<01:36, 10.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0021.png-peach_0072.png: 2214 matches @ 224th pair(aliked+lightglue)\n",
      "aliked> peach_0021.png-peach_0077.png: 1553 matches @ 225th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|   | 2261/3256 [03:28<01:15, 13.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0027.png-peach_0112.png: 242 matches @ 226th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 2266/3256 [03:28<00:59, 16.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0027.png-peach_0058.png: 261 matches @ 227th pair(aliked+lightglue)\n",
      "aliked> peach_0027.png-peach_0003.png: 832 matches @ 228th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 2293/3256 [03:30<01:30, 10.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0192.png-peach_0163.png: 465 matches @ 229th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|   | 2311/3256 [03:32<01:31, 10.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0125.png-peach_0108.png: 3032 matches @ 230th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|   | 2313/3256 [03:32<01:31, 10.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0125.png-peach_0005.png: 2181 matches @ 231th pair(aliked+lightglue)\n",
      "aliked> peach_0125.png-peach_0094.png: 2210 matches @ 232th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|   | 2319/3256 [03:33<01:28, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0125.png-peach_0182.png: 1451 matches @ 233th pair(aliked+lightglue)\n",
      "aliked> peach_0125.png-peach_0009.png: 1426 matches @ 234th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|  | 2321/3256 [03:33<01:29, 10.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0125.png-peach_0065.png: 585 matches @ 235th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|  | 2335/3256 [03:34<01:29, 10.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0017.png-peach_0066.png: 686 matches @ 236th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|  | 2339/3256 [03:35<01:28, 10.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0114.png-peach_0191.png: 975 matches @ 237th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|  | 2345/3256 [03:35<01:28, 10.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0114.png-peach_0034.png: 1451 matches @ 238th pair(aliked+lightglue)\n",
      "aliked> peach_0114.png-peach_0117.png: 966 matches @ 239th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|  | 2359/3256 [03:37<01:20, 11.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0142.png-peach_0169.png: 954 matches @ 240th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|  | 2363/3256 [03:37<01:17, 11.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0142.png-peach_0186.png: 945 matches @ 241th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|  | 2367/3256 [03:37<01:19, 11.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0142.png-peach_0168.png: 398 matches @ 242th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|  | 2397/3256 [03:40<01:22, 10.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0112.png-peach_0111.png: 317 matches @ 243th pair(aliked+lightglue)\n",
      "aliked> peach_0112.png-peach_0073.png: 490 matches @ 244th pair(aliked+lightglue)\n",
      "aliked> peach_0112.png-peach_0193.png: 224 matches @ 245th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|  | 2401/3256 [03:41<01:21, 10.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0112.png-peach_0099.png: 2422 matches @ 246th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|  | 2405/3256 [03:41<01:22, 10.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0112.png-peach_0166.png: 286 matches @ 247th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|  | 2411/3256 [03:42<01:17, 10.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0112.png-peach_0134.png: 917 matches @ 248th pair(aliked+lightglue)\n",
      "aliked> peach_0112.png-peach_0067.png: 338 matches @ 249th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|  | 2413/3256 [03:42<01:18, 10.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0112.png-peach_0019.png: 258 matches @ 250th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|  | 2427/3256 [03:43<01:19, 10.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0095.png-peach_0090.png: 448 matches @ 251th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|  | 2433/3256 [03:44<01:19, 10.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0095.png-peach_0063.png: 398 matches @ 252th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|  | 2443/3256 [03:45<01:20, 10.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0095.png-peach_0065.png: 211 matches @ 253th pair(aliked+lightglue)\n",
      "aliked> peach_0038.png-peach_0162.png: 2157 matches @ 254th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|  | 2451/3256 [03:45<01:18, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0038.png-peach_0111.png: 1000 matches @ 255th pair(aliked+lightglue)\n",
      "aliked> peach_0038.png-peach_0073.png: 286 matches @ 256th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|  | 2457/3256 [03:46<01:17, 10.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0038.png-peach_0079.png: 357 matches @ 257th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|  | 2465/3256 [03:47<01:17, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0162.png-peach_0111.png: 1314 matches @ 258th pair(aliked+lightglue)\n",
      "aliked> peach_0162.png-peach_0073.png: 408 matches @ 259th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|  | 2467/3256 [03:47<01:17, 10.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0162.png-peach_0055.png: 657 matches @ 260th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|  | 2471/3256 [03:47<01:16, 10.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0162.png-peach_0079.png: 489 matches @ 261th pair(aliked+lightglue)\n",
      "aliked> peach_0162.png-peach_0134.png: 454 matches @ 262th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|  | 2479/3256 [03:48<01:15, 10.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0191.png-peach_0034.png: 562 matches @ 263th pair(aliked+lightglue)\n",
      "aliked> peach_0191.png-peach_0117.png: 374 matches @ 264th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|  | 2487/3256 [03:49<01:15, 10.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0159.png-peach_0113.png: 601 matches @ 265th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|  | 2533/3256 [03:53<01:10, 10.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0072.png-peach_0077.png: 1092 matches @ 266th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|  | 2553/3256 [03:55<01:08, 10.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0022.png-peach_0109.png: 965 matches @ 267th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 2599/3256 [04:00<01:00, 10.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0185.png-peach_0160.png: 701 matches @ 268th pair(aliked+lightglue)\n",
      "aliked> peach_0185.png-peach_0197.png: 2065 matches @ 269th pair(aliked+lightglue)\n",
      "aliked> peach_0185.png-peach_0179.png: 1979 matches @ 270th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 2603/3256 [04:00<01:02, 10.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0185.png-peach_0005.png: 1867 matches @ 271th pair(aliked+lightglue)\n",
      "aliked> peach_0185.png-peach_0182.png: 1340 matches @ 272th pair(aliked+lightglue)\n",
      "aliked> peach_0185.png-peach_0176.png: 2315 matches @ 273th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 2607/3256 [04:01<01:01, 10.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0093.png-peach_0157.png: 318 matches @ 274th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 2619/3256 [04:02<01:00, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0093.png-peach_0178.png: 742 matches @ 275th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|  | 2637/3256 [04:03<00:58, 10.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0150.png-peach_0090.png: 850 matches @ 276th pair(aliked+lightglue)\n",
      "aliked> peach_0150.png-peach_0010.png: 278 matches @ 277th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|  | 2643/3256 [04:04<00:59, 10.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0150.png-peach_0063.png: 650 matches @ 278th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%| | 2647/3256 [04:04<00:58, 10.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0033.png-peach_0104.png: 309 matches @ 279th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%| | 2655/3256 [04:05<00:57, 10.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0033.png-peach_0146.png: 1404 matches @ 280th pair(aliked+lightglue)\n",
      "aliked> peach_0033.png-peach_0079.png: 234 matches @ 281th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%| | 2661/3256 [04:06<00:57, 10.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0033.png-peach_0065.png: 1328 matches @ 282th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%| | 2671/3256 [04:07<00:57, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0081.png-peach_0141.png: 1166 matches @ 283th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%| | 2675/3256 [04:07<00:56, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0081.png-peach_0128.png: 874 matches @ 284th pair(aliked+lightglue)\n",
      "aliked> peach_0081.png-peach_0199.png: 1348 matches @ 285th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%| | 2689/3256 [04:09<00:55, 10.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0081.png-peach_0037.png: 1428 matches @ 286th pair(aliked+lightglue)\n",
      "aliked> peach_0104.png-peach_0073.png: 243 matches @ 287th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%| | 2693/3256 [04:09<00:55, 10.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0104.png-peach_0128.png: 1447 matches @ 288th pair(aliked+lightglue)\n",
      "aliked> peach_0104.png-peach_0146.png: 1425 matches @ 289th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%| | 2715/3256 [04:11<00:52, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0141.png-peach_0199.png: 3040 matches @ 290th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%| | 2735/3256 [04:13<00:50, 10.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0141.png-peach_0037.png: 2809 matches @ 291th pair(aliked+lightglue)\n",
      "aliked> peach_0141.png-peach_0076.png: 617 matches @ 292th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%| | 2743/3256 [04:14<00:50, 10.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0122.png-peach_0046.png: 1859 matches @ 293th pair(aliked+lightglue)\n",
      "aliked> peach_0122.png-peach_0079.png: 962 matches @ 294th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%| | 2765/3256 [04:16<00:46, 10.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0157.png-peach_0187.png: 572 matches @ 295th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%| | 2771/3256 [04:16<00:46, 10.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0111.png-peach_0073.png: 337 matches @ 296th pair(aliked+lightglue)\n",
      "aliked> peach_0111.png-peach_0099.png: 313 matches @ 297th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%| | 2777/3256 [04:17<00:44, 10.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0111.png-peach_0134.png: 416 matches @ 298th pair(aliked+lightglue)\n",
      "aliked> peach_0111.png-peach_0019.png: 201 matches @ 299th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%| | 2783/3256 [04:17<00:45, 10.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0073.png-peach_0099.png: 635 matches @ 300th pair(aliked+lightglue)\n",
      "aliked> peach_0073.png-peach_0055.png: 1018 matches @ 301th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%| | 2789/3256 [04:18<00:45, 10.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0073.png-peach_0134.png: 1762 matches @ 302th pair(aliked+lightglue)\n",
      "aliked> peach_0073.png-peach_0019.png: 251 matches @ 303th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%| | 2793/3256 [04:18<00:44, 10.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0193.png-peach_0099.png: 375 matches @ 304th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%| | 2797/3256 [04:19<00:39, 11.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0193.png-peach_0166.png: 285 matches @ 305th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%| | 2799/3256 [04:19<00:39, 11.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0193.png-peach_0067.png: 676 matches @ 306th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%| | 2819/3256 [04:21<00:42, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0020.png-peach_0149.png: 1274 matches @ 307th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%| | 2825/3256 [04:21<00:42, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0020.png-peach_0139.png: 414 matches @ 308th pair(aliked+lightglue)\n",
      "aliked> peach_0020.png-peach_0040.png: 1874 matches @ 309th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%| | 2827/3256 [04:22<00:41, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0020.png-peach_0026.png: 1042 matches @ 310th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%| | 2847/3256 [04:24<00:39, 10.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0144.png-peach_0186.png: 375 matches @ 311th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%| | 2853/3256 [04:24<00:38, 10.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0034.png-peach_0117.png: 1788 matches @ 312th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%| | 2865/3256 [04:25<00:38, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0099.png-peach_0166.png: 537 matches @ 313th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%| | 2867/3256 [04:26<00:36, 10.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0099.png-peach_0134.png: 1094 matches @ 314th pair(aliked+lightglue)\n",
      "aliked> peach_0099.png-peach_0067.png: 319 matches @ 315th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%| | 2871/3256 [04:26<00:36, 10.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0099.png-peach_0019.png: 200 matches @ 316th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%| | 2883/3256 [04:27<00:36, 10.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0055.png-peach_0079.png: 1280 matches @ 317th pair(aliked+lightglue)\n",
      "aliked> peach_0055.png-peach_0134.png: 407 matches @ 318th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%| | 2889/3256 [04:28<00:35, 10.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0090.png-peach_0046.png: 252 matches @ 319th pair(aliked+lightglue)\n",
      "aliked> peach_0090.png-peach_0063.png: 1857 matches @ 320th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 2935/3256 [04:32<00:31, 10.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0129.png-peach_0048.png: 1254 matches @ 321th pair(aliked+lightglue)\n",
      "aliked> peach_0128.png-peach_0146.png: 387 matches @ 322th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 2941/3256 [04:33<00:30, 10.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0128.png-peach_0044.png: 396 matches @ 323th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%| | 2957/3256 [04:34<00:29, 10.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0199.png-peach_0037.png: 3466 matches @ 324th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%| | 2969/3256 [04:35<00:28, 10.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0108.png-peach_0197.png: 1024 matches @ 325th pair(aliked+lightglue)\n",
      "aliked> peach_0108.png-peach_0005.png: 1837 matches @ 326th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|| 2973/3256 [04:36<00:26, 10.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0108.png-peach_0094.png: 2518 matches @ 327th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|| 2979/3256 [04:36<00:26, 10.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0108.png-peach_0182.png: 1320 matches @ 328th pair(aliked+lightglue)\n",
      "aliked> peach_0108.png-peach_0009.png: 1559 matches @ 329th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|| 2981/3256 [04:37<00:26, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0108.png-peach_0065.png: 579 matches @ 330th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|| 2995/3256 [04:38<00:23, 11.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0101.png-peach_0018.png: 324 matches @ 331th pair(aliked+lightglue)\n",
      "aliked> peach_0101.png-peach_0092.png: 865 matches @ 332th pair(aliked+lightglue)\n",
      "aliked> peach_0101.png-peach_0194.png: 1439 matches @ 333th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|| 3011/3256 [04:39<00:23, 10.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0046.png-peach_0079.png: 1072 matches @ 334th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|| 3029/3256 [04:41<00:21, 10.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0069.png-peach_0147.png: 1152 matches @ 335th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|| 3036/3256 [04:42<00:15, 14.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0069.png-peach_0168.png: 649 matches @ 336th pair(aliked+lightglue)\n",
      "aliked> peach_0058.png-peach_0003.png: 433 matches @ 337th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|| 3055/3256 [04:43<00:19, 10.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0149.png-peach_0044.png: 769 matches @ 338th pair(aliked+lightglue)\n",
      "aliked> peach_0149.png-peach_0026.png: 514 matches @ 339th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|| 3065/3256 [04:44<00:18, 10.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0061.png-peach_0035.png: 588 matches @ 340th pair(aliked+lightglue)\n",
      "aliked> peach_0018.png-peach_0092.png: 251 matches @ 341th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|| 3067/3256 [04:44<00:17, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0018.png-peach_0194.png: 612 matches @ 342th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|| 3071/3256 [04:45<00:16, 10.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0166.png-peach_0134.png: 432 matches @ 343th pair(aliked+lightglue)\n",
      "aliked> peach_0166.png-peach_0067.png: 1038 matches @ 344th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|| 3075/3256 [04:45<00:17, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0166.png-peach_0019.png: 1046 matches @ 345th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|| 3079/3256 [04:46<00:16, 10.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0039.png-peach_0030.png: 816 matches @ 346th pair(aliked+lightglue)\n",
      "aliked> peach_0039.png-peach_0036.png: 492 matches @ 347th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|| 3089/3256 [04:47<00:16, 10.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0039.png-peach_0137.png: 200 matches @ 348th pair(aliked+lightglue)\n",
      "aliked> peach_0039.png-peach_0130.png: 2490 matches @ 349th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|| 3091/3256 [04:47<00:15, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0092.png-peach_0194.png: 500 matches @ 350th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|| 3111/3256 [04:49<00:14, 10.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0030.png-peach_0036.png: 1505 matches @ 351th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|| 3135/3256 [04:51<00:12, 10.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0052.png-peach_0137.png: 528 matches @ 352th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|| 3139/3256 [04:51<00:11, 10.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0160.png-peach_0197.png: 840 matches @ 353th pair(aliked+lightglue)\n",
      "aliked> peach_0160.png-peach_0179.png: 731 matches @ 354th pair(aliked+lightglue)\n",
      "aliked> peach_0160.png-peach_0005.png: 717 matches @ 355th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 3143/3256 [04:52<00:10, 10.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0160.png-peach_0182.png: 1203 matches @ 356th pair(aliked+lightglue)\n",
      "aliked> peach_0160.png-peach_0176.png: 789 matches @ 357th pair(aliked+lightglue)\n",
      "aliked> peach_0160.png-peach_0065.png: 350 matches @ 358th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 3147/3256 [04:52<00:10, 10.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0197.png-peach_0179.png: 1651 matches @ 359th pair(aliked+lightglue)\n",
      "aliked> peach_0197.png-peach_0005.png: 1544 matches @ 360th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 3151/3256 [04:53<00:09, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0197.png-peach_0182.png: 1412 matches @ 361th pair(aliked+lightglue)\n",
      "aliked> peach_0197.png-peach_0176.png: 2127 matches @ 362th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 3155/3256 [04:53<00:09, 10.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0179.png-peach_0005.png: 3073 matches @ 363th pair(aliked+lightglue)\n",
      "aliked> peach_0179.png-peach_0094.png: 1195 matches @ 364th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 3157/3256 [04:53<00:09, 10.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0179.png-peach_0176.png: 1805 matches @ 365th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 3161/3256 [04:54<00:09, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0008.png-peach_0044.png: 892 matches @ 366th pair(aliked+lightglue)\n",
      "aliked> peach_0008.png-peach_0004.png: 1708 matches @ 367th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 3167/3256 [04:54<00:08, 10.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0186.png-peach_0147.png: 628 matches @ 368th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 3171/3256 [04:54<00:08, 10.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0186.png-peach_0168.png: 1262 matches @ 369th pair(aliked+lightglue)\n",
      "aliked> peach_0005.png-peach_0094.png: 1307 matches @ 370th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 3173/3256 [04:55<00:08, 10.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0005.png-peach_0182.png: 1549 matches @ 371th pair(aliked+lightglue)\n",
      "aliked> peach_0005.png-peach_0176.png: 1606 matches @ 372th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 3183/3256 [04:56<00:07, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0094.png-peach_0182.png: 1494 matches @ 373th pair(aliked+lightglue)\n",
      "aliked> peach_0094.png-peach_0009.png: 1838 matches @ 374th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 3187/3256 [04:56<00:06, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0094.png-peach_0065.png: 776 matches @ 375th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 3197/3256 [04:57<00:05, 10.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0134.png-peach_0019.png: 351 matches @ 376th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 3205/3256 [04:58<00:04, 11.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0067.png-peach_0019.png: 833 matches @ 377th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|| 3213/3256 [04:58<00:04, 10.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0147.png-peach_0168.png: 953 matches @ 378th pair(aliked+lightglue)\n",
      "aliked> peach_0044.png-peach_0004.png: 1057 matches @ 379th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|| 3235/3256 [05:01<00:02, 10.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0182.png-peach_0009.png: 1849 matches @ 380th pair(aliked+lightglue)\n",
      "aliked> peach_0182.png-peach_0176.png: 1389 matches @ 381th pair(aliked+lightglue)\n",
      "aliked> peach_0182.png-peach_0065.png: 619 matches @ 382th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3241/3256 [05:01<00:01, 10.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0009.png-peach_0065.png: 774 matches @ 383th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3247/3256 [05:02<00:00, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0037.png-peach_0076.png: 533 matches @ 384th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3249/3256 [05:02<00:00, 10.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0040.png-peach_0026.png: 1609 matches @ 385th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3256/3256 [05:03<00:00, 10.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> peach_0137.png-peach_0130.png: 206 matches @ 386th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features matched in  316.4800 sec (aliked+LightGlue)\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\n",
      "Loaded LightGlue model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3256 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0100.png-peach_0091.png: 1425 matches @ 1th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 30/3256 [00:02<05:21, 10.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0091.png-peach_0075.png: 1392 matches @ 2th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 34/3256 [00:03<05:20, 10.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0091.png-peach_0143.png: 714 matches @ 3th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 42/3256 [00:04<05:19, 10.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0091.png-peach_0081.png: 581 matches @ 4th pair(disk+lightglue)\n",
      "disk> peach_0091.png-peach_0104.png: 585 matches @ 5th pair(disk+lightglue)\n",
      "disk> peach_0091.png-peach_0141.png: 533 matches @ 6th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 48/3256 [00:04<05:23,  9.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0091.png-peach_0128.png: 1509 matches @ 7th pair(disk+lightglue)\n",
      "disk> peach_0091.png-peach_0199.png: 481 matches @ 8th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 53/3256 [00:05<05:23,  9.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0091.png-peach_0044.png: 265 matches @ 9th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 55/3256 [00:05<05:24,  9.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0091.png-peach_0076.png: 452 matches @ 10th pair(disk+lightglue)\n",
      "disk> peach_0075.png-peach_0087.png: 1605 matches @ 11th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 58/3256 [00:05<05:23,  9.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0075.png-peach_0143.png: 1048 matches @ 12th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 75/3256 [00:07<05:16, 10.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0075.png-peach_0081.png: 1074 matches @ 13th pair(disk+lightglue)\n",
      "disk> peach_0075.png-peach_0104.png: 848 matches @ 14th pair(disk+lightglue)\n",
      "disk> peach_0075.png-peach_0141.png: 530 matches @ 15th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 85/3256 [00:08<05:14, 10.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0075.png-peach_0128.png: 1323 matches @ 16th pair(disk+lightglue)\n",
      "disk> peach_0075.png-peach_0146.png: 378 matches @ 17th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 95/3256 [00:09<05:14, 10.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0075.png-peach_0044.png: 378 matches @ 18th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 103/3256 [00:10<05:14, 10.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0087.png-peach_0089.png: 201 matches @ 19th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 109/3256 [00:10<05:11, 10.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0087.png-peach_0183.png: 590 matches @ 20th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 117/3256 [00:11<05:11, 10.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0087.png-peach_0033.png: 1362 matches @ 21th pair(disk+lightglue)\n",
      "disk> peach_0087.png-peach_0104.png: 850 matches @ 22th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 127/3256 [00:12<05:12, 10.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0087.png-peach_0128.png: 944 matches @ 23th pair(disk+lightglue)\n",
      "disk> peach_0087.png-peach_0146.png: 1293 matches @ 24th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 143/3256 [00:14<05:11, 10.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0089.png-peach_0183.png: 2015 matches @ 25th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 147/3256 [00:14<05:09, 10.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0089.png-peach_0185.png: 283 matches @ 26th pair(disk+lightglue)\n",
      "disk> peach_0089.png-peach_0033.png: 1292 matches @ 27th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 155/3256 [00:15<05:09, 10.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0089.png-peach_0146.png: 352 matches @ 28th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 157/3256 [00:15<05:09, 10.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0089.png-peach_0160.png: 248 matches @ 29th pair(disk+lightglue)\n",
      "disk> peach_0089.png-peach_0197.png: 265 matches @ 30th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 164/3256 [00:16<05:07, 10.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0089.png-peach_0182.png: 299 matches @ 31th pair(disk+lightglue)\n",
      "disk> peach_0089.png-peach_0065.png: 1859 matches @ 32th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 166/3256 [00:16<05:06, 10.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0028.png-peach_0161.png: 1655 matches @ 33th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 178/3256 [00:17<05:05, 10.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0028.png-peach_0088.png: 1213 matches @ 34th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|         | 184/3256 [00:18<05:06, 10.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0028.png-peach_0016.png: 723 matches @ 35th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|         | 197/3256 [00:19<05:06,  9.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0161.png-peach_0189.png: 256 matches @ 36th pair(disk+lightglue)\n",
      "disk> peach_0161.png-peach_0155.png: 500 matches @ 37th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 219/3256 [00:21<05:01, 10.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0161.png-peach_0088.png: 1054 matches @ 38th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 234/3256 [00:23<05:00, 10.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0189.png-peach_0155.png: 575 matches @ 39th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|         | 258/3256 [00:25<04:58, 10.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0155.png-peach_0042.png: 375 matches @ 40th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|         | 286/3256 [00:28<04:55, 10.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0042.png-peach_0188.png: 589 matches @ 41th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|         | 298/3256 [00:29<04:54, 10.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0042.png-peach_0086.png: 1246 matches @ 42th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|         | 304/3256 [00:30<04:53, 10.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0042.png-peach_0025.png: 870 matches @ 43th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|         | 308/3256 [00:30<04:53, 10.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0042.png-peach_0016.png: 975 matches @ 44th pair(disk+lightglue)\n",
      "disk> peach_0042.png-peach_0103.png: 837 matches @ 45th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 330/3256 [00:32<04:50, 10.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0188.png-peach_0025.png: 957 matches @ 46th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 334/3256 [00:33<04:50, 10.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0188.png-peach_0103.png: 1193 matches @ 47th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|        | 410/3256 [00:40<04:43, 10.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0121.png-peach_0126.png: 1792 matches @ 48th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|        | 422/3256 [00:41<04:43, 10.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0121.png-peach_0180.png: 518 matches @ 49th pair(disk+lightglue)\n",
      "disk> peach_0121.png-peach_0107.png: 841 matches @ 50th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 448/3256 [00:44<04:39, 10.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0045.png-peach_0080.png: 1263 matches @ 51th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 468/3256 [00:46<04:38, 10.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0045.png-peach_0107.png: 929 matches @ 52th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|        | 500/3256 [00:49<04:32, 10.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0080.png-peach_0107.png: 630 matches @ 53th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|        | 522/3256 [00:51<04:33, 10.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0043.png-peach_0145.png: 363 matches @ 54th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|        | 582/3256 [00:57<04:24, 10.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0136.png-peach_0029.png: 833 matches @ 55th pair(disk+lightglue)\n",
      "disk> peach_0136.png-peach_0050.png: 344 matches @ 56th pair(disk+lightglue)\n",
      "disk> peach_0136.png-peach_0001.png: 370 matches @ 57th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|        | 602/3256 [00:59<04:25, 10.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0136.png-peach_0159.png: 586 matches @ 58th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|        | 605/3256 [01:00<04:25,  9.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0136.png-peach_0113.png: 1775 matches @ 59th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|        | 631/3256 [01:02<04:21, 10.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0135.png-peach_0032.png: 424 matches @ 60th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 659/3256 [01:05<04:17, 10.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0158.png-peach_0133.png: 1744 matches @ 61th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 665/3256 [01:06<04:18, 10.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0158.png-peach_0168.png: 692 matches @ 62th pair(disk+lightglue)\n",
      "disk> peach_0151.png-peach_0154.png: 910 matches @ 63th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|        | 679/3256 [01:07<04:17, 10.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0151.png-peach_0169.png: 734 matches @ 64th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|        | 683/3256 [01:07<04:17,  9.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0151.png-peach_0171.png: 838 matches @ 65th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|       | 704/3256 [01:10<04:12, 10.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0154.png-peach_0171.png: 1965 matches @ 66th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|       | 716/3256 [01:11<04:11, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0097.png-peach_0061.png: 1477 matches @ 67th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|       | 720/3256 [01:11<04:09, 10.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0097.png-peach_0035.png: 391 matches @ 68th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|       | 726/3256 [01:12<04:11, 10.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0024.png-peach_0084.png: 2488 matches @ 69th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|       | 744/3256 [01:13<04:10, 10.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0116.png-peach_0006.png: 1726 matches @ 70th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|       | 756/3256 [01:15<04:08, 10.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0116.png-peach_0118.png: 692 matches @ 71th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|       | 774/3256 [01:16<04:07, 10.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0006.png-peach_0118.png: 585 matches @ 72th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|       | 836/3256 [01:23<04:01, 10.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0175.png-peach_0132.png: 250 matches @ 73th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 976/3256 [01:36<03:46, 10.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0057.png-peach_0095.png: 2559 matches @ 74th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 984/3256 [01:37<03:44, 10.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0057.png-peach_0090.png: 372 matches @ 75th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 990/3256 [01:38<03:45, 10.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0057.png-peach_0063.png: 295 matches @ 76th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|      | 1018/3256 [01:41<03:42, 10.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0002.png-peach_0010.png: 436 matches @ 77th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|      | 1042/3256 [01:43<03:40, 10.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0086.png-peach_0025.png: 886 matches @ 78th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|      | 1048/3256 [01:44<03:38, 10.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0086.png-peach_0103.png: 1240 matches @ 79th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|      | 1070/3256 [01:46<03:36, 10.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0064.png-peach_0145.png: 1206 matches @ 80th pair(disk+lightglue)\n",
      "disk> peach_0064.png-peach_0007.png: 1155 matches @ 81th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|      | 1072/3256 [01:46<03:37, 10.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0064.png-peach_0177.png: 739 matches @ 82th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|      | 1080/3256 [01:47<03:36, 10.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0064.png-peach_0131.png: 211 matches @ 83th pair(disk+lightglue)\n",
      "disk> peach_0064.png-peach_0196.png: 311 matches @ 84th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|      | 1102/3256 [01:49<03:33, 10.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0064.png-peach_0034.png: 350 matches @ 85th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|      | 1104/3256 [01:49<03:32, 10.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0064.png-peach_0117.png: 901 matches @ 86th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|      | 1118/3256 [01:51<03:31, 10.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0145.png-peach_0007.png: 3101 matches @ 87th pair(disk+lightglue)\n",
      "disk> peach_0145.png-peach_0177.png: 1666 matches @ 88th pair(disk+lightglue)\n",
      "disk> peach_0145.png-peach_0174.png: 974 matches @ 89th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|      | 1152/3256 [01:54<03:29, 10.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0007.png-peach_0177.png: 1791 matches @ 90th pair(disk+lightglue)\n",
      "disk> peach_0007.png-peach_0174.png: 1047 matches @ 91th pair(disk+lightglue)\n",
      "disk> peach_0007.png-peach_0083.png: 309 matches @ 92th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|      | 1160/3256 [01:55<03:27, 10.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0007.png-peach_0131.png: 968 matches @ 93th pair(disk+lightglue)\n",
      "disk> peach_0007.png-peach_0196.png: 915 matches @ 94th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|      | 1202/3256 [01:59<03:25,  9.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0177.png-peach_0174.png: 1642 matches @ 95th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|      | 1208/3256 [02:00<03:22, 10.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0177.png-peach_0131.png: 681 matches @ 96th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|      | 1214/3256 [02:00<03:23, 10.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0177.png-peach_0047.png: 260 matches @ 97th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|      | 1242/3256 [02:03<03:19, 10.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0174.png-peach_0102.png: 639 matches @ 98th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|      | 1321/3256 [02:11<03:11, 10.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0029.png-peach_0115.png: 287 matches @ 99th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|     | 1349/3256 [02:14<03:10,  9.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0050.png-peach_0159.png: 2426 matches @ 100th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|     | 1353/3256 [02:14<03:08, 10.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0050.png-peach_0113.png: 1105 matches @ 101th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|     | 1361/3256 [02:15<03:08, 10.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0001.png-peach_0172.png: 1472 matches @ 102th pair(disk+lightglue)\n",
      "disk> peach_0001.png-peach_0041.png: 1299 matches @ 103th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|     | 1371/3256 [02:16<03:07, 10.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0001.png-peach_0013.png: 821 matches @ 104th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|     | 1375/3256 [02:16<03:08,  9.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0001.png-peach_0085.png: 544 matches @ 105th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|     | 1404/3256 [02:19<03:04, 10.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0068.png-peach_0142.png: 324 matches @ 106th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|     | 1422/3256 [02:21<03:01, 10.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0068.png-peach_0186.png: 1354 matches @ 107th pair(disk+lightglue)\n",
      "disk> peach_0068.png-peach_0147.png: 1018 matches @ 108th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|     | 1426/3256 [02:21<03:02, 10.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0068.png-peach_0168.png: 2962 matches @ 109th pair(disk+lightglue)\n",
      "disk> peach_0172.png-peach_0041.png: 1097 matches @ 110th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|     | 1438/3256 [02:22<03:00, 10.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0172.png-peach_0013.png: 810 matches @ 111th pair(disk+lightglue)\n",
      "disk> peach_0172.png-peach_0085.png: 1011 matches @ 112th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|     | 1462/3256 [02:25<02:58, 10.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0143.png-peach_0081.png: 1810 matches @ 113th pair(disk+lightglue)\n",
      "disk> peach_0143.png-peach_0141.png: 1515 matches @ 114th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|     | 1468/3256 [02:25<02:58, 10.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0143.png-peach_0199.png: 1608 matches @ 115th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|     | 1480/3256 [02:27<02:55, 10.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0143.png-peach_0037.png: 1604 matches @ 116th pair(disk+lightglue)\n",
      "disk> peach_0143.png-peach_0076.png: 403 matches @ 117th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|     | 1494/3256 [02:28<02:56, 10.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0041.png-peach_0085.png: 1979 matches @ 118th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 1519/3256 [02:30<02:52, 10.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0106.png-peach_0167.png: 2841 matches @ 119th pair(disk+lightglue)\n",
      "disk> peach_0106.png-peach_0148.png: 1413 matches @ 120th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 1525/3256 [02:31<02:51, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0106.png-peach_0027.png: 259 matches @ 121th pair(disk+lightglue)\n",
      "disk> peach_0106.png-peach_0112.png: 1834 matches @ 122th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 1533/3256 [02:32<02:52,  9.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0106.png-peach_0111.png: 251 matches @ 123th pair(disk+lightglue)\n",
      "disk> peach_0106.png-peach_0073.png: 369 matches @ 124th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 1535/3256 [02:32<02:53,  9.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0106.png-peach_0099.png: 701 matches @ 125th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 1544/3256 [02:33<02:50, 10.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0106.png-peach_0134.png: 707 matches @ 126th pair(disk+lightglue)\n",
      "disk> peach_0106.png-peach_0003.png: 303 matches @ 127th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 1550/3256 [02:34<02:49, 10.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0102.png-peach_0131.png: 722 matches @ 128th pair(disk+lightglue)\n",
      "disk> peach_0102.png-peach_0196.png: 514 matches @ 129th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 1558/3256 [02:34<02:49, 10.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0102.png-peach_0060.png: 1450 matches @ 130th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 1570/3256 [02:36<02:47, 10.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0167.png-peach_0148.png: 1660 matches @ 131th pair(disk+lightglue)\n",
      "disk> peach_0167.png-peach_0027.png: 252 matches @ 132th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 1572/3256 [02:36<02:47, 10.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0167.png-peach_0112.png: 2111 matches @ 133th pair(disk+lightglue)\n",
      "disk> peach_0167.png-peach_0162.png: 219 matches @ 134th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 1578/3256 [02:36<02:47, 10.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0167.png-peach_0111.png: 335 matches @ 135th pair(disk+lightglue)\n",
      "disk> peach_0167.png-peach_0073.png: 277 matches @ 136th pair(disk+lightglue)\n",
      "disk> peach_0167.png-peach_0099.png: 663 matches @ 137th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|     | 1593/3256 [02:38<02:47,  9.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0131.png-peach_0196.png: 2219 matches @ 138th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|     | 1604/3256 [02:39<02:43, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0131.png-peach_0060.png: 1607 matches @ 139th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|     | 1648/3256 [02:43<02:42,  9.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0184.png-peach_0031.png: 1127 matches @ 140th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|    | 1682/3256 [02:47<02:35, 10.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0196.png-peach_0060.png: 1329 matches @ 141th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|    | 1712/3256 [02:50<02:34,  9.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0156.png-peach_0191.png: 805 matches @ 142th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|    | 1764/3256 [02:55<02:28, 10.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0074.png-peach_0053.png: 444 matches @ 143th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|    | 1770/3256 [02:55<02:28, 10.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0074.png-peach_0014.png: 712 matches @ 144th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|    | 1773/3256 [02:56<02:28,  9.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0074.png-peach_0195.png: 1487 matches @ 145th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|    | 1787/3256 [02:57<02:27,  9.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0056.png-peach_0141.png: 230 matches @ 146th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|    | 1791/3256 [02:58<02:26,  9.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0056.png-peach_0149.png: 681 matches @ 147th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|    | 1796/3256 [02:58<02:26, 10.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0056.png-peach_0044.png: 1098 matches @ 148th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|    | 1800/3256 [02:58<02:23, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0053.png-peach_0152.png: 1087 matches @ 149th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|    | 1806/3256 [02:59<02:23, 10.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0053.png-peach_0014.png: 1494 matches @ 150th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|    | 1818/3256 [03:00<02:23, 10.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0124.png-peach_0071.png: 1234 matches @ 151th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|    | 1822/3256 [03:01<02:21, 10.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0124.png-peach_0093.png: 398 matches @ 152th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|    | 1828/3256 [03:01<02:21, 10.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0124.png-peach_0018.png: 996 matches @ 153th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|    | 1860/3256 [03:04<02:18, 10.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0032.png-peach_0013.png: 534 matches @ 154th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|    | 1870/3256 [03:05<02:17, 10.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0032.png-peach_0069.png: 822 matches @ 155th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|    | 1910/3256 [03:09<02:13, 10.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0098.png-peach_0152.png: 2544 matches @ 156th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|    | 1918/3256 [03:10<02:12, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0098.png-peach_0072.png: 302 matches @ 157th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|    | 1922/3256 [03:11<02:13, 10.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0098.png-peach_0014.png: 547 matches @ 158th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|    | 1936/3256 [03:12<02:11, 10.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0148.png-peach_0027.png: 267 matches @ 159th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 1939/3256 [03:12<02:12,  9.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0148.png-peach_0111.png: 384 matches @ 160th pair(disk+lightglue)\n",
      "disk> peach_0148.png-peach_0058.png: 365 matches @ 161th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 1943/3256 [03:13<02:11,  9.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0148.png-peach_0003.png: 276 matches @ 162th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 1949/3256 [03:13<02:08, 10.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0110.png-peach_0125.png: 1642 matches @ 163th pair(disk+lightglue)\n",
      "disk> peach_0110.png-peach_0185.png: 1280 matches @ 164th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 1956/3256 [03:14<02:10,  9.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0110.png-peach_0108.png: 1559 matches @ 165th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 1958/3256 [03:14<02:11,  9.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0110.png-peach_0160.png: 1099 matches @ 166th pair(disk+lightglue)\n",
      "disk> peach_0110.png-peach_0197.png: 1333 matches @ 167th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 1961/3256 [03:14<02:10,  9.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0110.png-peach_0179.png: 1481 matches @ 168th pair(disk+lightglue)\n",
      "disk> peach_0110.png-peach_0005.png: 1470 matches @ 169th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 1963/3256 [03:15<02:10,  9.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0110.png-peach_0094.png: 1783 matches @ 170th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 1966/3256 [03:15<02:10,  9.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0110.png-peach_0182.png: 2670 matches @ 171th pair(disk+lightglue)\n",
      "disk> peach_0110.png-peach_0009.png: 1658 matches @ 172th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 1969/3256 [03:15<02:10,  9.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0110.png-peach_0176.png: 1210 matches @ 173th pair(disk+lightglue)\n",
      "disk> peach_0110.png-peach_0065.png: 657 matches @ 174th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|    | 1985/3256 [03:17<02:05, 10.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0071.png-peach_0101.png: 404 matches @ 175th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|    | 1987/3256 [03:17<02:05, 10.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0071.png-peach_0061.png: 1047 matches @ 176th pair(disk+lightglue)\n",
      "disk> peach_0071.png-peach_0018.png: 809 matches @ 177th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|    | 1993/3256 [03:18<02:05, 10.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0071.png-peach_0194.png: 958 matches @ 178th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|   | 2007/3256 [03:19<02:03, 10.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0025.png-peach_0103.png: 1333 matches @ 179th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|   | 2021/3256 [03:20<02:02, 10.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0138.png-peach_0021.png: 981 matches @ 180th pair(disk+lightglue)\n",
      "disk> peach_0138.png-peach_0072.png: 794 matches @ 181th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|   | 2023/3256 [03:21<02:01, 10.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0138.png-peach_0077.png: 1869 matches @ 182th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|   | 2047/3256 [03:23<01:59, 10.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0070.png-peach_0190.png: 2047 matches @ 183th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|   | 2079/3256 [03:26<01:57,  9.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0047.png-peach_0115.png: 240 matches @ 184th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|   | 2100/3256 [03:28<01:55, 10.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0119.png-peach_0157.png: 312 matches @ 185th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|   | 2151/3256 [03:33<01:49, 10.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0115.png-peach_0015.png: 1253 matches @ 186th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|   | 2173/3256 [03:36<01:47, 10.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0152.png-peach_0014.png: 648 matches @ 187th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|   | 2197/3256 [03:38<01:44, 10.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0127.png-peach_0149.png: 1087 matches @ 188th pair(disk+lightglue)\n",
      "disk> peach_0127.png-peach_0139.png: 656 matches @ 189th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|   | 2207/3256 [03:39<01:44, 10.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0183.png-peach_0033.png: 1873 matches @ 190th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|   | 2215/3256 [03:40<01:43, 10.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0183.png-peach_0108.png: 208 matches @ 191th pair(disk+lightglue)\n",
      "disk> peach_0183.png-peach_0146.png: 897 matches @ 192th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|   | 2223/3256 [03:41<01:42, 10.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0183.png-peach_0182.png: 247 matches @ 193th pair(disk+lightglue)\n",
      "disk> peach_0183.png-peach_0065.png: 1592 matches @ 194th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|   | 2233/3256 [03:42<01:41, 10.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0062.png-peach_0122.png: 302 matches @ 195th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|   | 2235/3256 [03:42<01:42, 10.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0062.png-peach_0090.png: 513 matches @ 196th pair(disk+lightglue)\n",
      "disk> peach_0062.png-peach_0063.png: 463 matches @ 197th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|   | 2247/3256 [03:43<01:40, 10.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0021.png-peach_0072.png: 2226 matches @ 198th pair(disk+lightglue)\n",
      "disk> peach_0021.png-peach_0077.png: 1481 matches @ 199th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|   | 2259/3256 [03:44<01:39, 10.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0027.png-peach_0112.png: 234 matches @ 200th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 2265/3256 [03:45<01:39, 10.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0027.png-peach_0058.png: 751 matches @ 201th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 2269/3256 [03:45<01:38, 10.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0027.png-peach_0003.png: 1836 matches @ 202th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|   | 2311/3256 [03:49<01:33, 10.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0125.png-peach_0108.png: 2877 matches @ 203th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|   | 2313/3256 [03:49<01:33, 10.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0125.png-peach_0005.png: 2345 matches @ 204th pair(disk+lightglue)\n",
      "disk> peach_0125.png-peach_0094.png: 1803 matches @ 205th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|   | 2319/3256 [03:50<01:32, 10.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0125.png-peach_0182.png: 1451 matches @ 206th pair(disk+lightglue)\n",
      "disk> peach_0125.png-peach_0009.png: 911 matches @ 207th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|  | 2321/3256 [03:50<01:32, 10.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0125.png-peach_0065.png: 292 matches @ 208th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|  | 2335/3256 [03:52<01:30, 10.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0017.png-peach_0066.png: 939 matches @ 209th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|  | 2337/3256 [03:52<01:30, 10.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0114.png-peach_0191.png: 1101 matches @ 210th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|  | 2345/3256 [03:53<01:30, 10.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0114.png-peach_0034.png: 1526 matches @ 211th pair(disk+lightglue)\n",
      "disk> peach_0114.png-peach_0117.png: 1225 matches @ 212th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|  | 2359/3256 [03:54<01:28, 10.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0142.png-peach_0169.png: 1355 matches @ 213th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|  | 2363/3256 [03:54<01:28, 10.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0142.png-peach_0186.png: 1229 matches @ 214th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|  | 2367/3256 [03:55<01:28, 10.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0142.png-peach_0168.png: 613 matches @ 215th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|  | 2399/3256 [03:58<01:25, 10.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0112.png-peach_0073.png: 273 matches @ 216th pair(disk+lightglue)\n",
      "disk> peach_0112.png-peach_0099.png: 1855 matches @ 217th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|  | 2411/3256 [03:59<01:24, 10.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0112.png-peach_0134.png: 785 matches @ 218th pair(disk+lightglue)\n",
      "disk> peach_0112.png-peach_0003.png: 227 matches @ 219th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|  | 2428/3256 [04:01<01:23,  9.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0095.png-peach_0090.png: 340 matches @ 220th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|  | 2433/3256 [04:01<01:23,  9.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0095.png-peach_0063.png: 295 matches @ 221th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|  | 2445/3256 [04:03<01:22,  9.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0038.png-peach_0162.png: 1966 matches @ 222th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|  | 2449/3256 [04:03<01:21,  9.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0038.png-peach_0122.png: 312 matches @ 223th pair(disk+lightglue)\n",
      "disk> peach_0038.png-peach_0111.png: 989 matches @ 224th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|  | 2455/3256 [04:04<01:20,  9.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0038.png-peach_0046.png: 260 matches @ 225th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|  | 2462/3256 [04:04<01:19, 10.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0162.png-peach_0122.png: 246 matches @ 226th pair(disk+lightglue)\n",
      "disk> peach_0162.png-peach_0111.png: 1245 matches @ 227th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|  | 2466/3256 [04:05<01:19,  9.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0162.png-peach_0073.png: 374 matches @ 228th pair(disk+lightglue)\n",
      "disk> peach_0162.png-peach_0055.png: 489 matches @ 229th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|  | 2470/3256 [04:05<01:19,  9.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0162.png-peach_0046.png: 249 matches @ 230th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|  | 2472/3256 [04:05<01:19,  9.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0162.png-peach_0134.png: 379 matches @ 231th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|  | 2480/3256 [04:06<01:17,  9.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0191.png-peach_0034.png: 588 matches @ 232th pair(disk+lightglue)\n",
      "disk> peach_0191.png-peach_0117.png: 256 matches @ 233th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|  | 2487/3256 [04:07<01:16, 10.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0159.png-peach_0113.png: 980 matches @ 234th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|  | 2534/3256 [04:12<01:11, 10.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0072.png-peach_0077.png: 1244 matches @ 235th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|  | 2552/3256 [04:13<01:09, 10.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0022.png-peach_0109.png: 929 matches @ 236th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 2600/3256 [04:18<01:05, 10.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0185.png-peach_0160.png: 884 matches @ 237th pair(disk+lightglue)\n",
      "disk> peach_0185.png-peach_0197.png: 2077 matches @ 238th pair(disk+lightglue)\n",
      "disk> peach_0185.png-peach_0179.png: 2061 matches @ 239th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 2602/3256 [04:18<01:05, 10.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0185.png-peach_0005.png: 1931 matches @ 240th pair(disk+lightglue)\n",
      "disk> peach_0185.png-peach_0182.png: 1478 matches @ 241th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 2604/3256 [04:18<01:05, 10.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0185.png-peach_0176.png: 2393 matches @ 242th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 2607/3256 [04:19<01:05,  9.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0093.png-peach_0157.png: 442 matches @ 243th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 2618/3256 [04:20<01:04,  9.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0093.png-peach_0178.png: 670 matches @ 244th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|  | 2637/3256 [04:22<01:01, 10.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0150.png-peach_0090.png: 1177 matches @ 245th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%| | 2655/3256 [04:24<00:59, 10.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0033.png-peach_0146.png: 1445 matches @ 246th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%| | 2661/3256 [04:24<00:59, 10.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0033.png-peach_0065.png: 1642 matches @ 247th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%| | 2671/3256 [04:25<00:58, 10.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0081.png-peach_0141.png: 788 matches @ 248th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%| | 2675/3256 [04:26<00:57, 10.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0081.png-peach_0128.png: 786 matches @ 249th pair(disk+lightglue)\n",
      "disk> peach_0081.png-peach_0199.png: 1092 matches @ 250th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%| | 2689/3256 [04:27<00:56, 10.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0081.png-peach_0037.png: 1208 matches @ 251th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%| | 2691/3256 [04:27<00:56, 10.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0104.png-peach_0128.png: 1797 matches @ 252th pair(disk+lightglue)\n",
      "disk> peach_0104.png-peach_0146.png: 1603 matches @ 253th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%| | 2716/3256 [04:30<00:53, 10.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0141.png-peach_0199.png: 2798 matches @ 254th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%| | 2734/3256 [04:31<00:52, 10.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0141.png-peach_0037.png: 2521 matches @ 255th pair(disk+lightglue)\n",
      "disk> peach_0141.png-peach_0076.png: 586 matches @ 256th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%| | 2736/3256 [04:32<00:52,  9.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0122.png-peach_0111.png: 268 matches @ 257th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%| | 2743/3256 [04:32<00:51, 10.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0122.png-peach_0046.png: 1673 matches @ 258th pair(disk+lightglue)\n",
      "disk> peach_0122.png-peach_0079.png: 804 matches @ 259th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%| | 2765/3256 [04:35<00:49, 10.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0157.png-peach_0187.png: 919 matches @ 260th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%| | 2771/3256 [04:35<00:48,  9.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0111.png-peach_0073.png: 267 matches @ 261th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%| | 2777/3256 [04:36<00:48,  9.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0111.png-peach_0134.png: 484 matches @ 262th pair(disk+lightglue)\n",
      "disk> peach_0111.png-peach_0019.png: 207 matches @ 263th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%| | 2782/3256 [04:36<00:47,  9.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0073.png-peach_0099.png: 543 matches @ 264th pair(disk+lightglue)\n",
      "disk> peach_0073.png-peach_0055.png: 1159 matches @ 265th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%| | 2789/3256 [04:37<00:46, 10.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0073.png-peach_0134.png: 1601 matches @ 266th pair(disk+lightglue)\n",
      "disk> peach_0073.png-peach_0019.png: 372 matches @ 267th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%| | 2793/3256 [04:37<00:46, 10.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0193.png-peach_0099.png: 477 matches @ 268th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%| | 2799/3256 [04:38<00:45, 10.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0193.png-peach_0067.png: 727 matches @ 269th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%| | 2819/3256 [04:40<00:43, 10.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0020.png-peach_0149.png: 1525 matches @ 270th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%| | 2827/3256 [04:41<00:42, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0020.png-peach_0040.png: 2098 matches @ 271th pair(disk+lightglue)\n",
      "disk> peach_0020.png-peach_0026.png: 1475 matches @ 272th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%| | 2848/3256 [04:43<00:40, 10.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0144.png-peach_0186.png: 385 matches @ 273th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%| | 2853/3256 [04:43<00:40, 10.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0034.png-peach_0117.png: 1940 matches @ 274th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%| | 2868/3256 [04:45<00:38, 10.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0099.png-peach_0134.png: 961 matches @ 275th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%| | 2882/3256 [04:46<00:37, 10.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0055.png-peach_0079.png: 1215 matches @ 276th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%| | 2890/3256 [04:47<00:36, 10.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0090.png-peach_0063.png: 1954 matches @ 277th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 2935/3256 [04:51<00:31, 10.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0129.png-peach_0048.png: 1347 matches @ 278th pair(disk+lightglue)\n",
      "disk> peach_0128.png-peach_0146.png: 543 matches @ 279th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 2941/3256 [04:52<00:31, 10.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0128.png-peach_0044.png: 303 matches @ 280th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%| | 2957/3256 [04:54<00:29, 10.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0199.png-peach_0037.png: 3472 matches @ 281th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%| | 2969/3256 [04:55<00:28, 10.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0108.png-peach_0197.png: 947 matches @ 282th pair(disk+lightglue)\n",
      "disk> peach_0108.png-peach_0005.png: 1799 matches @ 283th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|| 2973/3256 [04:55<00:27, 10.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0108.png-peach_0094.png: 2302 matches @ 284th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|| 2977/3256 [04:56<00:27, 10.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0108.png-peach_0182.png: 1291 matches @ 285th pair(disk+lightglue)\n",
      "disk> peach_0108.png-peach_0009.png: 1104 matches @ 286th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|| 2981/3256 [04:56<00:27,  9.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0108.png-peach_0065.png: 532 matches @ 287th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|| 2994/3256 [04:57<00:26, 10.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0101.png-peach_0018.png: 466 matches @ 288th pair(disk+lightglue)\n",
      "disk> peach_0101.png-peach_0092.png: 1076 matches @ 289th pair(disk+lightglue)\n",
      "disk> peach_0101.png-peach_0194.png: 1592 matches @ 290th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|| 3012/3256 [04:59<00:24, 10.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0046.png-peach_0079.png: 918 matches @ 291th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|| 3030/3256 [05:01<00:22, 10.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0069.png-peach_0147.png: 1293 matches @ 292th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|| 3032/3256 [05:01<00:22, 10.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0069.png-peach_0168.png: 886 matches @ 293th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|| 3037/3256 [05:02<00:21,  9.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0058.png-peach_0003.png: 1373 matches @ 294th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|| 3054/3256 [05:03<00:20,  9.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0149.png-peach_0044.png: 910 matches @ 295th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|| 3057/3256 [05:04<00:20,  9.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0149.png-peach_0026.png: 690 matches @ 296th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|| 3063/3256 [05:04<00:19,  9.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0061.png-peach_0194.png: 239 matches @ 297th pair(disk+lightglue)\n",
      "disk> peach_0061.png-peach_0035.png: 245 matches @ 298th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|| 3067/3256 [05:05<00:18, 10.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0018.png-peach_0092.png: 351 matches @ 299th pair(disk+lightglue)\n",
      "disk> peach_0018.png-peach_0194.png: 793 matches @ 300th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|| 3071/3256 [05:05<00:18, 10.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0166.png-peach_0134.png: 297 matches @ 301th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|| 3073/3256 [05:05<00:18,  9.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0166.png-peach_0067.png: 1402 matches @ 302th pair(disk+lightglue)\n",
      "disk> peach_0166.png-peach_0019.png: 1033 matches @ 303th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|| 3078/3256 [05:06<00:17, 10.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0039.png-peach_0030.png: 1163 matches @ 304th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|| 3081/3256 [05:06<00:17,  9.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0039.png-peach_0036.png: 840 matches @ 305th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|| 3090/3256 [05:07<00:16, 10.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0039.png-peach_0130.png: 2747 matches @ 306th pair(disk+lightglue)\n",
      "disk> peach_0092.png-peach_0194.png: 583 matches @ 307th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|| 3111/3256 [05:09<00:14, 10.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0030.png-peach_0036.png: 1496 matches @ 308th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|| 3122/3256 [05:10<00:13,  9.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0178.png-peach_0171.png: 367 matches @ 309th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|| 3135/3256 [05:11<00:12, 10.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0052.png-peach_0137.png: 719 matches @ 310th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|| 3138/3256 [05:12<00:11,  9.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0160.png-peach_0197.png: 957 matches @ 311th pair(disk+lightglue)\n",
      "disk> peach_0160.png-peach_0179.png: 949 matches @ 312th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|| 3141/3256 [05:12<00:11,  9.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0160.png-peach_0005.png: 902 matches @ 313th pair(disk+lightglue)\n",
      "disk> peach_0160.png-peach_0182.png: 1348 matches @ 314th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 3143/3256 [05:12<00:11,  9.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0160.png-peach_0176.png: 940 matches @ 315th pair(disk+lightglue)\n",
      "disk> peach_0160.png-peach_0065.png: 249 matches @ 316th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 3148/3256 [05:13<00:10,  9.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0197.png-peach_0179.png: 1756 matches @ 317th pair(disk+lightglue)\n",
      "disk> peach_0197.png-peach_0005.png: 1638 matches @ 318th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 3151/3256 [05:13<00:10,  9.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0197.png-peach_0182.png: 1525 matches @ 319th pair(disk+lightglue)\n",
      "disk> peach_0197.png-peach_0176.png: 2203 matches @ 320th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 3154/3256 [05:13<00:10,  9.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0179.png-peach_0005.png: 3091 matches @ 321th pair(disk+lightglue)\n",
      "disk> peach_0179.png-peach_0094.png: 967 matches @ 322th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 3158/3256 [05:14<00:09,  9.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0179.png-peach_0176.png: 1895 matches @ 323th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 3160/3256 [05:14<00:09,  9.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0008.png-peach_0044.png: 1402 matches @ 324th pair(disk+lightglue)\n",
      "disk> peach_0008.png-peach_0004.png: 2042 matches @ 325th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 3166/3256 [05:15<00:09,  9.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0186.png-peach_0147.png: 700 matches @ 326th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 3170/3256 [05:15<00:08,  9.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0186.png-peach_0168.png: 1520 matches @ 327th pair(disk+lightglue)\n",
      "disk> peach_0005.png-peach_0094.png: 1011 matches @ 328th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 3173/3256 [05:15<00:08,  9.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0005.png-peach_0182.png: 1517 matches @ 329th pair(disk+lightglue)\n",
      "disk> peach_0005.png-peach_0176.png: 1753 matches @ 330th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 3183/3256 [05:16<00:07,  9.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0094.png-peach_0182.png: 1195 matches @ 331th pair(disk+lightglue)\n",
      "disk> peach_0094.png-peach_0009.png: 1506 matches @ 332th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 3186/3256 [05:17<00:07,  9.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0094.png-peach_0065.png: 825 matches @ 333th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 3197/3256 [05:18<00:05, 10.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0134.png-peach_0019.png: 646 matches @ 334th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|| 3212/3256 [05:19<00:04, 10.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0147.png-peach_0168.png: 1037 matches @ 335th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|| 3214/3256 [05:19<00:04, 10.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0044.png-peach_0004.png: 1243 matches @ 336th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|| 3234/3256 [05:21<00:02, 10.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0182.png-peach_0009.png: 1038 matches @ 337th pair(disk+lightglue)\n",
      "disk> peach_0182.png-peach_0176.png: 1488 matches @ 338th pair(disk+lightglue)\n",
      "disk> peach_0182.png-peach_0065.png: 535 matches @ 339th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3242/3256 [05:22<00:01, 10.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0009.png-peach_0065.png: 490 matches @ 340th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3246/3256 [05:23<00:00, 10.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0037.png-peach_0076.png: 440 matches @ 341th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3250/3256 [05:23<00:00, 10.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0040.png-peach_0026.png: 1762 matches @ 342th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3256/3256 [05:24<00:00, 10.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> peach_0137.png-peach_0130.png: 202 matches @ 343th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features matched in  360.6589 sec (disk+LightGlue)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='3256' class='' max='3256' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3256/3256 03:51&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filter_FundamentalMatrix: 2416 matches --> 441 matches\n",
      "peach_0100.png-peach_0091.png: 2416 --> 441 matches\n",
      "filter_FundamentalMatrix: 471 matches --> 60 matches\n",
      "peach_0100.png-peach_0075.png: 471 --> 60 matches\n",
      "filter_FundamentalMatrix: 752 matches --> 162 matches\n",
      "peach_0100.png-peach_0128.png: 752 --> 162 matches\n",
      "filter_FundamentalMatrix: 2583 matches --> 496 matches\n",
      "peach_0091.png-peach_0075.png: 2583 --> 496 matches\n",
      "filter_FundamentalMatrix: 218 matches --> 38 matches\n",
      "peach_0091.png-peach_0087.png: 218 --> 38 matches\n",
      "filter_FundamentalMatrix: 1549 matches --> 169 matches\n",
      "peach_0091.png-peach_0143.png: 1549 --> 169 matches\n",
      "filter_FundamentalMatrix: 1591 matches --> 203 matches\n",
      "peach_0091.png-peach_0081.png: 1591 --> 203 matches\n",
      "filter_FundamentalMatrix: 1394 matches --> 234 matches\n",
      "peach_0091.png-peach_0104.png: 1394 --> 234 matches\n",
      "filter_FundamentalMatrix: 1320 matches --> 158 matches\n",
      "peach_0091.png-peach_0141.png: 1320 --> 158 matches\n",
      "filter_FundamentalMatrix: 2883 matches --> 509 matches\n",
      "peach_0091.png-peach_0128.png: 2883 --> 509 matches\n",
      "filter_FundamentalMatrix: 1296 matches --> 148 matches\n",
      "peach_0091.png-peach_0199.png: 1296 --> 148 matches\n",
      "filter_FundamentalMatrix: 740 matches --> 70 matches\n",
      "peach_0091.png-peach_0044.png: 740 --> 70 matches\n",
      "filter_FundamentalMatrix: 1164 matches --> 133 matches\n",
      "peach_0091.png-peach_0076.png: 1164 --> 133 matches\n",
      "filter_FundamentalMatrix: 2852 matches --> 571 matches\n",
      "peach_0075.png-peach_0087.png: 2852 --> 571 matches\n",
      "filter_FundamentalMatrix: 2169 matches --> 268 matches\n",
      "peach_0075.png-peach_0143.png: 2169 --> 268 matches\n",
      "filter_FundamentalMatrix: 257 matches --> 24 matches\n",
      "peach_0075.png-peach_0033.png: 257 --> 24 matches\n",
      "filter_FundamentalMatrix: 2123 matches --> 284 matches\n",
      "peach_0075.png-peach_0081.png: 2123 --> 284 matches\n",
      "filter_FundamentalMatrix: 1957 matches --> 419 matches\n",
      "peach_0075.png-peach_0104.png: 1957 --> 419 matches\n",
      "filter_FundamentalMatrix: 1185 matches --> 147 matches\n",
      "peach_0075.png-peach_0141.png: 1185 --> 147 matches\n",
      "filter_FundamentalMatrix: 245 matches --> 25 matches\n",
      "peach_0075.png-peach_0073.png: 245 --> 25 matches\n",
      "filter_FundamentalMatrix: 2809 matches --> 556 matches\n",
      "peach_0075.png-peach_0128.png: 2809 --> 556 matches\n",
      "filter_FundamentalMatrix: 1056 matches --> 149 matches\n",
      "peach_0075.png-peach_0146.png: 1056 --> 149 matches\n",
      "filter_FundamentalMatrix: 277 matches --> 33 matches\n",
      "peach_0075.png-peach_0134.png: 277 --> 33 matches\n",
      "filter_FundamentalMatrix: 699 matches --> 54 matches\n",
      "peach_0075.png-peach_0044.png: 699 --> 54 matches\n",
      "filter_FundamentalMatrix: 383 matches --> 38 matches\n",
      "peach_0075.png-peach_0004.png: 383 --> 38 matches\n",
      "filter_FundamentalMatrix: 769 matches --> 94 matches\n",
      "peach_0075.png-peach_0037.png: 769 --> 94 matches\n",
      "filter_FundamentalMatrix: 425 matches --> 73 matches\n",
      "peach_0087.png-peach_0089.png: 425 --> 73 matches\n",
      "filter_FundamentalMatrix: 469 matches --> 56 matches\n",
      "peach_0087.png-peach_0143.png: 469 --> 56 matches\n",
      "filter_FundamentalMatrix: 842 matches --> 122 matches\n",
      "peach_0087.png-peach_0183.png: 842 --> 122 matches\n",
      "filter_FundamentalMatrix: 2379 matches --> 385 matches\n",
      "peach_0087.png-peach_0033.png: 2379 --> 385 matches\n",
      "filter_FundamentalMatrix: 569 matches --> 53 matches\n",
      "peach_0087.png-peach_0081.png: 569 --> 53 matches\n",
      "filter_FundamentalMatrix: 1998 matches --> 405 matches\n",
      "peach_0087.png-peach_0104.png: 1998 --> 405 matches\n",
      "filter_FundamentalMatrix: 1796 matches --> 260 matches\n",
      "peach_0087.png-peach_0128.png: 1796 --> 260 matches\n",
      "filter_FundamentalMatrix: 2512 matches --> 504 matches\n",
      "peach_0087.png-peach_0146.png: 2512 --> 504 matches\n",
      "filter_FundamentalMatrix: 271 matches --> 36 matches\n",
      "peach_0087.png-peach_0044.png: 271 --> 36 matches\n",
      "filter_FundamentalMatrix: 3909 matches --> 1015 matches\n",
      "peach_0089.png-peach_0183.png: 3909 --> 1015 matches\n",
      "filter_FundamentalMatrix: 554 matches --> 68 matches\n",
      "peach_0089.png-peach_0185.png: 554 --> 68 matches\n",
      "filter_FundamentalMatrix: 2546 matches --> 431 matches\n",
      "peach_0089.png-peach_0033.png: 2546 --> 431 matches\n",
      "filter_FundamentalMatrix: 874 matches --> 129 matches\n",
      "peach_0089.png-peach_0146.png: 874 --> 129 matches\n",
      "filter_FundamentalMatrix: 573 matches --> 64 matches\n",
      "peach_0089.png-peach_0160.png: 573 --> 64 matches\n",
      "filter_FundamentalMatrix: 619 matches --> 79 matches\n",
      "peach_0089.png-peach_0197.png: 619 --> 79 matches\n",
      "filter_FundamentalMatrix: 684 matches --> 82 matches\n",
      "peach_0089.png-peach_0182.png: 684 --> 82 matches\n",
      "filter_FundamentalMatrix: 3506 matches --> 688 matches\n",
      "peach_0089.png-peach_0065.png: 3506 --> 688 matches\n",
      "filter_FundamentalMatrix: 3142 matches --> 772 matches\n",
      "peach_0028.png-peach_0161.png: 3142 --> 772 matches\n",
      "filter_FundamentalMatrix: 2306 matches --> 534 matches\n",
      "peach_0028.png-peach_0088.png: 2306 --> 534 matches\n",
      "filter_FundamentalMatrix: 1242 matches --> 177 matches\n",
      "peach_0028.png-peach_0016.png: 1242 --> 177 matches\n",
      "filter_FundamentalMatrix: 715 matches --> 64 matches\n",
      "peach_0161.png-peach_0189.png: 715 --> 64 matches\n",
      "filter_FundamentalMatrix: 832 matches --> 85 matches\n",
      "peach_0161.png-peach_0155.png: 832 --> 85 matches\n",
      "filter_FundamentalMatrix: 1824 matches --> 334 matches\n",
      "peach_0161.png-peach_0088.png: 1824 --> 334 matches\n",
      "filter_FundamentalMatrix: 1009 matches --> 135 matches\n",
      "peach_0189.png-peach_0155.png: 1009 --> 135 matches\n",
      "filter_FundamentalMatrix: 257 matches --> 19 matches\n",
      "peach_0189.png-peach_0042.png: 257 --> 19 matches\n",
      "filter_FundamentalMatrix: 936 matches --> 156 matches\n",
      "peach_0155.png-peach_0042.png: 936 --> 156 matches\n",
      "filter_FundamentalMatrix: 204 matches --> 25 matches\n",
      "peach_0155.png-peach_0025.png: 204 --> 25 matches\n",
      "filter_FundamentalMatrix: 205 matches --> 17 matches\n",
      "peach_0155.png-peach_0103.png: 205 --> 17 matches\n",
      "filter_FundamentalMatrix: 1005 matches --> 152 matches\n",
      "peach_0042.png-peach_0188.png: 1005 --> 152 matches\n",
      "filter_FundamentalMatrix: 2525 matches --> 420 matches\n",
      "peach_0042.png-peach_0086.png: 2525 --> 420 matches\n",
      "filter_FundamentalMatrix: 1592 matches --> 286 matches\n",
      "peach_0042.png-peach_0025.png: 1592 --> 286 matches\n",
      "filter_FundamentalMatrix: 1590 matches --> 203 matches\n",
      "peach_0042.png-peach_0016.png: 1590 --> 203 matches\n",
      "filter_FundamentalMatrix: 1805 matches --> 462 matches\n",
      "peach_0042.png-peach_0103.png: 1805 --> 462 matches\n",
      "filter_FundamentalMatrix: 1616 matches --> 294 matches\n",
      "peach_0188.png-peach_0025.png: 1616 --> 294 matches\n",
      "filter_FundamentalMatrix: 1971 matches --> 456 matches\n",
      "peach_0188.png-peach_0103.png: 1971 --> 456 matches\n",
      "filter_FundamentalMatrix: 3535 matches --> 928 matches\n",
      "peach_0121.png-peach_0126.png: 3535 --> 928 matches\n",
      "filter_FundamentalMatrix: 1040 matches --> 156 matches\n",
      "peach_0121.png-peach_0180.png: 1040 --> 156 matches\n",
      "filter_FundamentalMatrix: 1462 matches --> 232 matches\n",
      "peach_0121.png-peach_0107.png: 1462 --> 232 matches\n",
      "filter_FundamentalMatrix: 2400 matches --> 628 matches\n",
      "peach_0045.png-peach_0080.png: 2400 --> 628 matches\n",
      "filter_FundamentalMatrix: 1787 matches --> 302 matches\n",
      "peach_0045.png-peach_0107.png: 1787 --> 302 matches\n",
      "filter_FundamentalMatrix: 1192 matches --> 188 matches\n",
      "peach_0080.png-peach_0107.png: 1192 --> 188 matches\n",
      "filter_FundamentalMatrix: 644 matches --> 43 matches\n",
      "peach_0043.png-peach_0145.png: 644 --> 43 matches\n",
      "filter_FundamentalMatrix: 1496 matches --> 262 matches\n",
      "peach_0136.png-peach_0029.png: 1496 --> 262 matches\n",
      "filter_FundamentalMatrix: 843 matches --> 112 matches\n",
      "peach_0136.png-peach_0050.png: 843 --> 112 matches\n",
      "filter_FundamentalMatrix: 755 matches --> 94 matches\n",
      "peach_0136.png-peach_0001.png: 755 --> 94 matches\n",
      "filter_FundamentalMatrix: 1099 matches --> 132 matches\n",
      "peach_0136.png-peach_0159.png: 1099 --> 132 matches\n",
      "filter_FundamentalMatrix: 3522 matches --> 857 matches\n",
      "peach_0136.png-peach_0113.png: 3522 --> 857 matches\n",
      "filter_FundamentalMatrix: 807 matches --> 77 matches\n",
      "peach_0135.png-peach_0032.png: 807 --> 77 matches\n",
      "filter_FundamentalMatrix: 3363 matches --> 816 matches\n",
      "peach_0158.png-peach_0133.png: 3363 --> 816 matches\n",
      "filter_FundamentalMatrix: 1219 matches --> 146 matches\n",
      "peach_0158.png-peach_0168.png: 1219 --> 146 matches\n",
      "filter_FundamentalMatrix: 1561 matches --> 249 matches\n",
      "peach_0151.png-peach_0154.png: 1561 --> 249 matches\n",
      "filter_FundamentalMatrix: 1328 matches --> 213 matches\n",
      "peach_0151.png-peach_0169.png: 1328 --> 213 matches\n",
      "filter_FundamentalMatrix: 1526 matches --> 255 matches\n",
      "peach_0151.png-peach_0171.png: 1526 --> 255 matches\n",
      "filter_FundamentalMatrix: 400 matches --> 74 matches\n",
      "peach_0154.png-peach_0169.png: 400 --> 74 matches\n",
      "filter_FundamentalMatrix: 3727 matches --> 1061 matches\n",
      "peach_0154.png-peach_0171.png: 3727 --> 1061 matches\n",
      "filter_FundamentalMatrix: 2950 matches --> 610 matches\n",
      "peach_0097.png-peach_0061.png: 2950 --> 610 matches\n",
      "filter_FundamentalMatrix: 248 matches --> 27 matches\n",
      "peach_0097.png-peach_0051.png: 248 --> 27 matches\n",
      "filter_FundamentalMatrix: 1013 matches --> 176 matches\n",
      "peach_0097.png-peach_0035.png: 1013 --> 176 matches\n",
      "filter_FundamentalMatrix: 4964 matches --> 1555 matches\n",
      "peach_0024.png-peach_0084.png: 4964 --> 1555 matches\n",
      "skipped key1=peach_0024.png, key2=peach_0118.png: mkpts.shape=(14, 4) after filtered.\n",
      "filter_FundamentalMatrix: 3415 matches --> 1099 matches\n",
      "peach_0116.png-peach_0006.png: 3415 --> 1099 matches\n",
      "filter_FundamentalMatrix: 1554 matches --> 224 matches\n",
      "peach_0116.png-peach_0118.png: 1554 --> 224 matches\n",
      "filter_FundamentalMatrix: 1202 matches --> 170 matches\n",
      "peach_0006.png-peach_0118.png: 1202 --> 170 matches\n",
      "filter_FundamentalMatrix: 250 matches --> 17 matches\n",
      "peach_0175.png-peach_0132.png: 250 --> 17 matches\n",
      "filter_FundamentalMatrix: 361 matches --> 76 matches\n",
      "peach_0132.png-peach_0181.png: 361 --> 76 matches\n",
      "filter_FundamentalMatrix: 4868 matches --> 1581 matches\n",
      "peach_0057.png-peach_0095.png: 4868 --> 1581 matches\n",
      "filter_FundamentalMatrix: 792 matches --> 56 matches\n",
      "peach_0057.png-peach_0090.png: 792 --> 56 matches\n",
      "filter_FundamentalMatrix: 622 matches --> 59 matches\n",
      "peach_0057.png-peach_0063.png: 622 --> 59 matches\n",
      "filter_FundamentalMatrix: 784 matches --> 59 matches\n",
      "peach_0002.png-peach_0010.png: 784 --> 59 matches\n",
      "filter_FundamentalMatrix: 1662 matches --> 272 matches\n",
      "peach_0086.png-peach_0025.png: 1662 --> 272 matches\n",
      "filter_FundamentalMatrix: 2288 matches --> 459 matches\n",
      "peach_0086.png-peach_0103.png: 2288 --> 459 matches\n",
      "filter_FundamentalMatrix: 2155 matches --> 386 matches\n",
      "peach_0064.png-peach_0145.png: 2155 --> 386 matches\n",
      "filter_FundamentalMatrix: 2100 matches --> 416 matches\n",
      "peach_0064.png-peach_0007.png: 2100 --> 416 matches\n",
      "filter_FundamentalMatrix: 1215 matches --> 175 matches\n",
      "peach_0064.png-peach_0177.png: 1215 --> 175 matches\n",
      "filter_FundamentalMatrix: 485 matches --> 60 matches\n",
      "peach_0064.png-peach_0131.png: 485 --> 60 matches\n",
      "filter_FundamentalMatrix: 721 matches --> 87 matches\n",
      "peach_0064.png-peach_0196.png: 721 --> 87 matches\n",
      "filter_FundamentalMatrix: 876 matches --> 118 matches\n",
      "peach_0064.png-peach_0034.png: 876 --> 118 matches\n",
      "filter_FundamentalMatrix: 1609 matches --> 234 matches\n",
      "peach_0064.png-peach_0117.png: 1609 --> 234 matches\n",
      "filter_FundamentalMatrix: 6147 matches --> 2508 matches\n",
      "peach_0145.png-peach_0007.png: 6147 --> 2508 matches\n",
      "filter_FundamentalMatrix: 3132 matches --> 700 matches\n",
      "peach_0145.png-peach_0177.png: 3132 --> 700 matches\n",
      "filter_FundamentalMatrix: 1613 matches --> 263 matches\n",
      "peach_0145.png-peach_0174.png: 1613 --> 263 matches\n",
      "filter_FundamentalMatrix: 3365 matches --> 818 matches\n",
      "peach_0007.png-peach_0177.png: 3365 --> 818 matches\n",
      "filter_FundamentalMatrix: 1788 matches --> 311 matches\n",
      "peach_0007.png-peach_0174.png: 1788 --> 311 matches\n",
      "filter_FundamentalMatrix: 590 matches --> 84 matches\n",
      "peach_0007.png-peach_0083.png: 590 --> 84 matches\n",
      "filter_FundamentalMatrix: 2095 matches --> 359 matches\n",
      "peach_0007.png-peach_0131.png: 2095 --> 359 matches\n",
      "filter_FundamentalMatrix: 2000 matches --> 363 matches\n",
      "peach_0007.png-peach_0196.png: 2000 --> 363 matches\n",
      "filter_FundamentalMatrix: 3131 matches --> 743 matches\n",
      "peach_0177.png-peach_0174.png: 3131 --> 743 matches\n",
      "filter_FundamentalMatrix: 1528 matches --> 261 matches\n",
      "peach_0177.png-peach_0131.png: 1528 --> 261 matches\n",
      "filter_FundamentalMatrix: 260 matches --> 18 matches\n",
      "peach_0177.png-peach_0047.png: 260 --> 18 matches\n",
      "filter_FundamentalMatrix: 1103 matches --> 141 matches\n",
      "peach_0174.png-peach_0102.png: 1103 --> 141 matches\n",
      "filter_FundamentalMatrix: 230 matches --> 34 matches\n",
      "peach_0083.png-peach_0093.png: 230 --> 34 matches\n",
      "filter_FundamentalMatrix: 210 matches --> 23 matches\n",
      "peach_0083.png-peach_0129.png: 210 --> 23 matches\n",
      "filter_FundamentalMatrix: 615 matches --> 37 matches\n",
      "peach_0029.png-peach_0115.png: 615 --> 37 matches\n",
      "skipped key1=peach_0029.png, key2=peach_0129.png: mkpts.shape=(10, 4) after filtered.\n",
      "filter_FundamentalMatrix: 4438 matches --> 1486 matches\n",
      "peach_0050.png-peach_0159.png: 4438 --> 1486 matches\n",
      "filter_FundamentalMatrix: 1897 matches --> 333 matches\n",
      "peach_0050.png-peach_0113.png: 1897 --> 333 matches\n",
      "filter_FundamentalMatrix: 2504 matches --> 547 matches\n",
      "peach_0001.png-peach_0172.png: 2504 --> 547 matches\n",
      "filter_FundamentalMatrix: 2136 matches --> 289 matches\n",
      "peach_0001.png-peach_0041.png: 2136 --> 289 matches\n",
      "filter_FundamentalMatrix: 1277 matches --> 255 matches\n",
      "peach_0001.png-peach_0013.png: 1277 --> 255 matches\n",
      "filter_FundamentalMatrix: 1065 matches --> 135 matches\n",
      "peach_0001.png-peach_0085.png: 1065 --> 135 matches\n",
      "filter_FundamentalMatrix: 744 matches --> 73 matches\n",
      "peach_0068.png-peach_0142.png: 744 --> 73 matches\n",
      "filter_FundamentalMatrix: 2504 matches --> 498 matches\n",
      "peach_0068.png-peach_0186.png: 2504 --> 498 matches\n",
      "filter_FundamentalMatrix: 1947 matches --> 421 matches\n",
      "peach_0068.png-peach_0147.png: 1947 --> 421 matches\n",
      "filter_FundamentalMatrix: 5627 matches --> 2050 matches\n",
      "peach_0068.png-peach_0168.png: 5627 --> 2050 matches\n",
      "filter_FundamentalMatrix: 2023 matches --> 476 matches\n",
      "peach_0172.png-peach_0041.png: 2023 --> 476 matches\n",
      "filter_FundamentalMatrix: 1255 matches --> 209 matches\n",
      "peach_0172.png-peach_0013.png: 1255 --> 209 matches\n",
      "filter_FundamentalMatrix: 1927 matches --> 328 matches\n",
      "peach_0172.png-peach_0085.png: 1927 --> 328 matches\n",
      "filter_FundamentalMatrix: 4137 matches --> 1809 matches\n",
      "peach_0143.png-peach_0081.png: 4137 --> 1809 matches\n",
      "filter_FundamentalMatrix: 2870 matches --> 652 matches\n",
      "peach_0143.png-peach_0141.png: 2870 --> 652 matches\n",
      "filter_FundamentalMatrix: 3033 matches --> 725 matches\n",
      "peach_0143.png-peach_0199.png: 3033 --> 725 matches\n",
      "filter_FundamentalMatrix: 358 matches --> 21 matches\n",
      "peach_0143.png-peach_0044.png: 358 --> 21 matches\n",
      "filter_FundamentalMatrix: 3096 matches --> 735 matches\n",
      "peach_0143.png-peach_0037.png: 3096 --> 735 matches\n",
      "filter_FundamentalMatrix: 897 matches --> 268 matches\n",
      "peach_0143.png-peach_0076.png: 897 --> 268 matches\n",
      "filter_FundamentalMatrix: 3815 matches --> 1140 matches\n",
      "peach_0041.png-peach_0085.png: 3815 --> 1140 matches\n",
      "filter_FundamentalMatrix: 5704 matches --> 2520 matches\n",
      "peach_0106.png-peach_0167.png: 5704 --> 2520 matches\n",
      "filter_FundamentalMatrix: 308 matches --> 21 matches\n",
      "peach_0106.png-peach_0031.png: 308 --> 21 matches\n",
      "filter_FundamentalMatrix: 2498 matches --> 343 matches\n",
      "peach_0106.png-peach_0148.png: 2498 --> 343 matches\n",
      "filter_FundamentalMatrix: 259 matches --> 34 matches\n",
      "peach_0106.png-peach_0027.png: 259 --> 34 matches\n",
      "filter_FundamentalMatrix: 3907 matches --> 1230 matches\n",
      "peach_0106.png-peach_0112.png: 3907 --> 1230 matches\n",
      "filter_FundamentalMatrix: 465 matches --> 61 matches\n",
      "peach_0106.png-peach_0111.png: 465 --> 61 matches\n",
      "filter_FundamentalMatrix: 1031 matches --> 136 matches\n",
      "peach_0106.png-peach_0073.png: 1031 --> 136 matches\n",
      "filter_FundamentalMatrix: 2104 matches --> 743 matches\n",
      "peach_0106.png-peach_0099.png: 2104 --> 743 matches\n",
      "filter_FundamentalMatrix: 258 matches --> 16 matches\n",
      "peach_0106.png-peach_0055.png: 258 --> 16 matches\n",
      "filter_FundamentalMatrix: 201 matches --> 36 matches\n",
      "peach_0106.png-peach_0058.png: 201 --> 36 matches\n",
      "filter_FundamentalMatrix: 279 matches --> 26 matches\n",
      "peach_0106.png-peach_0166.png: 279 --> 26 matches\n",
      "filter_FundamentalMatrix: 1435 matches --> 198 matches\n",
      "peach_0106.png-peach_0134.png: 1435 --> 198 matches\n",
      "filter_FundamentalMatrix: 509 matches --> 38 matches\n",
      "peach_0106.png-peach_0003.png: 509 --> 38 matches\n",
      "filter_FundamentalMatrix: 218 matches --> 23 matches\n",
      "peach_0106.png-peach_0019.png: 218 --> 23 matches\n",
      "filter_FundamentalMatrix: 1286 matches --> 269 matches\n",
      "peach_0102.png-peach_0131.png: 1286 --> 269 matches\n",
      "filter_FundamentalMatrix: 808 matches --> 158 matches\n",
      "peach_0102.png-peach_0196.png: 808 --> 158 matches\n",
      "filter_FundamentalMatrix: 2723 matches --> 695 matches\n",
      "peach_0102.png-peach_0060.png: 2723 --> 695 matches\n",
      "filter_FundamentalMatrix: 222 matches --> 29 matches\n",
      "peach_0167.png-peach_0031.png: 222 --> 29 matches\n",
      "filter_FundamentalMatrix: 3007 matches --> 503 matches\n",
      "peach_0167.png-peach_0148.png: 3007 --> 503 matches\n",
      "filter_FundamentalMatrix: 252 matches --> 32 matches\n",
      "peach_0167.png-peach_0027.png: 252 --> 32 matches\n",
      "filter_FundamentalMatrix: 4360 matches --> 1251 matches\n",
      "peach_0167.png-peach_0112.png: 4360 --> 1251 matches\n",
      "filter_FundamentalMatrix: 219 matches --> 27 matches\n",
      "peach_0167.png-peach_0162.png: 219 --> 27 matches\n",
      "filter_FundamentalMatrix: 605 matches --> 66 matches\n",
      "peach_0167.png-peach_0111.png: 605 --> 66 matches\n",
      "filter_FundamentalMatrix: 771 matches --> 101 matches\n",
      "peach_0167.png-peach_0073.png: 771 --> 101 matches\n",
      "filter_FundamentalMatrix: 2023 matches --> 672 matches\n",
      "peach_0167.png-peach_0099.png: 2023 --> 672 matches\n",
      "filter_FundamentalMatrix: 205 matches --> 31 matches\n",
      "peach_0167.png-peach_0019.png: 205 --> 31 matches\n",
      "filter_FundamentalMatrix: 4370 matches --> 1463 matches\n",
      "peach_0131.png-peach_0196.png: 4370 --> 1463 matches\n",
      "filter_FundamentalMatrix: 3072 matches --> 948 matches\n",
      "peach_0131.png-peach_0060.png: 3072 --> 948 matches\n",
      "filter_FundamentalMatrix: 2044 matches --> 261 matches\n",
      "peach_0184.png-peach_0031.png: 2044 --> 261 matches\n",
      "skipped key1=peach_0184.png, key2=peach_0059.png: mkpts.shape=(9, 4) after filtered.\n",
      "filter_FundamentalMatrix: 2534 matches --> 681 matches\n",
      "peach_0196.png-peach_0060.png: 2534 --> 681 matches\n",
      "filter_FundamentalMatrix: 1308 matches --> 189 matches\n",
      "peach_0156.png-peach_0191.png: 1308 --> 189 matches\n",
      "filter_FundamentalMatrix: 675 matches --> 60 matches\n",
      "peach_0074.png-peach_0053.png: 675 --> 60 matches\n",
      "filter_FundamentalMatrix: 1449 matches --> 201 matches\n",
      "peach_0074.png-peach_0014.png: 1449 --> 201 matches\n",
      "filter_FundamentalMatrix: 2953 matches --> 644 matches\n",
      "peach_0074.png-peach_0195.png: 2953 --> 644 matches\n",
      "filter_FundamentalMatrix: 473 matches --> 20 matches\n",
      "peach_0056.png-peach_0141.png: 473 --> 20 matches\n",
      "filter_FundamentalMatrix: 1336 matches --> 197 matches\n",
      "peach_0056.png-peach_0149.png: 1336 --> 197 matches\n",
      "filter_FundamentalMatrix: 2226 matches --> 432 matches\n",
      "peach_0056.png-peach_0044.png: 2226 --> 432 matches\n",
      "filter_FundamentalMatrix: 2082 matches --> 417 matches\n",
      "peach_0053.png-peach_0152.png: 2082 --> 417 matches\n",
      "filter_FundamentalMatrix: 2972 matches --> 681 matches\n",
      "peach_0053.png-peach_0014.png: 2972 --> 681 matches\n",
      "filter_FundamentalMatrix: 2182 matches --> 367 matches\n",
      "peach_0124.png-peach_0071.png: 2182 --> 367 matches\n",
      "filter_FundamentalMatrix: 747 matches --> 92 matches\n",
      "peach_0124.png-peach_0093.png: 747 --> 92 matches\n",
      "filter_FundamentalMatrix: 1708 matches --> 335 matches\n",
      "peach_0124.png-peach_0018.png: 1708 --> 335 matches\n",
      "filter_FundamentalMatrix: 256 matches --> 24 matches\n",
      "peach_0084.png-peach_0118.png: 256 --> 24 matches\n",
      "filter_FundamentalMatrix: 884 matches --> 167 matches\n",
      "peach_0032.png-peach_0013.png: 884 --> 167 matches\n",
      "filter_FundamentalMatrix: 1586 matches --> 369 matches\n",
      "peach_0032.png-peach_0069.png: 1586 --> 369 matches\n",
      "filter_FundamentalMatrix: 5084 matches --> 2051 matches\n",
      "peach_0098.png-peach_0152.png: 5084 --> 2051 matches\n",
      "filter_FundamentalMatrix: 616 matches --> 76 matches\n",
      "peach_0098.png-peach_0072.png: 616 --> 76 matches\n",
      "filter_FundamentalMatrix: 871 matches --> 110 matches\n",
      "peach_0098.png-peach_0014.png: 871 --> 110 matches\n",
      "filter_FundamentalMatrix: 267 matches --> 33 matches\n",
      "peach_0148.png-peach_0027.png: 267 --> 33 matches\n",
      "filter_FundamentalMatrix: 634 matches --> 80 matches\n",
      "peach_0148.png-peach_0111.png: 634 --> 80 matches\n",
      "filter_FundamentalMatrix: 365 matches --> 55 matches\n",
      "peach_0148.png-peach_0058.png: 365 --> 55 matches\n",
      "filter_FundamentalMatrix: 276 matches --> 42 matches\n",
      "peach_0148.png-peach_0003.png: 276 --> 42 matches\n",
      "filter_FundamentalMatrix: 3285 matches --> 642 matches\n",
      "peach_0110.png-peach_0125.png: 3285 --> 642 matches\n",
      "filter_FundamentalMatrix: 2394 matches --> 371 matches\n",
      "peach_0110.png-peach_0185.png: 2394 --> 371 matches\n",
      "filter_FundamentalMatrix: 3177 matches --> 660 matches\n",
      "peach_0110.png-peach_0108.png: 3177 --> 660 matches\n",
      "filter_FundamentalMatrix: 2193 matches --> 336 matches\n",
      "peach_0110.png-peach_0160.png: 2193 --> 336 matches\n",
      "filter_FundamentalMatrix: 2531 matches --> 440 matches\n",
      "peach_0110.png-peach_0197.png: 2531 --> 440 matches\n",
      "filter_FundamentalMatrix: 2896 matches --> 486 matches\n",
      "peach_0110.png-peach_0179.png: 2896 --> 486 matches\n",
      "filter_FundamentalMatrix: 2901 matches --> 500 matches\n",
      "peach_0110.png-peach_0005.png: 2901 --> 500 matches\n",
      "filter_FundamentalMatrix: 3614 matches --> 836 matches\n",
      "peach_0110.png-peach_0094.png: 3614 --> 836 matches\n",
      "filter_FundamentalMatrix: 5517 matches --> 1975 matches\n",
      "peach_0110.png-peach_0182.png: 5517 --> 1975 matches\n",
      "filter_FundamentalMatrix: 4021 matches --> 1398 matches\n",
      "peach_0110.png-peach_0009.png: 4021 --> 1398 matches\n",
      "filter_FundamentalMatrix: 2381 matches --> 345 matches\n",
      "peach_0110.png-peach_0176.png: 2381 --> 345 matches\n",
      "filter_FundamentalMatrix: 1460 matches --> 170 matches\n",
      "peach_0110.png-peach_0065.png: 1460 --> 170 matches\n",
      "filter_FundamentalMatrix: 680 matches --> 119 matches\n",
      "peach_0071.png-peach_0101.png: 680 --> 119 matches\n",
      "filter_FundamentalMatrix: 1844 matches --> 191 matches\n",
      "peach_0071.png-peach_0061.png: 1844 --> 191 matches\n",
      "filter_FundamentalMatrix: 1445 matches --> 244 matches\n",
      "peach_0071.png-peach_0018.png: 1445 --> 244 matches\n",
      "filter_FundamentalMatrix: 1742 matches --> 265 matches\n",
      "peach_0071.png-peach_0194.png: 1742 --> 265 matches\n",
      "filter_FundamentalMatrix: 271 matches --> 40 matches\n",
      "peach_0025.png-peach_0016.png: 271 --> 40 matches\n",
      "filter_FundamentalMatrix: 2466 matches --> 590 matches\n",
      "peach_0025.png-peach_0103.png: 2466 --> 590 matches\n",
      "filter_FundamentalMatrix: 2088 matches --> 367 matches\n",
      "peach_0138.png-peach_0021.png: 2088 --> 367 matches\n",
      "filter_FundamentalMatrix: 1342 matches --> 222 matches\n",
      "peach_0138.png-peach_0072.png: 1342 --> 222 matches\n",
      "filter_FundamentalMatrix: 3766 matches --> 859 matches\n",
      "peach_0138.png-peach_0077.png: 3766 --> 859 matches\n",
      "filter_FundamentalMatrix: 221 matches --> 20 matches\n",
      "peach_0070.png-peach_0198.png: 221 --> 20 matches\n",
      "filter_FundamentalMatrix: 4010 matches --> 1377 matches\n",
      "peach_0070.png-peach_0190.png: 4010 --> 1377 matches\n",
      "filter_FundamentalMatrix: 611 matches --> 77 matches\n",
      "peach_0047.png-peach_0115.png: 611 --> 77 matches\n",
      "filter_FundamentalMatrix: 611 matches --> 91 matches\n",
      "peach_0119.png-peach_0157.png: 611 --> 91 matches\n",
      "filter_FundamentalMatrix: 2168 matches --> 450 matches\n",
      "peach_0115.png-peach_0015.png: 2168 --> 450 matches\n",
      "filter_FundamentalMatrix: 245 matches --> 20 matches\n",
      "peach_0152.png-peach_0072.png: 245 --> 20 matches\n",
      "filter_FundamentalMatrix: 1099 matches --> 168 matches\n",
      "peach_0152.png-peach_0014.png: 1099 --> 168 matches\n",
      "filter_FundamentalMatrix: 1727 matches --> 246 matches\n",
      "peach_0127.png-peach_0149.png: 1727 --> 246 matches\n",
      "filter_FundamentalMatrix: 1344 matches --> 240 matches\n",
      "peach_0127.png-peach_0139.png: 1344 --> 240 matches\n",
      "filter_FundamentalMatrix: 3574 matches --> 621 matches\n",
      "peach_0183.png-peach_0033.png: 3574 --> 621 matches\n",
      "filter_FundamentalMatrix: 208 matches --> 19 matches\n",
      "peach_0183.png-peach_0108.png: 208 --> 19 matches\n",
      "filter_FundamentalMatrix: 1841 matches --> 300 matches\n",
      "peach_0183.png-peach_0146.png: 1841 --> 300 matches\n",
      "filter_FundamentalMatrix: 279 matches --> 20 matches\n",
      "peach_0183.png-peach_0046.png: 279 --> 20 matches\n",
      "filter_FundamentalMatrix: 229 matches --> 25 matches\n",
      "peach_0183.png-peach_0079.png: 229 --> 25 matches\n",
      "filter_FundamentalMatrix: 247 matches --> 26 matches\n",
      "peach_0183.png-peach_0182.png: 247 --> 26 matches\n",
      "filter_FundamentalMatrix: 2908 matches --> 495 matches\n",
      "peach_0183.png-peach_0065.png: 2908 --> 495 matches\n",
      "filter_FundamentalMatrix: 552 matches --> 88 matches\n",
      "peach_0062.png-peach_0122.png: 552 --> 88 matches\n",
      "filter_FundamentalMatrix: 1108 matches --> 113 matches\n",
      "peach_0062.png-peach_0090.png: 1108 --> 113 matches\n",
      "filter_FundamentalMatrix: 958 matches --> 86 matches\n",
      "peach_0062.png-peach_0063.png: 958 --> 86 matches\n",
      "filter_FundamentalMatrix: 4440 matches --> 1550 matches\n",
      "peach_0021.png-peach_0072.png: 4440 --> 1550 matches\n",
      "filter_FundamentalMatrix: 3034 matches --> 575 matches\n",
      "peach_0021.png-peach_0077.png: 3034 --> 575 matches\n",
      "filter_FundamentalMatrix: 476 matches --> 57 matches\n",
      "peach_0027.png-peach_0112.png: 476 --> 57 matches\n",
      "filter_FundamentalMatrix: 1012 matches --> 154 matches\n",
      "peach_0027.png-peach_0058.png: 1012 --> 154 matches\n",
      "filter_FundamentalMatrix: 2668 matches --> 831 matches\n",
      "peach_0027.png-peach_0003.png: 2668 --> 831 matches\n",
      "filter_FundamentalMatrix: 465 matches --> 68 matches\n",
      "peach_0192.png-peach_0163.png: 465 --> 68 matches\n",
      "filter_FundamentalMatrix: 5909 matches --> 2545 matches\n",
      "peach_0125.png-peach_0108.png: 5909 --> 2545 matches\n",
      "filter_FundamentalMatrix: 4526 matches --> 1436 matches\n",
      "peach_0125.png-peach_0005.png: 4526 --> 1436 matches\n",
      "filter_FundamentalMatrix: 4013 matches --> 1753 matches\n",
      "peach_0125.png-peach_0094.png: 4013 --> 1753 matches\n",
      "filter_FundamentalMatrix: 2902 matches --> 507 matches\n",
      "peach_0125.png-peach_0182.png: 2902 --> 507 matches\n",
      "filter_FundamentalMatrix: 2337 matches --> 553 matches\n",
      "peach_0125.png-peach_0009.png: 2337 --> 553 matches\n",
      "filter_FundamentalMatrix: 877 matches --> 74 matches\n",
      "peach_0125.png-peach_0065.png: 877 --> 74 matches\n",
      "filter_FundamentalMatrix: 1625 matches --> 256 matches\n",
      "peach_0017.png-peach_0066.png: 1625 --> 256 matches\n",
      "filter_FundamentalMatrix: 2076 matches --> 419 matches\n",
      "peach_0114.png-peach_0191.png: 2076 --> 419 matches\n",
      "filter_FundamentalMatrix: 2977 matches --> 573 matches\n",
      "peach_0114.png-peach_0034.png: 2977 --> 573 matches\n",
      "filter_FundamentalMatrix: 2191 matches --> 351 matches\n",
      "peach_0114.png-peach_0117.png: 2191 --> 351 matches\n",
      "filter_FundamentalMatrix: 2309 matches --> 495 matches\n",
      "peach_0142.png-peach_0169.png: 2309 --> 495 matches\n",
      "filter_FundamentalMatrix: 2174 matches --> 385 matches\n",
      "peach_0142.png-peach_0186.png: 2174 --> 385 matches\n",
      "filter_FundamentalMatrix: 1011 matches --> 96 matches\n",
      "peach_0142.png-peach_0168.png: 1011 --> 96 matches\n",
      "filter_FundamentalMatrix: 317 matches --> 20 matches\n",
      "peach_0112.png-peach_0111.png: 317 --> 20 matches\n",
      "filter_FundamentalMatrix: 763 matches --> 105 matches\n",
      "peach_0112.png-peach_0073.png: 763 --> 105 matches\n",
      "filter_FundamentalMatrix: 224 matches --> 29 matches\n",
      "peach_0112.png-peach_0193.png: 224 --> 29 matches\n",
      "filter_FundamentalMatrix: 4277 matches --> 1722 matches\n",
      "peach_0112.png-peach_0099.png: 4277 --> 1722 matches\n",
      "filter_FundamentalMatrix: 286 matches --> 28 matches\n",
      "peach_0112.png-peach_0166.png: 286 --> 28 matches\n",
      "filter_FundamentalMatrix: 1702 matches --> 231 matches\n",
      "peach_0112.png-peach_0134.png: 1702 --> 231 matches\n",
      "filter_FundamentalMatrix: 227 matches --> 29 matches\n",
      "peach_0112.png-peach_0003.png: 227 --> 29 matches\n",
      "filter_FundamentalMatrix: 338 matches --> 42 matches\n",
      "peach_0112.png-peach_0067.png: 338 --> 42 matches\n",
      "filter_FundamentalMatrix: 258 matches --> 22 matches\n",
      "peach_0112.png-peach_0019.png: 258 --> 22 matches\n",
      "filter_FundamentalMatrix: 788 matches --> 76 matches\n",
      "peach_0095.png-peach_0090.png: 788 --> 76 matches\n",
      "filter_FundamentalMatrix: 693 matches --> 33 matches\n",
      "peach_0095.png-peach_0063.png: 693 --> 33 matches\n",
      "filter_FundamentalMatrix: 211 matches --> 22 matches\n",
      "peach_0095.png-peach_0065.png: 211 --> 22 matches\n",
      "filter_FundamentalMatrix: 4123 matches --> 1094 matches\n",
      "peach_0038.png-peach_0162.png: 4123 --> 1094 matches\n",
      "filter_FundamentalMatrix: 312 matches --> 60 matches\n",
      "peach_0038.png-peach_0122.png: 312 --> 60 matches\n",
      "filter_FundamentalMatrix: 1989 matches --> 476 matches\n",
      "peach_0038.png-peach_0111.png: 1989 --> 476 matches\n",
      "filter_FundamentalMatrix: 286 matches --> 42 matches\n",
      "peach_0038.png-peach_0073.png: 286 --> 42 matches\n",
      "filter_FundamentalMatrix: 260 matches --> 52 matches\n",
      "peach_0038.png-peach_0046.png: 260 --> 52 matches\n",
      "filter_FundamentalMatrix: 357 matches --> 38 matches\n",
      "peach_0038.png-peach_0079.png: 357 --> 38 matches\n",
      "filter_FundamentalMatrix: 246 matches --> 44 matches\n",
      "peach_0162.png-peach_0122.png: 246 --> 44 matches\n",
      "filter_FundamentalMatrix: 2559 matches --> 562 matches\n",
      "peach_0162.png-peach_0111.png: 2559 --> 562 matches\n",
      "filter_FundamentalMatrix: 782 matches --> 77 matches\n",
      "peach_0162.png-peach_0073.png: 782 --> 77 matches\n",
      "filter_FundamentalMatrix: 1146 matches --> 148 matches\n",
      "peach_0162.png-peach_0055.png: 1146 --> 148 matches\n",
      "filter_FundamentalMatrix: 249 matches --> 36 matches\n",
      "peach_0162.png-peach_0046.png: 249 --> 36 matches\n",
      "filter_FundamentalMatrix: 489 matches --> 72 matches\n",
      "peach_0162.png-peach_0079.png: 489 --> 72 matches\n",
      "filter_FundamentalMatrix: 833 matches --> 94 matches\n",
      "peach_0162.png-peach_0134.png: 833 --> 94 matches\n",
      "filter_FundamentalMatrix: 1150 matches --> 132 matches\n",
      "peach_0191.png-peach_0034.png: 1150 --> 132 matches\n",
      "filter_FundamentalMatrix: 630 matches --> 64 matches\n",
      "peach_0191.png-peach_0117.png: 630 --> 64 matches\n",
      "filter_FundamentalMatrix: 1581 matches --> 274 matches\n",
      "peach_0159.png-peach_0113.png: 1581 --> 274 matches\n",
      "filter_FundamentalMatrix: 2336 matches --> 438 matches\n",
      "peach_0072.png-peach_0077.png: 2336 --> 438 matches\n",
      "filter_FundamentalMatrix: 1894 matches --> 381 matches\n",
      "peach_0022.png-peach_0109.png: 1894 --> 381 matches\n",
      "filter_FundamentalMatrix: 1585 matches --> 297 matches\n",
      "peach_0185.png-peach_0160.png: 1585 --> 297 matches\n",
      "filter_FundamentalMatrix: 4142 matches --> 1030 matches\n",
      "peach_0185.png-peach_0197.png: 4142 --> 1030 matches\n",
      "filter_FundamentalMatrix: 4040 matches --> 808 matches\n",
      "peach_0185.png-peach_0179.png: 4040 --> 808 matches\n",
      "filter_FundamentalMatrix: 3798 matches --> 708 matches\n",
      "peach_0185.png-peach_0005.png: 3798 --> 708 matches\n",
      "filter_FundamentalMatrix: 2818 matches --> 508 matches\n",
      "peach_0185.png-peach_0182.png: 2818 --> 508 matches\n",
      "filter_FundamentalMatrix: 4708 matches --> 1010 matches\n",
      "peach_0185.png-peach_0176.png: 4708 --> 1010 matches\n",
      "filter_FundamentalMatrix: 760 matches --> 106 matches\n",
      "peach_0093.png-peach_0157.png: 760 --> 106 matches\n",
      "filter_FundamentalMatrix: 1412 matches --> 218 matches\n",
      "peach_0093.png-peach_0178.png: 1412 --> 218 matches\n",
      "filter_FundamentalMatrix: 2027 matches --> 312 matches\n",
      "peach_0150.png-peach_0090.png: 2027 --> 312 matches\n",
      "filter_FundamentalMatrix: 278 matches --> 41 matches\n",
      "peach_0150.png-peach_0010.png: 278 --> 41 matches\n",
      "filter_FundamentalMatrix: 650 matches --> 92 matches\n",
      "peach_0150.png-peach_0063.png: 650 --> 92 matches\n",
      "filter_FundamentalMatrix: 309 matches --> 45 matches\n",
      "peach_0033.png-peach_0104.png: 309 --> 45 matches\n",
      "filter_FundamentalMatrix: 2849 matches --> 606 matches\n",
      "peach_0033.png-peach_0146.png: 2849 --> 606 matches\n",
      "filter_FundamentalMatrix: 234 matches --> 31 matches\n",
      "peach_0033.png-peach_0079.png: 234 --> 31 matches\n",
      "filter_FundamentalMatrix: 2970 matches --> 584 matches\n",
      "peach_0033.png-peach_0065.png: 2970 --> 584 matches\n",
      "filter_FundamentalMatrix: 1954 matches --> 384 matches\n",
      "peach_0081.png-peach_0141.png: 1954 --> 384 matches\n",
      "filter_FundamentalMatrix: 1660 matches --> 204 matches\n",
      "peach_0081.png-peach_0128.png: 1660 --> 204 matches\n",
      "filter_FundamentalMatrix: 2440 matches --> 522 matches\n",
      "peach_0081.png-peach_0199.png: 2440 --> 522 matches\n",
      "filter_FundamentalMatrix: 2636 matches --> 644 matches\n",
      "peach_0081.png-peach_0037.png: 2636 --> 644 matches\n",
      "filter_FundamentalMatrix: 243 matches --> 33 matches\n",
      "peach_0104.png-peach_0073.png: 243 --> 33 matches\n",
      "filter_FundamentalMatrix: 3244 matches --> 777 matches\n",
      "peach_0104.png-peach_0128.png: 3244 --> 777 matches\n",
      "filter_FundamentalMatrix: 3028 matches --> 649 matches\n",
      "peach_0104.png-peach_0146.png: 3028 --> 649 matches\n",
      "filter_FundamentalMatrix: 5838 matches --> 2420 matches\n",
      "peach_0141.png-peach_0199.png: 5838 --> 2420 matches\n",
      "filter_FundamentalMatrix: 5330 matches --> 2110 matches\n",
      "peach_0141.png-peach_0037.png: 5330 --> 2110 matches\n",
      "filter_FundamentalMatrix: 1203 matches --> 218 matches\n",
      "peach_0141.png-peach_0076.png: 1203 --> 218 matches\n",
      "filter_FundamentalMatrix: 268 matches --> 44 matches\n",
      "peach_0122.png-peach_0111.png: 268 --> 44 matches\n",
      "filter_FundamentalMatrix: 3532 matches --> 898 matches\n",
      "peach_0122.png-peach_0046.png: 3532 --> 898 matches\n",
      "filter_FundamentalMatrix: 1766 matches --> 299 matches\n",
      "peach_0122.png-peach_0079.png: 1766 --> 299 matches\n",
      "filter_FundamentalMatrix: 1491 matches --> 293 matches\n",
      "peach_0157.png-peach_0187.png: 1491 --> 293 matches\n",
      "filter_FundamentalMatrix: 604 matches --> 48 matches\n",
      "peach_0111.png-peach_0073.png: 604 --> 48 matches\n",
      "filter_FundamentalMatrix: 313 matches --> 34 matches\n",
      "peach_0111.png-peach_0099.png: 313 --> 34 matches\n",
      "filter_FundamentalMatrix: 900 matches --> 91 matches\n",
      "peach_0111.png-peach_0134.png: 900 --> 91 matches\n",
      "filter_FundamentalMatrix: 408 matches --> 37 matches\n",
      "peach_0111.png-peach_0019.png: 408 --> 37 matches\n",
      "filter_FundamentalMatrix: 1178 matches --> 159 matches\n",
      "peach_0073.png-peach_0099.png: 1178 --> 159 matches\n",
      "filter_FundamentalMatrix: 2177 matches --> 388 matches\n",
      "peach_0073.png-peach_0055.png: 2177 --> 388 matches\n",
      "filter_FundamentalMatrix: 3363 matches --> 762 matches\n",
      "peach_0073.png-peach_0134.png: 3363 --> 762 matches\n",
      "filter_FundamentalMatrix: 623 matches --> 76 matches\n",
      "peach_0073.png-peach_0019.png: 623 --> 76 matches\n",
      "filter_FundamentalMatrix: 852 matches --> 124 matches\n",
      "peach_0193.png-peach_0099.png: 852 --> 124 matches\n",
      "filter_FundamentalMatrix: 285 matches --> 27 matches\n",
      "peach_0193.png-peach_0166.png: 285 --> 27 matches\n",
      "filter_FundamentalMatrix: 1403 matches --> 172 matches\n",
      "peach_0193.png-peach_0067.png: 1403 --> 172 matches\n",
      "filter_FundamentalMatrix: 2799 matches --> 615 matches\n",
      "peach_0020.png-peach_0149.png: 2799 --> 615 matches\n",
      "filter_FundamentalMatrix: 414 matches --> 54 matches\n",
      "peach_0020.png-peach_0139.png: 414 --> 54 matches\n",
      "filter_FundamentalMatrix: 3972 matches --> 1115 matches\n",
      "peach_0020.png-peach_0040.png: 3972 --> 1115 matches\n",
      "filter_FundamentalMatrix: 2517 matches --> 515 matches\n",
      "peach_0020.png-peach_0026.png: 2517 --> 515 matches\n",
      "filter_FundamentalMatrix: 760 matches --> 56 matches\n",
      "peach_0144.png-peach_0186.png: 760 --> 56 matches\n",
      "filter_FundamentalMatrix: 3728 matches --> 1008 matches\n",
      "peach_0034.png-peach_0117.png: 3728 --> 1008 matches\n",
      "filter_FundamentalMatrix: 537 matches --> 63 matches\n",
      "peach_0099.png-peach_0166.png: 537 --> 63 matches\n",
      "filter_FundamentalMatrix: 2055 matches --> 286 matches\n",
      "peach_0099.png-peach_0134.png: 2055 --> 286 matches\n",
      "filter_FundamentalMatrix: 319 matches --> 30 matches\n",
      "peach_0099.png-peach_0067.png: 319 --> 30 matches\n",
      "filter_FundamentalMatrix: 200 matches --> 24 matches\n",
      "peach_0099.png-peach_0019.png: 200 --> 24 matches\n",
      "filter_FundamentalMatrix: 2495 matches --> 347 matches\n",
      "peach_0055.png-peach_0079.png: 2495 --> 347 matches\n",
      "filter_FundamentalMatrix: 407 matches --> 55 matches\n",
      "peach_0055.png-peach_0134.png: 407 --> 55 matches\n",
      "skipped key1=peach_0090.png, key2=peach_0046.png: mkpts.shape=(13, 4) after filtered.\n",
      "filter_FundamentalMatrix: 3811 matches --> 941 matches\n",
      "peach_0090.png-peach_0063.png: 3811 --> 941 matches\n",
      "filter_FundamentalMatrix: 2601 matches --> 660 matches\n",
      "peach_0129.png-peach_0048.png: 2601 --> 660 matches\n",
      "filter_FundamentalMatrix: 930 matches --> 123 matches\n",
      "peach_0128.png-peach_0146.png: 930 --> 123 matches\n",
      "filter_FundamentalMatrix: 699 matches --> 71 matches\n",
      "peach_0128.png-peach_0044.png: 699 --> 71 matches\n",
      "filter_FundamentalMatrix: 6938 matches --> 3189 matches\n",
      "peach_0199.png-peach_0037.png: 6938 --> 3189 matches\n",
      "filter_FundamentalMatrix: 1971 matches --> 250 matches\n",
      "peach_0108.png-peach_0197.png: 1971 --> 250 matches\n",
      "filter_FundamentalMatrix: 3636 matches --> 1162 matches\n",
      "peach_0108.png-peach_0005.png: 3636 --> 1162 matches\n",
      "filter_FundamentalMatrix: 4820 matches --> 2150 matches\n",
      "peach_0108.png-peach_0094.png: 4820 --> 2150 matches\n",
      "filter_FundamentalMatrix: 2611 matches --> 443 matches\n",
      "peach_0108.png-peach_0182.png: 2611 --> 443 matches\n",
      "filter_FundamentalMatrix: 2663 matches --> 552 matches\n",
      "peach_0108.png-peach_0009.png: 2663 --> 552 matches\n",
      "filter_FundamentalMatrix: 1111 matches --> 86 matches\n",
      "peach_0108.png-peach_0065.png: 1111 --> 86 matches\n",
      "filter_FundamentalMatrix: 790 matches --> 123 matches\n",
      "peach_0101.png-peach_0018.png: 790 --> 123 matches\n",
      "filter_FundamentalMatrix: 1941 matches --> 398 matches\n",
      "peach_0101.png-peach_0092.png: 1941 --> 398 matches\n",
      "filter_FundamentalMatrix: 3031 matches --> 807 matches\n",
      "peach_0101.png-peach_0194.png: 3031 --> 807 matches\n",
      "filter_FundamentalMatrix: 1990 matches --> 265 matches\n",
      "peach_0046.png-peach_0079.png: 1990 --> 265 matches\n",
      "filter_FundamentalMatrix: 2445 matches --> 517 matches\n",
      "peach_0069.png-peach_0147.png: 2445 --> 517 matches\n",
      "filter_FundamentalMatrix: 1535 matches --> 203 matches\n",
      "peach_0069.png-peach_0168.png: 1535 --> 203 matches\n",
      "filter_FundamentalMatrix: 1806 matches --> 338 matches\n",
      "peach_0058.png-peach_0003.png: 1806 --> 338 matches\n",
      "filter_FundamentalMatrix: 1679 matches --> 264 matches\n",
      "peach_0149.png-peach_0044.png: 1679 --> 264 matches\n",
      "filter_FundamentalMatrix: 1204 matches --> 180 matches\n",
      "peach_0149.png-peach_0026.png: 1204 --> 180 matches\n",
      "filter_FundamentalMatrix: 239 matches --> 20 matches\n",
      "peach_0061.png-peach_0194.png: 239 --> 20 matches\n",
      "filter_FundamentalMatrix: 833 matches --> 117 matches\n",
      "peach_0061.png-peach_0035.png: 833 --> 117 matches\n",
      "filter_FundamentalMatrix: 602 matches --> 81 matches\n",
      "peach_0018.png-peach_0092.png: 602 --> 81 matches\n",
      "filter_FundamentalMatrix: 1405 matches --> 245 matches\n",
      "peach_0018.png-peach_0194.png: 1405 --> 245 matches\n",
      "filter_FundamentalMatrix: 729 matches --> 80 matches\n",
      "peach_0166.png-peach_0134.png: 729 --> 80 matches\n",
      "filter_FundamentalMatrix: 2440 matches --> 515 matches\n",
      "peach_0166.png-peach_0067.png: 2440 --> 515 matches\n",
      "filter_FundamentalMatrix: 2079 matches --> 443 matches\n",
      "peach_0166.png-peach_0019.png: 2079 --> 443 matches\n",
      "filter_FundamentalMatrix: 1979 matches --> 276 matches\n",
      "peach_0039.png-peach_0030.png: 1979 --> 276 matches\n",
      "filter_FundamentalMatrix: 1332 matches --> 166 matches\n",
      "peach_0039.png-peach_0036.png: 1332 --> 166 matches\n",
      "filter_FundamentalMatrix: 200 matches --> 21 matches\n",
      "peach_0039.png-peach_0137.png: 200 --> 21 matches\n",
      "filter_FundamentalMatrix: 5237 matches --> 1797 matches\n",
      "peach_0039.png-peach_0130.png: 5237 --> 1797 matches\n",
      "filter_FundamentalMatrix: 1083 matches --> 166 matches\n",
      "peach_0092.png-peach_0194.png: 1083 --> 166 matches\n",
      "filter_FundamentalMatrix: 3001 matches --> 741 matches\n",
      "peach_0030.png-peach_0036.png: 3001 --> 741 matches\n",
      "filter_FundamentalMatrix: 367 matches --> 57 matches\n",
      "peach_0178.png-peach_0171.png: 367 --> 57 matches\n",
      "filter_FundamentalMatrix: 1247 matches --> 165 matches\n",
      "peach_0052.png-peach_0137.png: 1247 --> 165 matches\n",
      "filter_FundamentalMatrix: 1797 matches --> 276 matches\n",
      "peach_0160.png-peach_0197.png: 1797 --> 276 matches\n",
      "filter_FundamentalMatrix: 1680 matches --> 255 matches\n",
      "peach_0160.png-peach_0179.png: 1680 --> 255 matches\n",
      "filter_FundamentalMatrix: 1619 matches --> 204 matches\n",
      "peach_0160.png-peach_0005.png: 1619 --> 204 matches\n",
      "filter_FundamentalMatrix: 2551 matches --> 509 matches\n",
      "peach_0160.png-peach_0182.png: 2551 --> 509 matches\n",
      "filter_FundamentalMatrix: 1729 matches --> 325 matches\n",
      "peach_0160.png-peach_0176.png: 1729 --> 325 matches\n",
      "filter_FundamentalMatrix: 599 matches --> 71 matches\n",
      "peach_0160.png-peach_0065.png: 599 --> 71 matches\n",
      "filter_FundamentalMatrix: 3407 matches --> 583 matches\n",
      "peach_0197.png-peach_0179.png: 3407 --> 583 matches\n",
      "filter_FundamentalMatrix: 3182 matches --> 477 matches\n",
      "peach_0197.png-peach_0005.png: 3182 --> 477 matches\n",
      "filter_FundamentalMatrix: 2937 matches --> 550 matches\n",
      "peach_0197.png-peach_0182.png: 2937 --> 550 matches\n",
      "filter_FundamentalMatrix: 4330 matches --> 1143 matches\n",
      "peach_0197.png-peach_0176.png: 4330 --> 1143 matches\n",
      "filter_FundamentalMatrix: 6164 matches --> 2269 matches\n",
      "peach_0179.png-peach_0005.png: 6164 --> 2269 matches\n",
      "filter_FundamentalMatrix: 2162 matches --> 641 matches\n",
      "peach_0179.png-peach_0094.png: 2162 --> 641 matches\n",
      "filter_FundamentalMatrix: 3700 matches --> 688 matches\n",
      "peach_0179.png-peach_0176.png: 3700 --> 688 matches\n",
      "filter_FundamentalMatrix: 2294 matches --> 325 matches\n",
      "peach_0008.png-peach_0044.png: 2294 --> 325 matches\n",
      "filter_FundamentalMatrix: 3750 matches --> 899 matches\n",
      "peach_0008.png-peach_0004.png: 3750 --> 899 matches\n",
      "filter_FundamentalMatrix: 1328 matches --> 181 matches\n",
      "peach_0186.png-peach_0147.png: 1328 --> 181 matches\n",
      "filter_FundamentalMatrix: 2782 matches --> 501 matches\n",
      "peach_0186.png-peach_0168.png: 2782 --> 501 matches\n",
      "filter_FundamentalMatrix: 2318 matches --> 863 matches\n",
      "peach_0005.png-peach_0094.png: 2318 --> 863 matches\n",
      "filter_FundamentalMatrix: 3066 matches --> 555 matches\n",
      "peach_0005.png-peach_0182.png: 3066 --> 555 matches\n",
      "filter_FundamentalMatrix: 3359 matches --> 597 matches\n",
      "peach_0005.png-peach_0176.png: 3359 --> 597 matches\n",
      "filter_FundamentalMatrix: 2689 matches --> 437 matches\n",
      "peach_0094.png-peach_0182.png: 2689 --> 437 matches\n",
      "filter_FundamentalMatrix: 3344 matches --> 925 matches\n",
      "peach_0094.png-peach_0009.png: 3344 --> 925 matches\n",
      "filter_FundamentalMatrix: 1601 matches --> 161 matches\n",
      "peach_0094.png-peach_0065.png: 1601 --> 161 matches\n",
      "filter_FundamentalMatrix: 997 matches --> 129 matches\n",
      "peach_0134.png-peach_0019.png: 997 --> 129 matches\n",
      "filter_FundamentalMatrix: 833 matches --> 167 matches\n",
      "peach_0067.png-peach_0019.png: 833 --> 167 matches\n",
      "filter_FundamentalMatrix: 1990 matches --> 418 matches\n",
      "peach_0147.png-peach_0168.png: 1990 --> 418 matches\n",
      "filter_FundamentalMatrix: 2300 matches --> 380 matches\n",
      "peach_0044.png-peach_0004.png: 2300 --> 380 matches\n",
      "filter_FundamentalMatrix: 2887 matches --> 963 matches\n",
      "peach_0182.png-peach_0009.png: 2887 --> 963 matches\n",
      "filter_FundamentalMatrix: 2877 matches --> 569 matches\n",
      "peach_0182.png-peach_0176.png: 2877 --> 569 matches\n",
      "filter_FundamentalMatrix: 1154 matches --> 120 matches\n",
      "peach_0182.png-peach_0065.png: 1154 --> 120 matches\n",
      "filter_FundamentalMatrix: 1264 matches --> 118 matches\n",
      "peach_0009.png-peach_0065.png: 1264 --> 118 matches\n",
      "filter_FundamentalMatrix: 973 matches --> 203 matches\n",
      "peach_0037.png-peach_0076.png: 973 --> 203 matches\n",
      "filter_FundamentalMatrix: 3371 matches --> 916 matches\n",
      "peach_0040.png-peach_0026.png: 3371 --> 916 matches\n",
      "filter_FundamentalMatrix: 408 matches --> 37 matches\n",
      "peach_0137.png-peach_0130.png: 408 --> 37 matches\n",
      "Ensembled pairs : 400 pairs\n",
      "Local feature extracting and matching. Done in 912.7625 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 181/181 [00:04<00:00, 36.34it/s]\n",
      "  4%|         | 400/9045 [00:00<00:02, 4040.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colmap database\n",
      "matching done!!!!\n",
      "RANSAC in 3.4837 sec\n",
      "{0: Reconstruction(num_reg_images=3, num_cameras=3, num_points3D=0, num_observations=0), 1: Reconstruction(num_reg_images=5, num_cameras=5, num_points3D=44, num_observations=144), 2: Reconstruction(num_reg_images=14, num_cameras=14, num_points3D=2648, num_observations=8655), 3: Reconstruction(num_reg_images=9, num_cameras=9, num_points3D=1020, num_observations=3067), 4: Reconstruction(num_reg_images=30, num_cameras=30, num_points3D=8171, num_observations=34534), 5: Reconstruction(num_reg_images=9, num_cameras=9, num_points3D=953, num_observations=2984), 6: Reconstruction(num_reg_images=7, num_cameras=7, num_points3D=932, num_observations=2772), 7: Reconstruction(num_reg_images=10, num_cameras=10, num_points3D=897, num_observations=2731), 8: Reconstruction(num_reg_images=5, num_cameras=5, num_points3D=599, num_observations=1831), 9: Reconstruction(num_reg_images=5, num_cameras=5, num_points3D=363, num_observations=957), 10: Reconstruction(num_reg_images=18, num_cameras=18, num_points3D=1910, num_observations=6260)}\n",
      "Reconstruction done in 53.6676 sec\n",
      "Dataset  amy_gardens -> Registered 115 / 200 images with 11 clusters\n",
      "Skipping \"fbk_vineyard\"\n",
      "Skipping \"ETs\"\n",
      "Skipping \"stairs\"\n",
      "\n",
      "Results\n",
      "Dataset  amy_gardens -> Registered 115 / 200 images with 11 clusters\n",
      "\n",
      "Timings\n",
      "rotation_detection -> total=0.00 sec.\n",
      "global feature extraction -> total=0.00 sec.\n",
      "shortlisting -> total=60.23 sec.\n",
      "feature_detection -> total=0.00 sec.\n",
      "feature_matching -> total=677.14 sec.\n",
      "RANSAC -> total=3.48 sec.\n",
      "Reconstruction -> total=53.67 sec.\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "\n",
    "max_images = None  # Used For debugging only. Set to None to disable.\n",
    "datasets_to_process = None  # Not the best convention, but None means all datasets.\n",
    "\n",
    "if is_train:\n",
    "    # max_images = 5\n",
    "\n",
    "    # Note: When running on the training dataset, the notebook will hit the time limit and die. Use this filter to run on a few specific datasets.\n",
    "    datasets_to_process = [\n",
    "    \t# New data.\n",
    "    \t'amy_gardens',\n",
    "    \t# 'ETs',\n",
    "    \t# 'fbk_vineyard',\n",
    "    \t# 'stairs',\n",
    "    \t# Data from IMC 2023 and 2024.\n",
    "    \t# 'imc2024_dioscuri_baalshamin',\n",
    "    \t# 'imc2023_theather_imc2024_church',\n",
    "    \t# 'imc2023_heritage',\n",
    "    \t# 'imc2023_haiper',\n",
    "    \t# 'imc2024_lizard_pond',\n",
    "    \t# Crowdsourced PhotoTourism data.\n",
    "    \t# 'pt_stpeters_stpauls',\n",
    "    \t# 'pt_brandenburg_british_buckingham',\n",
    "    \t# 'pt_piazzasanmarco_grandplace',\n",
    "    \t# 'pt_sacrecoeur_trevi_tajmahal',\n",
    "    ]\n",
    "\n",
    "timings = {\n",
    "    'rotation_detection':[],\n",
    "    \"global feature extraction\":[],\n",
    "    \"shortlisting\":[],\n",
    "    \"feature_detection\": [],\n",
    "    \"feature_matching\":[],\n",
    "    \"RANSAC\": [],\n",
    "    \"Reconstruction\": [],\n",
    "}\n",
    "mapping_result_strs = []\n",
    "\n",
    "# Load DINOv2 model (for feature extraction, not global descriptor here)\n",
    "print(\"Loading DINOv2 model for patch feature extraction...\")\n",
    "dino_processor = AutoImageProcessor.from_pretrained('/kaggle/input/dinov2/pytorch/base/1')\n",
    "dino_model = AutoModel.from_pretrained('/kaggle/input/dinov2/pytorch/base/1')\n",
    "dino_model = dino_model.eval().to(device)\n",
    "print(\"DINOv2 model loaded.\")\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=CONFIG.NUM_CORES) as executors:\n",
    "    # print (f\"Extracting on device {device}\")\n",
    "    for dataset, predictions in samples.items():\n",
    "        if datasets_to_process and dataset not in datasets_to_process:\n",
    "            print(f'Skipping \"{dataset}\"')\n",
    "            continue\n",
    "        \n",
    "        images_dir = os.path.join(data_dir, 'train' if is_train else 'test', dataset)\n",
    "        images = [os.path.join(images_dir, p.filename) for p in predictions]\n",
    "        if max_images is not None:\n",
    "            images = images[:max_images]\n",
    "    \n",
    "        print(f'\\nProcessing dataset \"{dataset}\": {len(images)} images')\n",
    "    \n",
    "        filename_to_index = {p.filename: idx for idx, p in enumerate(predictions)}\n",
    "    \n",
    "        feature_dir = os.path.join(workdir, 'featureout', dataset)\n",
    "        os.makedirs(feature_dir, exist_ok=True)\n",
    "    \n",
    "        # Wrap algos in try-except blocks so we can populate a submission even if one scene crashes.\n",
    "        try:\n",
    "            # --- Pipeline Execution ---\n",
    "            \n",
    "            #############################################################\n",
    "            # get image rotations\n",
    "            #############################################################\n",
    "            t = time()\n",
    "            # if CONFIG.ROTATION_CORRECTION:\n",
    "            #     rots = exec_rotation_detection(images, device)\n",
    "            # else:\n",
    "            #     rots = [ 0 for fname in images ]\n",
    "            rots = [ 0 for fname in images ]\n",
    "            t = time()-t\n",
    "            timings['rotation_detection'].append(t)\n",
    "            print(f'rotation_detection for {len(images)} images : {t:.4f} sec')\n",
    "            # print(\"!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "            gc.collect()\n",
    "            #############################################################\n",
    "            # get image pairs\n",
    "            #############################################################\n",
    "            # 1. Detect ALIKED features and combine with DINO patch features\n",
    "            t = time()\n",
    "            index_pairs = get_image_pairs_shortlist(\n",
    "                images,\n",
    "                sim_th = 0.3, # should be strict\n",
    "                min_pairs = 20, # we should select at least min_pairs PER IMAGE with biggest similarity\n",
    "                max_pairs = 25,\n",
    "                exhaustive_if_less = 20,\n",
    "                device=device\n",
    "            )\n",
    "            timings['shortlisting'].append(time() - t)\n",
    "            print (f'Shortlisting. Number of pairs to match: {len(index_pairs)}. Done in {time() - t:.4f} sec')\n",
    "            gc.collect()\n",
    "            # print(\"\\n--- Step 1: Detecting ALIKED and Combining with DINO Patch Features ---\")\n",
    "            # detect_aliked_and_combine_with_dino(\n",
    "            #     img_fnames=images,\n",
    "            #     feature_dir=feature_dir,\n",
    "            #     num_features=4096,\n",
    "            #     resize_to=1024,\n",
    "            #     dino_processor=dino_processor,\n",
    "            #     dino_model=dino_model,\n",
    "            #     dino_patch_size=14, # Adjust based on your DINO model's patch size (e.g., 14 for DINOv2 base)\n",
    "            #     device=device\n",
    "            # )\n",
    "            # timings['global feature extraction'].append(time() - t)\n",
    "            # print (f'Gloabl feature extracting. Done in {time() - t:.4f} sec')\n",
    "            # gc.collect()\n",
    "            \n",
    "            # # 2. Get image pairs shortlist using VLAD global descriptors\n",
    "            # print(\"\\n--- Step 2: Generating Image Pair Shortlist using VLAD ---\")\n",
    "            # # Adjust num_clusters_vlad as needed (e.g., 64, 128, 256)\n",
    "            # # Higher clusters mean higher dimensionality for global descriptor.\n",
    "            # index_pairs = get_image_pairs_shortlist_vlad(\n",
    "            #     fnames=images,\n",
    "            #     sim_th=0.5,\n",
    "            #     min_pairs=20,\n",
    "            #     exhaustive_if_less=20,\n",
    "            #     feature_dir=feature_dir,\n",
    "            #     num_clusters_vlad=128, # Example: 128 clusters for VLAD\n",
    "            #     device=device\n",
    "            # )\n",
    "            # index_pairs = get_img_pairs_exhaustive(images)\n",
    "            \n",
    "            print(f\"Generated {len(index_pairs)} image pairs using VLAD global descriptor.\")\n",
    "            timings['shortlisting'].append(time() - t)\n",
    "            print (f'Shortlisting. Number of pairs to match: {len(index_pairs)}. Done in {time() - t:.4f} sec')\n",
    "            gc.collect()\n",
    "            #############################################################\n",
    "            # get keypoints\n",
    "            #############################################################    \n",
    "            t=time()\n",
    "            keypoints_timings = wrapper_keypoints(\n",
    "                images, index_pairs, feature_dir, device, timings, rots\n",
    "            )\n",
    "            timings['feature_matching'] = keypoints_timings['feature_matching']\n",
    "            gc.collect()\n",
    "            print (f'Local feature extracting and matching. Done in {time() - t:.4f} sec')\n",
    "            #############################################################\n",
    "            # kick COLMAP reconstruction\n",
    "            #############################################################            \n",
    "            future = executors.submit(\n",
    "                reconstruct_from_db, \n",
    "                feature_dir, images_dir)\n",
    "            maps, local_timings = future.result()\n",
    "            #  timings\n",
    "            for k in local_timings:\n",
    "                timings[k].extend(local_timings[k])\n",
    "            # clear_output(wait=False)\n",
    "            registered = 0\n",
    "            for map_index, cur_map in maps.items():  # cur_map: image_name  {'R': list, 't': list}\n",
    "                for image_name, pose in cur_map.items():\n",
    "                    idx = filename_to_index[image_name]\n",
    "                    pred = predictions[idx]\n",
    "                    pred.cluster_index = map_index\n",
    "                    pred.rotation = np.array(pose['R'])  # convert back to np.ndarray\n",
    "                    pred.translation = np.array(pose['t'])\n",
    "                    registered += 1\n",
    "            mapping_result_str = f\"Dataset  {dataset} -> Registered {registered} / {len(images)} images with {len(maps)} clusters\"\n",
    "            mapping_result_strs.append(mapping_result_str)\n",
    "            print(mapping_result_str)\n",
    "\n",
    "            gc.collect()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            # raise e\n",
    "            mapping_result_str = f'Dataset \"{dataset}\" -> Failed!'\n",
    "            mapping_result_strs.append(mapping_result_str)\n",
    "            print(mapping_result_str)\n",
    "\n",
    "print('\\nResults')\n",
    "for s in mapping_result_strs:\n",
    "    print(s)\n",
    "\n",
    "print('\\nTimings')\n",
    "for k, v in timings.items():\n",
    "    print(f'{k} -> total={sum(v):.02f} sec.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3fffc2fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T22:40:59.636288Z",
     "iopub.status.busy": "2025-05-28T22:40:59.635962Z",
     "iopub.status.idle": "2025-05-28T22:40:59.813895Z",
     "shell.execute_reply": "2025-05-28T22:40:59.812936Z"
    },
    "papermill": {
     "duration": 0.392924,
     "end_time": "2025-05-28T22:40:59.815311",
     "exception": false,
     "start_time": "2025-05-28T22:40:59.422387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset,scene,image,rotation_matrix,translation_vector\r\n",
      "imc2023_haiper,outliers,fountain_image_116.png,nan;nan;nan;nan;nan;nan;nan;nan;nan,nan;nan;nan\r\n",
      "imc2023_haiper,outliers,fountain_image_108.png,nan;nan;nan;nan;nan;nan;nan;nan;nan,nan;nan;nan\r\n",
      "imc2023_haiper,outliers,fountain_image_101.png,nan;nan;nan;nan;nan;nan;nan;nan;nan,nan;nan;nan\r\n",
      "imc2023_haiper,outliers,fountain_image_082.png,nan;nan;nan;nan;nan;nan;nan;nan;nan,nan;nan;nan\r\n",
      "imc2023_haiper,outliers,fountain_image_071.png,nan;nan;nan;nan;nan;nan;nan;nan;nan,nan;nan;nan\r\n",
      "imc2023_haiper,outliers,fountain_image_025.png,nan;nan;nan;nan;nan;nan;nan;nan;nan,nan;nan;nan\r\n",
      "imc2023_haiper,outliers,fountain_image_000.png,nan;nan;nan;nan;nan;nan;nan;nan;nan,nan;nan;nan\r\n",
      "imc2023_haiper,outliers,fountain_image_007.png,nan;nan;nan;nan;nan;nan;nan;nan;nan,nan;nan;nan\r\n",
      "imc2023_haiper,outliers,fountain_image_012.png,nan;nan;nan;nan;nan;nan;nan;nan;nan,nan;nan;nan\r\n"
     ]
    }
   ],
   "source": [
    "# Helpers\n",
    "array_to_str = lambda array: ';'.join([f\"{x:.09f}\" for x in array])\n",
    "none_to_str = lambda n: ';'.join(['nan'] * n)\n",
    "\n",
    "submission_file = '/kaggle/working/submission.csv'\n",
    "with open(submission_file, 'w') as f:\n",
    "    if is_train:\n",
    "        f.write('dataset,scene,image,rotation_matrix,translation_vector\\n')\n",
    "        for dataset, predictions in samples.items():\n",
    "            for prediction in predictions:\n",
    "                cluster_name = 'outliers' if prediction.cluster_index is None else f'cluster{prediction.cluster_index}'\n",
    "\n",
    "                #  `rotation` is a list of lists, flatten it\n",
    "                if prediction.rotation is None:\n",
    "                    rotation_str = none_to_str(9)\n",
    "                else:\n",
    "                    rotation_flat =  prediction.rotation.flatten()  # flatten 3x3 list -> 9 elems\n",
    "                    rotation_str = array_to_str(rotation_flat)\n",
    "\n",
    "                #  `translation` is a flat list\n",
    "                if prediction.translation is None:\n",
    "                    translation_str = none_to_str(3)\n",
    "                else:\n",
    "                    translation_str = array_to_str(prediction.translation)\n",
    "\n",
    "                f.write(f'{prediction.dataset},{cluster_name},{prediction.filename},{rotation_str},{translation_str}\\n')\n",
    "    else:\n",
    "        f.write('image_id,dataset,scene,image,rotation_matrix,translation_vector\\n')\n",
    "        for dataset, predictions in samples.items():\n",
    "            for prediction in predictions:\n",
    "                cluster_name = 'outliers' if prediction.cluster_index is None else f'cluster{prediction.cluster_index}'\n",
    "\n",
    "                if prediction.rotation is None:\n",
    "                    rotation_str = none_to_str(9)\n",
    "                else:\n",
    "                    rotation_flat =  prediction.rotation.flatten()\n",
    "                    rotation_str = array_to_str(rotation_flat)\n",
    "\n",
    "                if prediction.translation is None:\n",
    "                    translation_str = none_to_str(3)\n",
    "                else:\n",
    "                    translation_str = array_to_str(prediction.translation)\n",
    "\n",
    "                f.write(f'{prediction.image_id},{prediction.dataset},{cluster_name},{prediction.filename},{rotation_str},{translation_str}\\n')\n",
    "\n",
    "# Preview the output\n",
    "!head {submission_file}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cbddfac8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T22:41:00.249715Z",
     "iopub.status.busy": "2025-05-28T22:41:00.249357Z",
     "iopub.status.idle": "2025-05-28T22:41:07.333954Z",
     "shell.execute_reply": "2025-05-28T22:41:07.332867Z"
    },
    "papermill": {
     "duration": 7.299665,
     "end_time": "2025-05-28T22:41:07.335229",
     "exception": false,
     "start_time": "2025-05-28T22:41:00.035564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imc2023_haiper: score=0.00% (mAA=0.00%, clusterness=100.00%)\n",
      "imc2023_heritage: score=0.00% (mAA=0.00%, clusterness=100.00%)\n",
      "imc2023_theather_imc2024_church: score=0.00% (mAA=0.00%, clusterness=100.00%)\n",
      "imc2024_dioscuri_baalshamin: score=0.00% (mAA=0.00%, clusterness=100.00%)\n",
      "imc2024_lizard_pond: score=0.00% (mAA=0.00%, clusterness=100.00%)\n",
      "pt_brandenburg_british_buckingham: score=0.00% (mAA=0.00%, clusterness=100.00%)\n",
      "pt_piazzasanmarco_grandplace: score=0.00% (mAA=0.00%, clusterness=100.00%)\n",
      "pt_sacrecoeur_trevi_tajmahal: score=0.00% (mAA=0.00%, clusterness=100.00%)\n",
      "pt_stpeters_stpauls: score=0.00% (mAA=0.00%, clusterness=100.00%)\n",
      "amy_gardens: score=15.24% (mAA=8.25%, clusterness=100.00%)\n",
      "fbk_vineyard: score=0.00% (mAA=0.00%, clusterness=100.00%)\n",
      "ETs: score=0.00% (mAA=0.00%, clusterness=100.00%)\n",
      "stairs: score=0.00% (mAA=0.00%, clusterness=100.00%)\n",
      "Average over all datasets: score=1.17% (mAA=0.63%, clusterness=100.00%)\n",
      "Computed metric in: 7.08 sec.\n"
     ]
    }
   ],
   "source": [
    "# Definitely Compute results if running on the training set.\n",
    "# Do not do this when submitting a notebook for scoring. All you have to do is save your submission to /kaggle/working/submission.csv.\n",
    "\n",
    "if is_train:\n",
    "    t = time()\n",
    "    final_score, dataset_scores = metric.score(\n",
    "        gt_csv='/kaggle/input/image-matching-challenge-2025/train_labels.csv',\n",
    "        user_csv=submission_file,\n",
    "        thresholds_csv='/kaggle/input/image-matching-challenge-2025/train_thresholds.csv',\n",
    "        mask_csv=None if is_train else os.path.join(data_dir, 'mask.csv'),\n",
    "        inl_cf=0,\n",
    "        strict_cf=-1,\n",
    "        verbose=True,\n",
    "    )\n",
    "    print(f'Computed metric in: {time() - t:.02f} sec.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7fd096",
   "metadata": {
    "papermill": {
     "duration": 0.257434,
     "end_time": "2025-05-28T22:41:07.806830",
     "exception": false,
     "start_time": "2025-05-28T22:41:07.549396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11655853,
     "sourceId": 91498,
     "sourceType": "competition"
    },
    {
     "datasetId": 4628051,
     "sourceId": 7884485,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6988459,
     "sourceId": 11924468,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7505602,
     "sourceId": 11938492,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 986,
     "modelInstanceId": 3326,
     "sourceId": 4534,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 21716,
     "modelInstanceId": 14317,
     "sourceId": 17191,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 22086,
     "modelInstanceId": 14611,
     "sourceId": 17555,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1075.963407,
   "end_time": "2025-05-28T22:41:11.891960",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-28T22:23:15.928553",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
