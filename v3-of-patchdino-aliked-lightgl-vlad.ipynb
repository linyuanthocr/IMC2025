{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":91498,"databundleVersionId":11655853,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":7884485,"sourceType":"datasetVersion","datasetId":4628051},{"sourceId":11924468,"sourceType":"datasetVersion","datasetId":6988459},{"sourceId":11938492,"sourceType":"datasetVersion","datasetId":7505602},{"sourceId":11991336,"sourceType":"datasetVersion","datasetId":7542297},{"sourceId":4534,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":3326,"modelId":986},{"sourceId":17191,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":14317,"modelId":21716},{"sourceId":17555,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":14611,"modelId":22086}],"dockerImageVersionId":30919,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Example submission\n\nImage Matching Challenge 2025: https://www.kaggle.com/competitions/image-matching-challenge-2025\n\nThis notebook creates a simple submission using ALIKED and LightGlue, plus DINO for shortlisting, on GPU. Adapted from [last year](https://www.kaggle.com/code/oldufo/imc-2024-submission-example).\n\nRemember to select an accelerator on the sidebar to the right, and to disable internet access when submitting a notebook to the competition.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"# IMPORTANT \n#Install dependencies and copy model weights to run the notebook without internet access when submitting to the competition.\n\n!pip install --no-index /kaggle/input/imc2024-packages-lightglue-rerun-kornia/* --no-deps\n!mkdir -p /root/.cache/torch/hub/checkpoints\n!cp /kaggle/input/aliked/pytorch/aliked-n16/1/aliked-n16.pth /root/.cache/torch/hub/checkpoints/\n!cp /kaggle/input/lightglue/pytorch/aliked/1/aliked_lightglue.pth /root/.cache/torch/hub/checkpoints/\n!cp /kaggle/input/lightglue/pytorch/aliked/1/aliked_lightglue.pth /root/.cache/torch/hub/checkpoints/aliked_lightglue_v0-1_arxiv-pth","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T18:57:22.676502Z","iopub.execute_input":"2025-05-29T18:57:22.676922Z","iopub.status.idle":"2025-05-29T18:57:28.002428Z","shell.execute_reply.started":"2025-05-29T18:57:22.676896Z","shell.execute_reply":"2025-05-29T18:57:28.001481Z"}},"outputs":[{"name":"stdout","text":"Processing /kaggle/input/imc2024-packages-lightglue-rerun-kornia/kornia-0.7.2-py2.py3-none-any.whl\nProcessing /kaggle/input/imc2024-packages-lightglue-rerun-kornia/kornia_moons-0.2.9-py3-none-any.whl\nProcessing /kaggle/input/imc2024-packages-lightglue-rerun-kornia/kornia_rs-0.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nProcessing /kaggle/input/imc2024-packages-lightglue-rerun-kornia/lightglue-0.0-py3-none-any.whl\nProcessing /kaggle/input/imc2024-packages-lightglue-rerun-kornia/pycolmap-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nProcessing /kaggle/input/imc2024-packages-lightglue-rerun-kornia/rerun_sdk-0.15.0a2-cp38-abi3-manylinux_2_31_x86_64.whl\nInstalling collected packages: rerun-sdk, pycolmap, lightglue, kornia-rs, kornia-moons, kornia\n  Attempting uninstall: kornia-rs\n    Found existing installation: kornia_rs 0.1.8\n    Uninstalling kornia_rs-0.1.8:\n      Successfully uninstalled kornia_rs-0.1.8\n  Attempting uninstall: kornia\n    Found existing installation: kornia 0.8.0\n    Uninstalling kornia-0.8.0:\n      Successfully uninstalled kornia-0.8.0\nSuccessfully installed kornia-0.7.2 kornia-moons-0.2.9 kornia-rs-0.1.2 lightglue-0.0 pycolmap-0.6.1 rerun-sdk-0.15.0a2\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!cp /kaggle/input/disk-depth/disk_lightglue.pth /root/.cache/torch/hub/checkpoints/\n!cp /kaggle/input/disk-depth/disk_lightglue.pth /root/.cache/torch/hub/checkpoints/disk_lightglue_v0-1_arxiv-pth\n!cp /kaggle/input/disk-depth/depth-save.pth /root/.cache/torch/hub/checkpoints/depth-save.pth\n!cp /kaggle/input/disk-depth/depth-save.pth /root/.cache/torch/hub/checkpoints/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T18:57:28.003614Z","iopub.execute_input":"2025-05-29T18:57:28.003856Z","iopub.status.idle":"2025-05-29T18:57:28.897409Z","shell.execute_reply.started":"2025-05-29T18:57:28.003825Z","shell.execute_reply":"2025-05-29T18:57:28.896491Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!cp /kaggle/input/superpoint-lightglue/superpoint_lightglue.pth /root/.cache/torch/hub/checkpoints/\n!cp /kaggle/input/superpoint-lightglue/superpoint_lightglue.pth  /root/.cache/torch/hub/checkpoints/superpoint_lightglue_v0-1_arxiv-pth\n!cp /kaggle/input/superpoint-lightglue/superpoint_v1.pth /root/.cache/torch/hub/checkpoints/superpoint_v1.pth\n!cp /kaggle/input/superpoint-lightglue/superpoint_v1.pth /root/.cache/torch/hub/checkpoints/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T18:57:28.899320Z","iopub.execute_input":"2025-05-29T18:57:28.899601Z","iopub.status.idle":"2025-05-29T18:57:29.835892Z","shell.execute_reply.started":"2025-05-29T18:57:28.899578Z","shell.execute_reply":"2025-05-29T18:57:29.834993Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import os\nprint(os.path.exists(\"/root/.cache/torch/hub/checkpoints/depth-save.pth\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T18:57:29.837189Z","iopub.execute_input":"2025-05-29T18:57:29.837504Z","iopub.status.idle":"2025-05-29T18:57:29.841900Z","shell.execute_reply.started":"2025-05-29T18:57:29.837480Z","shell.execute_reply":"2025-05-29T18:57:29.841195Z"}},"outputs":[{"name":"stdout","text":"True\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import sys\nimport os\nfrom tqdm import tqdm\nfrom time import time, sleep\nimport gc\nimport numpy as np\nimport h5py\nimport dataclasses\nimport pandas as pd\nfrom IPython.display import clear_output\nfrom collections import defaultdict\nfrom copy import deepcopy\nfrom PIL import Image\n\nimport cv2\nimport torch\nimport torch.nn.functional as F\nimport kornia as K\nimport kornia.feature as KF\n\nimport torch\nfrom lightglue import match_pair\nfrom lightglue import ALIKED, LightGlue\nfrom lightglue.utils import load_image, rbd\nfrom transformers import AutoImageProcessor, AutoModel\n\n# from lightglue import DISK\nfrom kornia.feature import LightGlueMatcher as KF_LightGlueMatcher\nfrom scipy.spatial import cKDTree # For efficient nearest neighbor search to remove duplicate keypoints\n\n# IMPORTANT Utilities: importing data into colmap and competition metric\nimport pycolmap\nsys.path.append('/kaggle/input/imc25-utils')\nfrom database import *\nfrom h5_to_db import *\nimport metric\n\n\n# LightGlue\nfrom lightglue import match_pair\nfrom lightglue import ALIKED, SuperPoint,DISK, DoGHardNet, LightGlue, SIFT\nfrom fastprogress import progress_bar\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T18:57:29.842929Z","iopub.execute_input":"2025-05-29T18:57:29.843238Z","iopub.status.idle":"2025-05-29T18:57:52.965736Z","shell.execute_reply.started":"2025-05-29T18:57:29.843208Z","shell.execute_reply":"2025-05-29T18:57:52.965030Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/kornia/feature/lightglue.py:44: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n/usr/local/lib/python3.10/dist-packages/lightglue/lightglue.py:24: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from collections import defaultdict\nfrom copy import deepcopy\nimport concurrent.futures\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T18:57:52.966482Z","iopub.execute_input":"2025-05-29T18:57:52.967119Z","iopub.status.idle":"2025-05-29T18:57:52.970790Z","shell.execute_reply.started":"2025-05-29T18:57:52.967091Z","shell.execute_reply":"2025-05-29T18:57:52.969935Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"\nprint(\"PyTorch version:\", torch.__version__)\nimport sys\nprint(\"Python version:\", sys.version)\n\nprint(\"CUDA available:\", torch.cuda.is_available())\nprint(\"CUDA version:\", torch.version.cuda)\nprint(\"Device count:\", torch.cuda.device_count())\nprint(\"Current device:\", torch.cuda.current_device())\nprint(\"Device name:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T18:57:52.971610Z","iopub.execute_input":"2025-05-29T18:57:52.971883Z","iopub.status.idle":"2025-05-29T18:57:53.128888Z","shell.execute_reply.started":"2025-05-29T18:57:52.971851Z","shell.execute_reply":"2025-05-29T18:57:53.128154Z"}},"outputs":[{"name":"stdout","text":"PyTorch version: 2.5.1+cu121\nPython version: 3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]\nCUDA available: True\nCUDA version: 12.1\nDevice count: 2\nCurrent device: 0\nDevice name: Tesla T4\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Do not forget to select an accelerator on the sidebar to the right.\ndevice = K.utils.get_cuda_device_if_available(0)\nprint(f'{device=}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T18:57:53.130892Z","iopub.execute_input":"2025-05-29T18:57:53.131109Z","iopub.status.idle":"2025-05-29T18:57:53.135370Z","shell.execute_reply.started":"2025-05-29T18:57:53.131091Z","shell.execute_reply":"2025-05-29T18:57:53.134551Z"}},"outputs":[{"name":"stdout","text":"device=device(type='cuda', index=0)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"VERBOSE = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T18:57:53.136742Z","iopub.execute_input":"2025-05-29T18:57:53.136936Z","iopub.status.idle":"2025-05-29T18:57:53.153002Z","shell.execute_reply.started":"2025-05-29T18:57:53.136919Z","shell.execute_reply":"2025-05-29T18:57:53.152339Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"class CONFIG:\n    # DEBUG Settings\n    DRY_RUN = False\n    DRY_RUN_MAX_IMAGES = 10\n\n    # Pipeline settings\n    NUM_CORES = 2\n    \n    # COLMAP Reconstruction\n    CAMERA_MODEL = \"simple-radial\"\n    \n    # Rotation correction\n    ROTATION_CORRECTION = False\n    \n    # Keypoints handling\n    MERGE_PARAMS = {\n        \"min_matches\" : 15,\n        # When merging keypoints, it is enable to filtering matches with cv2.findFundamentalMatrix.\n        \"filter_FundamentalMatrix\" : True,\n        \"filter_iterations\" : 5,\n        \"filter_threshold\" : 3,\n    }\n    \n    # Keypoints Extraction\n    use_aliked_lightglue = True\n    use_doghardnet_lightglue = False\n    use_superpoint_lightglue = True\n    use_disk_lightglue = True\n    use_sift_lightglue = False\n    use_loftr = False\n    use_dkm = False\n    use_superglue = False\n    use_matchformer = False\n        \n    # Keypoints Extraction Parameters\n    params_aliked_lightglue = {\n        \"num_features\" : 4096,\n        \"detection_threshold\" : 0.1,\n        \"min_matches\" : 100,\n        \"resize_to\" : 2048,\n        \"match_confidence_threshold\":0.2\n    }\n    \n    params_doghardnet_lightglue = {\n        \"num_features\" : 8192,\n        \"detection_threshold\" : 0.001,\n        \"min_matches\" : 15,\n        \"resize_to\" : 1024,\n    }\n    \n    params_superpoint_lightglue = {\n        \"num_features\" : 4096,\n        \"detection_threshold\" : 0.1,\n        \"min_matches\" : 50,\n        \"resize_to\" : 1024,\n        \"match_confidence_threshold\":0.2\n    }\n    \n    params_disk_lightglue = {\n        \"num_features\" : 4096,\n        \"detection_threshold\" : 0.1,\n        \"min_matches\" : 100,\n        \"resize_to\" : 2048,\n        \"match_confidence_threshold\":0.2\n    }\n\n    params_sift_lightglue = {\n        \"num_features\" : 8192,\n        \"detection_threshold\" : 0.001,\n        \"min_matches\" : 15,\n        \"resize_to\" : 1024,\n    }\n\n    params_loftr = {\n        \"resize_small_edge_to\" : 750,\n        \"min_matches\" : 15,\n    }\n    \n    params_dkm = {\n        \"num_features\" : 2048,\n        \"detection_threshold\" : 0.4,\n        \"min_matches\" : 15,\n        \"resize_to\" : (540, 720),    \n    }\n    \n    # superpoint + superglue  ...  https://www.kaggle.com/competitions/image-matching-challenge-2023/discussion/416873\n    params_sg1 = {\n        \"sg_config\" : \n        {\n            \"superpoint\": {\n                \"nms_radius\": 4, \n                \"keypoint_threshold\": 0.005,\n                \"max_keypoints\": -1,\n            },\n            \"superglue\": {\n                \"weights\": \"outdoor\",\n                \"sinkhorn_iterations\": 20,\n                \"match_threshold\": 0.2,\n            },\n        },\n        \"resize_to\": 1088,\n        \"min_matches\": 15,\n    }\n    params_sg2 = {\n        \"sg_config\" : \n        {\n            \"superpoint\": {\n                \"nms_radius\": 4, \n                \"keypoint_threshold\": 0.005,\n                \"max_keypoints\": -1,\n            },\n            \"superglue\": {\n                \"weights\": \"outdoor\",\n                \"sinkhorn_iterations\": 20,\n                \"match_threshold\": 0.2,\n            },\n        },\n        \"resize_to\": 1280,\n        \"min_matches\": 15,\n    }\n    params_sg3 = {\n        \"sg_config\" : \n        {\n            \"superpoint\": {\n                \"nms_radius\": 4, \n                \"keypoint_threshold\": 0.005,\n                \"max_keypoints\": -1,\n            },\n            \"superglue\": {\n                \"weights\": \"outdoor\",\n                \"sinkhorn_iterations\": 20,\n                \"match_threshold\": 0.2,\n            },\n        },\n        \"resize_to\": 1376,\n        \"min_matches\": 15,\n    }\n    params_sgs = [params_sg1, params_sg2, params_sg3]\n    \n    params_matchformer = {\n        \"detection_threshold\" : 0.15,\n        \"resize_to\" : (560, 750),\n        \"num_features\" : 2000,\n        \"min_matches\" : 15, \n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T18:57:53.153834Z","iopub.execute_input":"2025-05-29T18:57:53.154113Z","iopub.status.idle":"2025-05-29T18:57:53.173298Z","shell.execute_reply.started":"2025-05-29T18:57:53.154078Z","shell.execute_reply":"2025-05-29T18:57:53.172618Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Assume these are available from your environment or previous code\n# from .utils import load_torch_image # Assuming load_torch_image is defined elsewhere\n# from kornia.feature import ALIKED # Already in your detect_aliked\n# from kornia.feature import LightGlueMatcher as KF_LightGlueMatcher # Already in your match_with_lightglue\n# from kornia.geometry import laf_from_center_scale_ori # Already in your match_with_lightglue\n# from colmap_database import COLMAPDatabase, add_keypoints, add_matches # Already in your colmap_import\n\n# --- Helper function for image loading (if not already defined) ---\ndef load_torch_image(fname, device=torch.device('cpu')):\n    img = K.io.load_image(fname, K.io.ImageLoadType.RGB32, device=device)[None, ...]\n    return img\ndef get_dino_patch_features_for_keypoints(img_path, keypoints_xy, dino_processor, dino_model, patch_size=16, device=torch.device('cpu')):\n    \"\"\"\n    Extracts DINO patch features corresponding to given ALIKED keypoint locations.\n    It correctly infers the DINO patch grid dimensions from the processed input.\n\n    Args:\n        img_path (str): Path to the image file.\n        keypoints_xy (torch.Tensor): Nx2 tensor of (x, y) keypoint coordinates in image pixel space.\n                                     These keypoints are assumed to be in the original image's coordinate system.\n        dino_processor: HuggingFace AutoImageProcessor for DINO.\n        dino_model: HuggingFace AutoModel for DINO.\n        patch_size (int): The patch size used by the DINO model (e.g., 14 or 16).\n        device (torch.device): Device to run the models on.\n\n    Returns:\n        torch.Tensor: NxD_dino tensor of DINO patch features for each keypoint.\n                      Returns None if no keypoints or image loading fails.\n    \"\"\"\n    if len(keypoints_xy) == 0:\n        dino_feature_dim = dino_model.config.hidden_size # Get actual DINO hidden size\n        return torch.empty((0, dino_feature_dim), device=device)\n\n    # 1. Load the original image (ALIKED processed this size)\n    original_img = load_torch_image(img_path, device=device)\n    original_h, original_w = original_img.shape[-2], original_img.shape[-1]\n\n\n    # 2. Process the image with DINO's processor\n    #    This step performs resizing, padding, etc., as needed by the DINO model\n    with torch.inference_mode():\n        # dino_processor returns a BatchFeature object which includes pixel_values\n        # and potentially other information like `pixel_mask`\n        inputs = dino_processor(images=original_img, return_tensors=\"pt\", do_rescale=False).to(device)\n        outputs = dino_model(**inputs)\n\n        # Get the actual dimensions of the image as processed by the DINO model\n        # This is the crucial part: the actual H and W that produced `patch_tokens`\n        # We can infer this from the `pixel_values` shape\n        processed_h = inputs['pixel_values'].shape[-2]\n        processed_w = inputs['pixel_values'].shape[-1]\n\n        # Extract patch tokens (excluding the CLS token)\n        patch_tokens = outputs.last_hidden_state[:, 1:].squeeze(0) # Shape: (num_patches, hidden_size)\n\n        # Calculate the actual grid dimensions based on the *processed* image size\n        # and the model's patch size.\n        # This should perfectly match the number of patch_tokens if the model is well-behaved.\n        num_patches_h = processed_h // patch_size\n        num_patches_w = processed_w // patch_size\n\n        # Safety check: ensure calculated grid matches actual token count\n        expected_token_count = num_patches_h * num_patches_w\n        if patch_tokens.shape[0] != expected_token_count:\n            # This indicates a deeper issue with how the model's output tokens\n            # map to the spatial grid, or an unexpected patch size/model behavior.\n            # Some models might have slightly different patch token arrangements.\n            # DINOv2 typically aligns well.\n            raise ValueError(\n                f\"DINO patch token count ({patch_tokens.shape[0]}) does not match \"\n                f\"expected grid dimensions ({num_patches_h}x{num_patches_w} = {expected_token_count}) \"\n                f\"for processed image size {processed_w}x{processed_h} with patch size {patch_size}. \"\n                f\"Please verify DINO model and processor configuration.\"\n            )\n\n        # Reshape patch tokens into a 2D grid\n        patch_features_grid = patch_tokens.reshape(num_patches_h, num_patches_w, -1)\n        dino_feature_dim = patch_features_grid.shape[-1] # Actual feature dimension\n\n\n    dino_features_for_kpts = torch.zeros((len(keypoints_xy), dino_feature_dim), device=device)\n\n    # 3. Rescale ALIKED keypoints to the DINO *processed* image dimensions\n    #    ALIKED keypoints are in original_w x original_h coordinates.\n    #    DINO patches correspond to processed_w x processed_h coordinates.\n    scale_x = processed_w / original_w\n    scale_y = processed_h / original_h\n\n    scaled_keypoints_xy = keypoints_xy.clone()\n    scaled_keypoints_xy[:, 0] *= scale_x\n    scaled_keypoints_xy[:, 1] *= scale_y\n\n    # 4. Map scaled keypoints to DINO patch grid indices\n    keypoint_cols = (scaled_keypoints_xy[:, 0] / patch_size).long()\n    keypoint_rows = (scaled_keypoints_xy[:, 1] / patch_size).long()\n\n    # Clip indices to ensure they are within bounds of the patch grid\n    keypoint_rows = torch.clamp(keypoint_rows, 0, num_patches_h - 1)\n    keypoint_cols = torch.clamp(keypoint_cols, 0, num_patches_w - 1)\n\n    # Gather DINO features for each keypoint's corresponding patch\n    dino_features_for_kpts = patch_features_grid[keypoint_rows, keypoint_cols]\n\n    return dino_features_for_kpts\n\n\ndef convert_coord(r, w, h, rotk):\n    if rotk == 0:\n        return r\n    elif rotk == 1:\n        rx = w-1-r[:, 1]\n        ry = r[:, 0]\n        return torch.concat([rx[None], ry[None]], dim=0).T\n    elif rotk == 2:\n        rx = w-1-r[:, 0]\n        ry = h-1-r[:, 1]\n        return torch.concat([rx[None], ry[None]], dim=0).T\n    elif rotk == 3:\n        rx = r[:, 1]\n        ry = h-1-r[:, 0]\n        return torch.concat([rx[None], ry[None]], dim=0).T\n\ndef detect_common(img_fnames,\n                  model_name,\n                  rots,\n                  file_keypoints,\n                  feature_dir = '.featureout',\n                  num_features = 4096,\n                  resize_to = 1024,\n                  detection_threshold = 0.01,\n                  device=torch.device('cpu'),\n                  min_matches=15,\n                  match_confidence_threshold = 0.0,\n                  verbose=VERBOSE\n                 ):\n    if not os.path.isdir(feature_dir):\n        os.makedirs(feature_dir)\n\n    #####################################################\n    # Extract keypoints and descriptions\n    #####################################################\n    dict_model = {\n        \"aliked\" : ALIKED,\n        \"superpoint\" : SuperPoint,\n        \"doghardnet\" : DoGHardNet,\n        \"disk\" : DISK,\n        \"sift\" : SIFT,\n    }\n    extractor_class = dict_model[model_name]\n    dtype = torch.float32 # ALIKED has issues with float16\n    # extractor = extractor_class(max_num_keypoints=num_features, detection_threshold=detection_threshold, \n    #                             resize=resize_to).eval().to(device, dtype)\n    # if model_name == 'disk':\n    #     extractor = DISK(\n    #         max_num_keypoints=num_features,\n    #         detection_threshold=detection_threshold,\n    #         resize=resize_to\n    #     ).to(device).eval()\n    #     checkpoint = torch.load(ckpt_path, map_location=device)\n    #     extractor.load_state_dict(checkpoint['model'])\n    # else:\n    #     extractor_class = dict_model[model_name]\n    #     extractor = extractor_class(\n    #         max_num_keypoints=num_features,\n    #         detection_threshold=detection_threshold,\n    #         resize=resize_to\n    #     ).to(device, dtype).eval()\n\n    extractor_class = dict_model[model_name]\n    extractor = extractor_class(\n        max_num_keypoints=num_features,\n        detection_threshold=detection_threshold,\n        resize=resize_to\n    ).to(device, dtype).eval()\n    dict_kpts_cuda = {}\n    dict_descs_cuda = {}\n    for (img_path, rot_k) in zip(img_fnames, rots):\n        img_fname = img_path.split('/')[-1]\n        key = img_fname\n        with torch.inference_mode():\n            image0 = load_torch_image(img_path, device=device).to(dtype)\n            h, w = image0.shape[2], image0.shape[3]\n            image1 = torch.rot90(image0, rot_k, [2, 3])\n            feats0 = extractor.extract(image1)  # auto-resize the image, disable with resize=None\n            kpts = feats0['keypoints'].reshape(-1, 2).detach()\n            descs = feats0['descriptors'].reshape(len(kpts), -1).detach()\n            kpts = convert_coord(kpts, w, h, rot_k)\n            dict_kpts_cuda[f\"{key}\"] = kpts\n            dict_descs_cuda[f\"{key}\"] = descs\n            if verbose:\n                print(f\"{model_name} > rot_k={rot_k}, kpts.shape={kpts.shape}, descs.shape={descs.shape}\")\n    del extractor\n    gc.collect()\n\n    #####################################################\n    # Matching keypoints\n    #####################################################\n    lg_matcher = KF.LightGlueMatcher(model_name, {\"width_confidence\": -1,\n                                            \"depth_confidence\": -1,\n                                            \"filter_threshold\":match_confidence_threshold,\n                                             \"mp\": True if 'cuda' in str(device) else False}).eval().to(device)\n    \n    cnt_pairs = 0\n    with h5py.File(file_keypoints, mode='w') as f_match:\n        for pair_idx in tqdm(index_pairs):\n            idx1, idx2 = pair_idx\n            fname1, fname2 = img_fnames[idx1], img_fnames[idx2]\n            \n            key1, key2 = fname1.split('/')[-1], fname2.split('/')[-1]\n            \n            kp1 = dict_kpts_cuda[key1]\n            kp2 = dict_kpts_cuda[key2]\n            desc1 = dict_descs_cuda[key1]\n            desc2 = dict_descs_cuda[key2]\n            with torch.inference_mode():\n                dists, idxs = lg_matcher(desc1,\n                                     desc2,\n                                     KF.laf_from_center_scale_ori(kp1[None]),\n                                     KF.laf_from_center_scale_ori(kp2[None]))\n            if len(idxs)  == 0:\n                continue\n            len1 = len(idxs)\n            n_matches = len1\n            kp1 = kp1[idxs[:,0], :].cpu().numpy().reshape(-1, 2).astype(np.float32)\n            kp2 = kp2[idxs[:,1], :].cpu().numpy().reshape(-1, 2).astype(np.float32)\n            group  = f_match.require_group(key1)\n            if n_matches >= min_matches:\n                group.create_dataset(key2, data=np.concatenate([kp1, kp2], axis=1))\n                cnt_pairs+=1\n                if verbose:\n                    print (f'{model_name}> {key1}-{key2}: {n_matches} matches @ {cnt_pairs}th pair({model_name}+lightglue)')            \n            else:\n                pass\n                # if verbose:\n                #     print (f'{model_name}> {key1}-{key2}: {n_matches} matches --> skipped')\n    del lg_matcher\n    torch.cuda.empty_cache()\n    gc.collect()\n    return\n\ndef detect_lightglue_common(\n    img_fnames, model_name, index_pairs, feature_dir, device, file_keypoints, rots,\n    resize_to=1024,\n    detection_threshold=0.01, \n    num_features=4096, \n    min_matches=15,\n    match_confidence_threshold = 0.0\n):\n    t=time()\n    detect_common(\n        img_fnames, model_name, rots, file_keypoints, feature_dir, \n        resize_to=resize_to,\n        num_features=num_features, \n        detection_threshold=detection_threshold, \n        device=device,\n        min_matches=min_matches,\n        match_confidence_threshold = match_confidence_threshold\n    )\n    gc.collect()\n    t=time() -t \n    print(f'Features matched in  {t:.4f} sec ({model_name}+LightGlue)')\n    return t\n\ndef get_unique_idxs(A, dim=0):\n    # https://stackoverflow.com/questions/72001505/how-to-get-unique-elements-and-their-firstly-appeared-indices-of-a-pytorch-tenso\n    unique, idx, counts = torch.unique(A, dim=dim, sorted=True, return_inverse=True, return_counts=True)\n    _, ind_sorted = torch.sort(idx, stable=True)\n    cum_sum = counts.cumsum(0)\n    cum_sum = torch.cat((torch.tensor([0],device=cum_sum.device), cum_sum[:-1]))\n    first_indices = ind_sorted[cum_sum]\n    return first_indices\n\ndef get_keypoint_from_h5(fp, key1, key2):\n    rc = -1\n    try:\n        kpts = np.array(fp[key1][key2])\n        rc = 0\n        return (rc, kpts)\n    except:\n        return (rc, None)\n\ndef get_keypoint_from_multi_h5(fps, key1, key2):\n    list_mkpts = []\n    for fp in fps:\n        rc, mkpts = get_keypoint_from_h5(fp, key1, key2)\n        if rc == 0:\n            list_mkpts.append(mkpts)\n    if len(list_mkpts) > 0:\n        list_mkpts = np.concatenate(list_mkpts, axis=0)\n    else:\n        list_mkpts = None\n    return list_mkpts\n\ndef matches_merger(\n    img_fnames,\n    index_pairs,\n    files_keypoints,\n    save_file,\n    feature_dir = 'featureout',\n    filter_FundamentalMatrix = False,\n    filter_iterations = 10,\n    filter_threshold = 8,\n    verbose = VERBOSE\n):\n    # open h5 files\n    fps = [ h5py.File(file, mode=\"r\") for file in files_keypoints ]\n\n    with h5py.File(save_file, mode='w') as f_match:\n        counter = 0\n        for pair_idx in progress_bar(index_pairs):\n            idx1, idx2 = pair_idx\n            fname1, fname2 = img_fnames[idx1], img_fnames[idx2]\n            key1, key2 = fname1.split('/')[-1], fname2.split('/')[-1]\n\n            # extract keypoints\n            mkpts = get_keypoint_from_multi_h5(fps, key1, key2)\n            if mkpts is None:\n                # if verbose:\n                #     print(f\"skipped key1={key1}, key2={key2}\")\n                continue\n\n            ori_size = mkpts.shape[0]\n            if mkpts.shape[0] < CONFIG.MERGE_PARAMS[\"min_matches\"]:\n                continue\n            \n            if filter_FundamentalMatrix:\n                store_inliers = { idx:0 for idx in range(mkpts.shape[0]) }\n                idxs = np.array(range(mkpts.shape[0]))\n                for iter in range(filter_iterations):\n                    try:\n                        Fm, inliers = cv2.findFundamentalMat(\n                            mkpts[:,:2], mkpts[:,2:4], cv2.USAC_MAGSAC, 3, 0.9999, 20000)\n                        if Fm is not None:\n                            inliers = inliers > 0\n                            inlier_idxs = idxs[inliers[:, 0]]\n                            #print(inliers.shape, inlier_idxs[:5])\n                            for idx in inlier_idxs:\n                                store_inliers[idx] += 1\n                    except:\n                        print(f\"Failed to cv2.findFundamentalMat. mkpts.shape={mkpts.shape}\")\n                inliers = np.array([ count for (idx, count) in store_inliers.items() ]) >= filter_threshold\n                mkpts = mkpts[inliers]\n                if mkpts.shape[0] < 15:\n                    if verbose:\n                        print(f\"skipped key1={key1}, key2={key2}: mkpts.shape={mkpts.shape} after filtered.\")\n                    continue\n                if verbose:\n                    print(f\"filter_FundamentalMatrix: {len(store_inliers)} matches --> {mkpts.shape[0]} matches\")\n            \n            if verbose:\n                print (f'{key1}-{key2}: {ori_size} --> {mkpts.shape[0]} matches')            \n            # regist tmp file\n            group  = f_match.require_group(key1)\n            group.create_dataset(key2, data=mkpts)\n            counter += 1\n    print( f\"Ensembled pairs : {counter} pairs\" )\n    for fp in fps:\n        fp.close()\n\ndef keypoints_merger(\n    img_fnames,\n    index_pairs,\n    files_keypoints,\n    feature_dir = 'featureout',\n    filter_FundamentalMatrix = False,\n    filter_iterations = 10,\n    filter_threshold = 8,\n):\n    save_file = f'{feature_dir}/merge_tmp.h5'\n    !rm -rf {save_file}\n    matches_merger(\n        img_fnames,\n        index_pairs,\n        files_keypoints,\n        save_file,\n        feature_dir = feature_dir,\n        filter_FundamentalMatrix = filter_FundamentalMatrix,\n        filter_iterations = filter_iterations,\n        filter_threshold = filter_threshold,\n    )\n        \n    # Let's find unique loftr pixels and group them together.\n    kpts = defaultdict(list)\n    match_indexes = defaultdict(dict)\n    total_kpts=defaultdict(int)\n    with h5py.File(save_file, mode='r') as f_match:\n        for k1 in f_match.keys():\n            group  = f_match[k1]\n            for k2 in group.keys():\n                matches = group[k2][...]\n                total_kpts[k1]\n                kpts[k1].append(matches[:, :2])\n                kpts[k2].append(matches[:, 2:])\n                current_match = torch.arange(len(matches)).reshape(-1, 1).repeat(1, 2)\n                current_match[:, 0]+=total_kpts[k1]\n                current_match[:, 1]+=total_kpts[k2]\n                total_kpts[k1]+=len(matches)\n                total_kpts[k2]+=len(matches)\n                match_indexes[k1][k2]=current_match\n\n    for k in kpts.keys():\n        kpts[k] = np.round(np.concatenate(kpts[k], axis=0))\n    unique_kpts = {}\n    unique_match_idxs = {}\n    out_match = defaultdict(dict)\n    for k in kpts.keys():\n        uniq_kps, uniq_reverse_idxs = torch.unique(torch.from_numpy(kpts[k]),dim=0, return_inverse=True)\n        unique_match_idxs[k] = uniq_reverse_idxs\n        unique_kpts[k] = uniq_kps.numpy()\n    for k1, group in match_indexes.items():\n        for k2, m in group.items():\n            m2 = deepcopy(m)\n            m2[:,0] = unique_match_idxs[k1][m2[:,0]]\n            m2[:,1] = unique_match_idxs[k2][m2[:,1]]\n            mkpts = np.concatenate([unique_kpts[k1][ m2[:,0]],\n                                    unique_kpts[k2][  m2[:,1]],\n                                   ],\n                                   axis=1)\n            unique_idxs_current = get_unique_idxs(torch.from_numpy(mkpts), dim=0)\n            m2_semiclean = m2[unique_idxs_current]\n            unique_idxs_current1 = get_unique_idxs(m2_semiclean[:, 0], dim=0)\n            m2_semiclean = m2_semiclean[unique_idxs_current1]\n            unique_idxs_current2 = get_unique_idxs(m2_semiclean[:, 1], dim=0)\n            m2_semiclean2 = m2_semiclean[unique_idxs_current2]\n            out_match[k1][k2] = m2_semiclean2.numpy()\n    with h5py.File(f'{feature_dir}/keypoints.h5', mode='w') as f_kp:\n        for k, kpts1 in unique_kpts.items():\n            f_kp[k] = kpts1\n    \n    with h5py.File(f'{feature_dir}/matches.h5', mode='w') as f_match:\n        for k1, gr in out_match.items():\n            group  = f_match.require_group(k1)\n            for k2, match in gr.items():\n                group[k2] = match\n                # print(f\"KKKKKKK KKKKKK {k1} - {k2}: {len(match)} matches\")\n    return","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T18:57:53.174064Z","iopub.execute_input":"2025-05-29T18:57:53.174289Z","iopub.status.idle":"2025-05-29T18:57:53.200421Z","shell.execute_reply.started":"2025-05-29T18:57:53.174259Z","shell.execute_reply":"2025-05-29T18:57:53.199852Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !rm -rf /kaggle/working/result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T18:57:53.231118Z","iopub.execute_input":"2025-05-29T18:57:53.231387Z","iopub.status.idle":"2025-05-29T18:57:53.249695Z","shell.execute_reply.started":"2025-05-29T18:57:53.231368Z","shell.execute_reply":"2025-05-29T18:57:53.248973Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# --- MODIFIED: Detect ALIKED and Combine with DINO Patch Features ---\ndef detect_aliked_and_combine_with_dino(img_fnames,\n                                        feature_dir='.featureout',\n                                        num_features=4096,\n                                        resize_to=1024,\n                                        dino_processor=None,\n                                        dino_model=None,\n                                        dino_patch_size=16, # Typically 14 or 16 for DINO\n                                        device=torch.device('cpu')):\n    dtype = torch.float32 # ALIKED has issues with float16\n    aliked_extractor = ALIKED(max_num_keypoints=num_features, detection_threshold=0.1).eval().to(device, dtype)\n    aliked_extractor.preprocess_conf[\"resize\"] = resize_to\n    if not os.path.isdir(feature_dir):\n        os.makedirs(feature_dir)\n\n    with h5py.File(f'{feature_dir}/keypoints.h5', mode='w') as f_kp, \\\n         h5py.File(f'{feature_dir}/descriptors_aliked.h5', mode='w') as f_desc_aliked, \\\n         h5py.File(f'{feature_dir}/descriptors_combined.h5', mode='w') as f_desc_combined: # New HDF5 for combined features\n        for img_path in tqdm(img_fnames):\n            img_fname = img_path.split('/')[-1]\n            key = img_fname\n\n            with torch.inference_mode():\n                image0 = load_torch_image(img_path, device=device).to(dtype)\n                feats0 = aliked_extractor.extract(image0)\n                kpts = feats0['keypoints'].reshape(-1, 2).detach().cpu().numpy() # ALIKED keypoints (x,y)\n                descs_aliked = feats0['descriptors'].reshape(len(kpts), -1).detach().cpu().numpy() # ALIKED descriptors\n\n                # Get DINO patch features for these keypoints\n                kpts_torch = torch.from_numpy(kpts).to(device)\n                descs_dino_patch = get_dino_patch_features_for_keypoints(\n                    img_path, kpts_torch, dino_processor, dino_model, dino_patch_size, device\n                ).detach().cpu().numpy()\n\n                # Concatenate ALIKED and DINO features\n                if len(descs_aliked) > 0 and len(descs_dino_patch) > 0:\n                    combined_descs = np.concatenate((descs_aliked, descs_dino_patch), axis=1)\n                elif len(descs_aliked) > 0: # Only ALIKED if no DINO features (shouldn't happen often)\n                    combined_descs = descs_aliked\n                else: # No features found\n                    combined_descs = np.array([]) # Empty array\n\n                f_kp[key] = kpts\n                f_desc_aliked[key] = descs_aliked # Keep ALIKED descriptors for debugging or other uses\n                f_desc_combined[key] = combined_descs # Store the new combined descriptors\n    print(f\"Combined features saved to {feature_dir}/descriptors_combined.h5\")\n    return","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T18:57:53.250561Z","iopub.execute_input":"2025-05-29T18:57:53.250871Z","iopub.status.idle":"2025-05-29T18:57:53.268040Z","shell.execute_reply.started":"2025-05-29T18:57:53.250843Z","shell.execute_reply":"2025-05-29T18:57:53.267189Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"from sklearn.cluster import MiniBatchKMeans # MiniBatchKMeans is faster for large datasets\n\n# --- VLAD Aggregation Function ---\ndef vlad_encode(descriptors, centroids):\n    \"\"\"\n    Performs VLAD encoding.\n\n    Args:\n        descriptors (np.ndarray): NxM array of local descriptors.\n        centroids (np.ndarray): KxM array of K-Means cluster centroids.\n\n    Returns:\n        np.ndarray: 1x(K*M) VLAD descriptor.\n    \"\"\"\n    if descriptors.shape[0] == 0:\n        return np.zeros(centroids.shape[0] * centroids.shape[1], dtype=np.float32)\n\n    num_descriptors, desc_dim = descriptors.shape\n    num_centroids, _ = centroids.shape\n\n    # Assign each descriptor to its nearest centroid\n    # Using cdist for efficiency\n    distances = np.sqrt(np.sum((descriptors[:, None, :] - centroids[None, :, :])**2, axis=2))\n    # distances = cdist(descriptors, centroids, 'sqeuclidean') # Could use cdist for sqeuclidean\n    cluster_assignments = np.argmin(distances, axis=1)\n\n    # Initialize VLAD accumulator\n    vlad_accumulator = np.zeros((num_centroids, desc_dim), dtype=np.float32)\n\n    # Accumulate residuals\n    for i in range(num_descriptors):\n        cluster_idx = cluster_assignments[i]\n        residual = descriptors[i] - centroids[cluster_idx]\n        vlad_accumulator[cluster_idx] += residual\n\n    # Flatten and L2 normalize\n    vlad_descriptor = vlad_accumulator.flatten()\n    vlad_descriptor = F.normalize(torch.from_numpy(vlad_descriptor).unsqueeze(0), dim=1, p=2).squeeze(0).numpy()\n\n    return vlad_descriptor","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T18:57:53.268874Z","iopub.execute_input":"2025-05-29T18:57:53.269100Z","iopub.status.idle":"2025-05-29T18:57:53.645869Z","shell.execute_reply.started":"2025-05-29T18:57:53.269082Z","shell.execute_reply":"2025-05-29T18:57:53.645170Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# --- NEW: Get Global Descriptors using K-Means + VLAD ---\ndef get_global_desc_vlad(fnames, feature_dir='.featureout', num_clusters=64, device=torch.device('cpu')):\n    \"\"\"\n    Generates global descriptors for images using K-Means + VLAD on combined ALIKED+DINO features.\n\n    Args:\n        fnames (list): List of image file paths.\n        feature_dir (str): Directory where combined descriptors are stored.\n        num_clusters (int): Number of clusters for K-Means (K in VLAD).\n        device (torch.device): Not directly used for VLAD computation, but passed for consistency.\n\n    Returns:\n        torch.Tensor: Nx(K*M) tensor of global VLAD descriptors.\n    \"\"\"\n    all_local_descs = []\n    keys_order = [] # To maintain order of descriptors with respect to fnames\n\n    # 1. Load all combined local descriptors\n    with h5py.File(f'{feature_dir}/descriptors_combined.h5', mode='r') as f_desc_combined:\n        for img_path in tqdm(fnames, desc=\"Loading combined local descriptors for K-Means\"):\n            key = img_path.split('/')[-1]\n            if key in f_desc_combined:\n                descs = f_desc_combined[key][...]\n                if descs.shape[0] > 0:\n                    all_local_descs.append(descs)\n                    keys_order.append(key)\n\n    if not all_local_descs:\n        print(\"No combined local descriptors found. Cannot train K-Means or compute VLAD.\")\n        return torch.empty((0, num_clusters * 0), dtype=torch.float32) # Return empty tensor\n\n    # Concatenate all descriptors for K-Means training\n    all_local_descs_flat = np.concatenate(all_local_descs, axis=0)\n\n    # 2. Train K-Means on a subset of descriptors if the dataset is too large\n    # Or directly on all_local_descs_flat if memory permits\n    print(f\"Training K-Means with {num_clusters} clusters on {all_local_descs_flat.shape[0]} descriptors...\")\n    # Use MiniBatchKMeans for efficiency\n    kmeans = MiniBatchKMeans(n_clusters=num_clusters, random_state=0, n_init='auto', batch_size=256).fit(all_local_descs_flat)\n    centroids = kmeans.cluster_centers_\n    print(\"K-Means training complete.\")\n\n    # 3. Compute VLAD descriptor for each image\n    global_descs_vlad = []\n    # Re-iterate through original fnames to match the output order\n    with h5py.File(f'{feature_dir}/descriptors_combined.h5', mode='r') as f_desc_combined:\n        for img_path in tqdm(fnames, desc=\"Computing VLAD descriptors\"):\n            key = img_path.split('/')[-1]\n            if key in f_desc_combined:\n                descs = f_desc_combined[key][...]\n                vlad_desc = vlad_encode(descs, centroids)\n                global_descs_vlad.append(torch.from_numpy(vlad_desc).unsqueeze(0))\n            else:\n                # Handle cases where an image might not have any combined descriptors\n                # (e.g., no ALIKED keypoints detected). Append a zero vector of correct size.\n                print(f\"Warning: No combined descriptors for {key}. Appending zero VLAD descriptor.\")\n                # Determine descriptor dimension from centroids\n                desc_dim_per_cluster = centroids.shape[1] if centroids.shape[1] > 0 else 0 # Should not be 0 normally\n                zero_vlad = np.zeros(num_clusters * desc_dim_per_cluster, dtype=np.float32)\n                global_descs_vlad.append(torch.from_numpy(zero_vlad).unsqueeze(0))\n\n\n    if not global_descs_vlad:\n        return torch.empty((0, num_clusters * centroids.shape[1] if centroids.shape[1] > 0 else 0), dtype=torch.float32)\n\n    global_descs_vlad = torch.cat(global_descs_vlad, dim=0)\n    return global_descs_vlad","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T18:57:53.646707Z","iopub.execute_input":"2025-05-29T18:57:53.646953Z","iopub.status.idle":"2025-05-29T18:57:53.654993Z","shell.execute_reply.started":"2025-05-29T18:57:53.646932Z","shell.execute_reply":"2025-05-29T18:57:53.654190Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# --- RE-DEFINED: get_image_pairs_shortlist to use the new VLAD global descriptor ---\ndef get_image_pairs_shortlist_vlad(fnames,\n                                   sim_th=0.6, # should be strict\n                                   min_pairs=30,\n                                   exhaustive_if_less=20,\n                                   feature_dir='.featureout', # Pass feature_dir\n                                   num_clusters_vlad=64, # New parameter for VLAD\n                                   device=torch.device('cpu')):\n    num_imgs = len(fnames)\n    if num_imgs <= exhaustive_if_less:\n        return get_img_pairs_exhaustive(fnames) # You need to define get_img_pairs_exhaustive if not done.\n\n    # Use the new VLAD-based global descriptor\n    descs = get_global_desc_vlad(fnames, feature_dir=feature_dir, num_clusters=num_clusters_vlad, device=device)\n\n    if descs.shape[0] == 0:\n        print(\"No global descriptors generated. Returning empty matching list.\")\n        return []\n\n    dm = torch.cdist(descs, descs, p=2).detach().cpu().numpy()\n\n    # 只分析上三角（去掉对角线），避免重复\n    triu_indices = np.triu_indices_from(dm, k=1)\n    dm_flat = dm[triu_indices]\n    \n    # 打印统计信息\n    print(\"Distance Matrix Statistics:\")\n    print(f\"Min:  {dm_flat.min():.4f}\")\n    print(f\"Max:  {dm_flat.max():.4f}\")\n    print(f\"Mean: {dm_flat.mean():.4f}\")\n    print(f\"Std:  {dm_flat.std():.4f}\")\n    print(f\"20%:  {np.percentile(dm_flat, 20):.4f}\")\n    print(f\"25%:  {np.percentile(dm_flat, 25):.4f}\")\n    print(f\"USED 60%:  {np.percentile(dm_flat, 60):.4f}\")\n    print(f\"75%:  {np.percentile(dm_flat, 75):.4f}\")\n    threshold = np.percentile(dm_flat, 60) + np.sqrt(3) * dm_flat.std()\n\n    # removing half\n    mask = dm <= np.percentile(dm_flat, 60)\n    total = 0\n    matching_list = []\n    ar = np.arange(num_imgs)\n    already_there_set = set() # Use a set for faster lookup of already added pairs\n\n    for st_idx in range(num_imgs - 1):\n        mask_idx = mask[st_idx]\n        to_match = ar[mask_idx]\n        if len(to_match) < min_pairs:\n            to_match = np.argsort(dm[st_idx])[:min_pairs]\n\n        for idx in to_match:\n            if st_idx == idx:\n                continue\n            if dm[st_idx, idx] < threshold: # Ensure distance is not effectively infinite\n                pair = tuple(sorted((st_idx, idx.item())))\n                if pair not in already_there_set:\n                    matching_list.append(pair)\n                    already_there_set.add(pair)\n                    total += 1\n    matching_list = sorted(list(matching_list)) # Sort the list of tuples\n    return matching_list","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T18:57:53.655699Z","iopub.execute_input":"2025-05-29T18:57:53.655983Z","iopub.status.idle":"2025-05-29T18:57:53.679062Z","shell.execute_reply.started":"2025-05-29T18:57:53.655952Z","shell.execute_reply":"2025-05-29T18:57:53.678360Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def get_img_pairs_exhaustive(img_fnames):\n    index_pairs = []\n    for i in range(len(img_fnames)):\n        for j in range(i+1, len(img_fnames)):\n            index_pairs.append((i,j))\n    return index_pairs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T18:57:53.679746Z","iopub.execute_input":"2025-05-29T18:57:53.679936Z","iopub.status.idle":"2025-05-29T18:57:53.700604Z","shell.execute_reply.started":"2025-05-29T18:57:53.679919Z","shell.execute_reply":"2025-05-29T18:57:53.699704Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# Must Use efficientnet global descriptor to get matching shortlists.\ndef get_global_desc(fnames, device = torch.device('cpu')):\n    processor = AutoImageProcessor.from_pretrained('/kaggle/input/dinov2/pytorch/base/1')\n    model = AutoModel.from_pretrained('/kaggle/input/dinov2/pytorch/base/1')\n    model = model.eval()\n    model = model.to(device)\n    global_descs_dinov2 = []\n    for i, img_fname_full in tqdm(enumerate(fnames),total= len(fnames)):\n        key = os.path.splitext(os.path.basename(img_fname_full))[0]\n        timg = load_torch_image(img_fname_full)\n        with torch.inference_mode():\n            inputs = processor(images=timg, return_tensors=\"pt\", do_rescale=False).to(device)\n            outputs = model(**inputs)\n            dino_mac = F.normalize(outputs.last_hidden_state[:,1:].max(dim=1)[0], dim=1, p=2)\n        global_descs_dinov2.append(dino_mac.detach().cpu())\n    global_descs_dinov2 = torch.cat(global_descs_dinov2, dim=0)\n    return global_descs_dinov2\n\n\ndef get_img_pairs_exhaustive(img_fnames):\n    index_pairs = []\n    for i in range(len(img_fnames)):\n        for j in range(i+1, len(img_fnames)):\n            index_pairs.append((i,j))\n    return index_pairs\n\n\ndef get_image_pairs_shortlist(fnames,\n                              sim_th=0.6,\n                              min_pairs=30,\n                              max_pairs=100,  # 每张图像最多匹配 max_pairs 个\n                              exhaustive_if_less=20,\n                              device=torch.device('cpu')):\n    num_imgs = len(fnames)\n    if num_imgs <= exhaustive_if_less:\n        return get_img_pairs_exhaustive(fnames)\n\n    descs = get_global_desc(fnames, device=device)\n    dm = torch.cdist(descs, descs, p=2).detach().cpu().numpy()\n\n    # 上三角分析（排除重复）\n    triu_indices = np.triu_indices_from(dm, k=1)\n    dm_flat = dm[triu_indices]\n\n    print(\"Distance Matrix Statistics:\")\n    print(f\"Min:  {dm_flat.min():.4f}\")\n    print(f\"Max:  {dm_flat.max():.4f}\")\n    print(f\"Mean: {dm_flat.mean():.4f}\")\n    print(f\"Std:  {dm_flat.std():.4f}\")\n    print(f\"20%:  {np.percentile(dm_flat, 20):.4f}\")\n    print(f\"25%:  {np.percentile(dm_flat, 25):.4f}\")\n    print(f\"60%:  {np.percentile(dm_flat, 60):.4f}\")\n    print(f\"75%:  {np.percentile(dm_flat, 75):.4f}\")\n\n    threshold = np.percentile(dm_flat, 60) + np.sqrt(3) * dm_flat.std()\n    mask = dm <= np.percentile(dm_flat, 50)\n\n    ar = np.arange(num_imgs)\n    matching_set = set()\n\n    for st_idx in range(num_imgs):\n        mask_idx = mask[st_idx]\n        to_match = ar[mask_idx]\n\n        # 保证每张图像至少有 min_pairs 个\n        if len(to_match) < min_pairs:\n            to_match = np.argsort(dm[st_idx])[:min_pairs]\n\n        # 按距离排序，选出前 max_pairs\n        sorted_matches = sorted(\n            [(idx, dm[st_idx, idx]) for idx in to_match if idx != st_idx and dm[st_idx, idx] < threshold],\n            key=lambda x: x[1]\n        )\n        for idx, _ in sorted_matches[:max_pairs]:\n            pair = tuple(sorted((st_idx, idx)))\n            matching_set.add(pair)\n\n    matching_list = sorted(list(matching_set))\n    return matching_list\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T18:57:53.701408Z","iopub.execute_input":"2025-05-29T18:57:53.701643Z","iopub.status.idle":"2025-05-29T18:57:53.718284Z","shell.execute_reply.started":"2025-05-29T18:57:53.701617Z","shell.execute_reply":"2025-05-29T18:57:53.717620Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"def wrapper_keypoints(\n    img_fnames, index_pairs, feature_dir, device, timings, rots\n):\n    #############################################################\n    # get keypoints\n    #############################################################\n    files_keypoints = []\n    \n    if CONFIG.use_superglue:\n        for params_sg in CONFIG.params_sgs:\n            resize_to = params_sg[\"resize_to\"]\n            file_keypoints = f\"{feature_dir}/matches_superglue_{resize_to}pix.h5\"\n            !rm -rf {file_keypoints}\n            t = detect_superglue(\n                img_fnames, index_pairs, feature_dir, device, \n                params_sg[\"sg_config\"], file_keypoints, \n                resize_to=params_sg[\"resize_to\"], \n                min_matches=params_sg[\"min_matches\"],\n            )\n            gc.collect()\n            files_keypoints.append( file_keypoints )\n            timings['feature_matching'].append(t)\n\n    if CONFIG.use_aliked_lightglue:\n        model_name = \"aliked\"\n        file_keypoints = f'{feature_dir}/matches_lightglue_{model_name}.h5'\n        t = detect_lightglue_common(\n            img_fnames, model_name, index_pairs, feature_dir, device, file_keypoints, rots,\n            resize_to=CONFIG.params_aliked_lightglue[\"resize_to\"],\n            detection_threshold=CONFIG.params_aliked_lightglue[\"detection_threshold\"],\n            num_features=CONFIG.params_aliked_lightglue[\"num_features\"],\n            min_matches=CONFIG.params_aliked_lightglue[\"min_matches\"],\n            match_confidence_threshold=CONFIG.params_aliked_lightglue[\"match_confidence_threshold\"]\n        )\n        gc.collect()\n        files_keypoints.append(file_keypoints)\n        timings['feature_matching'].append(t)\n\n    if CONFIG.use_doghardnet_lightglue:\n        model_name = \"doghardnet\"\n        file_keypoints = f'{feature_dir}/matches_lightglue_{model_name}.h5'\n        t = detect_lightglue_common(\n            img_fnames, model_name, index_pairs, feature_dir, device, file_keypoints, rots,\n            resize_to=CONFIG.params_doghardnet_lightglue[\"resize_to\"],\n            detection_threshold=CONFIG.params_doghardnet_lightglue[\"detection_threshold\"],\n            num_features=CONFIG.params_doghardnet_lightglue[\"num_features\"],\n            min_matches=CONFIG.params_doghardnet_lightglue[\"min_matches\"],\n        )\n        gc.collect()\n        files_keypoints.append(file_keypoints)\n        timings['feature_matching'].append(t)\n\n    if CONFIG.use_superpoint_lightglue:\n        model_name = \"superpoint\"\n        file_keypoints = f'{feature_dir}/matches_lightglue_{model_name}.h5'\n        t = detect_lightglue_common(\n            img_fnames, model_name, index_pairs, feature_dir, device, file_keypoints, rots,\n            resize_to=CONFIG.params_superpoint_lightglue[\"resize_to\"],\n            detection_threshold=CONFIG.params_superpoint_lightglue[\"detection_threshold\"],\n            num_features=CONFIG.params_superpoint_lightglue[\"num_features\"],\n            min_matches=CONFIG.params_superpoint_lightglue[\"min_matches\"],\n            match_confidence_threshold=CONFIG.params_superpoint_lightglue[\"match_confidence_threshold\"]\n        )\n        gc.collect()\n        files_keypoints.append(file_keypoints)\n        timings['feature_matching'].append(t)\n\n    if CONFIG.use_disk_lightglue:\n        model_name = \"disk\"\n        file_keypoints = f'{feature_dir}/matches_lightglue_{model_name}.h5'\n        t = detect_lightglue_common(\n            img_fnames, model_name, index_pairs, feature_dir, device, file_keypoints, rots,\n            resize_to=CONFIG.params_disk_lightglue[\"resize_to\"],\n            detection_threshold=CONFIG.params_disk_lightglue[\"detection_threshold\"],\n            num_features=CONFIG.params_disk_lightglue[\"num_features\"],\n            min_matches=CONFIG.params_disk_lightglue[\"min_matches\"],\n            match_confidence_threshold=CONFIG.params_disk_lightglue[\"match_confidence_threshold\"]\n        )\n        gc.collect()\n        files_keypoints.append(file_keypoints)\n        timings['feature_matching'].append(t)\n\n    if CONFIG.use_sift_lightglue:\n        model_name = \"sift\"\n        file_keypoints = f'{feature_dir}/matches_lightglue_{model_name}.h5'\n        t = detect_lightglue_common(\n            img_fnames, model_name, index_pairs, feature_dir, device, file_keypoints, rots,\n            resize_to=CONFIG.params_sift_lightglue[\"resize_to\"],\n            detection_threshold=CONFIG.params_sift_lightglue[\"detection_threshold\"],\n            num_features=CONFIG.params_sift_lightglue[\"num_features\"],\n            min_matches=CONFIG.params_sift_lightglue[\"min_matches\"],\n        )\n        gc.collect()\n        files_keypoints.append(file_keypoints)\n        timings['feature_matching'].append(t)\n\n    if CONFIG.use_loftr:\n        file_keypoints = f'{feature_dir}/matches_loftr_{CONFIG.params_loftr[\"resize_small_edge_to\"]}pix.h5'\n        t = detect_loftr(\n            img_fnames, index_pairs, feature_dir, device, file_keypoints,\n            resize_small_edge_to=CONFIG.params_loftr[\"resize_small_edge_to\"],\n            min_matches=CONFIG.params_loftr[\"min_matches\"],\n        )\n        gc.collect()\n        files_keypoints.append( file_keypoints )\n        timings['feature_matching'].append(t)\n\n    if CONFIG.use_dkm:\n        file_keypoints = f'{feature_dir}/matches_dkm.h5'\n        t = detect_dkm(\n            img_fnames, index_pairs, feature_dir, device, file_keypoints,\n            resize_to=CONFIG.params_dkm[\"resize_to\"], \n            detection_threshold=CONFIG.params_dkm[\"detection_threshold\"], \n            num_features=CONFIG.params_dkm[\"num_features\"], \n            min_matches=CONFIG.params_dkm[\"min_matches\"]\n        )\n        gc.collect()\n        files_keypoints.append(file_keypoints)\n        timings['feature_matching'].append(t)\n\n    if CONFIG.use_matchformer:\n        file_keypoints = f'{feature_dir}/matches_matchformer_{CONFIG.params_matchformer[\"resize_to\"]}pix.h5'\n        t = detect_matchformer(\n            img_fnames, index_pairs, feature_dir, device, file_keypoints,\n            resize_to=CONFIG.params_matchformer[\"resize_to\"],\n            num_features=CONFIG.params_matchformer[\"num_features\"], \n            min_matches=CONFIG.params_matchformer[\"min_matches\"]\n        )\n        gc.collect()\n        files_keypoints.append( file_keypoints )\n        timings['feature_matching'].append(t)\n\n    #############################################################\n    # merge keypoints\n    #############################################################\n    keypoints_merger(\n        img_fnames,\n        index_pairs,\n        files_keypoints,\n        feature_dir = feature_dir,\n        filter_FundamentalMatrix = CONFIG.MERGE_PARAMS[\"filter_FundamentalMatrix\"],\n        filter_iterations = CONFIG.MERGE_PARAMS[\"filter_iterations\"],\n        filter_threshold = CONFIG.MERGE_PARAMS[\"filter_threshold\"],\n    )    \n    return timings\n\n\ndef import_into_colmap(img_dir, feature_dir ='.featureout', database_path = 'colmap.db'):\n    db = COLMAPDatabase.connect(database_path)\n    db.create_tables()\n    single_camera = False\n    fname_to_id = add_keypoints(db, feature_dir, img_dir, '', 'simple-pinhole', single_camera)\n    add_matches(\n        db,\n        feature_dir,\n        fname_to_id,\n    )\n    db.commit()\n    return","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T18:57:53.719015Z","iopub.execute_input":"2025-05-29T18:57:53.719291Z","iopub.status.idle":"2025-05-29T18:57:53.742297Z","shell.execute_reply.started":"2025-05-29T18:57:53.719268Z","shell.execute_reply":"2025-05-29T18:57:53.741359Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"def reconstruct_from_db(feature_dir, img_dir):\n    result = {}\n    local_timings = {'RANSAC': [], 'Reconstruction': []}\n    #############################################################\n    # regist keypoints from h5 into colmap db\n    #############################################################\n    database_path = f'{feature_dir}/colmap.db'\n    if os.path.isfile(database_path):\n        os.remove(database_path)\n    gc.collect()\n    import_into_colmap(img_dir, feature_dir=feature_dir, database_path=database_path)\n    output_path = f'{feature_dir}/colmap_rec'\n    os.makedirs(output_path, exist_ok=True)\n    print(\"colmap database\")\n    #############################################################\n    # Calculate fundamental matrix with colmap api\n    #############################################################\n    t=time()\n    # options = pycolmap.SiftMatchingOptions()\n    # options.confidence = 0.9999\n    # options.max_num_trials = 20000\n    # pycolmap.match_exhaustive(database_path, sift_options=options)\n    pycolmap.match_exhaustive(database_path)\n    print(\"matching done!!!!\")\n    local_timings['RANSAC'].append(time() - t)\n    print(f'RANSAC in {local_timings[\"RANSAC\"][-1]:.4f} sec')\n\n    #############################################################\n    # Execute bundle adjustmnet with colmap api\n    # --> Bundle adjustment Calcs Camera matrix, R and t\n    #############################################################\n    t=time()\n    # By default colmap does not generate a reconstruction if less than 10 images are registered. Lower it to 3.\n    mapper_options = pycolmap.IncrementalPipelineOptions()\n    # mapper_options.mapper.filter_max_reproj_error\t = 1.0\n    # mapper_options.mapper.init_max_error = 2.0\n    mapper_options.min_model_size = 5\n    mapper_options.max_num_models = 25\n    # mapper_options.ba_global_images_freq = 5\n    # # mapper_options.ba_local_num_images = 8\n    # # mapper_options.mapper.abs_pose_min_inlier_ratio = 0.4\n    # mapper_options.ba_global_max_num_iterations = 100\n    # # mapper_options.mapper.filter_max_reproj_error = 6.0\n    # mapper_options.mapper.max_reg_trials = 10\n    # mapper_options.mapper.init_min_num_inliers = 50\n    # mapper_options.mapper.abs_pose_min_num_inliers = 60\n    \n\n    \n    maps = pycolmap.incremental_mapping(database_path=database_path, image_path=img_dir, \n                                        output_path=output_path, options=mapper_options)\n    print(maps)\n    for map_index, rec in maps.items():\n        result[map_index] = {}\n        for img_id, image in rec.images.items():\n            result[map_index][image.name] = {\n                'R': image.cam_from_world.rotation.matrix().tolist(),\n                't': image.cam_from_world.translation.tolist()\n            }\n    # clear_output(wait=False)\n    local_timings['Reconstruction'].append(time() - t)\n    print(f'Reconstruction done in {local_timings[\"Reconstruction\"][-1]:.4f} sec')\n\n    #############################################################\n    # Extract R,t from maps \n    #############################################################            \n    return result, local_timings","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T18:57:53.743219Z","iopub.execute_input":"2025-05-29T18:57:53.743548Z","iopub.status.idle":"2025-05-29T18:57:53.762930Z","shell.execute_reply.started":"2025-05-29T18:57:53.743528Z","shell.execute_reply":"2025-05-29T18:57:53.762098Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# Collect vital info from the dataset\n\n@dataclasses.dataclass\nclass Prediction:\n    image_id: str | None  # A unique identifier for the row -- unused otherwise. Used only on the hidden test set.\n    dataset: str\n    filename: str\n    cluster_index: int | None = None\n    rotation: np.ndarray | None = None\n    translation: np.ndarray | None = None\n\n# Set is_train=True to run the notebook on the training data.\n# Set is_train=False if submitting an entry to the competition (test data is hidden, and different from what you see on the \"test\" folder).\nis_train = False\ndata_dir = '/kaggle/input/image-matching-challenge-2025'\nworkdir = '/kaggle/working/result/'\nos.makedirs(workdir, exist_ok=True)\n\nif is_train:\n    sample_submission_csv = os.path.join(data_dir, 'train_labels.csv')\nelse:\n    sample_submission_csv = os.path.join(data_dir, 'sample_submission.csv')\n\nsamples = {}\ncompetition_data = pd.read_csv(sample_submission_csv)\nfor _, row in competition_data.iterrows():\n    # Note: For the test data, the \"scene\" column has no meaning, and the rotation_matrix and translation_vector columns are random.\n    if row.dataset not in samples:\n        samples[row.dataset] = []\n    samples[row.dataset].append(\n        Prediction(\n            image_id=None if is_train else row.image_id,\n            dataset=row.dataset,\n            filename=row.image\n        )\n    )\n\nfor dataset in samples:\n    print(f'Dataset \"{dataset}\" -> num_images={len(samples[dataset])}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T18:57:53.763782Z","iopub.execute_input":"2025-05-29T18:57:53.764106Z","iopub.status.idle":"2025-05-29T18:57:53.959220Z","shell.execute_reply.started":"2025-05-29T18:57:53.764056Z","shell.execute_reply":"2025-05-29T18:57:53.958591Z"}},"outputs":[{"name":"stdout","text":"Dataset \"ETs\" -> num_images=22\nDataset \"amy_gardens\" -> num_images=200\nDataset \"fbk_vineyard\" -> num_images=163\nDataset \"imc2023_haiper\" -> num_images=54\nDataset \"imc2023_heritage\" -> num_images=209\nDataset \"imc2023_theather_imc2024_church\" -> num_images=76\nDataset \"imc2024_dioscuri_baalshamin\" -> num_images=138\nDataset \"imc2024_lizard_pond\" -> num_images=214\nDataset \"pt_brandenburg_british_buckingham\" -> num_images=225\nDataset \"pt_piazzasanmarco_grandplace\" -> num_images=168\nDataset \"pt_sacrecoeur_trevi_tajmahal\" -> num_images=225\nDataset \"pt_stpeters_stpauls\" -> num_images=200\nDataset \"stairs\" -> num_images=51\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"import cv2\nimport h5py\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n\n\ndef draw_keypoints_and_matches(images_input, unified_kp_path, remapped_matches_path, feature_dir='visualization_output'):\n    output_dir = os.path.join(feature_dir, 'visualization_output')\n    os.makedirs(output_dir, exist_ok=True)\n\n    # Load images and determine image_keys for HDF5 lookup\n    if isinstance(images_input[0], str):\n        loaded_images = [cv2.imread(img_path) for img_path in images_input]\n        image_keys = [os.path.basename(img_path) for img_path in images_input]\n    else:\n        loaded_images = images_input\n        # If images_input are already arrays, you need to provide the corresponding keys\n        # This part is crucial: image_keys MUST align with the HDF5 keys\n        image_keys = image_keys_in_h5 # Use the predefined list for the dummy case\n\n    # Load unified keypoints\n    keypoints_data = {}\n    with h5py.File(unified_kp_path, 'r') as f_kp:\n        for img_name_raw in f_kp.keys():\n            img_name = img_name_raw.decode('utf-8') if isinstance(img_name_raw, bytes) else img_name_raw\n            keypoints_data[img_name] = f_kp[img_name_raw][()] # Access with raw key if bytes\n\n    # Load remapped matches - CORRECTED LOGIC\n    # Store (img1_key, img2_key) directly with matches for robust iteration\n    matches_data_pairs = [] # Will store (img1_key, img2_key, matches_array)\n    with h5py.File(remapped_matches_path, 'r') as f_matches:\n        print(\"\\n--- Loading remapped matches from HDF5 ---\")\n        for img1_group_key_candidate in tqdm(f_matches.keys(), desc=\"Loading matches\"):\n            img1_key = img1_group_key_candidate.decode('utf-8') if isinstance(img1_group_key_candidate, bytes) else img1_group_key_candidate\n\n            img1_group = f_matches[img1_group_key_candidate] # Access with raw key\n\n            if isinstance(img1_group, h5py.Group):\n                for img2_dataset_key_candidate in img1_group.keys():\n                    img2_key = img2_dataset_key_candidate.decode('utf-8') if isinstance(img2_dataset_key_candidate, bytes) else img2_dataset_key_candidate\n\n                    try:\n                        matches_array = img1_group[img2_dataset_key_candidate][()]\n                        matches_data_pairs.append((img1_key, img2_key, matches_array))\n                    except Exception as e:\n                        print(f\"Error loading matches for pair ({img1_key}, {img2_key}): {e}\")\n            else:\n                print(f\"Warning: Expected '{img1_key}' to be a group, but found {type(img1_group)}. Skipping its contents.\")\n\n\n    # --- Drawing Keypoints ---\n    print(\"\\n--- Drawing Keypoints ---\")\n    for i, img_key in enumerate(image_keys):\n        if img_key in keypoints_data:\n            img = loaded_images[i].copy()\n            kpts = keypoints_data[img_key]\n\n            for kp in kpts:\n                x, y = int(kp[0]), int(kp[1])\n                cv2.circle(img, (x, y), 3, (0, 255, 0), -1) # Green circle for keypoint\n\n            output_kp_path = os.path.join(output_dir, f\"keypoints_{img_key}\")\n            if len(img.shape) == 2:\n                img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n            cv2.imwrite(output_kp_path, img)\n            print(f\"Keypoints drawn on {img_key}, saved to {output_kp_path}\")\n        else:\n            print(f\"No keypoints found for {img_key} in unified keypoints file.\")\n\n    # --- Drawing Matches ---\n    print(\"\\n--- Drawing Matches ---\")\n    # Iterate through the (img1_key, img2_key, matches) tuples directly\n    for img_name1, img_name2, matches in matches_data_pairs:\n        # We no longer need to split img_pair_key, as we have img_name1 and img_name2 directly\n\n        # Find the actual image objects and their keypoints using image_keys list\n        try:\n            img1_idx = image_keys.index(img_name1)\n            img2_idx = image_keys.index(img_name2)\n        except ValueError:\n            print(f\"Skipping matches for {img_name1}-{img_name2}: One or both image names not found in the provided 'images' list/keys.\")\n            continue\n\n        img1 = loaded_images[img1_idx].copy()\n        img2 = loaded_images[img2_idx].copy()\n\n        kpts1 = keypoints_data.get(img_name1)\n        kpts2 = keypoints_data.get(img_name2)\n\n        if kpts1 is None or kpts2 is None:\n            print(f\"Skipping matches for {img_name1}-{img_name2}: keypoints not found for one or both images in unified keypoints.\")\n            continue\n        if len(matches) == 0:\n            print(f\"No matches to draw for {img_name1}-{img_name2}.\")\n            continue\n\n        # Ensure images are 3 channels for drawing lines\n        if len(img1.shape) == 2:\n            img1 = cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR)\n        if len(img2.shape) == 2:\n            img2 = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n\n        # Create a concatenated image for drawing matches\n        h1, w1 = img1.shape[:2]\n        h2, w2 = img2.shape[:2]\n        max_h = max(h1, h2)\n        matched_img = np.zeros((max_h, w1 + w2, 3), dtype=np.uint8)\n        matched_img[0:h1, 0:w1] = img1\n        matched_img[0:h2, w1:w1+w2] = img2\n\n        num_matches_to_draw = min(len(matches), 200) # Draw up to 200 matches to avoid clutter, adjust as needed\n\n        for i in range(num_matches_to_draw):\n            match = matches[i]\n            kp1_idx, kp2_idx = int(match[0]), int(match[1])\n\n            # Bounds check for keypoint indices\n            if kp1_idx >= len(kpts1) or kp2_idx >= len(kpts2):\n                # print(f\"Warning: Match index out of bounds for {img_name1}-{img_name2}. Skipping match {kp1_idx}-{kp2_idx}.\")\n                continue\n\n            pt1 = tuple(map(int, kpts1[kp1_idx][:2]))\n            pt2 = tuple(map(int, kpts2[kp2_idx][:2]))\n\n            # Draw circles on the concatenated image\n            cv2.circle(matched_img, pt1, 5, (0, 0, 255), 2) # Red circle on img1 side\n            cv2.circle(matched_img, (pt2[0] + w1, pt2[1]), 5, (255, 0, 0), 2) # Blue circle on img2 side\n\n            # Draw a line connecting the matched keypoints\n            color = tuple(np.random.randint(0, 255, 3).tolist())\n            cv2.line(matched_img, pt1, (pt2[0] + w1, pt2[1]), color, 1)\n\n        output_match_path = os.path.join(output_dir, f\"matches_{img_name1}_{img_name2}.png\")\n        cv2.imwrite(output_match_path, matched_img)\n        print(f\"Matches drawn between {img_name1} and {img_name2}, saved to {output_match_path}\")\n\n\n# Example call (replace with your actual 'images' list)\n# If your 'images' are file paths:\n# images_file_paths = ['path/to/your/image1.jpg', 'path/to/your/image2.jpg', ...]\n# draw_keypoints_and_matches(images_file_paths, unified_kp_path, remapped_matches_path)\n\n# If your 'images' are loaded numpy arrays (as in the dummy example above):\n# draw_keypoints_and_matches(images, unified_kp_path, remapped_matches_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T18:57:53.962009Z","iopub.execute_input":"2025-05-29T18:57:53.962211Z","iopub.status.idle":"2025-05-29T18:57:53.977156Z","shell.execute_reply.started":"2025-05-29T18:57:53.962194Z","shell.execute_reply":"2025-05-29T18:57:53.976358Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"gc.collect()\n\nmax_images = None  # Used For debugging only. Set to None to disable.\ndatasets_to_process = None  # Not the best convention, but None means all datasets.\n\nif is_train:\n    # max_images = 5\n\n    # Note: When running on the training dataset, the notebook will hit the time limit and die. Use this filter to run on a few specific datasets.\n    datasets_to_process = [\n    \t# New data.\n    \t# 'amy_gardens',\n    \t'ETs',\n    \t# 'fbk_vineyard',\n    \t'stairs',\n    \t# Data from IMC 2023 and 2024.\n    \t# 'imc2024_dioscuri_baalshamin',\n    \t# 'imc2023_theather_imc2024_church',\n    \t# 'imc2023_heritage',\n    \t# 'imc2023_haiper',\n    \t# 'imc2024_lizard_pond',\n    \t# Crowdsourced PhotoTourism data.\n    \t# 'pt_stpeters_stpauls',\n    \t# 'pt_brandenburg_british_buckingham',\n    \t# 'pt_piazzasanmarco_grandplace',\n    \t# 'pt_sacrecoeur_trevi_tajmahal',\n    ]\n\ntimings = {\n    'rotation_detection':[],\n    \"global feature extraction\":[],\n    \"shortlisting\":[],\n    \"feature_detection\": [],\n    \"feature_matching\":[],\n    \"RANSAC\": [],\n    \"Reconstruction\": [],\n}\nmapping_result_strs = []\n\n# Load DINOv2 model (for feature extraction, not global descriptor here)\nprint(\"Loading DINOv2 model for patch feature extraction...\")\ndino_processor = AutoImageProcessor.from_pretrained('/kaggle/input/dinov2/pytorch/base/1')\ndino_model = AutoModel.from_pretrained('/kaggle/input/dinov2/pytorch/base/1')\ndino_model = dino_model.eval().to(device)\nprint(\"DINOv2 model loaded.\")\n\nwith concurrent.futures.ProcessPoolExecutor(max_workers=CONFIG.NUM_CORES) as executors:\n    # print (f\"Extracting on device {device}\")\n    for dataset, predictions in samples.items():\n        if datasets_to_process and dataset not in datasets_to_process:\n            print(f'Skipping \"{dataset}\"')\n            continue\n        \n        images_dir = os.path.join(data_dir, 'train' if is_train else 'test', dataset)\n        images = [os.path.join(images_dir, p.filename) for p in predictions]\n        if max_images is not None:\n            images = images[:max_images]\n    \n        print(f'\\nProcessing dataset \"{dataset}\": {len(images)} images')\n    \n        filename_to_index = {p.filename: idx for idx, p in enumerate(predictions)}\n    \n        feature_dir = os.path.join(workdir, 'featureout', dataset)\n        os.makedirs(feature_dir, exist_ok=True)\n    \n        # Wrap algos in try-except blocks so we can populate a submission even if one scene crashes.\n        try:\n            # --- Pipeline Execution ---\n            \n            #############################################################\n            # get image rotations\n            #############################################################\n            t = time()\n            # if CONFIG.ROTATION_CORRECTION:\n            #     rots = exec_rotation_detection(images, device)\n            # else:\n            #     rots = [ 0 for fname in images ]\n            rots = [ 0 for fname in images ]\n            t = time()-t\n            timings['rotation_detection'].append(t)\n            print(f'rotation_detection for {len(images)} images : {t:.4f} sec')\n            # print(\"!!!!!!!!!!!!!!!!!!!!!!\")\n            gc.collect()\n            #############################################################\n            # get image pairs\n            #############################################################\n            # 1. Detect ALIKED features and combine with DINO patch features\n            t = time()\n            index_pairs = get_image_pairs_shortlist(\n                images,\n                sim_th = 0.3, # should be strict\n                min_pairs = 10, # we should select at least min_pairs PER IMAGE with biggest similarity\n                max_pairs = 20,\n                exhaustive_if_less = 20,\n                device=device\n            )\n            timings['shortlisting'].append(time() - t)\n            print (f'Shortlisting. Number of pairs to match: {len(index_pairs)}. Done in {time() - t:.4f} sec')\n            gc.collect()\n            # print(\"\\n--- Step 1: Detecting ALIKED and Combining with DINO Patch Features ---\")\n            # detect_aliked_and_combine_with_dino(\n            #     img_fnames=images,\n            #     feature_dir=feature_dir,\n            #     num_features=4096,\n            #     resize_to=1024,\n            #     dino_processor=dino_processor,\n            #     dino_model=dino_model,\n            #     dino_patch_size=14, # Adjust based on your DINO model's patch size (e.g., 14 for DINOv2 base)\n            #     device=device\n            # )\n            # timings['global feature extraction'].append(time() - t)\n            # print (f'Gloabl feature extracting. Done in {time() - t:.4f} sec')\n            # gc.collect()\n            \n            # # 2. Get image pairs shortlist using VLAD global descriptors\n            # print(\"\\n--- Step 2: Generating Image Pair Shortlist using VLAD ---\")\n            # # Adjust num_clusters_vlad as needed (e.g., 64, 128, 256)\n            # # Higher clusters mean higher dimensionality for global descriptor.\n            # index_pairs = get_image_pairs_shortlist_vlad(\n            #     fnames=images,\n            #     sim_th=0.5,\n            #     min_pairs=20,\n            #     exhaustive_if_less=20,\n            #     feature_dir=feature_dir,\n            #     num_clusters_vlad=128, # Example: 128 clusters for VLAD\n            #     device=device\n            # )\n            # index_pairs = get_img_pairs_exhaustive(images)\n            \n            print(f\"Generated {len(index_pairs)} image pairs using VLAD global descriptor.\")\n            timings['shortlisting'].append(time() - t)\n            print (f'Shortlisting. Number of pairs to match: {len(index_pairs)}. Done in {time() - t:.4f} sec')\n            gc.collect()\n            #############################################################\n            # get keypoints\n            #############################################################    \n            t=time()\n            keypoints_timings = wrapper_keypoints(\n                images, index_pairs, feature_dir, device, timings, rots\n            )\n            timings['feature_matching'] = keypoints_timings['feature_matching']\n            gc.collect()\n            print (f'Local feature extracting and matching. Done in {time() - t:.4f} sec')\n            #############################################################\n            # kick COLMAP reconstruction\n            #############################################################            \n            future = executors.submit(\n                reconstruct_from_db, \n                feature_dir, images_dir)\n            maps, local_timings = future.result()\n            # 合并 timings（主进程里）\n            for k in local_timings:\n                timings[k].extend(local_timings[k])\n            # clear_output(wait=False)\n            registered = 0\n            for map_index, cur_map in maps.items():  # cur_map: image_name → {'R': list, 't': list}\n                for image_name, pose in cur_map.items():\n                    idx = filename_to_index[image_name]\n                    pred = predictions[idx]\n                    pred.cluster_index = map_index\n                    pred.rotation = np.array(pose['R'])  # convert back to np.ndarray\n                    pred.translation = np.array(pose['t'])\n                    registered += 1\n            mapping_result_str = f\"Dataset  {dataset} -> Registered {registered} / {len(images)} images with {len(maps)} clusters\"\n            mapping_result_strs.append(mapping_result_str)\n            print(mapping_result_str)\n\n            gc.collect()\n        except Exception as e:\n            print(e)\n            # raise e\n            mapping_result_str = f'Dataset \"{dataset}\" -> Failed!'\n            mapping_result_strs.append(mapping_result_str)\n            print(mapping_result_str)\n\nprint('\\nResults')\nfor s in mapping_result_strs:\n    print(s)\n\nprint('\\nTimings')\nfor k, v in timings.items():\n    print(f'{k} -> total={sum(v):.02f} sec.')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T18:57:53.978196Z","iopub.execute_input":"2025-05-29T18:57:53.978507Z","iopub.status.idle":"2025-05-29T19:02:59.703483Z","shell.execute_reply.started":"2025-05-29T18:57:53.978485Z","shell.execute_reply":"2025-05-29T19:02:59.702681Z"}},"outputs":[{"name":"stdout","text":"Loading DINOv2 model for patch feature extraction...\nDINOv2 model loaded.\n\nProcessing dataset \"ETs\": 22 images\nrotation_detection for 22 images : 0.0000 sec\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 22/22 [00:02<00:00,  8.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"Distance Matrix Statistics:\nMin:  0.1504\nMax:  0.4104\nMean: 0.2817\nStd:  0.0495\n20%:  0.2356\n25%:  0.2547\n60%:  0.2913\n75%:  0.3260\nShortlisting. Number of pairs to match: 150. Done in 3.0262 sec\nGenerated 150 image pairs using VLAD global descriptor.\nShortlisting. Number of pairs to match: 150. Done in 3.3374 sec\naliked > rot_k=0, kpts.shape=torch.Size([1656, 2]), descs.shape=torch.Size([1656, 128])\naliked > rot_k=0, kpts.shape=torch.Size([1449, 2]), descs.shape=torch.Size([1449, 128])\naliked > rot_k=0, kpts.shape=torch.Size([1341, 2]), descs.shape=torch.Size([1341, 128])\naliked > rot_k=0, kpts.shape=torch.Size([1395, 2]), descs.shape=torch.Size([1395, 128])\naliked > rot_k=0, kpts.shape=torch.Size([1387, 2]), descs.shape=torch.Size([1387, 128])\naliked > rot_k=0, kpts.shape=torch.Size([1343, 2]), descs.shape=torch.Size([1343, 128])\naliked > rot_k=0, kpts.shape=torch.Size([1422, 2]), descs.shape=torch.Size([1422, 128])\naliked > rot_k=0, kpts.shape=torch.Size([1375, 2]), descs.shape=torch.Size([1375, 128])\naliked > rot_k=0, kpts.shape=torch.Size([1132, 2]), descs.shape=torch.Size([1132, 128])\naliked > rot_k=0, kpts.shape=torch.Size([1022, 2]), descs.shape=torch.Size([1022, 128])\naliked > rot_k=0, kpts.shape=torch.Size([2785, 2]), descs.shape=torch.Size([2785, 128])\naliked > rot_k=0, kpts.shape=torch.Size([2762, 2]), descs.shape=torch.Size([2762, 128])\naliked > rot_k=0, kpts.shape=torch.Size([2473, 2]), descs.shape=torch.Size([2473, 128])\naliked > rot_k=0, kpts.shape=torch.Size([2462, 2]), descs.shape=torch.Size([2462, 128])\naliked > rot_k=0, kpts.shape=torch.Size([2866, 2]), descs.shape=torch.Size([2866, 128])\naliked > rot_k=0, kpts.shape=torch.Size([2248, 2]), descs.shape=torch.Size([2248, 128])\naliked > rot_k=0, kpts.shape=torch.Size([2026, 2]), descs.shape=torch.Size([2026, 128])\naliked > rot_k=0, kpts.shape=torch.Size([2171, 2]), descs.shape=torch.Size([2171, 128])\naliked > rot_k=0, kpts.shape=torch.Size([2480, 2]), descs.shape=torch.Size([2480, 128])\naliked > rot_k=0, kpts.shape=torch.Size([1830, 2]), descs.shape=torch.Size([1830, 128])\naliked > rot_k=0, kpts.shape=torch.Size([2499, 2]), descs.shape=torch.Size([2499, 128])\naliked > rot_k=0, kpts.shape=torch.Size([2361, 2]), descs.shape=torch.Size([2361, 128])\nLoaded LightGlue model\n","output_type":"stream"},{"name":"stderr","text":"  3%|▎         | 5/150 [00:00<00:10, 13.90it/s]","output_type":"stream"},{"name":"stdout","text":"aliked> another_et_another_et001.png-another_et_another_et002.png: 962 matches @ 1th pair(aliked+lightglue)\naliked> another_et_another_et001.png-another_et_another_et004.png: 682 matches @ 2th pair(aliked+lightglue)\naliked> another_et_another_et001.png-another_et_another_et005.png: 746 matches @ 3th pair(aliked+lightglue)\naliked> another_et_another_et001.png-another_et_another_et006.png: 342 matches @ 4th pair(aliked+lightglue)\naliked> another_et_another_et001.png-another_et_another_et007.png: 262 matches @ 5th pair(aliked+lightglue)\naliked> another_et_another_et001.png-another_et_another_et008.png: 107 matches @ 6th pair(aliked+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 11%|█         | 16/150 [00:00<00:04, 27.05it/s]","output_type":"stream"},{"name":"stdout","text":"aliked> another_et_another_et002.png-another_et_another_et003.png: 486 matches @ 7th pair(aliked+lightglue)\naliked> another_et_another_et002.png-another_et_another_et004.png: 707 matches @ 8th pair(aliked+lightglue)\naliked> another_et_another_et002.png-another_et_another_et005.png: 652 matches @ 9th pair(aliked+lightglue)\naliked> another_et_another_et002.png-another_et_another_et006.png: 373 matches @ 10th pair(aliked+lightglue)\naliked> another_et_another_et002.png-another_et_another_et007.png: 296 matches @ 11th pair(aliked+lightglue)\naliked> another_et_another_et002.png-another_et_another_et008.png: 103 matches @ 12th pair(aliked+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 22%|██▏       | 33/150 [00:01<00:03, 33.60it/s]","output_type":"stream"},{"name":"stdout","text":"aliked> another_et_another_et003.png-another_et_another_et004.png: 498 matches @ 13th pair(aliked+lightglue)\naliked> another_et_another_et003.png-another_et_another_et005.png: 378 matches @ 14th pair(aliked+lightglue)\naliked> another_et_another_et003.png-another_et_another_et006.png: 259 matches @ 15th pair(aliked+lightglue)\naliked> another_et_another_et003.png-another_et_another_et007.png: 183 matches @ 16th pair(aliked+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 45/150 [00:01<00:03, 33.45it/s]","output_type":"stream"},{"name":"stdout","text":"aliked> another_et_another_et004.png-another_et_another_et005.png: 682 matches @ 17th pair(aliked+lightglue)\naliked> another_et_another_et004.png-another_et_another_et006.png: 333 matches @ 18th pair(aliked+lightglue)\naliked> another_et_another_et004.png-another_et_another_et007.png: 197 matches @ 19th pair(aliked+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 35%|███▌      | 53/150 [00:01<00:02, 34.40it/s]","output_type":"stream"},{"name":"stdout","text":"aliked> another_et_another_et005.png-another_et_another_et006.png: 269 matches @ 20th pair(aliked+lightglue)\naliked> another_et_another_et005.png-another_et_another_et007.png: 177 matches @ 21th pair(aliked+lightglue)\naliked> another_et_another_et006.png-another_et_another_et007.png: 393 matches @ 22th pair(aliked+lightglue)\naliked> another_et_another_et006.png-another_et_another_et008.png: 271 matches @ 23th pair(aliked+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 49%|████▊     | 73/150 [00:02<00:02, 33.38it/s]","output_type":"stream"},{"name":"stdout","text":"aliked> another_et_another_et007.png-another_et_another_et008.png: 393 matches @ 24th pair(aliked+lightglue)\naliked> another_et_another_et007.png-another_et_another_et009.png: 170 matches @ 25th pair(aliked+lightglue)\naliked> another_et_another_et007.png-another_et_another_et010.png: 113 matches @ 26th pair(aliked+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 57%|█████▋    | 85/150 [00:02<00:02, 32.02it/s]","output_type":"stream"},{"name":"stdout","text":"aliked> another_et_another_et008.png-another_et_another_et009.png: 329 matches @ 27th pair(aliked+lightglue)\naliked> another_et_another_et008.png-another_et_another_et010.png: 239 matches @ 28th pair(aliked+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 62%|██████▏   | 93/150 [00:03<00:01, 33.18it/s]","output_type":"stream"},{"name":"stdout","text":"aliked> another_et_another_et009.png-another_et_another_et010.png: 225 matches @ 29th pair(aliked+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 105/150 [00:03<00:01, 27.61it/s]","output_type":"stream"},{"name":"stdout","text":"aliked> et_et000.png-et_et001.png: 1330 matches @ 30th pair(aliked+lightglue)\naliked> et_et000.png-et_et002.png: 892 matches @ 31th pair(aliked+lightglue)\naliked> et_et000.png-et_et003.png: 1738 matches @ 32th pair(aliked+lightglue)\naliked> et_et000.png-et_et004.png: 1003 matches @ 33th pair(aliked+lightglue)\naliked> et_et000.png-et_et005.png: 137 matches @ 34th pair(aliked+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 72%|███████▏  | 108/150 [00:03<00:01, 25.97it/s]","output_type":"stream"},{"name":"stdout","text":"aliked> et_et000.png-et_et006.png: 135 matches @ 35th pair(aliked+lightglue)\naliked> et_et000.png-et_et007.png: 101 matches @ 36th pair(aliked+lightglue)\naliked> et_et001.png-et_et002.png: 1416 matches @ 37th pair(aliked+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 76%|███████▌  | 114/150 [00:03<00:01, 23.38it/s]","output_type":"stream"},{"name":"stdout","text":"aliked> et_et001.png-et_et003.png: 985 matches @ 38th pair(aliked+lightglue)\naliked> et_et001.png-et_et004.png: 1239 matches @ 39th pair(aliked+lightglue)\naliked> et_et001.png-et_et005.png: 227 matches @ 40th pair(aliked+lightglue)\naliked> et_et001.png-et_et006.png: 270 matches @ 41th pair(aliked+lightglue)\naliked> et_et001.png-et_et007.png: 229 matches @ 42th pair(aliked+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 120/150 [00:04<00:01, 22.61it/s]","output_type":"stream"},{"name":"stdout","text":"aliked> et_et002.png-et_et003.png: 680 matches @ 43th pair(aliked+lightglue)\naliked> et_et002.png-et_et004.png: 905 matches @ 44th pair(aliked+lightglue)\naliked> et_et002.png-et_et005.png: 328 matches @ 45th pair(aliked+lightglue)\naliked> et_et002.png-et_et006.png: 403 matches @ 46th pair(aliked+lightglue)\naliked> et_et002.png-et_et007.png: 272 matches @ 47th pair(aliked+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 84%|████████▍ | 126/150 [00:04<00:01, 22.98it/s]","output_type":"stream"},{"name":"stdout","text":"aliked> et_et002.png-et_et008.png: 204 matches @ 48th pair(aliked+lightglue)\naliked> et_et003.png-et_et004.png: 792 matches @ 49th pair(aliked+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 88%|████████▊ | 132/150 [00:04<00:00, 22.93it/s]","output_type":"stream"},{"name":"stdout","text":"aliked> et_et004.png-et_et005.png: 208 matches @ 50th pair(aliked+lightglue)\naliked> et_et004.png-et_et006.png: 245 matches @ 51th pair(aliked+lightglue)\naliked> et_et004.png-et_et007.png: 189 matches @ 52th pair(aliked+lightglue)\naliked> et_et004.png-et_et008.png: 141 matches @ 53th pair(aliked+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 92%|█████████▏| 138/150 [00:04<00:00, 23.23it/s]","output_type":"stream"},{"name":"stdout","text":"aliked> et_et005.png-et_et006.png: 1235 matches @ 54th pair(aliked+lightglue)\naliked> et_et005.png-et_et007.png: 1281 matches @ 55th pair(aliked+lightglue)\naliked> et_et005.png-et_et008.png: 933 matches @ 56th pair(aliked+lightglue)\naliked> et_et006.png-et_et007.png: 1362 matches @ 57th pair(aliked+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 96%|█████████▌| 144/150 [00:05<00:00, 24.78it/s]","output_type":"stream"},{"name":"stdout","text":"aliked> et_et006.png-et_et008.png: 690 matches @ 58th pair(aliked+lightglue)\naliked> et_et007.png-et_et008.png: 884 matches @ 59th pair(aliked+lightglue)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 150/150 [00:05<00:00, 27.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Features matched in  8.1462 sec (aliked+LightGlue)\nsuperpoint > rot_k=0, kpts.shape=torch.Size([395, 2]), descs.shape=torch.Size([395, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([218, 2]), descs.shape=torch.Size([218, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([166, 2]), descs.shape=torch.Size([166, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([207, 2]), descs.shape=torch.Size([207, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([262, 2]), descs.shape=torch.Size([262, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([215, 2]), descs.shape=torch.Size([215, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([203, 2]), descs.shape=torch.Size([203, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([163, 2]), descs.shape=torch.Size([163, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([145, 2]), descs.shape=torch.Size([145, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([165, 2]), descs.shape=torch.Size([165, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([324, 2]), descs.shape=torch.Size([324, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([332, 2]), descs.shape=torch.Size([332, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([319, 2]), descs.shape=torch.Size([319, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([239, 2]), descs.shape=torch.Size([239, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([273, 2]), descs.shape=torch.Size([273, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([181, 2]), descs.shape=torch.Size([181, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([206, 2]), descs.shape=torch.Size([206, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([207, 2]), descs.shape=torch.Size([207, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([198, 2]), descs.shape=torch.Size([198, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([88, 2]), descs.shape=torch.Size([88, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([55, 2]), descs.shape=torch.Size([55, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([103, 2]), descs.shape=torch.Size([103, 256])\nLoaded LightGlue model\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 3/150 [00:00<00:05, 27.23it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> another_et_another_et001.png-another_et_another_et002.png: 184 matches @ 1th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et001.png-another_et_another_et004.png: 151 matches @ 2th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et001.png-another_et_another_et005.png: 192 matches @ 3th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et001.png-another_et_another_et006.png: 155 matches @ 4th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et001.png-another_et_another_et007.png: 131 matches @ 5th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":"  5%|▍         | 7/150 [00:00<00:04, 34.37it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> another_et_another_et001.png-another_et_another_et008.png: 98 matches @ 6th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et001.png-another_et_another_et009.png: 86 matches @ 7th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et001.png-et_et000.png: 122 matches @ 8th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":"  7%|▋         | 11/150 [00:00<00:03, 36.50it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> another_et_another_et001.png-et_et002.png: 85 matches @ 9th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et001.png-outliers_out_et003.png: 62 matches @ 10th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et002.png-another_et_another_et003.png: 93 matches @ 11th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et002.png-another_et_another_et004.png: 120 matches @ 12th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et002.png-another_et_another_et005.png: 135 matches @ 13th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 11%|█         | 16/150 [00:00<00:03, 38.24it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> another_et_another_et002.png-another_et_another_et006.png: 124 matches @ 14th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et002.png-another_et_another_et007.png: 97 matches @ 15th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et002.png-another_et_another_et008.png: 81 matches @ 16th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 13%|█▎        | 20/150 [00:00<00:03, 38.49it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> another_et_another_et002.png-another_et_another_et009.png: 73 matches @ 17th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et002.png-another_et_another_et010.png: 55 matches @ 18th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et002.png-et_et000.png: 97 matches @ 19th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et002.png-et_et001.png: 94 matches @ 20th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et002.png-et_et003.png: 91 matches @ 21th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 16%|█▌        | 24/150 [00:00<00:03, 38.89it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> another_et_another_et002.png-et_et004.png: 73 matches @ 22th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et002.png-et_et006.png: 79 matches @ 23th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et002.png-et_et007.png: 65 matches @ 24th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 19%|█▊        | 28/150 [00:00<00:03, 38.72it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> another_et_another_et002.png-et_et008.png: 77 matches @ 25th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et003.png-another_et_another_et004.png: 86 matches @ 26th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et003.png-another_et_another_et005.png: 91 matches @ 27th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et003.png-another_et_another_et006.png: 70 matches @ 28th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 21%|██▏       | 32/150 [00:00<00:03, 38.31it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> another_et_another_et003.png-another_et_another_et007.png: 72 matches @ 29th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et003.png-another_et_another_et008.png: 55 matches @ 30th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et003.png-another_et_another_et009.png: 63 matches @ 31th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 24%|██▍       | 36/150 [00:00<00:02, 38.24it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> another_et_another_et003.png-et_et003.png: 58 matches @ 32th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et003.png-et_et004.png: 75 matches @ 33th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et003.png-et_et006.png: 62 matches @ 34th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et003.png-et_et007.png: 51 matches @ 35th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 27%|██▋       | 40/150 [00:01<00:02, 38.35it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> another_et_another_et004.png-another_et_another_et005.png: 136 matches @ 36th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et004.png-another_et_another_et006.png: 77 matches @ 37th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 45/150 [00:01<00:02, 38.88it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> another_et_another_et004.png-another_et_another_et007.png: 99 matches @ 38th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et004.png-another_et_another_et008.png: 65 matches @ 39th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et004.png-et_et003.png: 80 matches @ 40th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et004.png-et_et006.png: 75 matches @ 41th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et005.png-another_et_another_et006.png: 115 matches @ 42th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 33%|███▎      | 49/150 [00:01<00:02, 39.11it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> another_et_another_et005.png-another_et_another_et007.png: 114 matches @ 43th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et005.png-another_et_another_et008.png: 79 matches @ 44th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 36%|███▌      | 54/150 [00:01<00:02, 39.41it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> another_et_another_et005.png-another_et_another_et009.png: 75 matches @ 45th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et005.png-et_et000.png: 103 matches @ 46th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et006.png-another_et_another_et007.png: 122 matches @ 47th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et006.png-another_et_another_et008.png: 80 matches @ 48th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et006.png-another_et_another_et009.png: 74 matches @ 49th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et006.png-another_et_another_et010.png: 74 matches @ 50th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et006.png-et_et000.png: 84 matches @ 51th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 41%|████▏     | 62/150 [00:01<00:02, 39.12it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> another_et_another_et006.png-et_et001.png: 64 matches @ 52th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et006.png-et_et003.png: 84 matches @ 53th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et006.png-et_et004.png: 70 matches @ 54th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et006.png-et_et005.png: 63 matches @ 55th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et006.png-et_et006.png: 79 matches @ 56th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et006.png-et_et007.png: 71 matches @ 57th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et006.png-et_et008.png: 64 matches @ 58th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 47%|████▋     | 70/150 [00:01<00:02, 38.94it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> another_et_another_et007.png-another_et_another_et008.png: 96 matches @ 59th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et007.png-another_et_another_et009.png: 85 matches @ 60th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et007.png-another_et_another_et010.png: 66 matches @ 61th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et007.png-et_et000.png: 92 matches @ 62th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et007.png-et_et003.png: 68 matches @ 63th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 49%|████▉     | 74/150 [00:01<00:01, 38.97it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> another_et_another_et007.png-et_et004.png: 77 matches @ 64th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et007.png-et_et005.png: 62 matches @ 65th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et007.png-et_et006.png: 73 matches @ 66th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 52%|█████▏    | 78/150 [00:02<00:01, 38.88it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> another_et_another_et007.png-et_et007.png: 84 matches @ 67th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et007.png-et_et008.png: 68 matches @ 68th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et007.png-outliers_out_et003.png: 50 matches @ 69th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et008.png-another_et_another_et009.png: 75 matches @ 70th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 55%|█████▍    | 82/150 [00:02<00:01, 38.64it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> another_et_another_et008.png-another_et_another_et010.png: 76 matches @ 71th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et008.png-et_et000.png: 88 matches @ 72th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et008.png-et_et001.png: 56 matches @ 73th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 57%|█████▋    | 86/150 [00:02<00:01, 38.91it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> another_et_another_et008.png-et_et003.png: 79 matches @ 74th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et008.png-et_et004.png: 56 matches @ 75th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et008.png-et_et006.png: 68 matches @ 76th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et008.png-et_et007.png: 67 matches @ 77th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 90/150 [00:02<00:01, 39.19it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> another_et_another_et008.png-et_et008.png: 52 matches @ 78th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et009.png-another_et_another_et010.png: 64 matches @ 79th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et009.png-et_et000.png: 68 matches @ 80th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 63%|██████▎   | 94/150 [00:02<00:01, 39.41it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> another_et_another_et009.png-et_et003.png: 61 matches @ 81th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et009.png-et_et004.png: 67 matches @ 82th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et010.png-et_et000.png: 92 matches @ 83th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 66%|██████▌   | 99/150 [00:02<00:01, 39.53it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> another_et_another_et010.png-et_et003.png: 52 matches @ 84th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et010.png-et_et004.png: 57 matches @ 85th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et010.png-et_et007.png: 67 matches @ 86th pair(superpoint+lightglue)\nsuperpoint> another_et_another_et010.png-et_et008.png: 53 matches @ 87th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 69%|██████▊   | 103/150 [00:02<00:01, 39.57it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> et_et000.png-et_et001.png: 207 matches @ 88th pair(superpoint+lightglue)\nsuperpoint> et_et000.png-et_et002.png: 181 matches @ 89th pair(superpoint+lightglue)\nsuperpoint> et_et000.png-et_et003.png: 210 matches @ 90th pair(superpoint+lightglue)\nsuperpoint> et_et000.png-et_et004.png: 150 matches @ 91th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 71%|███████▏  | 107/150 [00:02<00:01, 39.16it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> et_et000.png-et_et005.png: 80 matches @ 92th pair(superpoint+lightglue)\nsuperpoint> et_et000.png-et_et006.png: 102 matches @ 93th pair(superpoint+lightglue)\nsuperpoint> et_et000.png-et_et007.png: 100 matches @ 94th pair(superpoint+lightglue)\nsuperpoint> et_et000.png-et_et008.png: 96 matches @ 95th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 74%|███████▍  | 111/150 [00:02<00:01, 38.65it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> et_et000.png-outliers_out_et003.png: 61 matches @ 96th pair(superpoint+lightglue)\nsuperpoint> et_et001.png-et_et002.png: 235 matches @ 97th pair(superpoint+lightglue)\nsuperpoint> et_et001.png-et_et003.png: 165 matches @ 98th pair(superpoint+lightglue)\nsuperpoint> et_et001.png-et_et004.png: 169 matches @ 99th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 77%|███████▋  | 115/150 [00:02<00:00, 38.64it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> et_et001.png-et_et005.png: 99 matches @ 100th pair(superpoint+lightglue)\nsuperpoint> et_et001.png-et_et006.png: 107 matches @ 101th pair(superpoint+lightglue)\nsuperpoint> et_et001.png-et_et007.png: 98 matches @ 102th pair(superpoint+lightglue)\nsuperpoint> et_et001.png-et_et008.png: 94 matches @ 103th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 79%|███████▉  | 119/150 [00:03<00:00, 38.62it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> et_et002.png-et_et003.png: 148 matches @ 104th pair(superpoint+lightglue)\nsuperpoint> et_et002.png-et_et004.png: 152 matches @ 105th pair(superpoint+lightglue)\nsuperpoint> et_et002.png-et_et005.png: 95 matches @ 106th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 82%|████████▏ | 123/150 [00:03<00:00, 36.98it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> et_et002.png-et_et006.png: 120 matches @ 107th pair(superpoint+lightglue)\nsuperpoint> et_et002.png-et_et007.png: 110 matches @ 108th pair(superpoint+lightglue)\nsuperpoint> et_et002.png-et_et008.png: 99 matches @ 109th pair(superpoint+lightglue)\nsuperpoint> et_et003.png-et_et004.png: 131 matches @ 110th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 85%|████████▍ | 127/150 [00:03<00:00, 36.83it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> et_et003.png-et_et005.png: 85 matches @ 111th pair(superpoint+lightglue)\nsuperpoint> et_et003.png-et_et006.png: 96 matches @ 112th pair(superpoint+lightglue)\nsuperpoint> et_et003.png-et_et007.png: 80 matches @ 113th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 87%|████████▋ | 131/150 [00:03<00:00, 37.64it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> et_et003.png-et_et008.png: 73 matches @ 114th pair(superpoint+lightglue)\nsuperpoint> et_et004.png-et_et005.png: 83 matches @ 115th pair(superpoint+lightglue)\nsuperpoint> et_et004.png-et_et006.png: 109 matches @ 116th pair(superpoint+lightglue)\nsuperpoint> et_et004.png-et_et007.png: 94 matches @ 117th pair(superpoint+lightglue)\nsuperpoint> et_et004.png-et_et008.png: 96 matches @ 118th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 135/150 [00:03<00:00, 37.52it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> et_et005.png-et_et006.png: 130 matches @ 119th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 93%|█████████▎| 139/150 [00:03<00:00, 37.23it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> et_et005.png-et_et007.png: 125 matches @ 120th pair(superpoint+lightglue)\nsuperpoint> et_et005.png-et_et008.png: 103 matches @ 121th pair(superpoint+lightglue)\nsuperpoint> et_et006.png-et_et007.png: 152 matches @ 122th pair(superpoint+lightglue)\nsuperpoint> et_et006.png-et_et008.png: 106 matches @ 123th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 150/150 [00:03<00:00, 38.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"superpoint> et_et006.png-outliers_out_et003.png: 50 matches @ 124th pair(superpoint+lightglue)\nsuperpoint> et_et007.png-et_et008.png: 107 matches @ 125th pair(superpoint+lightglue)\nFeatures matched in  5.8842 sec (superpoint+LightGlue)\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([3959, 2]), descs.shape=torch.Size([3959, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([3945, 2]), descs.shape=torch.Size([3945, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([3789, 2]), descs.shape=torch.Size([3789, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([3722, 2]), descs.shape=torch.Size([3722, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([3725, 2]), descs.shape=torch.Size([3725, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([3742, 2]), descs.shape=torch.Size([3742, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([3406, 2]), descs.shape=torch.Size([3406, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([3319, 2]), descs.shape=torch.Size([3319, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([2928, 2]), descs.shape=torch.Size([2928, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\nLoaded LightGlue model\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/150 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"disk> another_et_another_et001.png-another_et_another_et002.png: 2565 matches @ 1th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":"  1%|▏         | 2/150 [00:00<00:12, 11.54it/s]","output_type":"stream"},{"name":"stdout","text":"disk> another_et_another_et001.png-another_et_another_et004.png: 1794 matches @ 2th pair(disk+lightglue)\ndisk> another_et_another_et001.png-another_et_another_et005.png: 1929 matches @ 3th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":"  3%|▎         | 4/150 [00:00<00:12, 11.60it/s]","output_type":"stream"},{"name":"stdout","text":"disk> another_et_another_et001.png-another_et_another_et006.png: 1280 matches @ 4th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":"  4%|▍         | 6/150 [00:00<00:12, 11.79it/s]","output_type":"stream"},{"name":"stdout","text":"disk> another_et_another_et001.png-another_et_another_et007.png: 619 matches @ 5th pair(disk+lightglue)\ndisk> another_et_another_et001.png-another_et_another_et008.png: 255 matches @ 6th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":"  8%|▊         | 12/150 [00:01<00:12, 11.46it/s]","output_type":"stream"},{"name":"stdout","text":"disk> another_et_another_et002.png-another_et_another_et003.png: 1364 matches @ 7th pair(disk+lightglue)\ndisk> another_et_another_et002.png-another_et_another_et004.png: 1855 matches @ 8th pair(disk+lightglue)\ndisk> another_et_another_et002.png-another_et_another_et005.png: 1798 matches @ 9th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 11%|█         | 16/150 [00:01<00:11, 11.78it/s]","output_type":"stream"},{"name":"stdout","text":"disk> another_et_another_et002.png-another_et_another_et006.png: 1240 matches @ 10th pair(disk+lightglue)\ndisk> another_et_another_et002.png-another_et_another_et007.png: 675 matches @ 11th pair(disk+lightglue)\ndisk> another_et_another_et002.png-another_et_another_et008.png: 288 matches @ 12th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 19%|█▊        | 28/150 [00:02<00:10, 11.35it/s]","output_type":"stream"},{"name":"stdout","text":"disk> another_et_another_et003.png-another_et_another_et004.png: 1460 matches @ 13th pair(disk+lightglue)\ndisk> another_et_another_et003.png-another_et_another_et005.png: 1169 matches @ 14th pair(disk+lightglue)\ndisk> another_et_another_et003.png-another_et_another_et006.png: 852 matches @ 15th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 21%|██▏       | 32/150 [00:02<00:09, 11.84it/s]","output_type":"stream"},{"name":"stdout","text":"disk> another_et_another_et003.png-another_et_another_et007.png: 461 matches @ 16th pair(disk+lightglue)\ndisk> another_et_another_et003.png-another_et_another_et008.png: 193 matches @ 17th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 27%|██▋       | 40/150 [00:03<00:09, 11.67it/s]","output_type":"stream"},{"name":"stdout","text":"disk> another_et_another_et004.png-another_et_another_et005.png: 1791 matches @ 18th pair(disk+lightglue)\ndisk> another_et_another_et004.png-another_et_another_et006.png: 1024 matches @ 19th pair(disk+lightglue)\ndisk> another_et_another_et004.png-another_et_another_et007.png: 464 matches @ 20th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 29%|██▉       | 44/150 [00:03<00:08, 11.84it/s]","output_type":"stream"},{"name":"stdout","text":"disk> another_et_another_et004.png-another_et_another_et008.png: 240 matches @ 21th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 32%|███▏      | 48/150 [00:04<00:08, 12.01it/s]","output_type":"stream"},{"name":"stdout","text":"disk> another_et_another_et005.png-another_et_another_et006.png: 1185 matches @ 22th pair(disk+lightglue)\ndisk> another_et_another_et005.png-another_et_another_et007.png: 405 matches @ 23th pair(disk+lightglue)\ndisk> another_et_another_et005.png-another_et_another_et008.png: 213 matches @ 24th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 36%|███▌      | 54/150 [00:04<00:07, 12.38it/s]","output_type":"stream"},{"name":"stdout","text":"disk> another_et_another_et006.png-another_et_another_et007.png: 1201 matches @ 25th pair(disk+lightglue)\ndisk> another_et_another_et006.png-another_et_another_et008.png: 787 matches @ 26th pair(disk+lightglue)\ndisk> another_et_another_et006.png-another_et_another_et009.png: 160 matches @ 27th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 45%|████▌     | 68/150 [00:05<00:06, 12.29it/s]","output_type":"stream"},{"name":"stdout","text":"disk> another_et_another_et007.png-another_et_another_et008.png: 1104 matches @ 28th pair(disk+lightglue)\ndisk> another_et_another_et007.png-another_et_another_et009.png: 555 matches @ 29th pair(disk+lightglue)\ndisk> another_et_another_et007.png-another_et_another_et010.png: 292 matches @ 30th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 53%|█████▎    | 80/150 [00:06<00:05, 12.59it/s]","output_type":"stream"},{"name":"stdout","text":"disk> another_et_another_et008.png-another_et_another_et009.png: 993 matches @ 31th pair(disk+lightglue)\ndisk> another_et_another_et008.png-another_et_another_et010.png: 356 matches @ 32th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 61%|██████▏   | 92/150 [00:07<00:04, 12.72it/s]","output_type":"stream"},{"name":"stdout","text":"disk> another_et_another_et009.png-another_et_another_et010.png: 637 matches @ 33th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 68%|██████▊   | 102/150 [00:08<00:03, 12.27it/s]","output_type":"stream"},{"name":"stdout","text":"disk> et_et000.png-et_et001.png: 2182 matches @ 34th pair(disk+lightglue)\ndisk> et_et000.png-et_et002.png: 1747 matches @ 35th pair(disk+lightglue)\ndisk> et_et000.png-et_et003.png: 2874 matches @ 36th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 71%|███████   | 106/150 [00:08<00:03, 11.42it/s]","output_type":"stream"},{"name":"stdout","text":"disk> et_et000.png-et_et004.png: 1572 matches @ 37th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 75%|███████▍  | 112/150 [00:09<00:03, 10.87it/s]","output_type":"stream"},{"name":"stdout","text":"disk> et_et001.png-et_et002.png: 2335 matches @ 38th pair(disk+lightglue)\ndisk> et_et001.png-et_et003.png: 1873 matches @ 39th pair(disk+lightglue)\ndisk> et_et001.png-et_et004.png: 1855 matches @ 40th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 120/150 [00:10<00:02, 10.65it/s]","output_type":"stream"},{"name":"stdout","text":"disk> et_et002.png-et_et003.png: 1538 matches @ 41th pair(disk+lightglue)\ndisk> et_et002.png-et_et004.png: 1610 matches @ 42th pair(disk+lightglue)\ndisk> et_et002.png-et_et005.png: 290 matches @ 43th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 81%|████████▏ | 122/150 [00:10<00:02, 10.64it/s]","output_type":"stream"},{"name":"stdout","text":"disk> et_et002.png-et_et006.png: 774 matches @ 44th pair(disk+lightglue)\ndisk> et_et002.png-et_et007.png: 187 matches @ 45th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 84%|████████▍ | 126/150 [00:10<00:02, 10.64it/s]","output_type":"stream"},{"name":"stdout","text":"disk> et_et003.png-et_et004.png: 1410 matches @ 46th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 88%|████████▊ | 132/150 [00:11<00:01, 10.64it/s]","output_type":"stream"},{"name":"stdout","text":"disk> et_et004.png-et_et005.png: 224 matches @ 47th pair(disk+lightglue)\ndisk> et_et004.png-et_et006.png: 349 matches @ 48th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 91%|█████████ | 136/150 [00:11<00:01, 10.60it/s]","output_type":"stream"},{"name":"stdout","text":"disk> et_et005.png-et_et006.png: 2465 matches @ 49th pair(disk+lightglue)\ndisk> et_et005.png-et_et007.png: 2452 matches @ 50th pair(disk+lightglue)\ndisk> et_et005.png-et_et008.png: 1848 matches @ 51th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 95%|█████████▍| 142/150 [00:12<00:00, 10.62it/s]","output_type":"stream"},{"name":"stdout","text":"disk> et_et006.png-et_et007.png: 2729 matches @ 52th pair(disk+lightglue)\ndisk> et_et006.png-et_et008.png: 1614 matches @ 53th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 97%|█████████▋| 146/150 [00:12<00:00, 10.61it/s]","output_type":"stream"},{"name":"stdout","text":"disk> et_et007.png-et_et008.png: 1931 matches @ 54th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 150/150 [00:12<00:00, 11.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Features matched in  17.8944 sec (disk+LightGlue)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      <progress value='150' class='' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      100.00% [150/150 00:12&lt;00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"filter_FundamentalMatrix: 3711 matches --> 3687 matches\nanother_et_another_et001.png-another_et_another_et002.png: 3711 --> 3687 matches\nfilter_FundamentalMatrix: 2627 matches --> 2585 matches\nanother_et_another_et001.png-another_et_another_et004.png: 2627 --> 2585 matches\nfilter_FundamentalMatrix: 2867 matches --> 2835 matches\nanother_et_another_et001.png-another_et_another_et005.png: 2867 --> 2835 matches\nfilter_FundamentalMatrix: 1777 matches --> 1672 matches\nanother_et_another_et001.png-another_et_another_et006.png: 1777 --> 1672 matches\nfilter_FundamentalMatrix: 1012 matches --> 907 matches\nanother_et_another_et001.png-another_et_another_et007.png: 1012 --> 907 matches\nfilter_FundamentalMatrix: 460 matches --> 353 matches\nanother_et_another_et001.png-another_et_another_et008.png: 460 --> 353 matches\nfilter_FundamentalMatrix: 86 matches --> 18 matches\nanother_et_another_et001.png-another_et_another_et009.png: 86 --> 18 matches\nfilter_FundamentalMatrix: 122 matches --> 21 matches\nanother_et_another_et001.png-et_et000.png: 122 --> 21 matches\nfilter_FundamentalMatrix: 85 matches --> 22 matches\nanother_et_another_et001.png-et_et002.png: 85 --> 22 matches\nfilter_FundamentalMatrix: 62 matches --> 16 matches\nanother_et_another_et001.png-outliers_out_et003.png: 62 --> 16 matches\nfilter_FundamentalMatrix: 1943 matches --> 1898 matches\nanother_et_another_et002.png-another_et_another_et003.png: 1943 --> 1898 matches\nfilter_FundamentalMatrix: 2682 matches --> 2644 matches\nanother_et_another_et002.png-another_et_another_et004.png: 2682 --> 2644 matches\nfilter_FundamentalMatrix: 2585 matches --> 2543 matches\nanother_et_another_et002.png-another_et_another_et005.png: 2585 --> 2543 matches\nfilter_FundamentalMatrix: 1737 matches --> 1636 matches\nanother_et_another_et002.png-another_et_another_et006.png: 1737 --> 1636 matches\nfilter_FundamentalMatrix: 1068 matches --> 976 matches\nanother_et_another_et002.png-another_et_another_et007.png: 1068 --> 976 matches\nfilter_FundamentalMatrix: 472 matches --> 389 matches\nanother_et_another_et002.png-another_et_another_et008.png: 472 --> 389 matches\nfilter_FundamentalMatrix: 73 matches --> 19 matches\nanother_et_another_et002.png-another_et_another_et009.png: 73 --> 19 matches\nskipped key1=another_et_another_et002.png, key2=another_et_another_et010.png: mkpts.shape=(14, 4) after filtered.\nfilter_FundamentalMatrix: 97 matches --> 17 matches\nanother_et_another_et002.png-et_et000.png: 97 --> 17 matches\nfilter_FundamentalMatrix: 94 matches --> 19 matches\nanother_et_another_et002.png-et_et001.png: 94 --> 19 matches\nfilter_FundamentalMatrix: 91 matches --> 22 matches\nanother_et_another_et002.png-et_et003.png: 91 --> 22 matches\nfilter_FundamentalMatrix: 73 matches --> 15 matches\nanother_et_another_et002.png-et_et004.png: 73 --> 15 matches\nfilter_FundamentalMatrix: 79 matches --> 24 matches\nanother_et_another_et002.png-et_et006.png: 79 --> 24 matches\nfilter_FundamentalMatrix: 65 matches --> 16 matches\nanother_et_another_et002.png-et_et007.png: 65 --> 16 matches\nfilter_FundamentalMatrix: 77 matches --> 17 matches\nanother_et_another_et002.png-et_et008.png: 77 --> 17 matches\nfilter_FundamentalMatrix: 2044 matches --> 1993 matches\nanother_et_another_et003.png-another_et_another_et004.png: 2044 --> 1993 matches\nfilter_FundamentalMatrix: 1638 matches --> 1588 matches\nanother_et_another_et003.png-another_et_another_et005.png: 1638 --> 1588 matches\nfilter_FundamentalMatrix: 1181 matches --> 1113 matches\nanother_et_another_et003.png-another_et_another_et006.png: 1181 --> 1113 matches\nfilter_FundamentalMatrix: 716 matches --> 633 matches\nanother_et_another_et003.png-another_et_another_et007.png: 716 --> 633 matches\nfilter_FundamentalMatrix: 248 matches --> 192 matches\nanother_et_another_et003.png-another_et_another_et008.png: 248 --> 192 matches\nskipped key1=another_et_another_et003.png, key2=another_et_another_et009.png: mkpts.shape=(14, 4) after filtered.\nfilter_FundamentalMatrix: 58 matches --> 16 matches\nanother_et_another_et003.png-et_et003.png: 58 --> 16 matches\nfilter_FundamentalMatrix: 75 matches --> 17 matches\nanother_et_another_et003.png-et_et004.png: 75 --> 17 matches\nskipped key1=another_et_another_et003.png, key2=et_et006.png: mkpts.shape=(13, 4) after filtered.\nfilter_FundamentalMatrix: 51 matches --> 15 matches\nanother_et_another_et003.png-et_et007.png: 51 --> 15 matches\nfilter_FundamentalMatrix: 2609 matches --> 2568 matches\nanother_et_another_et004.png-another_et_another_et005.png: 2609 --> 2568 matches\nfilter_FundamentalMatrix: 1434 matches --> 1364 matches\nanother_et_another_et004.png-another_et_another_et006.png: 1434 --> 1364 matches\nfilter_FundamentalMatrix: 760 matches --> 669 matches\nanother_et_another_et004.png-another_et_another_et007.png: 760 --> 669 matches\nfilter_FundamentalMatrix: 305 matches --> 244 matches\nanother_et_another_et004.png-another_et_another_et008.png: 305 --> 244 matches\nskipped key1=another_et_another_et004.png, key2=et_et003.png: mkpts.shape=(14, 4) after filtered.\nfilter_FundamentalMatrix: 75 matches --> 22 matches\nanother_et_another_et004.png-et_et006.png: 75 --> 22 matches\nfilter_FundamentalMatrix: 1569 matches --> 1499 matches\nanother_et_another_et005.png-another_et_another_et006.png: 1569 --> 1499 matches\nfilter_FundamentalMatrix: 696 matches --> 587 matches\nanother_et_another_et005.png-another_et_another_et007.png: 696 --> 587 matches\nfilter_FundamentalMatrix: 292 matches --> 226 matches\nanother_et_another_et005.png-another_et_another_et008.png: 292 --> 226 matches\nfilter_FundamentalMatrix: 75 matches --> 18 matches\nanother_et_another_et005.png-another_et_another_et009.png: 75 --> 18 matches\nfilter_FundamentalMatrix: 103 matches --> 18 matches\nanother_et_another_et005.png-et_et000.png: 103 --> 18 matches\nfilter_FundamentalMatrix: 1716 matches --> 1629 matches\nanother_et_another_et006.png-another_et_another_et007.png: 1716 --> 1629 matches\nfilter_FundamentalMatrix: 1138 matches --> 1084 matches\nanother_et_another_et006.png-another_et_another_et008.png: 1138 --> 1084 matches\nfilter_FundamentalMatrix: 234 matches --> 169 matches\nanother_et_another_et006.png-another_et_another_et009.png: 234 --> 169 matches\nfilter_FundamentalMatrix: 74 matches --> 18 matches\nanother_et_another_et006.png-another_et_another_et010.png: 74 --> 18 matches\nfilter_FundamentalMatrix: 84 matches --> 19 matches\nanother_et_another_et006.png-et_et000.png: 84 --> 19 matches\nfilter_FundamentalMatrix: 64 matches --> 18 matches\nanother_et_another_et006.png-et_et001.png: 64 --> 18 matches\nfilter_FundamentalMatrix: 84 matches --> 16 matches\nanother_et_another_et006.png-et_et003.png: 84 --> 16 matches\nfilter_FundamentalMatrix: 70 matches --> 17 matches\nanother_et_another_et006.png-et_et004.png: 70 --> 17 matches\nfilter_FundamentalMatrix: 63 matches --> 19 matches\nanother_et_another_et006.png-et_et005.png: 63 --> 19 matches\nfilter_FundamentalMatrix: 79 matches --> 24 matches\nanother_et_another_et006.png-et_et006.png: 79 --> 24 matches\nfilter_FundamentalMatrix: 71 matches --> 16 matches\nanother_et_another_et006.png-et_et007.png: 71 --> 16 matches\nfilter_FundamentalMatrix: 64 matches --> 16 matches\nanother_et_another_et006.png-et_et008.png: 64 --> 16 matches\nfilter_FundamentalMatrix: 1593 matches --> 1521 matches\nanother_et_another_et007.png-another_et_another_et008.png: 1593 --> 1521 matches\nfilter_FundamentalMatrix: 810 matches --> 739 matches\nanother_et_another_et007.png-another_et_another_et009.png: 810 --> 739 matches\nfilter_FundamentalMatrix: 471 matches --> 420 matches\nanother_et_another_et007.png-another_et_another_et010.png: 471 --> 420 matches\nfilter_FundamentalMatrix: 92 matches --> 18 matches\nanother_et_another_et007.png-et_et000.png: 92 --> 18 matches\nfilter_FundamentalMatrix: 68 matches --> 15 matches\nanother_et_another_et007.png-et_et003.png: 68 --> 15 matches\nfilter_FundamentalMatrix: 77 matches --> 16 matches\nanother_et_another_et007.png-et_et004.png: 77 --> 16 matches\nfilter_FundamentalMatrix: 62 matches --> 16 matches\nanother_et_another_et007.png-et_et005.png: 62 --> 16 matches\nfilter_FundamentalMatrix: 73 matches --> 19 matches\nanother_et_another_et007.png-et_et006.png: 73 --> 19 matches\nfilter_FundamentalMatrix: 84 matches --> 20 matches\nanother_et_another_et007.png-et_et007.png: 84 --> 20 matches\nfilter_FundamentalMatrix: 68 matches --> 18 matches\nanother_et_another_et007.png-et_et008.png: 68 --> 18 matches\nskipped key1=another_et_another_et007.png, key2=outliers_out_et003.png: mkpts.shape=(14, 4) after filtered.\nfilter_FundamentalMatrix: 1397 matches --> 1352 matches\nanother_et_another_et008.png-another_et_another_et009.png: 1397 --> 1352 matches\nfilter_FundamentalMatrix: 671 matches --> 615 matches\nanother_et_another_et008.png-another_et_another_et010.png: 671 --> 615 matches\nfilter_FundamentalMatrix: 88 matches --> 19 matches\nanother_et_another_et008.png-et_et000.png: 88 --> 19 matches\nfilter_FundamentalMatrix: 56 matches --> 15 matches\nanother_et_another_et008.png-et_et001.png: 56 --> 15 matches\nfilter_FundamentalMatrix: 79 matches --> 24 matches\nanother_et_another_et008.png-et_et003.png: 79 --> 24 matches\nskipped key1=another_et_another_et008.png, key2=et_et004.png: mkpts.shape=(14, 4) after filtered.\nfilter_FundamentalMatrix: 68 matches --> 17 matches\nanother_et_another_et008.png-et_et006.png: 68 --> 17 matches\nfilter_FundamentalMatrix: 67 matches --> 15 matches\nanother_et_another_et008.png-et_et007.png: 67 --> 15 matches\nfilter_FundamentalMatrix: 52 matches --> 15 matches\nanother_et_another_et008.png-et_et008.png: 52 --> 15 matches\nfilter_FundamentalMatrix: 926 matches --> 859 matches\nanother_et_another_et009.png-another_et_another_et010.png: 926 --> 859 matches\nfilter_FundamentalMatrix: 68 matches --> 18 matches\nanother_et_another_et009.png-et_et000.png: 68 --> 18 matches\nfilter_FundamentalMatrix: 61 matches --> 16 matches\nanother_et_another_et009.png-et_et003.png: 61 --> 16 matches\nfilter_FundamentalMatrix: 67 matches --> 15 matches\nanother_et_another_et009.png-et_et004.png: 67 --> 15 matches\nfilter_FundamentalMatrix: 92 matches --> 22 matches\nanother_et_another_et010.png-et_et000.png: 92 --> 22 matches\nskipped key1=another_et_another_et010.png, key2=et_et003.png: mkpts.shape=(14, 4) after filtered.\nskipped key1=another_et_another_et010.png, key2=et_et004.png: mkpts.shape=(13, 4) after filtered.\nfilter_FundamentalMatrix: 67 matches --> 17 matches\nanother_et_another_et010.png-et_et007.png: 67 --> 17 matches\nfilter_FundamentalMatrix: 53 matches --> 18 matches\nanother_et_another_et010.png-et_et008.png: 53 --> 18 matches\nfilter_FundamentalMatrix: 3719 matches --> 3698 matches\net_et000.png-et_et001.png: 3719 --> 3698 matches\nfilter_FundamentalMatrix: 2820 matches --> 2784 matches\net_et000.png-et_et002.png: 2820 --> 2784 matches\nfilter_FundamentalMatrix: 4822 matches --> 4807 matches\net_et000.png-et_et003.png: 4822 --> 4807 matches\nfilter_FundamentalMatrix: 2725 matches --> 2686 matches\net_et000.png-et_et004.png: 2725 --> 2686 matches\nfilter_FundamentalMatrix: 217 matches --> 139 matches\net_et000.png-et_et005.png: 217 --> 139 matches\nfilter_FundamentalMatrix: 237 matches --> 153 matches\net_et000.png-et_et006.png: 237 --> 153 matches\nfilter_FundamentalMatrix: 201 matches --> 108 matches\net_et000.png-et_et007.png: 201 --> 108 matches\nfilter_FundamentalMatrix: 96 matches --> 18 matches\net_et000.png-et_et008.png: 96 --> 18 matches\nfilter_FundamentalMatrix: 61 matches --> 19 matches\net_et000.png-outliers_out_et003.png: 61 --> 19 matches\nfilter_FundamentalMatrix: 3986 matches --> 3957 matches\net_et001.png-et_et002.png: 3986 --> 3957 matches\nfilter_FundamentalMatrix: 3023 matches --> 2995 matches\net_et001.png-et_et003.png: 3023 --> 2995 matches\nfilter_FundamentalMatrix: 3263 matches --> 3216 matches\net_et001.png-et_et004.png: 3263 --> 3216 matches\nfilter_FundamentalMatrix: 326 matches --> 257 matches\net_et001.png-et_et005.png: 326 --> 257 matches\nfilter_FundamentalMatrix: 377 matches --> 328 matches\net_et001.png-et_et006.png: 377 --> 328 matches\nfilter_FundamentalMatrix: 327 matches --> 280 matches\net_et001.png-et_et007.png: 327 --> 280 matches\nfilter_FundamentalMatrix: 94 matches --> 18 matches\net_et001.png-et_et008.png: 94 --> 18 matches\nfilter_FundamentalMatrix: 2366 matches --> 2335 matches\net_et002.png-et_et003.png: 2366 --> 2335 matches\nfilter_FundamentalMatrix: 2667 matches --> 2614 matches\net_et002.png-et_et004.png: 2667 --> 2614 matches\nfilter_FundamentalMatrix: 713 matches --> 664 matches\net_et002.png-et_et005.png: 713 --> 664 matches\nfilter_FundamentalMatrix: 1297 matches --> 1251 matches\net_et002.png-et_et006.png: 1297 --> 1251 matches\nfilter_FundamentalMatrix: 569 matches --> 515 matches\net_et002.png-et_et007.png: 569 --> 515 matches\nfilter_FundamentalMatrix: 303 matches --> 220 matches\net_et002.png-et_et008.png: 303 --> 220 matches\nfilter_FundamentalMatrix: 2333 matches --> 2280 matches\net_et003.png-et_et004.png: 2333 --> 2280 matches\nfilter_FundamentalMatrix: 85 matches --> 15 matches\net_et003.png-et_et005.png: 85 --> 15 matches\nfilter_FundamentalMatrix: 96 matches --> 22 matches\net_et003.png-et_et006.png: 96 --> 22 matches\nfilter_FundamentalMatrix: 80 matches --> 18 matches\net_et003.png-et_et007.png: 80 --> 18 matches\nfilter_FundamentalMatrix: 73 matches --> 17 matches\net_et003.png-et_et008.png: 73 --> 17 matches\nfilter_FundamentalMatrix: 515 matches --> 476 matches\net_et004.png-et_et005.png: 515 --> 476 matches\nfilter_FundamentalMatrix: 703 matches --> 628 matches\net_et004.png-et_et006.png: 703 --> 628 matches\nfilter_FundamentalMatrix: 283 matches --> 240 matches\net_et004.png-et_et007.png: 283 --> 240 matches\nfilter_FundamentalMatrix: 237 matches --> 156 matches\net_et004.png-et_et008.png: 237 --> 156 matches\nfilter_FundamentalMatrix: 3830 matches --> 3806 matches\net_et005.png-et_et006.png: 3830 --> 3806 matches\nfilter_FundamentalMatrix: 3858 matches --> 3840 matches\net_et005.png-et_et007.png: 3858 --> 3840 matches\nfilter_FundamentalMatrix: 2884 matches --> 2858 matches\net_et005.png-et_et008.png: 2884 --> 2858 matches\nfilter_FundamentalMatrix: 4243 matches --> 4227 matches\net_et006.png-et_et007.png: 4243 --> 4227 matches\nfilter_FundamentalMatrix: 2410 matches --> 2370 matches\net_et006.png-et_et008.png: 2410 --> 2370 matches\nskipped key1=et_et006.png, key2=outliers_out_et003.png: mkpts.shape=(14, 4) after filtered.\nfilter_FundamentalMatrix: 2922 matches --> 2893 matches\net_et007.png-et_et008.png: 2922 --> 2893 matches\nEnsembled pairs : 116 pairs\nLocal feature extracting and matching. Done in 47.8121 sec\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 20/20 [00:00<00:00, 68.22it/s]\n 76%|███████▌  | 116/153 [00:00<00:00, 4442.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"colmap database\nmatching done!!!!\nRANSAC in 3.0423 sec\n{0: Reconstruction(num_reg_images=9, num_cameras=9, num_points3D=7816, num_observations=35442), 1: Reconstruction(num_reg_images=10, num_cameras=10, num_points3D=4920, num_observations=24547)}\nReconstruction done in 28.9712 sec\nDataset  ETs -> Registered 19 / 22 images with 2 clusters\n\nProcessing dataset \"amy_gardens\": 200 images\nrotation_detection for 200 images : 0.0000 sec\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/200 [00:00<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"File does not exist: /kaggle/input/image-matching-challenge-2025/test/amy_gardens/peach_0000.png\nDataset \"amy_gardens\" -> Failed!\n\nProcessing dataset \"fbk_vineyard\": 163 images\nrotation_detection for 163 images : 0.0001 sec\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/163 [00:00<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"File does not exist: /kaggle/input/image-matching-challenge-2025/test/fbk_vineyard/vineyard_split_1_frame_0900.png\nDataset \"fbk_vineyard\" -> Failed!\n\nProcessing dataset \"imc2023_haiper\": 54 images\nrotation_detection for 54 images : 0.0000 sec\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/54 [00:00<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"File does not exist: /kaggle/input/image-matching-challenge-2025/test/imc2023_haiper/bike_image_004.png\nDataset \"imc2023_haiper\" -> Failed!\n\nProcessing dataset \"imc2023_heritage\": 209 images\nrotation_detection for 209 images : 0.0000 sec\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/209 [00:00<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"File does not exist: /kaggle/input/image-matching-challenge-2025/test/imc2023_heritage/cyprus_dsc_6480.png\nDataset \"imc2023_heritage\" -> Failed!\n\nProcessing dataset \"imc2023_theather_imc2024_church\": 76 images\nrotation_detection for 76 images : 0.0000 sec\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/76 [00:00<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"File does not exist: /kaggle/input/image-matching-challenge-2025/test/imc2023_theather_imc2024_church/church_00004.png\nDataset \"imc2023_theather_imc2024_church\" -> Failed!\n\nProcessing dataset \"imc2024_dioscuri_baalshamin\": 138 images\nrotation_detection for 138 images : 0.0000 sec\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/138 [00:00<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"File does not exist: /kaggle/input/image-matching-challenge-2025/test/imc2024_dioscuri_baalshamin/baalshamin_182z.png\nDataset \"imc2024_dioscuri_baalshamin\" -> Failed!\n\nProcessing dataset \"imc2024_lizard_pond\": 214 images\nrotation_detection for 214 images : 0.0000 sec\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/214 [00:00<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"File does not exist: /kaggle/input/image-matching-challenge-2025/test/imc2024_lizard_pond/lizard_00003.png\nDataset \"imc2024_lizard_pond\" -> Failed!\n\nProcessing dataset \"pt_brandenburg_british_buckingham\": 225 images\nrotation_detection for 225 images : 0.0000 sec\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/225 [00:00<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"File does not exist: /kaggle/input/image-matching-challenge-2025/test/pt_brandenburg_british_buckingham/brandenburg_gate_01069771_8567470929.png\nDataset \"pt_brandenburg_british_buckingham\" -> Failed!\n\nProcessing dataset \"pt_piazzasanmarco_grandplace\": 168 images\nrotation_detection for 168 images : 0.0000 sec\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/168 [00:00<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"File does not exist: /kaggle/input/image-matching-challenge-2025/test/pt_piazzasanmarco_grandplace/grand_place_brussels_00460368_4162644685.png\nDataset \"pt_piazzasanmarco_grandplace\" -> Failed!\n\nProcessing dataset \"pt_sacrecoeur_trevi_tajmahal\": 225 images\nrotation_detection for 225 images : 0.0000 sec\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/225 [00:00<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"File does not exist: /kaggle/input/image-matching-challenge-2025/test/pt_sacrecoeur_trevi_tajmahal/sacre_coeur_02928139_3448003521.png\nDataset \"pt_sacrecoeur_trevi_tajmahal\" -> Failed!\n\nProcessing dataset \"pt_stpeters_stpauls\": 200 images\nrotation_detection for 200 images : 0.0000 sec\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/200 [00:00<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"File does not exist: /kaggle/input/image-matching-challenge-2025/test/pt_stpeters_stpauls/st_pauls_cathedral_00162897_2573777698.png\nDataset \"pt_stpeters_stpauls\" -> Failed!\n\nProcessing dataset \"stairs\": 51 images\nrotation_detection for 51 images : 0.0000 sec\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 51/51 [00:09<00:00,  5.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"Distance Matrix Statistics:\nMin:  0.1598\nMax:  0.4240\nMean: 0.2807\nStd:  0.0451\n20%:  0.2433\n25%:  0.2499\n60%:  0.2868\n75%:  0.3089\nShortlisting. Number of pairs to match: 564. Done in 9.9310 sec\nGenerated 564 image pairs using VLAD global descriptor.\nShortlisting. Number of pairs to match: 564. Done in 10.2342 sec\naliked > rot_k=0, kpts.shape=torch.Size([1430, 2]), descs.shape=torch.Size([1430, 128])\naliked > rot_k=0, kpts.shape=torch.Size([1514, 2]), descs.shape=torch.Size([1514, 128])\naliked > rot_k=0, kpts.shape=torch.Size([851, 2]), descs.shape=torch.Size([851, 128])\naliked > rot_k=0, kpts.shape=torch.Size([597, 2]), descs.shape=torch.Size([597, 128])\naliked > rot_k=0, kpts.shape=torch.Size([1017, 2]), descs.shape=torch.Size([1017, 128])\naliked > rot_k=0, kpts.shape=torch.Size([1702, 2]), descs.shape=torch.Size([1702, 128])\naliked > rot_k=0, kpts.shape=torch.Size([392, 2]), descs.shape=torch.Size([392, 128])\naliked > rot_k=0, kpts.shape=torch.Size([1327, 2]), descs.shape=torch.Size([1327, 128])\naliked > rot_k=0, kpts.shape=torch.Size([1172, 2]), descs.shape=torch.Size([1172, 128])\naliked > rot_k=0, kpts.shape=torch.Size([1025, 2]), descs.shape=torch.Size([1025, 128])\naliked > rot_k=0, kpts.shape=torch.Size([544, 2]), descs.shape=torch.Size([544, 128])\naliked > rot_k=0, kpts.shape=torch.Size([238, 2]), descs.shape=torch.Size([238, 128])\naliked > rot_k=0, kpts.shape=torch.Size([1467, 2]), descs.shape=torch.Size([1467, 128])\naliked > rot_k=0, kpts.shape=torch.Size([806, 2]), descs.shape=torch.Size([806, 128])\naliked > rot_k=0, kpts.shape=torch.Size([1209, 2]), descs.shape=torch.Size([1209, 128])\naliked > rot_k=0, kpts.shape=torch.Size([885, 2]), descs.shape=torch.Size([885, 128])\naliked > rot_k=0, kpts.shape=torch.Size([2303, 2]), descs.shape=torch.Size([2303, 128])\naliked > rot_k=0, kpts.shape=torch.Size([2208, 2]), descs.shape=torch.Size([2208, 128])\naliked > rot_k=0, kpts.shape=torch.Size([2183, 2]), descs.shape=torch.Size([2183, 128])\naliked > rot_k=0, kpts.shape=torch.Size([1486, 2]), descs.shape=torch.Size([1486, 128])\naliked > rot_k=0, kpts.shape=torch.Size([1257, 2]), descs.shape=torch.Size([1257, 128])\naliked > rot_k=0, kpts.shape=torch.Size([1933, 2]), descs.shape=torch.Size([1933, 128])\naliked > rot_k=0, kpts.shape=torch.Size([976, 2]), descs.shape=torch.Size([976, 128])\naliked > rot_k=0, kpts.shape=torch.Size([970, 2]), descs.shape=torch.Size([970, 128])\naliked > rot_k=0, kpts.shape=torch.Size([3646, 2]), descs.shape=torch.Size([3646, 128])\naliked > rot_k=0, kpts.shape=torch.Size([632, 2]), descs.shape=torch.Size([632, 128])\naliked > rot_k=0, kpts.shape=torch.Size([440, 2]), descs.shape=torch.Size([440, 128])\naliked > rot_k=0, kpts.shape=torch.Size([1128, 2]), descs.shape=torch.Size([1128, 128])\naliked > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\naliked > rot_k=0, kpts.shape=torch.Size([1541, 2]), descs.shape=torch.Size([1541, 128])\naliked > rot_k=0, kpts.shape=torch.Size([1054, 2]), descs.shape=torch.Size([1054, 128])\naliked > rot_k=0, kpts.shape=torch.Size([1133, 2]), descs.shape=torch.Size([1133, 128])\naliked > rot_k=0, kpts.shape=torch.Size([2563, 2]), descs.shape=torch.Size([2563, 128])\naliked > rot_k=0, kpts.shape=torch.Size([2114, 2]), descs.shape=torch.Size([2114, 128])\naliked > rot_k=0, kpts.shape=torch.Size([2995, 2]), descs.shape=torch.Size([2995, 128])\naliked > rot_k=0, kpts.shape=torch.Size([2111, 2]), descs.shape=torch.Size([2111, 128])\naliked > rot_k=0, kpts.shape=torch.Size([2149, 2]), descs.shape=torch.Size([2149, 128])\naliked > rot_k=0, kpts.shape=torch.Size([2257, 2]), descs.shape=torch.Size([2257, 128])\naliked > rot_k=0, kpts.shape=torch.Size([3735, 2]), descs.shape=torch.Size([3735, 128])\naliked > rot_k=0, kpts.shape=torch.Size([1181, 2]), descs.shape=torch.Size([1181, 128])\naliked > rot_k=0, kpts.shape=torch.Size([1078, 2]), descs.shape=torch.Size([1078, 128])\naliked > rot_k=0, kpts.shape=torch.Size([2382, 2]), descs.shape=torch.Size([2382, 128])\naliked > rot_k=0, kpts.shape=torch.Size([2769, 2]), descs.shape=torch.Size([2769, 128])\naliked > rot_k=0, kpts.shape=torch.Size([3269, 2]), descs.shape=torch.Size([3269, 128])\naliked > rot_k=0, kpts.shape=torch.Size([1897, 2]), descs.shape=torch.Size([1897, 128])\naliked > rot_k=0, kpts.shape=torch.Size([1729, 2]), descs.shape=torch.Size([1729, 128])\naliked > rot_k=0, kpts.shape=torch.Size([1319, 2]), descs.shape=torch.Size([1319, 128])\naliked > rot_k=0, kpts.shape=torch.Size([2404, 2]), descs.shape=torch.Size([2404, 128])\naliked > rot_k=0, kpts.shape=torch.Size([3395, 2]), descs.shape=torch.Size([3395, 128])\naliked > rot_k=0, kpts.shape=torch.Size([1450, 2]), descs.shape=torch.Size([1450, 128])\naliked > rot_k=0, kpts.shape=torch.Size([2413, 2]), descs.shape=torch.Size([2413, 128])\nLoaded LightGlue model\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 4/564 [00:00<00:15, 36.72it/s]","output_type":"stream"},{"name":"stdout","text":"aliked> stairs_split_1_1710453576271.png-stairs_split_1_1710453601885.png: 163 matches @ 1th pair(aliked+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 59/564 [00:01<00:15, 33.32it/s]","output_type":"stream"},{"name":"stdout","text":"aliked> stairs_split_1_1710453606287.png-stairs_split_1_1710453990286.png: 144 matches @ 2th pair(aliked+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 13%|█▎        | 76/564 [00:02<00:13, 37.33it/s]","output_type":"stream"},{"name":"stdout","text":"aliked> stairs_split_1_1710453612890.png-stairs_split_1_1710453985484.png: 141 matches @ 3th pair(aliked+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 25%|██▌       | 142/564 [00:04<00:11, 37.35it/s]","output_type":"stream"},{"name":"stdout","text":"aliked> stairs_split_1_1710453643106.png-stairs_split_1_1710453963274.png: 131 matches @ 4th pair(aliked+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 28%|██▊       | 158/564 [00:04<00:10, 37.04it/s]","output_type":"stream"},{"name":"stdout","text":"aliked> stairs_split_1_1710453651110.png-stairs_split_1_1710453668718.png: 141 matches @ 5th pair(aliked+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 29%|██▊       | 162/564 [00:04<00:11, 36.22it/s]","output_type":"stream"},{"name":"stdout","text":"aliked> stairs_split_1_1710453651110.png-stairs_split_1_1710453930259.png: 165 matches @ 6th pair(aliked+lightglue)\naliked> stairs_split_1_1710453651110.png-stairs_split_1_1710453955270.png: 201 matches @ 7th pair(aliked+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 34%|███▎      | 190/564 [00:05<00:10, 36.21it/s]","output_type":"stream"},{"name":"stdout","text":"aliked> stairs_split_1_1710453659313.png-stairs_split_1_1710453947066.png: 145 matches @ 8th pair(aliked+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 54%|█████▍    | 307/564 [00:09<00:10, 23.98it/s]","output_type":"stream"},{"name":"stdout","text":"aliked> stairs_split_1_1710453689727.png-stairs_split_2_1710453871430.png: 113 matches @ 9th pair(aliked+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 58%|█████▊    | 329/564 [00:10<00:09, 26.04it/s]","output_type":"stream"},{"name":"stdout","text":"aliked> stairs_split_1_1710453704934.png-stairs_split_1_1710453901046.png: 266 matches @ 10th pair(aliked+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 339/564 [00:10<00:08, 27.64it/s]","output_type":"stream"},{"name":"stdout","text":"aliked> stairs_split_1_1710453704934.png-stairs_split_2_1710453745156.png: 246 matches @ 11th pair(aliked+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 61%|██████▏   | 346/564 [00:10<00:07, 30.42it/s]","output_type":"stream"},{"name":"stdout","text":"aliked> stairs_split_1_1710453704934.png-stairs_split_2_1710453790978.png: 164 matches @ 12th pair(aliked+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 65%|██████▍   | 366/564 [00:11<00:06, 31.29it/s]","output_type":"stream"},{"name":"stdout","text":"aliked> stairs_split_1_1710453901046.png-stairs_split_2_1710453862225.png: 115 matches @ 13th pair(aliked+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 70%|██████▉   | 394/564 [00:12<00:04, 35.58it/s]","output_type":"stream"},{"name":"stdout","text":"aliked> stairs_split_1_1710453947066.png-stairs_split_1_1710453990286.png: 135 matches @ 14th pair(aliked+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 78%|███████▊  | 439/564 [00:14<00:06, 20.65it/s]","output_type":"stream"},{"name":"stdout","text":"aliked> stairs_split_2_1710453720741.png-stairs_split_2_1710453786375.png: 646 matches @ 15th pair(aliked+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 84%|████████▍ | 475/564 [00:15<00:03, 22.55it/s]","output_type":"stream"},{"name":"stdout","text":"aliked> stairs_split_2_1710453736752.png-stairs_split_2_1710453871430.png: 431 matches @ 16th pair(aliked+lightglue)\naliked> stairs_split_2_1710453739354.png-stairs_split_2_1710453740954.png: 740 matches @ 17th pair(aliked+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 85%|████████▌ | 481/564 [00:15<00:03, 21.64it/s]","output_type":"stream"},{"name":"stdout","text":"aliked> stairs_split_2_1710453739354.png-stairs_split_2_1710453783374.png: 116 matches @ 18th pair(aliked+lightglue)\naliked> stairs_split_2_1710453739354.png-stairs_split_2_1710453786375.png: 110 matches @ 19th pair(aliked+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 86%|████████▌ | 484/564 [00:15<00:03, 21.29it/s]","output_type":"stream"},{"name":"stdout","text":"aliked> stairs_split_2_1710453739354.png-stairs_split_2_1710453871430.png: 628 matches @ 20th pair(aliked+lightglue)\naliked> stairs_split_2_1710453740954.png-stairs_split_2_1710453759963.png: 372 matches @ 21th pair(aliked+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 87%|████████▋ | 489/564 [00:16<00:03, 19.25it/s]","output_type":"stream"},{"name":"stdout","text":"aliked> stairs_split_2_1710453740954.png-stairs_split_2_1710453786375.png: 661 matches @ 22th pair(aliked+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 89%|████████▉ | 503/564 [00:16<00:02, 22.41it/s]","output_type":"stream"},{"name":"stdout","text":"aliked> stairs_split_2_1710453745156.png-stairs_split_2_1710453790978.png: 263 matches @ 23th pair(aliked+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 93%|█████████▎| 527/564 [00:17<00:02, 18.34it/s]","output_type":"stream"},{"name":"stdout","text":"aliked> stairs_split_2_1710453759963.png-stairs_split_2_1710453786375.png: 430 matches @ 24th pair(aliked+lightglue)\naliked> stairs_split_2_1710453759963.png-stairs_split_2_1710453805788.png: 171 matches @ 25th pair(aliked+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 96%|█████████▋| 544/564 [00:18<00:00, 24.20it/s]","output_type":"stream"},{"name":"stdout","text":"aliked> stairs_split_2_1710453783374.png-stairs_split_2_1710453786375.png: 541 matches @ 26th pair(aliked+lightglue)\naliked> stairs_split_2_1710453783374.png-stairs_split_2_1710453805788.png: 257 matches @ 27th pair(aliked+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 97%|█████████▋| 547/564 [00:18<00:00, 21.98it/s]","output_type":"stream"},{"name":"stdout","text":"aliked> stairs_split_2_1710453783374.png-stairs_split_2_1710453871430.png: 146 matches @ 28th pair(aliked+lightglue)\naliked> stairs_split_2_1710453786375.png-stairs_split_2_1710453805788.png: 174 matches @ 29th pair(aliked+lightglue)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 564/564 [00:19<00:00, 29.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Features matched in  24.2093 sec (aliked+LightGlue)\nsuperpoint > rot_k=0, kpts.shape=torch.Size([177, 2]), descs.shape=torch.Size([177, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([163, 2]), descs.shape=torch.Size([163, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([117, 2]), descs.shape=torch.Size([117, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([70, 2]), descs.shape=torch.Size([70, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([84, 2]), descs.shape=torch.Size([84, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([94, 2]), descs.shape=torch.Size([94, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([87, 2]), descs.shape=torch.Size([87, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([193, 2]), descs.shape=torch.Size([193, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([122, 2]), descs.shape=torch.Size([122, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([129, 2]), descs.shape=torch.Size([129, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([68, 2]), descs.shape=torch.Size([68, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([4, 2]), descs.shape=torch.Size([4, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([69, 2]), descs.shape=torch.Size([69, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([49, 2]), descs.shape=torch.Size([49, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([122, 2]), descs.shape=torch.Size([122, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([157, 2]), descs.shape=torch.Size([157, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([247, 2]), descs.shape=torch.Size([247, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([136, 2]), descs.shape=torch.Size([136, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([296, 2]), descs.shape=torch.Size([296, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([164, 2]), descs.shape=torch.Size([164, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([208, 2]), descs.shape=torch.Size([208, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([218, 2]), descs.shape=torch.Size([218, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([65, 2]), descs.shape=torch.Size([65, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([97, 2]), descs.shape=torch.Size([97, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([176, 2]), descs.shape=torch.Size([176, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([135, 2]), descs.shape=torch.Size([135, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([55, 2]), descs.shape=torch.Size([55, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([102, 2]), descs.shape=torch.Size([102, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([163, 2]), descs.shape=torch.Size([163, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([191, 2]), descs.shape=torch.Size([191, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([181, 2]), descs.shape=torch.Size([181, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([300, 2]), descs.shape=torch.Size([300, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([255, 2]), descs.shape=torch.Size([255, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([103, 2]), descs.shape=torch.Size([103, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([143, 2]), descs.shape=torch.Size([143, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([206, 2]), descs.shape=torch.Size([206, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([318, 2]), descs.shape=torch.Size([318, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([263, 2]), descs.shape=torch.Size([263, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([137, 2]), descs.shape=torch.Size([137, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([116, 2]), descs.shape=torch.Size([116, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([204, 2]), descs.shape=torch.Size([204, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([300, 2]), descs.shape=torch.Size([300, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([130, 2]), descs.shape=torch.Size([130, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([120, 2]), descs.shape=torch.Size([120, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([170, 2]), descs.shape=torch.Size([170, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([179, 2]), descs.shape=torch.Size([179, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([152, 2]), descs.shape=torch.Size([152, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([140, 2]), descs.shape=torch.Size([140, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([119, 2]), descs.shape=torch.Size([119, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([158, 2]), descs.shape=torch.Size([158, 256])\nsuperpoint > rot_k=0, kpts.shape=torch.Size([218, 2]), descs.shape=torch.Size([218, 256])\nLoaded LightGlue model\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/564 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_1_1710453576271.png-stairs_split_1_1710453601885.png: 66 matches @ 1th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":"  1%|▏         | 8/564 [00:00<00:14, 38.83it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_1_1710453576271.png-stairs_split_1_1710453643106.png: 64 matches @ 2th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453576271.png-stairs_split_1_1710453651110.png: 55 matches @ 3th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453576271.png-stairs_split_1_1710453689727.png: 52 matches @ 4th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 12/564 [00:00<00:14, 38.84it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_1_1710453576271.png-stairs_split_1_1710453901046.png: 63 matches @ 5th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453576271.png-stairs_split_1_1710453912451.png: 72 matches @ 6th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":"  3%|▎         | 17/564 [00:00<00:13, 39.51it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_1_1710453576271.png-stairs_split_1_1710453955270.png: 65 matches @ 7th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453576271.png-stairs_split_2_1710453725143.png: 66 matches @ 8th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453576271.png-stairs_split_2_1710453745156.png: 55 matches @ 9th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453576271.png-stairs_split_2_1710453753160.png: 86 matches @ 10th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":"  4%|▎         | 21/564 [00:00<00:13, 39.55it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_1_1710453576271.png-stairs_split_2_1710453871430.png: 73 matches @ 11th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":"  4%|▍         | 25/564 [00:00<00:14, 37.57it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_1_1710453601885.png-stairs_split_1_1710453651110.png: 62 matches @ 12th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453601885.png-stairs_split_1_1710453689727.png: 61 matches @ 13th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453601885.png-stairs_split_1_1710453693529.png: 57 matches @ 14th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":"  5%|▌         | 29/564 [00:00<00:14, 38.15it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_1_1710453601885.png-stairs_split_1_1710453697531.png: 56 matches @ 15th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453601885.png-stairs_split_1_1710453704934.png: 50 matches @ 16th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453601885.png-stairs_split_1_1710453901046.png: 77 matches @ 17th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":"  6%|▌         | 33/564 [00:00<00:13, 38.59it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_1_1710453601885.png-stairs_split_1_1710453947066.png: 51 matches @ 18th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453601885.png-stairs_split_1_1710453955270.png: 70 matches @ 19th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453601885.png-stairs_split_1_1710453990286.png: 59 matches @ 20th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453601885.png-stairs_split_2_1710453736752.png: 68 matches @ 21th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":"  7%|▋         | 38/564 [00:00<00:13, 39.27it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_1_1710453601885.png-stairs_split_2_1710453745156.png: 60 matches @ 22th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453601885.png-stairs_split_2_1710453756762.png: 65 matches @ 23th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":"  8%|▊         | 46/564 [00:01<00:13, 39.14it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_1_1710453601885.png-stairs_split_2_1710453786375.png: 56 matches @ 24th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453601885.png-stairs_split_2_1710453790978.png: 55 matches @ 25th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":"  9%|▉         | 50/564 [00:01<00:13, 39.22it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_1_1710453601885.png-stairs_split_2_1710453871430.png: 75 matches @ 26th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 10%|▉         | 54/564 [00:01<00:12, 39.27it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_1_1710453606287.png-stairs_split_1_1710453947066.png: 58 matches @ 27th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453606287.png-stairs_split_1_1710453990286.png: 56 matches @ 28th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 59/564 [00:01<00:12, 39.75it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_1_1710453612890.png-stairs_split_1_1710453643106.png: 55 matches @ 29th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 21%|██        | 119/564 [00:03<00:11, 40.12it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_1_1710453620694.png-stairs_split_2_1710453745156.png: 52 matches @ 30th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453620694.png-stairs_split_2_1710453756762.png: 52 matches @ 31th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453620694.png-stairs_split_2_1710453759963.png: 54 matches @ 32th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453626698.png-stairs_split_1_1710453643106.png: 51 matches @ 33th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 23%|██▎       | 129/564 [00:03<00:10, 40.12it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_1_1710453626698.png-stairs_split_1_1710453912451.png: 51 matches @ 34th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453626698.png-stairs_split_2_1710453774370.png: 58 matches @ 35th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453643106.png-stairs_split_1_1710453659313.png: 69 matches @ 36th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 25%|██▍       | 139/564 [00:03<00:10, 40.01it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_1_1710453643106.png-stairs_split_1_1710453678922.png: 54 matches @ 37th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453643106.png-stairs_split_1_1710453683725.png: 70 matches @ 38th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453643106.png-stairs_split_1_1710453901046.png: 63 matches @ 39th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453643106.png-stairs_split_1_1710453912451.png: 76 matches @ 40th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453643106.png-stairs_split_1_1710453963274.png: 53 matches @ 41th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453643106.png-stairs_split_2_1710453733751.png: 76 matches @ 42th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 26%|██▌       | 148/564 [00:03<00:10, 39.57it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_1_1710453643106.png-stairs_split_2_1710453745156.png: 56 matches @ 43th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453643106.png-stairs_split_2_1710453753160.png: 75 matches @ 44th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453643106.png-stairs_split_2_1710453779372.png: 83 matches @ 45th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453643106.png-stairs_split_2_1710453793579.png: 60 matches @ 46th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453643106.png-stairs_split_2_1710453798181.png: 59 matches @ 47th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453643106.png-stairs_split_2_1710453862225.png: 57 matches @ 48th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 28%|██▊       | 160/564 [00:04<00:10, 39.23it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_1_1710453651110.png-stairs_split_1_1710453689727.png: 59 matches @ 49th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453651110.png-stairs_split_1_1710453693529.png: 60 matches @ 50th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453651110.png-stairs_split_1_1710453697531.png: 69 matches @ 51th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453651110.png-stairs_split_1_1710453704934.png: 62 matches @ 52th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453651110.png-stairs_split_1_1710453901046.png: 58 matches @ 53th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453651110.png-stairs_split_1_1710453912451.png: 63 matches @ 54th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 30%|██▉       | 168/564 [00:04<00:10, 39.26it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_1_1710453651110.png-stairs_split_1_1710453990286.png: 54 matches @ 55th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453651110.png-stairs_split_2_1710453720741.png: 70 matches @ 56th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453651110.png-stairs_split_2_1710453736752.png: 63 matches @ 57th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453651110.png-stairs_split_2_1710453739354.png: 55 matches @ 58th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453651110.png-stairs_split_2_1710453740954.png: 63 matches @ 59th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453651110.png-stairs_split_2_1710453745156.png: 66 matches @ 60th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453651110.png-stairs_split_2_1710453753160.png: 57 matches @ 61th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453651110.png-stairs_split_2_1710453756762.png: 61 matches @ 62th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 31%|███▏      | 177/564 [00:04<00:09, 39.64it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_1_1710453651110.png-stairs_split_2_1710453759963.png: 72 matches @ 63th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453651110.png-stairs_split_2_1710453779372.png: 80 matches @ 64th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453651110.png-stairs_split_2_1710453786375.png: 52 matches @ 65th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453651110.png-stairs_split_2_1710453790978.png: 66 matches @ 66th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453651110.png-stairs_split_2_1710453793579.png: 56 matches @ 67th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453651110.png-stairs_split_2_1710453805788.png: 60 matches @ 68th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 33%|███▎      | 186/564 [00:04<00:09, 39.87it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_1_1710453651110.png-stairs_split_2_1710453871430.png: 74 matches @ 69th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453659313.png-stairs_split_1_1710453678922.png: 61 matches @ 70th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453659313.png-stairs_split_1_1710453683725.png: 57 matches @ 71th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453659313.png-stairs_split_1_1710453912451.png: 52 matches @ 72th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 35%|███▍      | 195/564 [00:04<00:09, 39.52it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_1_1710453659313.png-stairs_split_2_1710453728949.png: 52 matches @ 73th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453659313.png-stairs_split_2_1710453753160.png: 58 matches @ 74th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 49%|████▉     | 277/564 [00:06<00:07, 38.06it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_1_1710453678922.png-stairs_split_2_1710453725143.png: 53 matches @ 75th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453678922.png-stairs_split_2_1710453728949.png: 52 matches @ 76th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453678922.png-stairs_split_2_1710453753160.png: 59 matches @ 77th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453678922.png-stairs_split_2_1710453774370.png: 50 matches @ 78th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453678922.png-stairs_split_2_1710453793579.png: 54 matches @ 79th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 289/564 [00:07<00:07, 38.01it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_1_1710453683725.png-stairs_split_2_1710453728949.png: 60 matches @ 80th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453683725.png-stairs_split_2_1710453733751.png: 71 matches @ 81th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453683725.png-stairs_split_2_1710453765165.png: 56 matches @ 82th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453689727.png-stairs_split_1_1710453693529.png: 73 matches @ 83th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453689727.png-stairs_split_1_1710453955270.png: 67 matches @ 84th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453689727.png-stairs_split_2_1710453720741.png: 82 matches @ 85th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 53%|█████▎    | 298/564 [00:07<00:06, 39.03it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_1_1710453689727.png-stairs_split_2_1710453736752.png: 116 matches @ 86th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453689727.png-stairs_split_2_1710453739354.png: 55 matches @ 87th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453689727.png-stairs_split_2_1710453740954.png: 70 matches @ 88th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453689727.png-stairs_split_2_1710453745156.png: 91 matches @ 89th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453689727.png-stairs_split_2_1710453753160.png: 89 matches @ 90th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453689727.png-stairs_split_2_1710453756762.png: 85 matches @ 91th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453689727.png-stairs_split_2_1710453759963.png: 71 matches @ 92th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453689727.png-stairs_split_2_1710453783374.png: 82 matches @ 93th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453689727.png-stairs_split_2_1710453786375.png: 60 matches @ 94th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 54%|█████▍    | 306/564 [00:07<00:06, 38.78it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_1_1710453689727.png-stairs_split_2_1710453790978.png: 90 matches @ 95th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453689727.png-stairs_split_2_1710453798181.png: 74 matches @ 96th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453689727.png-stairs_split_2_1710453801783.png: 70 matches @ 97th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453689727.png-stairs_split_2_1710453805788.png: 55 matches @ 98th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453689727.png-stairs_split_2_1710453871430.png: 79 matches @ 99th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453693529.png-stairs_split_1_1710453704934.png: 65 matches @ 100th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453693529.png-stairs_split_2_1710453736752.png: 65 matches @ 101th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453693529.png-stairs_split_2_1710453739354.png: 60 matches @ 102th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 56%|█████▌    | 315/564 [00:07<00:06, 39.55it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_1_1710453693529.png-stairs_split_2_1710453740954.png: 60 matches @ 103th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453693529.png-stairs_split_2_1710453745156.png: 68 matches @ 104th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453693529.png-stairs_split_2_1710453756762.png: 65 matches @ 105th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453693529.png-stairs_split_2_1710453759963.png: 52 matches @ 106th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453693529.png-stairs_split_2_1710453786375.png: 54 matches @ 107th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453693529.png-stairs_split_2_1710453790978.png: 67 matches @ 108th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 57%|█████▋    | 323/564 [00:08<00:06, 36.79it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_1_1710453693529.png-stairs_split_2_1710453871430.png: 57 matches @ 109th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453697531.png-stairs_split_2_1710453736752.png: 83 matches @ 110th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453697531.png-stairs_split_2_1710453745156.png: 94 matches @ 111th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453697531.png-stairs_split_2_1710453756762.png: 102 matches @ 112th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453697531.png-stairs_split_2_1710453759963.png: 68 matches @ 113th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453697531.png-stairs_split_2_1710453779372.png: 89 matches @ 114th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453697531.png-stairs_split_2_1710453786375.png: 52 matches @ 115th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 58%|█████▊    | 327/564 [00:08<00:06, 36.79it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_1_1710453697531.png-stairs_split_2_1710453790978.png: 83 matches @ 116th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453704934.png-stairs_split_1_1710453901046.png: 80 matches @ 117th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453704934.png-stairs_split_1_1710453955270.png: 52 matches @ 118th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453704934.png-stairs_split_2_1710453720741.png: 57 matches @ 119th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 59%|█████▉    | 335/564 [00:08<00:06, 35.28it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_1_1710453704934.png-stairs_split_2_1710453725143.png: 84 matches @ 120th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453704934.png-stairs_split_2_1710453736752.png: 62 matches @ 121th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453704934.png-stairs_split_2_1710453740954.png: 57 matches @ 122th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453704934.png-stairs_split_2_1710453745156.png: 102 matches @ 123th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453704934.png-stairs_split_2_1710453753160.png: 74 matches @ 124th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453704934.png-stairs_split_2_1710453756762.png: 67 matches @ 125th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453704934.png-stairs_split_2_1710453765165.png: 77 matches @ 126th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 61%|██████    | 343/564 [00:08<00:06, 35.79it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_1_1710453704934.png-stairs_split_2_1710453779372.png: 72 matches @ 127th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453704934.png-stairs_split_2_1710453783374.png: 56 matches @ 128th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453704934.png-stairs_split_2_1710453790978.png: 95 matches @ 129th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453704934.png-stairs_split_2_1710453793579.png: 83 matches @ 130th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453704934.png-stairs_split_2_1710453798181.png: 64 matches @ 131th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453704934.png-stairs_split_2_1710453801783.png: 57 matches @ 132th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453704934.png-stairs_split_2_1710453862225.png: 50 matches @ 133th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 62%|██████▏   | 351/564 [00:08<00:05, 36.96it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_1_1710453901046.png-stairs_split_1_1710453912451.png: 75 matches @ 134th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453901046.png-stairs_split_1_1710453947066.png: 58 matches @ 135th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453901046.png-stairs_split_1_1710453955270.png: 68 matches @ 136th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453901046.png-stairs_split_1_1710453963274.png: 53 matches @ 137th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453901046.png-stairs_split_1_1710453990286.png: 70 matches @ 138th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453901046.png-stairs_split_2_1710453725143.png: 78 matches @ 139th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453901046.png-stairs_split_2_1710453733751.png: 77 matches @ 140th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 64%|██████▎   | 359/564 [00:09<00:05, 37.79it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_1_1710453901046.png-stairs_split_2_1710453745156.png: 93 matches @ 141th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453901046.png-stairs_split_2_1710453753160.png: 85 matches @ 142th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453901046.png-stairs_split_2_1710453765165.png: 64 matches @ 143th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453901046.png-stairs_split_2_1710453774370.png: 63 matches @ 144th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453901046.png-stairs_split_2_1710453779372.png: 77 matches @ 145th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453901046.png-stairs_split_2_1710453790978.png: 67 matches @ 146th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453901046.png-stairs_split_2_1710453793579.png: 87 matches @ 147th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453901046.png-stairs_split_2_1710453798181.png: 59 matches @ 148th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 65%|██████▌   | 367/564 [00:09<00:05, 37.94it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_1_1710453901046.png-stairs_split_2_1710453801783.png: 50 matches @ 149th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453901046.png-stairs_split_2_1710453862225.png: 91 matches @ 150th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453901046.png-stairs_split_2_1710453871430.png: 72 matches @ 151th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453912451.png-stairs_split_1_1710453955270.png: 72 matches @ 152th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 66%|██████▋   | 375/564 [00:09<00:04, 38.25it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_1_1710453912451.png-stairs_split_2_1710453733751.png: 92 matches @ 153th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453912451.png-stairs_split_2_1710453745156.png: 73 matches @ 154th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453912451.png-stairs_split_2_1710453753160.png: 97 matches @ 155th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453912451.png-stairs_split_2_1710453765165.png: 54 matches @ 156th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453912451.png-stairs_split_2_1710453774370.png: 65 matches @ 157th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453912451.png-stairs_split_2_1710453779372.png: 99 matches @ 158th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453912451.png-stairs_split_2_1710453793579.png: 72 matches @ 159th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453912451.png-stairs_split_2_1710453862225.png: 70 matches @ 160th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 397/564 [00:10<00:04, 38.40it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_1_1710453947066.png-stairs_split_1_1710453990286.png: 69 matches @ 161th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453947066.png-stairs_split_2_1710453753160.png: 59 matches @ 162th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453947066.png-stairs_split_2_1710453790978.png: 52 matches @ 163th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 73%|███████▎  | 409/564 [00:10<00:04, 38.56it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_1_1710453955270.png-stairs_split_2_1710453736752.png: 75 matches @ 164th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453955270.png-stairs_split_2_1710453745156.png: 65 matches @ 165th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453955270.png-stairs_split_2_1710453753160.png: 62 matches @ 166th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453955270.png-stairs_split_2_1710453759963.png: 52 matches @ 167th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453955270.png-stairs_split_2_1710453779372.png: 68 matches @ 168th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 75%|███████▍  | 421/564 [00:10<00:03, 38.99it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_1_1710453955270.png-stairs_split_2_1710453871430.png: 74 matches @ 169th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453963274.png-stairs_split_2_1710453728949.png: 61 matches @ 170th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453963274.png-stairs_split_2_1710453733751.png: 66 matches @ 171th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453963274.png-stairs_split_2_1710453765165.png: 53 matches @ 172th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453963274.png-stairs_split_2_1710453774370.png: 55 matches @ 173th pair(superpoint+lightglue)\nsuperpoint> stairs_split_1_1710453963274.png-stairs_split_2_1710453779372.png: 56 matches @ 174th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 77%|███████▋  | 434/564 [00:11<00:03, 39.58it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_1_1710453990286.png-stairs_split_2_1710453745156.png: 51 matches @ 175th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453720741.png-stairs_split_2_1710453725143.png: 70 matches @ 176th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 78%|███████▊  | 442/564 [00:11<00:03, 39.14it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_2_1710453720741.png-stairs_split_2_1710453745156.png: 77 matches @ 177th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453720741.png-stairs_split_2_1710453783374.png: 64 matches @ 178th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453720741.png-stairs_split_2_1710453786375.png: 84 matches @ 179th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453720741.png-stairs_split_2_1710453805788.png: 62 matches @ 180th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453720741.png-stairs_split_2_1710453871430.png: 99 matches @ 181th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453725143.png-stairs_split_2_1710453728949.png: 68 matches @ 182th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453725143.png-stairs_split_2_1710453745156.png: 107 matches @ 183th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453725143.png-stairs_split_2_1710453753160.png: 105 matches @ 184th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 80%|███████▉  | 450/564 [00:11<00:02, 39.03it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_2_1710453725143.png-stairs_split_2_1710453765165.png: 74 matches @ 185th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453725143.png-stairs_split_2_1710453779372.png: 92 matches @ 186th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453725143.png-stairs_split_2_1710453793579.png: 80 matches @ 187th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453725143.png-stairs_split_2_1710453798181.png: 59 matches @ 188th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453728949.png-stairs_split_2_1710453753160.png: 83 matches @ 189th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453728949.png-stairs_split_2_1710453765165.png: 57 matches @ 190th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453728949.png-stairs_split_2_1710453774370.png: 80 matches @ 191th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453733751.png-stairs_split_2_1710453745156.png: 81 matches @ 192th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 81%|████████  | 458/564 [00:11<00:02, 38.39it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_2_1710453733751.png-stairs_split_2_1710453753160.png: 128 matches @ 193th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453733751.png-stairs_split_2_1710453765165.png: 63 matches @ 194th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453733751.png-stairs_split_2_1710453774370.png: 90 matches @ 195th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453733751.png-stairs_split_2_1710453779372.png: 93 matches @ 196th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453733751.png-stairs_split_2_1710453793579.png: 57 matches @ 197th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453733751.png-stairs_split_2_1710453798181.png: 67 matches @ 198th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453733751.png-stairs_split_2_1710453801783.png: 67 matches @ 199th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453733751.png-stairs_split_2_1710453862225.png: 70 matches @ 200th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 83%|████████▎ | 467/564 [00:11<00:02, 39.33it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_2_1710453736752.png-stairs_split_2_1710453740954.png: 70 matches @ 201th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453736752.png-stairs_split_2_1710453745156.png: 85 matches @ 202th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453736752.png-stairs_split_2_1710453756762.png: 115 matches @ 203th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453736752.png-stairs_split_2_1710453759963.png: 62 matches @ 204th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453736752.png-stairs_split_2_1710453779372.png: 125 matches @ 205th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453736752.png-stairs_split_2_1710453783374.png: 70 matches @ 206th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453736752.png-stairs_split_2_1710453786375.png: 59 matches @ 207th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453736752.png-stairs_split_2_1710453790978.png: 91 matches @ 208th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453736752.png-stairs_split_2_1710453793579.png: 76 matches @ 209th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 84%|████████▍ | 475/564 [00:12<00:02, 39.15it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_2_1710453736752.png-stairs_split_2_1710453798181.png: 78 matches @ 210th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453736752.png-stairs_split_2_1710453801783.png: 83 matches @ 211th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453736752.png-stairs_split_2_1710453805788.png: 76 matches @ 212th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453736752.png-stairs_split_2_1710453871430.png: 72 matches @ 213th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453739354.png-stairs_split_2_1710453740954.png: 70 matches @ 214th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453739354.png-stairs_split_2_1710453745156.png: 66 matches @ 215th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453739354.png-stairs_split_2_1710453756762.png: 54 matches @ 216th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453739354.png-stairs_split_2_1710453759963.png: 51 matches @ 217th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 86%|████████▌ | 483/564 [00:12<00:02, 39.01it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_2_1710453739354.png-stairs_split_2_1710453783374.png: 61 matches @ 218th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453739354.png-stairs_split_2_1710453786375.png: 56 matches @ 219th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453739354.png-stairs_split_2_1710453805788.png: 61 matches @ 220th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453739354.png-stairs_split_2_1710453871430.png: 64 matches @ 221th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453740954.png-stairs_split_2_1710453756762.png: 68 matches @ 222th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 87%|████████▋ | 492/564 [00:12<00:01, 39.45it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_2_1710453740954.png-stairs_split_2_1710453759963.png: 85 matches @ 223th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453740954.png-stairs_split_2_1710453783374.png: 58 matches @ 224th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453740954.png-stairs_split_2_1710453786375.png: 84 matches @ 225th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453740954.png-stairs_split_2_1710453790978.png: 61 matches @ 226th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453740954.png-stairs_split_2_1710453805788.png: 72 matches @ 227th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453740954.png-stairs_split_2_1710453871430.png: 72 matches @ 228th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453745156.png-stairs_split_2_1710453753160.png: 82 matches @ 229th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453745156.png-stairs_split_2_1710453756762.png: 65 matches @ 230th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 89%|████████▉ | 501/564 [00:12<00:01, 39.65it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_2_1710453745156.png-stairs_split_2_1710453759963.png: 54 matches @ 231th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453745156.png-stairs_split_2_1710453765165.png: 71 matches @ 232th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453745156.png-stairs_split_2_1710453779372.png: 91 matches @ 233th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453745156.png-stairs_split_2_1710453783374.png: 59 matches @ 234th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453745156.png-stairs_split_2_1710453786375.png: 57 matches @ 235th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453745156.png-stairs_split_2_1710453790978.png: 111 matches @ 236th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453745156.png-stairs_split_2_1710453793579.png: 97 matches @ 237th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453745156.png-stairs_split_2_1710453798181.png: 58 matches @ 238th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 510/564 [00:13<00:01, 39.72it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_2_1710453745156.png-stairs_split_2_1710453801783.png: 50 matches @ 239th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453745156.png-stairs_split_2_1710453862225.png: 59 matches @ 240th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453745156.png-stairs_split_2_1710453871430.png: 73 matches @ 241th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453753160.png-stairs_split_2_1710453779372.png: 112 matches @ 242th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453753160.png-stairs_split_2_1710453790978.png: 79 matches @ 243th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453753160.png-stairs_split_2_1710453793579.png: 73 matches @ 244th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453753160.png-stairs_split_2_1710453798181.png: 92 matches @ 245th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 92%|█████████▏| 519/564 [00:13<00:01, 39.72it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_2_1710453753160.png-stairs_split_2_1710453801783.png: 80 matches @ 246th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453753160.png-stairs_split_2_1710453862225.png: 69 matches @ 247th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453756762.png-stairs_split_2_1710453759963.png: 65 matches @ 248th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453756762.png-stairs_split_2_1710453783374.png: 87 matches @ 249th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453756762.png-stairs_split_2_1710453786375.png: 55 matches @ 250th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453756762.png-stairs_split_2_1710453790978.png: 86 matches @ 251th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453756762.png-stairs_split_2_1710453793579.png: 81 matches @ 252th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453756762.png-stairs_split_2_1710453798181.png: 71 matches @ 253th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 94%|█████████▎| 528/564 [00:13<00:00, 39.64it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_2_1710453756762.png-stairs_split_2_1710453801783.png: 86 matches @ 254th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453756762.png-stairs_split_2_1710453805788.png: 60 matches @ 255th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453756762.png-stairs_split_2_1710453871430.png: 92 matches @ 256th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453759963.png-stairs_split_2_1710453786375.png: 66 matches @ 257th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453759963.png-stairs_split_2_1710453790978.png: 56 matches @ 258th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453759963.png-stairs_split_2_1710453805788.png: 56 matches @ 259th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453759963.png-stairs_split_2_1710453871430.png: 63 matches @ 260th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 95%|█████████▌| 537/564 [00:13<00:00, 39.65it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_2_1710453765165.png-stairs_split_2_1710453774370.png: 59 matches @ 261th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453765165.png-stairs_split_2_1710453779372.png: 62 matches @ 262th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453765165.png-stairs_split_2_1710453790978.png: 63 matches @ 263th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453765165.png-stairs_split_2_1710453793579.png: 68 matches @ 264th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453765165.png-stairs_split_2_1710453798181.png: 50 matches @ 265th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453765165.png-stairs_split_2_1710453862225.png: 52 matches @ 266th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453774370.png-stairs_split_2_1710453779372.png: 73 matches @ 267th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453774370.png-stairs_split_2_1710453793579.png: 61 matches @ 268th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453774370.png-stairs_split_2_1710453862225.png: 58 matches @ 269th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 97%|█████████▋| 546/564 [00:13<00:00, 39.89it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_2_1710453779372.png-stairs_split_2_1710453793579.png: 90 matches @ 270th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453779372.png-stairs_split_2_1710453798181.png: 82 matches @ 271th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453779372.png-stairs_split_2_1710453801783.png: 72 matches @ 272th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453779372.png-stairs_split_2_1710453862225.png: 57 matches @ 273th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453783374.png-stairs_split_2_1710453786375.png: 54 matches @ 274th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453783374.png-stairs_split_2_1710453790978.png: 65 matches @ 275th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453783374.png-stairs_split_2_1710453801783.png: 53 matches @ 276th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453783374.png-stairs_split_2_1710453805788.png: 69 matches @ 277th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453783374.png-stairs_split_2_1710453871430.png: 71 matches @ 278th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 98%|█████████▊| 554/564 [00:14<00:00, 39.39it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_2_1710453786375.png-stairs_split_2_1710453801783.png: 51 matches @ 279th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453786375.png-stairs_split_2_1710453805788.png: 74 matches @ 280th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453786375.png-stairs_split_2_1710453871430.png: 57 matches @ 281th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453790978.png-stairs_split_2_1710453793579.png: 86 matches @ 282th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453790978.png-stairs_split_2_1710453798181.png: 59 matches @ 283th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453790978.png-stairs_split_2_1710453801783.png: 58 matches @ 284th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453790978.png-stairs_split_2_1710453805788.png: 61 matches @ 285th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453790978.png-stairs_split_2_1710453871430.png: 67 matches @ 286th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":"100%|█████████▉| 562/564 [00:14<00:00, 38.63it/s]","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_2_1710453793579.png-stairs_split_2_1710453798181.png: 69 matches @ 287th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453793579.png-stairs_split_2_1710453805788.png: 56 matches @ 288th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453793579.png-stairs_split_2_1710453862225.png: 67 matches @ 289th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453798181.png-stairs_split_2_1710453801783.png: 65 matches @ 290th pair(superpoint+lightglue)\nsuperpoint> stairs_split_2_1710453798181.png-stairs_split_2_1710453862225.png: 57 matches @ 291th pair(superpoint+lightglue)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 564/564 [00:14<00:00, 39.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"superpoint> stairs_split_2_1710453805788.png-stairs_split_2_1710453871430.png: 71 matches @ 292th pair(superpoint+lightglue)\nFeatures matched in  18.8920 sec (superpoint+LightGlue)\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\ndisk > rot_k=0, kpts.shape=torch.Size([4096, 2]), descs.shape=torch.Size([4096, 128])\nLoaded LightGlue model\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/564 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_1_1710453576271.png-stairs_split_1_1710453601885.png: 421 matches @ 1th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":"  6%|▌         | 33/564 [00:03<00:54,  9.71it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_1_1710453601885.png-stairs_split_1_1710453930259.png: 146 matches @ 2th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":"  6%|▋         | 36/564 [00:03<00:54,  9.71it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_1_1710453601885.png-stairs_split_1_1710453990286.png: 647 matches @ 3th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":"  7%|▋         | 38/564 [00:03<00:53,  9.80it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_1_1710453601885.png-stairs_split_2_1710453739354.png: 192 matches @ 4th pair(disk+lightglue)\ndisk> stairs_split_1_1710453601885.png-stairs_split_2_1710453740954.png: 219 matches @ 5th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":"  8%|▊         | 44/564 [00:04<00:53,  9.72it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_1_1710453601885.png-stairs_split_2_1710453786375.png: 207 matches @ 6th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":"  8%|▊         | 47/564 [00:04<00:52,  9.78it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_1_1710453601885.png-stairs_split_2_1710453805788.png: 191 matches @ 7th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 10%|▉         | 55/564 [00:05<00:52,  9.67it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_1_1710453606287.png-stairs_split_1_1710453985484.png: 414 matches @ 8th pair(disk+lightglue)\ndisk> stairs_split_1_1710453606287.png-stairs_split_1_1710453990286.png: 283 matches @ 9th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 58/564 [00:05<00:52,  9.62it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_1_1710453612890.png-stairs_split_1_1710453616892.png: 199 matches @ 10th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 13%|█▎        | 72/564 [00:07<00:51,  9.54it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_1_1710453612890.png-stairs_split_1_1710453985484.png: 766 matches @ 11th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 14%|█▍        | 79/564 [00:08<00:50,  9.55it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_1_1710453616892.png-stairs_split_1_1710453620694.png: 368 matches @ 12th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 18%|█▊        | 99/564 [00:10<00:48,  9.51it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_1_1710453620694.png-stairs_split_1_1710453651110.png: 107 matches @ 13th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 23%|██▎       | 128/564 [00:13<00:45,  9.55it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_1_1710453626698.png-stairs_split_1_1710453963274.png: 132 matches @ 14th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 25%|██▍       | 139/564 [00:14<00:45,  9.39it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_1_1710453643106.png-stairs_split_1_1710453963274.png: 559 matches @ 15th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 28%|██▊       | 160/564 [00:16<00:43,  9.34it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_1_1710453651110.png-stairs_split_1_1710453930259.png: 370 matches @ 16th pair(disk+lightglue)\ndisk> stairs_split_1_1710453651110.png-stairs_split_1_1710453947066.png: 382 matches @ 17th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 29%|██▉       | 166/564 [00:17<00:42,  9.33it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_1_1710453651110.png-stairs_split_2_1710453739354.png: 182 matches @ 18th pair(disk+lightglue)\ndisk> stairs_split_1_1710453651110.png-stairs_split_2_1710453740954.png: 156 matches @ 19th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 171/564 [00:17<00:42,  9.24it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_1_1710453651110.png-stairs_split_2_1710453759963.png: 132 matches @ 20th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 31%|███       | 174/564 [00:18<00:42,  9.26it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_1_1710453651110.png-stairs_split_2_1710453786375.png: 368 matches @ 21th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 32%|███▏      | 178/564 [00:18<00:41,  9.26it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_1_1710453651110.png-stairs_split_2_1710453805788.png: 180 matches @ 22th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 33%|███▎      | 186/564 [00:19<00:40,  9.31it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_1_1710453659313.png-stairs_split_1_1710453947066.png: 130 matches @ 23th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 41%|████      | 230/564 [00:24<00:36,  9.13it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_1_1710453668718.png-stairs_split_1_1710453930259.png: 586 matches @ 24th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 42%|████▏     | 239/564 [00:25<00:35,  9.14it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_1_1710453668718.png-stairs_split_2_1710453786375.png: 299 matches @ 25th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 43%|████▎     | 243/564 [00:25<00:35,  9.08it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_1_1710453668718.png-stairs_split_2_1710453871430.png: 413 matches @ 26th pair(disk+lightglue)\ndisk> stairs_split_1_1710453675921.png-stairs_split_1_1710453678922.png: 118 matches @ 27th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 44%|████▍     | 247/564 [00:26<00:35,  9.00it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_1_1710453675921.png-stairs_split_1_1710453704934.png: 231 matches @ 28th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 44%|████▍     | 249/564 [00:26<00:34,  9.04it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_1_1710453675921.png-stairs_split_1_1710453930259.png: 289 matches @ 29th pair(disk+lightglue)\ndisk> stairs_split_1_1710453675921.png-stairs_split_1_1710453947066.png: 111 matches @ 30th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 54%|█████▍    | 305/564 [00:32<00:28,  8.98it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_1_1710453689727.png-stairs_split_2_1710453871430.png: 306 matches @ 31th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 55%|█████▍    | 308/564 [00:32<00:28,  8.96it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_1_1710453693529.png-stairs_split_2_1710453739354.png: 106 matches @ 32th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 58%|█████▊    | 326/564 [00:34<00:26,  8.97it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_1_1710453704934.png-stairs_split_1_1710453901046.png: 859 matches @ 33th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 59%|█████▉    | 335/564 [00:35<00:25,  8.95it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_1_1710453704934.png-stairs_split_2_1710453745156.png: 323 matches @ 34th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 61%|██████    | 342/564 [00:36<00:24,  8.99it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_1_1710453704934.png-stairs_split_2_1710453790978.png: 292 matches @ 35th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 63%|██████▎   | 355/564 [00:38<00:23,  8.91it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_1_1710453901046.png-stairs_split_2_1710453745156.png: 170 matches @ 36th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 69%|██████▉   | 391/564 [00:42<00:19,  9.05it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_1_1710453947066.png-stairs_split_1_1710453990286.png: 119 matches @ 37th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 77%|███████▋  | 435/564 [00:46<00:14,  9.19it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_2_1710453720741.png-stairs_split_2_1710453725143.png: 187 matches @ 38th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 78%|███████▊  | 438/564 [00:47<00:13,  9.16it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_2_1710453720741.png-stairs_split_2_1710453786375.png: 993 matches @ 39th pair(disk+lightglue)\ndisk> stairs_split_2_1710453720741.png-stairs_split_2_1710453805788.png: 350 matches @ 40th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 78%|███████▊  | 440/564 [00:47<00:13,  9.22it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_2_1710453720741.png-stairs_split_2_1710453871430.png: 215 matches @ 41th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 82%|████████▏ | 463/564 [00:49<00:10,  9.27it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_2_1710453736752.png-stairs_split_2_1710453756762.png: 179 matches @ 42th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 83%|████████▎ | 466/564 [00:50<00:10,  9.27it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_2_1710453736752.png-stairs_split_2_1710453783374.png: 222 matches @ 43th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 84%|████████▎ | 471/564 [00:50<00:09,  9.37it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_2_1710453736752.png-stairs_split_2_1710453801783.png: 187 matches @ 44th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 84%|████████▍ | 473/564 [00:51<00:09,  9.30it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_2_1710453736752.png-stairs_split_2_1710453871430.png: 540 matches @ 45th pair(disk+lightglue)\ndisk> stairs_split_2_1710453739354.png-stairs_split_2_1710453740954.png: 1067 matches @ 46th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 85%|████████▍ | 477/564 [00:51<00:09,  9.28it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_2_1710453739354.png-stairs_split_2_1710453759963.png: 537 matches @ 47th pair(disk+lightglue)\ndisk> stairs_split_2_1710453739354.png-stairs_split_2_1710453783374.png: 201 matches @ 48th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 85%|████████▍ | 479/564 [00:51<00:09,  9.29it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_2_1710453739354.png-stairs_split_2_1710453786375.png: 172 matches @ 49th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 85%|████████▌ | 482/564 [00:52<00:08,  9.26it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_2_1710453739354.png-stairs_split_2_1710453805788.png: 365 matches @ 50th pair(disk+lightglue)\ndisk> stairs_split_2_1710453739354.png-stairs_split_2_1710453871430.png: 1422 matches @ 51th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 86%|████████▌ | 486/564 [00:52<00:08,  9.31it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_2_1710453740954.png-stairs_split_2_1710453759963.png: 942 matches @ 52th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 87%|████████▋ | 488/564 [00:52<00:08,  9.33it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_2_1710453740954.png-stairs_split_2_1710453786375.png: 625 matches @ 53th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 87%|████████▋ | 491/564 [00:52<00:07,  9.33it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_2_1710453740954.png-stairs_split_2_1710453805788.png: 207 matches @ 54th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 89%|████████▊ | 500/564 [00:53<00:06,  9.34it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_2_1710453745156.png-stairs_split_2_1710453790978.png: 688 matches @ 55th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 90%|████████▉ | 505/564 [00:54<00:06,  9.27it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_2_1710453745156.png-stairs_split_2_1710453862225.png: 104 matches @ 56th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 93%|█████████▎| 525/564 [00:56<00:04,  9.41it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_2_1710453759963.png-stairs_split_2_1710453786375.png: 549 matches @ 57th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 94%|█████████▎| 528/564 [00:56<00:03,  9.40it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_2_1710453759963.png-stairs_split_2_1710453805788.png: 163 matches @ 58th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 96%|█████████▋| 543/564 [00:58<00:02,  9.41it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_2_1710453783374.png-stairs_split_2_1710453786375.png: 549 matches @ 59th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 97%|█████████▋| 546/564 [00:58<00:01,  9.39it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_2_1710453783374.png-stairs_split_2_1710453805788.png: 934 matches @ 60th pair(disk+lightglue)\ndisk> stairs_split_2_1710453783374.png-stairs_split_2_1710453871430.png: 844 matches @ 61th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 97%|█████████▋| 548/564 [00:59<00:01,  9.36it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_2_1710453786375.png-stairs_split_2_1710453790978.png: 163 matches @ 62th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 98%|█████████▊| 550/564 [00:59<00:01,  9.36it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_2_1710453786375.png-stairs_split_2_1710453805788.png: 474 matches @ 63th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":" 98%|█████████▊| 552/564 [00:59<00:01,  9.37it/s]","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_2_1710453790978.png-stairs_split_2_1710453793579.png: 104 matches @ 64th pair(disk+lightglue)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 564/564 [01:00<00:00,  9.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"disk> stairs_split_2_1710453805788.png-stairs_split_2_1710453871430.png: 210 matches @ 65th pair(disk+lightglue)\nFeatures matched in  74.4713 sec (disk+LightGlue)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      <progress value='564' class='' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      100.00% [564/564 00:43&lt;00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"filter_FundamentalMatrix: 650 matches --> 558 matches\nstairs_split_1_1710453576271.png-stairs_split_1_1710453601885.png: 650 --> 558 matches\nfilter_FundamentalMatrix: 64 matches --> 26 matches\nstairs_split_1_1710453576271.png-stairs_split_1_1710453643106.png: 64 --> 26 matches\nfilter_FundamentalMatrix: 55 matches --> 15 matches\nstairs_split_1_1710453576271.png-stairs_split_1_1710453651110.png: 55 --> 15 matches\nfilter_FundamentalMatrix: 52 matches --> 21 matches\nstairs_split_1_1710453576271.png-stairs_split_1_1710453689727.png: 52 --> 21 matches\nfilter_FundamentalMatrix: 63 matches --> 24 matches\nstairs_split_1_1710453576271.png-stairs_split_1_1710453901046.png: 63 --> 24 matches\nfilter_FundamentalMatrix: 72 matches --> 20 matches\nstairs_split_1_1710453576271.png-stairs_split_1_1710453912451.png: 72 --> 20 matches\nfilter_FundamentalMatrix: 65 matches --> 25 matches\nstairs_split_1_1710453576271.png-stairs_split_1_1710453955270.png: 65 --> 25 matches\nfilter_FundamentalMatrix: 66 matches --> 16 matches\nstairs_split_1_1710453576271.png-stairs_split_2_1710453725143.png: 66 --> 16 matches\nskipped key1=stairs_split_1_1710453576271.png, key2=stairs_split_2_1710453745156.png: mkpts.shape=(12, 4) after filtered.\nfilter_FundamentalMatrix: 86 matches --> 19 matches\nstairs_split_1_1710453576271.png-stairs_split_2_1710453753160.png: 86 --> 19 matches\nfilter_FundamentalMatrix: 73 matches --> 24 matches\nstairs_split_1_1710453576271.png-stairs_split_2_1710453871430.png: 73 --> 24 matches\nfilter_FundamentalMatrix: 62 matches --> 30 matches\nstairs_split_1_1710453601885.png-stairs_split_1_1710453651110.png: 62 --> 30 matches\nfilter_FundamentalMatrix: 61 matches --> 16 matches\nstairs_split_1_1710453601885.png-stairs_split_1_1710453689727.png: 61 --> 16 matches\nfilter_FundamentalMatrix: 57 matches --> 26 matches\nstairs_split_1_1710453601885.png-stairs_split_1_1710453693529.png: 57 --> 26 matches\nfilter_FundamentalMatrix: 56 matches --> 23 matches\nstairs_split_1_1710453601885.png-stairs_split_1_1710453697531.png: 56 --> 23 matches\nfilter_FundamentalMatrix: 50 matches --> 18 matches\nstairs_split_1_1710453601885.png-stairs_split_1_1710453704934.png: 50 --> 18 matches\nfilter_FundamentalMatrix: 77 matches --> 17 matches\nstairs_split_1_1710453601885.png-stairs_split_1_1710453901046.png: 77 --> 17 matches\nfilter_FundamentalMatrix: 146 matches --> 124 matches\nstairs_split_1_1710453601885.png-stairs_split_1_1710453930259.png: 146 --> 124 matches\nfilter_FundamentalMatrix: 51 matches --> 29 matches\nstairs_split_1_1710453601885.png-stairs_split_1_1710453947066.png: 51 --> 29 matches\nfilter_FundamentalMatrix: 70 matches --> 16 matches\nstairs_split_1_1710453601885.png-stairs_split_1_1710453955270.png: 70 --> 16 matches\nfilter_FundamentalMatrix: 706 matches --> 606 matches\nstairs_split_1_1710453601885.png-stairs_split_1_1710453990286.png: 706 --> 606 matches\nfilter_FundamentalMatrix: 68 matches --> 21 matches\nstairs_split_1_1710453601885.png-stairs_split_2_1710453736752.png: 68 --> 21 matches\nfilter_FundamentalMatrix: 192 matches --> 159 matches\nstairs_split_1_1710453601885.png-stairs_split_2_1710453739354.png: 192 --> 159 matches\nfilter_FundamentalMatrix: 219 matches --> 184 matches\nstairs_split_1_1710453601885.png-stairs_split_2_1710453740954.png: 219 --> 184 matches\nfilter_FundamentalMatrix: 60 matches --> 15 matches\nstairs_split_1_1710453601885.png-stairs_split_2_1710453745156.png: 60 --> 15 matches\nfilter_FundamentalMatrix: 65 matches --> 18 matches\nstairs_split_1_1710453601885.png-stairs_split_2_1710453756762.png: 65 --> 18 matches\nfilter_FundamentalMatrix: 263 matches --> 194 matches\nstairs_split_1_1710453601885.png-stairs_split_2_1710453786375.png: 263 --> 194 matches\nfilter_FundamentalMatrix: 55 matches --> 15 matches\nstairs_split_1_1710453601885.png-stairs_split_2_1710453790978.png: 55 --> 15 matches\nfilter_FundamentalMatrix: 191 matches --> 169 matches\nstairs_split_1_1710453601885.png-stairs_split_2_1710453805788.png: 191 --> 169 matches\nfilter_FundamentalMatrix: 75 matches --> 31 matches\nstairs_split_1_1710453601885.png-stairs_split_2_1710453871430.png: 75 --> 31 matches\nfilter_FundamentalMatrix: 58 matches --> 29 matches\nstairs_split_1_1710453606287.png-stairs_split_1_1710453947066.png: 58 --> 29 matches\nfilter_FundamentalMatrix: 414 matches --> 354 matches\nstairs_split_1_1710453606287.png-stairs_split_1_1710453985484.png: 414 --> 354 matches\nfilter_FundamentalMatrix: 483 matches --> 401 matches\nstairs_split_1_1710453606287.png-stairs_split_1_1710453990286.png: 483 --> 401 matches\nfilter_FundamentalMatrix: 199 matches --> 164 matches\nstairs_split_1_1710453612890.png-stairs_split_1_1710453616892.png: 199 --> 164 matches\nfilter_FundamentalMatrix: 55 matches --> 15 matches\nstairs_split_1_1710453612890.png-stairs_split_1_1710453643106.png: 55 --> 15 matches\nfilter_FundamentalMatrix: 907 matches --> 862 matches\nstairs_split_1_1710453612890.png-stairs_split_1_1710453985484.png: 907 --> 862 matches\nfilter_FundamentalMatrix: 368 matches --> 303 matches\nstairs_split_1_1710453616892.png-stairs_split_1_1710453620694.png: 368 --> 303 matches\nfilter_FundamentalMatrix: 107 matches --> 78 matches\nstairs_split_1_1710453620694.png-stairs_split_1_1710453651110.png: 107 --> 78 matches\nskipped key1=stairs_split_1_1710453620694.png, key2=stairs_split_2_1710453745156.png: mkpts.shape=(12, 4) after filtered.\nfilter_FundamentalMatrix: 52 matches --> 29 matches\nstairs_split_1_1710453620694.png-stairs_split_2_1710453756762.png: 52 --> 29 matches\nfilter_FundamentalMatrix: 54 matches --> 22 matches\nstairs_split_1_1710453620694.png-stairs_split_2_1710453759963.png: 54 --> 22 matches\nfilter_FundamentalMatrix: 51 matches --> 18 matches\nstairs_split_1_1710453626698.png-stairs_split_1_1710453643106.png: 51 --> 18 matches\nfilter_FundamentalMatrix: 51 matches --> 15 matches\nstairs_split_1_1710453626698.png-stairs_split_1_1710453912451.png: 51 --> 15 matches\nfilter_FundamentalMatrix: 132 matches --> 96 matches\nstairs_split_1_1710453626698.png-stairs_split_1_1710453963274.png: 132 --> 96 matches\nfilter_FundamentalMatrix: 58 matches --> 15 matches\nstairs_split_1_1710453626698.png-stairs_split_2_1710453774370.png: 58 --> 15 matches\nfilter_FundamentalMatrix: 69 matches --> 15 matches\nstairs_split_1_1710453643106.png-stairs_split_1_1710453659313.png: 69 --> 15 matches\nskipped key1=stairs_split_1_1710453643106.png, key2=stairs_split_1_1710453678922.png: mkpts.shape=(13, 4) after filtered.\nfilter_FundamentalMatrix: 70 matches --> 19 matches\nstairs_split_1_1710453643106.png-stairs_split_1_1710453683725.png: 70 --> 19 matches\nfilter_FundamentalMatrix: 63 matches --> 15 matches\nstairs_split_1_1710453643106.png-stairs_split_1_1710453901046.png: 63 --> 15 matches\nfilter_FundamentalMatrix: 76 matches --> 25 matches\nstairs_split_1_1710453643106.png-stairs_split_1_1710453912451.png: 76 --> 25 matches\nfilter_FundamentalMatrix: 743 matches --> 679 matches\nstairs_split_1_1710453643106.png-stairs_split_1_1710453963274.png: 743 --> 679 matches\nskipped key1=stairs_split_1_1710453643106.png, key2=stairs_split_2_1710453733751.png: mkpts.shape=(13, 4) after filtered.\nskipped key1=stairs_split_1_1710453643106.png, key2=stairs_split_2_1710453745156.png: mkpts.shape=(12, 4) after filtered.\nskipped key1=stairs_split_1_1710453643106.png, key2=stairs_split_2_1710453753160.png: mkpts.shape=(11, 4) after filtered.\nfilter_FundamentalMatrix: 83 matches --> 19 matches\nstairs_split_1_1710453643106.png-stairs_split_2_1710453779372.png: 83 --> 19 matches\nskipped key1=stairs_split_1_1710453643106.png, key2=stairs_split_2_1710453793579.png: mkpts.shape=(12, 4) after filtered.\nskipped key1=stairs_split_1_1710453643106.png, key2=stairs_split_2_1710453798181.png: mkpts.shape=(12, 4) after filtered.\nskipped key1=stairs_split_1_1710453643106.png, key2=stairs_split_2_1710453862225.png: mkpts.shape=(12, 4) after filtered.\nfilter_FundamentalMatrix: 141 matches --> 133 matches\nstairs_split_1_1710453651110.png-stairs_split_1_1710453668718.png: 141 --> 133 matches\nfilter_FundamentalMatrix: 59 matches --> 17 matches\nstairs_split_1_1710453651110.png-stairs_split_1_1710453689727.png: 59 --> 17 matches\nfilter_FundamentalMatrix: 60 matches --> 29 matches\nstairs_split_1_1710453651110.png-stairs_split_1_1710453693529.png: 60 --> 29 matches\nfilter_FundamentalMatrix: 69 matches --> 25 matches\nstairs_split_1_1710453651110.png-stairs_split_1_1710453697531.png: 69 --> 25 matches\nskipped key1=stairs_split_1_1710453651110.png, key2=stairs_split_1_1710453704934.png: mkpts.shape=(14, 4) after filtered.\nfilter_FundamentalMatrix: 58 matches --> 19 matches\nstairs_split_1_1710453651110.png-stairs_split_1_1710453901046.png: 58 --> 19 matches\nfilter_FundamentalMatrix: 63 matches --> 16 matches\nstairs_split_1_1710453651110.png-stairs_split_1_1710453912451.png: 63 --> 16 matches\nfilter_FundamentalMatrix: 535 matches --> 377 matches\nstairs_split_1_1710453651110.png-stairs_split_1_1710453930259.png: 535 --> 377 matches\nfilter_FundamentalMatrix: 382 matches --> 344 matches\nstairs_split_1_1710453651110.png-stairs_split_1_1710453947066.png: 382 --> 344 matches\nfilter_FundamentalMatrix: 201 matches --> 172 matches\nstairs_split_1_1710453651110.png-stairs_split_1_1710453955270.png: 201 --> 172 matches\nfilter_FundamentalMatrix: 54 matches --> 27 matches\nstairs_split_1_1710453651110.png-stairs_split_1_1710453990286.png: 54 --> 27 matches\nfilter_FundamentalMatrix: 70 matches --> 30 matches\nstairs_split_1_1710453651110.png-stairs_split_2_1710453720741.png: 70 --> 30 matches\nfilter_FundamentalMatrix: 63 matches --> 22 matches\nstairs_split_1_1710453651110.png-stairs_split_2_1710453736752.png: 63 --> 22 matches\nfilter_FundamentalMatrix: 237 matches --> 133 matches\nstairs_split_1_1710453651110.png-stairs_split_2_1710453739354.png: 237 --> 133 matches\nfilter_FundamentalMatrix: 219 matches --> 127 matches\nstairs_split_1_1710453651110.png-stairs_split_2_1710453740954.png: 219 --> 127 matches\nfilter_FundamentalMatrix: 66 matches --> 16 matches\nstairs_split_1_1710453651110.png-stairs_split_2_1710453745156.png: 66 --> 16 matches\nskipped key1=stairs_split_1_1710453651110.png, key2=stairs_split_2_1710453753160.png: mkpts.shape=(14, 4) after filtered.\nfilter_FundamentalMatrix: 61 matches --> 20 matches\nstairs_split_1_1710453651110.png-stairs_split_2_1710453756762.png: 61 --> 20 matches\nfilter_FundamentalMatrix: 204 matches --> 105 matches\nstairs_split_1_1710453651110.png-stairs_split_2_1710453759963.png: 204 --> 105 matches\nfilter_FundamentalMatrix: 80 matches --> 24 matches\nstairs_split_1_1710453651110.png-stairs_split_2_1710453779372.png: 80 --> 24 matches\nfilter_FundamentalMatrix: 420 matches --> 282 matches\nstairs_split_1_1710453651110.png-stairs_split_2_1710453786375.png: 420 --> 282 matches\nfilter_FundamentalMatrix: 66 matches --> 21 matches\nstairs_split_1_1710453651110.png-stairs_split_2_1710453790978.png: 66 --> 21 matches\nskipped key1=stairs_split_1_1710453651110.png, key2=stairs_split_2_1710453793579.png: mkpts.shape=(13, 4) after filtered.\nfilter_FundamentalMatrix: 240 matches --> 131 matches\nstairs_split_1_1710453651110.png-stairs_split_2_1710453805788.png: 240 --> 131 matches\nfilter_FundamentalMatrix: 74 matches --> 36 matches\nstairs_split_1_1710453651110.png-stairs_split_2_1710453871430.png: 74 --> 36 matches\nfilter_FundamentalMatrix: 61 matches --> 18 matches\nstairs_split_1_1710453659313.png-stairs_split_1_1710453678922.png: 61 --> 18 matches\nfilter_FundamentalMatrix: 57 matches --> 16 matches\nstairs_split_1_1710453659313.png-stairs_split_1_1710453683725.png: 57 --> 16 matches\nskipped key1=stairs_split_1_1710453659313.png, key2=stairs_split_1_1710453912451.png: mkpts.shape=(13, 4) after filtered.\nfilter_FundamentalMatrix: 275 matches --> 242 matches\nstairs_split_1_1710453659313.png-stairs_split_1_1710453947066.png: 275 --> 242 matches\nfilter_FundamentalMatrix: 52 matches --> 16 matches\nstairs_split_1_1710453659313.png-stairs_split_2_1710453728949.png: 52 --> 16 matches\nfilter_FundamentalMatrix: 58 matches --> 16 matches\nstairs_split_1_1710453659313.png-stairs_split_2_1710453753160.png: 58 --> 16 matches\nfilter_FundamentalMatrix: 586 matches --> 427 matches\nstairs_split_1_1710453668718.png-stairs_split_1_1710453930259.png: 586 --> 427 matches\nfilter_FundamentalMatrix: 299 matches --> 236 matches\nstairs_split_1_1710453668718.png-stairs_split_2_1710453786375.png: 299 --> 236 matches\nfilter_FundamentalMatrix: 413 matches --> 354 matches\nstairs_split_1_1710453668718.png-stairs_split_2_1710453871430.png: 413 --> 354 matches\nfilter_FundamentalMatrix: 118 matches --> 109 matches\nstairs_split_1_1710453675921.png-stairs_split_1_1710453678922.png: 118 --> 109 matches\nfilter_FundamentalMatrix: 231 matches --> 201 matches\nstairs_split_1_1710453675921.png-stairs_split_1_1710453704934.png: 231 --> 201 matches\nfilter_FundamentalMatrix: 289 matches --> 247 matches\nstairs_split_1_1710453675921.png-stairs_split_1_1710453930259.png: 289 --> 247 matches\nfilter_FundamentalMatrix: 111 matches --> 86 matches\nstairs_split_1_1710453675921.png-stairs_split_1_1710453947066.png: 111 --> 86 matches\nskipped key1=stairs_split_1_1710453678922.png, key2=stairs_split_2_1710453725143.png: mkpts.shape=(14, 4) after filtered.\nskipped key1=stairs_split_1_1710453678922.png, key2=stairs_split_2_1710453728949.png: mkpts.shape=(13, 4) after filtered.\nskipped key1=stairs_split_1_1710453678922.png, key2=stairs_split_2_1710453753160.png: mkpts.shape=(14, 4) after filtered.\nfilter_FundamentalMatrix: 50 matches --> 15 matches\nstairs_split_1_1710453678922.png-stairs_split_2_1710453774370.png: 50 --> 15 matches\nskipped key1=stairs_split_1_1710453678922.png, key2=stairs_split_2_1710453793579.png: mkpts.shape=(13, 4) after filtered.\nskipped key1=stairs_split_1_1710453683725.png, key2=stairs_split_2_1710453728949.png: mkpts.shape=(12, 4) after filtered.\nskipped key1=stairs_split_1_1710453683725.png, key2=stairs_split_2_1710453733751.png: mkpts.shape=(14, 4) after filtered.\nskipped key1=stairs_split_1_1710453683725.png, key2=stairs_split_2_1710453765165.png: mkpts.shape=(14, 4) after filtered.\nfilter_FundamentalMatrix: 73 matches --> 17 matches\nstairs_split_1_1710453689727.png-stairs_split_1_1710453693529.png: 73 --> 17 matches\nfilter_FundamentalMatrix: 67 matches --> 20 matches\nstairs_split_1_1710453689727.png-stairs_split_1_1710453955270.png: 67 --> 20 matches\nfilter_FundamentalMatrix: 82 matches --> 24 matches\nstairs_split_1_1710453689727.png-stairs_split_2_1710453720741.png: 82 --> 24 matches\nfilter_FundamentalMatrix: 116 matches --> 38 matches\nstairs_split_1_1710453689727.png-stairs_split_2_1710453736752.png: 116 --> 38 matches\nfilter_FundamentalMatrix: 55 matches --> 22 matches\nstairs_split_1_1710453689727.png-stairs_split_2_1710453739354.png: 55 --> 22 matches\nfilter_FundamentalMatrix: 70 matches --> 20 matches\nstairs_split_1_1710453689727.png-stairs_split_2_1710453740954.png: 70 --> 20 matches\nskipped key1=stairs_split_1_1710453689727.png, key2=stairs_split_2_1710453745156.png: mkpts.shape=(14, 4) after filtered.\nfilter_FundamentalMatrix: 89 matches --> 19 matches\nstairs_split_1_1710453689727.png-stairs_split_2_1710453753160.png: 89 --> 19 matches\nfilter_FundamentalMatrix: 85 matches --> 17 matches\nstairs_split_1_1710453689727.png-stairs_split_2_1710453756762.png: 85 --> 17 matches\nfilter_FundamentalMatrix: 71 matches --> 20 matches\nstairs_split_1_1710453689727.png-stairs_split_2_1710453759963.png: 71 --> 20 matches\nfilter_FundamentalMatrix: 82 matches --> 25 matches\nstairs_split_1_1710453689727.png-stairs_split_2_1710453783374.png: 82 --> 25 matches\nfilter_FundamentalMatrix: 60 matches --> 15 matches\nstairs_split_1_1710453689727.png-stairs_split_2_1710453786375.png: 60 --> 15 matches\nskipped key1=stairs_split_1_1710453689727.png, key2=stairs_split_2_1710453790978.png: mkpts.shape=(14, 4) after filtered.\nfilter_FundamentalMatrix: 74 matches --> 15 matches\nstairs_split_1_1710453689727.png-stairs_split_2_1710453798181.png: 74 --> 15 matches\nfilter_FundamentalMatrix: 70 matches --> 15 matches\nstairs_split_1_1710453689727.png-stairs_split_2_1710453801783.png: 70 --> 15 matches\nfilter_FundamentalMatrix: 55 matches --> 24 matches\nstairs_split_1_1710453689727.png-stairs_split_2_1710453805788.png: 55 --> 24 matches\nfilter_FundamentalMatrix: 498 matches --> 265 matches\nstairs_split_1_1710453689727.png-stairs_split_2_1710453871430.png: 498 --> 265 matches\nfilter_FundamentalMatrix: 65 matches --> 18 matches\nstairs_split_1_1710453693529.png-stairs_split_1_1710453704934.png: 65 --> 18 matches\nfilter_FundamentalMatrix: 65 matches --> 21 matches\nstairs_split_1_1710453693529.png-stairs_split_2_1710453736752.png: 65 --> 21 matches\nfilter_FundamentalMatrix: 166 matches --> 100 matches\nstairs_split_1_1710453693529.png-stairs_split_2_1710453739354.png: 166 --> 100 matches\nfilter_FundamentalMatrix: 60 matches --> 25 matches\nstairs_split_1_1710453693529.png-stairs_split_2_1710453740954.png: 60 --> 25 matches\nfilter_FundamentalMatrix: 68 matches --> 18 matches\nstairs_split_1_1710453693529.png-stairs_split_2_1710453745156.png: 68 --> 18 matches\nskipped key1=stairs_split_1_1710453693529.png, key2=stairs_split_2_1710453756762.png: mkpts.shape=(14, 4) after filtered.\nfilter_FundamentalMatrix: 52 matches --> 24 matches\nstairs_split_1_1710453693529.png-stairs_split_2_1710453759963.png: 52 --> 24 matches\nfilter_FundamentalMatrix: 54 matches --> 21 matches\nstairs_split_1_1710453693529.png-stairs_split_2_1710453786375.png: 54 --> 21 matches\nfilter_FundamentalMatrix: 67 matches --> 18 matches\nstairs_split_1_1710453693529.png-stairs_split_2_1710453790978.png: 67 --> 18 matches\nfilter_FundamentalMatrix: 57 matches --> 22 matches\nstairs_split_1_1710453693529.png-stairs_split_2_1710453871430.png: 57 --> 22 matches\nfilter_FundamentalMatrix: 83 matches --> 21 matches\nstairs_split_1_1710453697531.png-stairs_split_2_1710453736752.png: 83 --> 21 matches\nfilter_FundamentalMatrix: 94 matches --> 20 matches\nstairs_split_1_1710453697531.png-stairs_split_2_1710453745156.png: 94 --> 20 matches\nfilter_FundamentalMatrix: 102 matches --> 22 matches\nstairs_split_1_1710453697531.png-stairs_split_2_1710453756762.png: 102 --> 22 matches\nfilter_FundamentalMatrix: 68 matches --> 17 matches\nstairs_split_1_1710453697531.png-stairs_split_2_1710453759963.png: 68 --> 17 matches\nskipped key1=stairs_split_1_1710453697531.png, key2=stairs_split_2_1710453779372.png: mkpts.shape=(14, 4) after filtered.\nfilter_FundamentalMatrix: 52 matches --> 17 matches\nstairs_split_1_1710453697531.png-stairs_split_2_1710453786375.png: 52 --> 17 matches\nfilter_FundamentalMatrix: 83 matches --> 20 matches\nstairs_split_1_1710453697531.png-stairs_split_2_1710453790978.png: 83 --> 20 matches\nfilter_FundamentalMatrix: 1205 matches --> 1052 matches\nstairs_split_1_1710453704934.png-stairs_split_1_1710453901046.png: 1205 --> 1052 matches\nskipped key1=stairs_split_1_1710453704934.png, key2=stairs_split_1_1710453955270.png: mkpts.shape=(11, 4) after filtered.\nfilter_FundamentalMatrix: 57 matches --> 15 matches\nstairs_split_1_1710453704934.png-stairs_split_2_1710453720741.png: 57 --> 15 matches\nfilter_FundamentalMatrix: 84 matches --> 21 matches\nstairs_split_1_1710453704934.png-stairs_split_2_1710453725143.png: 84 --> 21 matches\nskipped key1=stairs_split_1_1710453704934.png, key2=stairs_split_2_1710453736752.png: mkpts.shape=(14, 4) after filtered.\nskipped key1=stairs_split_1_1710453704934.png, key2=stairs_split_2_1710453740954.png: mkpts.shape=(14, 4) after filtered.\nfilter_FundamentalMatrix: 671 matches --> 534 matches\nstairs_split_1_1710453704934.png-stairs_split_2_1710453745156.png: 671 --> 534 matches\nfilter_FundamentalMatrix: 74 matches --> 15 matches\nstairs_split_1_1710453704934.png-stairs_split_2_1710453753160.png: 74 --> 15 matches\nfilter_FundamentalMatrix: 67 matches --> 15 matches\nstairs_split_1_1710453704934.png-stairs_split_2_1710453756762.png: 67 --> 15 matches\nfilter_FundamentalMatrix: 77 matches --> 18 matches\nstairs_split_1_1710453704934.png-stairs_split_2_1710453765165.png: 77 --> 18 matches\nfilter_FundamentalMatrix: 72 matches --> 16 matches\nstairs_split_1_1710453704934.png-stairs_split_2_1710453779372.png: 72 --> 16 matches\nfilter_FundamentalMatrix: 56 matches --> 16 matches\nstairs_split_1_1710453704934.png-stairs_split_2_1710453783374.png: 56 --> 16 matches\nfilter_FundamentalMatrix: 551 matches --> 423 matches\nstairs_split_1_1710453704934.png-stairs_split_2_1710453790978.png: 551 --> 423 matches\nfilter_FundamentalMatrix: 83 matches --> 25 matches\nstairs_split_1_1710453704934.png-stairs_split_2_1710453793579.png: 83 --> 25 matches\nfilter_FundamentalMatrix: 64 matches --> 16 matches\nstairs_split_1_1710453704934.png-stairs_split_2_1710453798181.png: 64 --> 16 matches\nskipped key1=stairs_split_1_1710453704934.png, key2=stairs_split_2_1710453801783.png: mkpts.shape=(12, 4) after filtered.\nfilter_FundamentalMatrix: 50 matches --> 17 matches\nstairs_split_1_1710453704934.png-stairs_split_2_1710453862225.png: 50 --> 17 matches\nfilter_FundamentalMatrix: 75 matches --> 18 matches\nstairs_split_1_1710453901046.png-stairs_split_1_1710453912451.png: 75 --> 18 matches\nfilter_FundamentalMatrix: 58 matches --> 18 matches\nstairs_split_1_1710453901046.png-stairs_split_1_1710453947066.png: 58 --> 18 matches\nfilter_FundamentalMatrix: 68 matches --> 15 matches\nstairs_split_1_1710453901046.png-stairs_split_1_1710453955270.png: 68 --> 15 matches\nskipped key1=stairs_split_1_1710453901046.png, key2=stairs_split_1_1710453963274.png: mkpts.shape=(13, 4) after filtered.\nfilter_FundamentalMatrix: 70 matches --> 17 matches\nstairs_split_1_1710453901046.png-stairs_split_1_1710453990286.png: 70 --> 17 matches\nfilter_FundamentalMatrix: 78 matches --> 17 matches\nstairs_split_1_1710453901046.png-stairs_split_2_1710453725143.png: 78 --> 17 matches\nskipped key1=stairs_split_1_1710453901046.png, key2=stairs_split_2_1710453733751.png: mkpts.shape=(13, 4) after filtered.\nfilter_FundamentalMatrix: 263 matches --> 120 matches\nstairs_split_1_1710453901046.png-stairs_split_2_1710453745156.png: 263 --> 120 matches\nfilter_FundamentalMatrix: 85 matches --> 20 matches\nstairs_split_1_1710453901046.png-stairs_split_2_1710453753160.png: 85 --> 20 matches\nfilter_FundamentalMatrix: 64 matches --> 19 matches\nstairs_split_1_1710453901046.png-stairs_split_2_1710453765165.png: 64 --> 19 matches\nskipped key1=stairs_split_1_1710453901046.png, key2=stairs_split_2_1710453774370.png: mkpts.shape=(13, 4) after filtered.\nfilter_FundamentalMatrix: 77 matches --> 15 matches\nstairs_split_1_1710453901046.png-stairs_split_2_1710453779372.png: 77 --> 15 matches\nfilter_FundamentalMatrix: 67 matches --> 22 matches\nstairs_split_1_1710453901046.png-stairs_split_2_1710453790978.png: 67 --> 22 matches\nfilter_FundamentalMatrix: 87 matches --> 28 matches\nstairs_split_1_1710453901046.png-stairs_split_2_1710453793579.png: 87 --> 28 matches\nfilter_FundamentalMatrix: 59 matches --> 20 matches\nstairs_split_1_1710453901046.png-stairs_split_2_1710453798181.png: 59 --> 20 matches\nskipped key1=stairs_split_1_1710453901046.png, key2=stairs_split_2_1710453801783.png: mkpts.shape=(13, 4) after filtered.\nfilter_FundamentalMatrix: 206 matches --> 102 matches\nstairs_split_1_1710453901046.png-stairs_split_2_1710453862225.png: 206 --> 102 matches\nfilter_FundamentalMatrix: 72 matches --> 17 matches\nstairs_split_1_1710453901046.png-stairs_split_2_1710453871430.png: 72 --> 17 matches\nfilter_FundamentalMatrix: 72 matches --> 35 matches\nstairs_split_1_1710453912451.png-stairs_split_1_1710453955270.png: 72 --> 35 matches\nskipped key1=stairs_split_1_1710453912451.png, key2=stairs_split_2_1710453733751.png: mkpts.shape=(14, 4) after filtered.\nskipped key1=stairs_split_1_1710453912451.png, key2=stairs_split_2_1710453745156.png: mkpts.shape=(14, 4) after filtered.\nfilter_FundamentalMatrix: 97 matches --> 15 matches\nstairs_split_1_1710453912451.png-stairs_split_2_1710453753160.png: 97 --> 15 matches\nskipped key1=stairs_split_1_1710453912451.png, key2=stairs_split_2_1710453765165.png: mkpts.shape=(11, 4) after filtered.\nskipped key1=stairs_split_1_1710453912451.png, key2=stairs_split_2_1710453774370.png: mkpts.shape=(13, 4) after filtered.\nfilter_FundamentalMatrix: 99 matches --> 19 matches\nstairs_split_1_1710453912451.png-stairs_split_2_1710453779372.png: 99 --> 19 matches\nskipped key1=stairs_split_1_1710453912451.png, key2=stairs_split_2_1710453793579.png: mkpts.shape=(11, 4) after filtered.\nfilter_FundamentalMatrix: 70 matches --> 15 matches\nstairs_split_1_1710453912451.png-stairs_split_2_1710453862225.png: 70 --> 15 matches\nfilter_FundamentalMatrix: 323 matches --> 241 matches\nstairs_split_1_1710453947066.png-stairs_split_1_1710453990286.png: 323 --> 241 matches\nfilter_FundamentalMatrix: 59 matches --> 15 matches\nstairs_split_1_1710453947066.png-stairs_split_2_1710453753160.png: 59 --> 15 matches\nfilter_FundamentalMatrix: 52 matches --> 16 matches\nstairs_split_1_1710453947066.png-stairs_split_2_1710453790978.png: 52 --> 16 matches\nfilter_FundamentalMatrix: 75 matches --> 19 matches\nstairs_split_1_1710453955270.png-stairs_split_2_1710453736752.png: 75 --> 19 matches\nskipped key1=stairs_split_1_1710453955270.png, key2=stairs_split_2_1710453745156.png: mkpts.shape=(14, 4) after filtered.\nskipped key1=stairs_split_1_1710453955270.png, key2=stairs_split_2_1710453753160.png: mkpts.shape=(12, 4) after filtered.\nfilter_FundamentalMatrix: 52 matches --> 15 matches\nstairs_split_1_1710453955270.png-stairs_split_2_1710453759963.png: 52 --> 15 matches\nfilter_FundamentalMatrix: 68 matches --> 23 matches\nstairs_split_1_1710453955270.png-stairs_split_2_1710453779372.png: 68 --> 23 matches\nfilter_FundamentalMatrix: 74 matches --> 38 matches\nstairs_split_1_1710453955270.png-stairs_split_2_1710453871430.png: 74 --> 38 matches\nskipped key1=stairs_split_1_1710453963274.png, key2=stairs_split_2_1710453728949.png: mkpts.shape=(13, 4) after filtered.\nskipped key1=stairs_split_1_1710453963274.png, key2=stairs_split_2_1710453733751.png: mkpts.shape=(14, 4) after filtered.\nskipped key1=stairs_split_1_1710453963274.png, key2=stairs_split_2_1710453765165.png: mkpts.shape=(14, 4) after filtered.\nfilter_FundamentalMatrix: 55 matches --> 15 matches\nstairs_split_1_1710453963274.png-stairs_split_2_1710453774370.png: 55 --> 15 matches\nskipped key1=stairs_split_1_1710453963274.png, key2=stairs_split_2_1710453779372.png: mkpts.shape=(13, 4) after filtered.\nfilter_FundamentalMatrix: 51 matches --> 17 matches\nstairs_split_1_1710453990286.png-stairs_split_2_1710453745156.png: 51 --> 17 matches\nfilter_FundamentalMatrix: 257 matches --> 177 matches\nstairs_split_2_1710453720741.png-stairs_split_2_1710453725143.png: 257 --> 177 matches\nfilter_FundamentalMatrix: 77 matches --> 18 matches\nstairs_split_2_1710453720741.png-stairs_split_2_1710453745156.png: 77 --> 18 matches\nfilter_FundamentalMatrix: 64 matches --> 30 matches\nstairs_split_2_1710453720741.png-stairs_split_2_1710453783374.png: 64 --> 30 matches\nfilter_FundamentalMatrix: 1723 matches --> 1178 matches\nstairs_split_2_1710453720741.png-stairs_split_2_1710453786375.png: 1723 --> 1178 matches\nfilter_FundamentalMatrix: 412 matches --> 320 matches\nstairs_split_2_1710453720741.png-stairs_split_2_1710453805788.png: 412 --> 320 matches\nfilter_FundamentalMatrix: 314 matches --> 185 matches\nstairs_split_2_1710453720741.png-stairs_split_2_1710453871430.png: 314 --> 185 matches\nfilter_FundamentalMatrix: 68 matches --> 19 matches\nstairs_split_2_1710453725143.png-stairs_split_2_1710453728949.png: 68 --> 19 matches\nfilter_FundamentalMatrix: 107 matches --> 23 matches\nstairs_split_2_1710453725143.png-stairs_split_2_1710453745156.png: 107 --> 23 matches\nskipped key1=stairs_split_2_1710453725143.png, key2=stairs_split_2_1710453753160.png: mkpts.shape=(14, 4) after filtered.\nfilter_FundamentalMatrix: 74 matches --> 35 matches\nstairs_split_2_1710453725143.png-stairs_split_2_1710453765165.png: 74 --> 35 matches\nfilter_FundamentalMatrix: 92 matches --> 16 matches\nstairs_split_2_1710453725143.png-stairs_split_2_1710453779372.png: 92 --> 16 matches\nfilter_FundamentalMatrix: 80 matches --> 19 matches\nstairs_split_2_1710453725143.png-stairs_split_2_1710453793579.png: 80 --> 19 matches\nskipped key1=stairs_split_2_1710453725143.png, key2=stairs_split_2_1710453798181.png: mkpts.shape=(13, 4) after filtered.\nskipped key1=stairs_split_2_1710453728949.png, key2=stairs_split_2_1710453753160.png: mkpts.shape=(13, 4) after filtered.\nfilter_FundamentalMatrix: 57 matches --> 15 matches\nstairs_split_2_1710453728949.png-stairs_split_2_1710453765165.png: 57 --> 15 matches\nfilter_FundamentalMatrix: 80 matches --> 22 matches\nstairs_split_2_1710453728949.png-stairs_split_2_1710453774370.png: 80 --> 22 matches\nfilter_FundamentalMatrix: 81 matches --> 21 matches\nstairs_split_2_1710453733751.png-stairs_split_2_1710453745156.png: 81 --> 21 matches\nfilter_FundamentalMatrix: 128 matches --> 23 matches\nstairs_split_2_1710453733751.png-stairs_split_2_1710453753160.png: 128 --> 23 matches\nskipped key1=stairs_split_2_1710453733751.png, key2=stairs_split_2_1710453765165.png: mkpts.shape=(13, 4) after filtered.\nfilter_FundamentalMatrix: 90 matches --> 21 matches\nstairs_split_2_1710453733751.png-stairs_split_2_1710453774370.png: 90 --> 21 matches\nfilter_FundamentalMatrix: 93 matches --> 41 matches\nstairs_split_2_1710453733751.png-stairs_split_2_1710453779372.png: 93 --> 41 matches\nfilter_FundamentalMatrix: 57 matches --> 17 matches\nstairs_split_2_1710453733751.png-stairs_split_2_1710453793579.png: 57 --> 17 matches\nfilter_FundamentalMatrix: 67 matches --> 18 matches\nstairs_split_2_1710453733751.png-stairs_split_2_1710453798181.png: 67 --> 18 matches\nfilter_FundamentalMatrix: 67 matches --> 22 matches\nstairs_split_2_1710453733751.png-stairs_split_2_1710453801783.png: 67 --> 22 matches\nskipped key1=stairs_split_2_1710453733751.png, key2=stairs_split_2_1710453862225.png: mkpts.shape=(14, 4) after filtered.\nfilter_FundamentalMatrix: 70 matches --> 19 matches\nstairs_split_2_1710453736752.png-stairs_split_2_1710453740954.png: 70 --> 19 matches\nfilter_FundamentalMatrix: 85 matches --> 19 matches\nstairs_split_2_1710453736752.png-stairs_split_2_1710453745156.png: 85 --> 19 matches\nfilter_FundamentalMatrix: 294 matches --> 171 matches\nstairs_split_2_1710453736752.png-stairs_split_2_1710453756762.png: 294 --> 171 matches\nfilter_FundamentalMatrix: 62 matches --> 19 matches\nstairs_split_2_1710453736752.png-stairs_split_2_1710453759963.png: 62 --> 19 matches\nfilter_FundamentalMatrix: 125 matches --> 43 matches\nstairs_split_2_1710453736752.png-stairs_split_2_1710453779372.png: 125 --> 43 matches\nfilter_FundamentalMatrix: 292 matches --> 200 matches\nstairs_split_2_1710453736752.png-stairs_split_2_1710453783374.png: 292 --> 200 matches\nfilter_FundamentalMatrix: 59 matches --> 16 matches\nstairs_split_2_1710453736752.png-stairs_split_2_1710453786375.png: 59 --> 16 matches\nfilter_FundamentalMatrix: 91 matches --> 17 matches\nstairs_split_2_1710453736752.png-stairs_split_2_1710453790978.png: 91 --> 17 matches\nskipped key1=stairs_split_2_1710453736752.png, key2=stairs_split_2_1710453793579.png: mkpts.shape=(14, 4) after filtered.\nfilter_FundamentalMatrix: 78 matches --> 17 matches\nstairs_split_2_1710453736752.png-stairs_split_2_1710453798181.png: 78 --> 17 matches\nfilter_FundamentalMatrix: 270 matches --> 195 matches\nstairs_split_2_1710453736752.png-stairs_split_2_1710453801783.png: 270 --> 195 matches\nfilter_FundamentalMatrix: 76 matches --> 22 matches\nstairs_split_2_1710453736752.png-stairs_split_2_1710453805788.png: 76 --> 22 matches\nfilter_FundamentalMatrix: 1043 matches --> 953 matches\nstairs_split_2_1710453736752.png-stairs_split_2_1710453871430.png: 1043 --> 953 matches\nfilter_FundamentalMatrix: 1877 matches --> 1695 matches\nstairs_split_2_1710453739354.png-stairs_split_2_1710453740954.png: 1877 --> 1695 matches\nfilter_FundamentalMatrix: 66 matches --> 24 matches\nstairs_split_2_1710453739354.png-stairs_split_2_1710453745156.png: 66 --> 24 matches\nfilter_FundamentalMatrix: 54 matches --> 21 matches\nstairs_split_2_1710453739354.png-stairs_split_2_1710453756762.png: 54 --> 21 matches\nfilter_FundamentalMatrix: 588 matches --> 498 matches\nstairs_split_2_1710453739354.png-stairs_split_2_1710453759963.png: 588 --> 498 matches\nfilter_FundamentalMatrix: 378 matches --> 221 matches\nstairs_split_2_1710453739354.png-stairs_split_2_1710453783374.png: 378 --> 221 matches\nfilter_FundamentalMatrix: 338 matches --> 203 matches\nstairs_split_2_1710453739354.png-stairs_split_2_1710453786375.png: 338 --> 203 matches\nfilter_FundamentalMatrix: 426 matches --> 287 matches\nstairs_split_2_1710453739354.png-stairs_split_2_1710453805788.png: 426 --> 287 matches\nfilter_FundamentalMatrix: 2114 matches --> 1960 matches\nstairs_split_2_1710453739354.png-stairs_split_2_1710453871430.png: 2114 --> 1960 matches\nfilter_FundamentalMatrix: 68 matches --> 23 matches\nstairs_split_2_1710453740954.png-stairs_split_2_1710453756762.png: 68 --> 23 matches\nfilter_FundamentalMatrix: 1399 matches --> 969 matches\nstairs_split_2_1710453740954.png-stairs_split_2_1710453759963.png: 1399 --> 969 matches\nfilter_FundamentalMatrix: 58 matches --> 26 matches\nstairs_split_2_1710453740954.png-stairs_split_2_1710453783374.png: 58 --> 26 matches\nfilter_FundamentalMatrix: 1370 matches --> 1242 matches\nstairs_split_2_1710453740954.png-stairs_split_2_1710453786375.png: 1370 --> 1242 matches\nfilter_FundamentalMatrix: 61 matches --> 23 matches\nstairs_split_2_1710453740954.png-stairs_split_2_1710453790978.png: 61 --> 23 matches\nfilter_FundamentalMatrix: 279 matches --> 132 matches\nstairs_split_2_1710453740954.png-stairs_split_2_1710453805788.png: 279 --> 132 matches\nfilter_FundamentalMatrix: 72 matches --> 34 matches\nstairs_split_2_1710453740954.png-stairs_split_2_1710453871430.png: 72 --> 34 matches\nfilter_FundamentalMatrix: 82 matches --> 15 matches\nstairs_split_2_1710453745156.png-stairs_split_2_1710453753160.png: 82 --> 15 matches\nfilter_FundamentalMatrix: 65 matches --> 18 matches\nstairs_split_2_1710453745156.png-stairs_split_2_1710453756762.png: 65 --> 18 matches\nskipped key1=stairs_split_2_1710453745156.png, key2=stairs_split_2_1710453759963.png: mkpts.shape=(13, 4) after filtered.\nfilter_FundamentalMatrix: 71 matches --> 20 matches\nstairs_split_2_1710453745156.png-stairs_split_2_1710453765165.png: 71 --> 20 matches\nskipped key1=stairs_split_2_1710453745156.png, key2=stairs_split_2_1710453779372.png: mkpts.shape=(13, 4) after filtered.\nfilter_FundamentalMatrix: 59 matches --> 15 matches\nstairs_split_2_1710453745156.png-stairs_split_2_1710453783374.png: 59 --> 15 matches\nfilter_FundamentalMatrix: 57 matches --> 18 matches\nstairs_split_2_1710453745156.png-stairs_split_2_1710453786375.png: 57 --> 18 matches\nfilter_FundamentalMatrix: 1062 matches --> 908 matches\nstairs_split_2_1710453745156.png-stairs_split_2_1710453790978.png: 1062 --> 908 matches\nfilter_FundamentalMatrix: 97 matches --> 25 matches\nstairs_split_2_1710453745156.png-stairs_split_2_1710453793579.png: 97 --> 25 matches\nskipped key1=stairs_split_2_1710453745156.png, key2=stairs_split_2_1710453798181.png: mkpts.shape=(13, 4) after filtered.\nskipped key1=stairs_split_2_1710453745156.png, key2=stairs_split_2_1710453801783.png: mkpts.shape=(12, 4) after filtered.\nfilter_FundamentalMatrix: 163 matches --> 84 matches\nstairs_split_2_1710453745156.png-stairs_split_2_1710453862225.png: 163 --> 84 matches\nfilter_FundamentalMatrix: 73 matches --> 16 matches\nstairs_split_2_1710453745156.png-stairs_split_2_1710453871430.png: 73 --> 16 matches\nfilter_FundamentalMatrix: 112 matches --> 18 matches\nstairs_split_2_1710453753160.png-stairs_split_2_1710453779372.png: 112 --> 18 matches\nfilter_FundamentalMatrix: 79 matches --> 15 matches\nstairs_split_2_1710453753160.png-stairs_split_2_1710453790978.png: 79 --> 15 matches\nskipped key1=stairs_split_2_1710453753160.png, key2=stairs_split_2_1710453793579.png: mkpts.shape=(13, 4) after filtered.\nfilter_FundamentalMatrix: 92 matches --> 22 matches\nstairs_split_2_1710453753160.png-stairs_split_2_1710453798181.png: 92 --> 22 matches\nfilter_FundamentalMatrix: 80 matches --> 26 matches\nstairs_split_2_1710453753160.png-stairs_split_2_1710453801783.png: 80 --> 26 matches\nfilter_FundamentalMatrix: 69 matches --> 24 matches\nstairs_split_2_1710453753160.png-stairs_split_2_1710453862225.png: 69 --> 24 matches\nfilter_FundamentalMatrix: 65 matches --> 21 matches\nstairs_split_2_1710453756762.png-stairs_split_2_1710453759963.png: 65 --> 21 matches\nfilter_FundamentalMatrix: 87 matches --> 31 matches\nstairs_split_2_1710453756762.png-stairs_split_2_1710453783374.png: 87 --> 31 matches\nskipped key1=stairs_split_2_1710453756762.png, key2=stairs_split_2_1710453786375.png: mkpts.shape=(14, 4) after filtered.\nskipped key1=stairs_split_2_1710453756762.png, key2=stairs_split_2_1710453790978.png: mkpts.shape=(13, 4) after filtered.\nfilter_FundamentalMatrix: 81 matches --> 16 matches\nstairs_split_2_1710453756762.png-stairs_split_2_1710453793579.png: 81 --> 16 matches\nfilter_FundamentalMatrix: 71 matches --> 18 matches\nstairs_split_2_1710453756762.png-stairs_split_2_1710453798181.png: 71 --> 18 matches\nfilter_FundamentalMatrix: 86 matches --> 39 matches\nstairs_split_2_1710453756762.png-stairs_split_2_1710453801783.png: 86 --> 39 matches\nfilter_FundamentalMatrix: 60 matches --> 20 matches\nstairs_split_2_1710453756762.png-stairs_split_2_1710453805788.png: 60 --> 20 matches\nfilter_FundamentalMatrix: 92 matches --> 33 matches\nstairs_split_2_1710453756762.png-stairs_split_2_1710453871430.png: 92 --> 33 matches\nfilter_FundamentalMatrix: 1045 matches --> 622 matches\nstairs_split_2_1710453759963.png-stairs_split_2_1710453786375.png: 1045 --> 622 matches\nfilter_FundamentalMatrix: 56 matches --> 16 matches\nstairs_split_2_1710453759963.png-stairs_split_2_1710453790978.png: 56 --> 16 matches\nfilter_FundamentalMatrix: 390 matches --> 250 matches\nstairs_split_2_1710453759963.png-stairs_split_2_1710453805788.png: 390 --> 250 matches\nfilter_FundamentalMatrix: 63 matches --> 26 matches\nstairs_split_2_1710453759963.png-stairs_split_2_1710453871430.png: 63 --> 26 matches\nfilter_FundamentalMatrix: 59 matches --> 17 matches\nstairs_split_2_1710453765165.png-stairs_split_2_1710453774370.png: 59 --> 17 matches\nskipped key1=stairs_split_2_1710453765165.png, key2=stairs_split_2_1710453779372.png: mkpts.shape=(12, 4) after filtered.\nfilter_FundamentalMatrix: 63 matches --> 18 matches\nstairs_split_2_1710453765165.png-stairs_split_2_1710453790978.png: 63 --> 18 matches\nfilter_FundamentalMatrix: 68 matches --> 17 matches\nstairs_split_2_1710453765165.png-stairs_split_2_1710453793579.png: 68 --> 17 matches\nskipped key1=stairs_split_2_1710453765165.png, key2=stairs_split_2_1710453798181.png: mkpts.shape=(13, 4) after filtered.\nfilter_FundamentalMatrix: 52 matches --> 15 matches\nstairs_split_2_1710453765165.png-stairs_split_2_1710453862225.png: 52 --> 15 matches\nskipped key1=stairs_split_2_1710453774370.png, key2=stairs_split_2_1710453779372.png: mkpts.shape=(14, 4) after filtered.\nfilter_FundamentalMatrix: 61 matches --> 15 matches\nstairs_split_2_1710453774370.png-stairs_split_2_1710453793579.png: 61 --> 15 matches\nskipped key1=stairs_split_2_1710453774370.png, key2=stairs_split_2_1710453862225.png: mkpts.shape=(13, 4) after filtered.\nfilter_FundamentalMatrix: 90 matches --> 20 matches\nstairs_split_2_1710453779372.png-stairs_split_2_1710453793579.png: 90 --> 20 matches\nfilter_FundamentalMatrix: 82 matches --> 21 matches\nstairs_split_2_1710453779372.png-stairs_split_2_1710453798181.png: 82 --> 21 matches\nfilter_FundamentalMatrix: 72 matches --> 40 matches\nstairs_split_2_1710453779372.png-stairs_split_2_1710453801783.png: 72 --> 40 matches\nfilter_FundamentalMatrix: 57 matches --> 15 matches\nstairs_split_2_1710453779372.png-stairs_split_2_1710453862225.png: 57 --> 15 matches\nfilter_FundamentalMatrix: 1144 matches --> 1030 matches\nstairs_split_2_1710453783374.png-stairs_split_2_1710453786375.png: 1144 --> 1030 matches\nfilter_FundamentalMatrix: 65 matches --> 16 matches\nstairs_split_2_1710453783374.png-stairs_split_2_1710453790978.png: 65 --> 16 matches\nfilter_FundamentalMatrix: 53 matches --> 15 matches\nstairs_split_2_1710453783374.png-stairs_split_2_1710453801783.png: 53 --> 15 matches\nfilter_FundamentalMatrix: 1260 matches --> 1159 matches\nstairs_split_2_1710453783374.png-stairs_split_2_1710453805788.png: 1260 --> 1159 matches\nfilter_FundamentalMatrix: 1061 matches --> 783 matches\nstairs_split_2_1710453783374.png-stairs_split_2_1710453871430.png: 1061 --> 783 matches\nfilter_FundamentalMatrix: 163 matches --> 124 matches\nstairs_split_2_1710453786375.png-stairs_split_2_1710453790978.png: 163 --> 124 matches\nfilter_FundamentalMatrix: 51 matches --> 17 matches\nstairs_split_2_1710453786375.png-stairs_split_2_1710453801783.png: 51 --> 17 matches\nfilter_FundamentalMatrix: 722 matches --> 505 matches\nstairs_split_2_1710453786375.png-stairs_split_2_1710453805788.png: 722 --> 505 matches\nfilter_FundamentalMatrix: 57 matches --> 27 matches\nstairs_split_2_1710453786375.png-stairs_split_2_1710453871430.png: 57 --> 27 matches\nfilter_FundamentalMatrix: 190 matches --> 110 matches\nstairs_split_2_1710453790978.png-stairs_split_2_1710453793579.png: 190 --> 110 matches\nskipped key1=stairs_split_2_1710453790978.png, key2=stairs_split_2_1710453798181.png: mkpts.shape=(13, 4) after filtered.\nfilter_FundamentalMatrix: 58 matches --> 18 matches\nstairs_split_2_1710453790978.png-stairs_split_2_1710453801783.png: 58 --> 18 matches\nfilter_FundamentalMatrix: 61 matches --> 22 matches\nstairs_split_2_1710453790978.png-stairs_split_2_1710453805788.png: 61 --> 22 matches\nfilter_FundamentalMatrix: 67 matches --> 21 matches\nstairs_split_2_1710453790978.png-stairs_split_2_1710453871430.png: 67 --> 21 matches\nfilter_FundamentalMatrix: 69 matches --> 19 matches\nstairs_split_2_1710453793579.png-stairs_split_2_1710453798181.png: 69 --> 19 matches\nskipped key1=stairs_split_2_1710453793579.png, key2=stairs_split_2_1710453805788.png: mkpts.shape=(13, 4) after filtered.\nfilter_FundamentalMatrix: 67 matches --> 25 matches\nstairs_split_2_1710453793579.png-stairs_split_2_1710453862225.png: 67 --> 25 matches\nfilter_FundamentalMatrix: 65 matches --> 17 matches\nstairs_split_2_1710453798181.png-stairs_split_2_1710453801783.png: 65 --> 17 matches\nfilter_FundamentalMatrix: 57 matches --> 16 matches\nstairs_split_2_1710453798181.png-stairs_split_2_1710453862225.png: 57 --> 16 matches\nfilter_FundamentalMatrix: 281 matches --> 120 matches\nstairs_split_2_1710453805788.png-stairs_split_2_1710453871430.png: 281 --> 120 matches\nEnsembled pairs : 253 pairs\nLocal feature extracting and matching. Done in 163.4789 sec\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 49/49 [00:02<00:00, 21.36it/s]\n 28%|██▊       | 253/903 [00:00<00:00, 4947.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"colmap database\nmatching done!!!!\nRANSAC in 3.1242 sec\n{0: Reconstruction(num_reg_images=16, num_cameras=16, num_points3D=2224, num_observations=6530), 1: Reconstruction(num_reg_images=5, num_cameras=5, num_points3D=1130, num_observations=2566)}\nReconstruction done in 29.4026 sec\nDataset  stairs -> Registered 21 / 51 images with 2 clusters\n\nResults\nDataset  ETs -> Registered 19 / 22 images with 2 clusters\nDataset \"amy_gardens\" -> Failed!\nDataset \"fbk_vineyard\" -> Failed!\nDataset \"imc2023_haiper\" -> Failed!\nDataset \"imc2023_heritage\" -> Failed!\nDataset \"imc2023_theather_imc2024_church\" -> Failed!\nDataset \"imc2024_dioscuri_baalshamin\" -> Failed!\nDataset \"imc2024_lizard_pond\" -> Failed!\nDataset \"pt_brandenburg_british_buckingham\" -> Failed!\nDataset \"pt_piazzasanmarco_grandplace\" -> Failed!\nDataset \"pt_sacrecoeur_trevi_tajmahal\" -> Failed!\nDataset \"pt_stpeters_stpauls\" -> Failed!\nDataset  stairs -> Registered 21 / 51 images with 2 clusters\n\nTimings\nrotation_detection -> total=0.00 sec.\nglobal feature extraction -> total=0.00 sec.\nshortlisting -> total=26.53 sec.\nfeature_detection -> total=0.00 sec.\nfeature_matching -> total=149.50 sec.\nRANSAC -> total=6.17 sec.\nReconstruction -> total=58.37 sec.\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# Helpers\narray_to_str = lambda array: ';'.join([f\"{x:.09f}\" for x in array])\nnone_to_str = lambda n: ';'.join(['nan'] * n)\n\nsubmission_file = '/kaggle/working/submission.csv'\nwith open(submission_file, 'w') as f:\n    if is_train:\n        f.write('dataset,scene,image,rotation_matrix,translation_vector\\n')\n        for dataset, predictions in samples.items():\n            for prediction in predictions:\n                cluster_name = 'outliers' if prediction.cluster_index is None else f'cluster{prediction.cluster_index}'\n\n                # ✅ `rotation` is a list of lists, flatten it\n                if prediction.rotation is None:\n                    rotation_str = none_to_str(9)\n                else:\n                    rotation_flat =  prediction.rotation.flatten()  # flatten 3x3 list -> 9 elems\n                    rotation_str = array_to_str(rotation_flat)\n\n                # ✅ `translation` is a flat list\n                if prediction.translation is None:\n                    translation_str = none_to_str(3)\n                else:\n                    translation_str = array_to_str(prediction.translation)\n\n                f.write(f'{prediction.dataset},{cluster_name},{prediction.filename},{rotation_str},{translation_str}\\n')\n    else:\n        f.write('image_id,dataset,scene,image,rotation_matrix,translation_vector\\n')\n        for dataset, predictions in samples.items():\n            for prediction in predictions:\n                cluster_name = 'outliers' if prediction.cluster_index is None else f'cluster{prediction.cluster_index}'\n\n                if prediction.rotation is None:\n                    rotation_str = none_to_str(9)\n                else:\n                    rotation_flat =  prediction.rotation.flatten()\n                    rotation_str = array_to_str(rotation_flat)\n\n                if prediction.translation is None:\n                    translation_str = none_to_str(3)\n                else:\n                    translation_str = array_to_str(prediction.translation)\n\n                f.write(f'{prediction.image_id},{prediction.dataset},{cluster_name},{prediction.filename},{rotation_str},{translation_str}\\n')\n\n# Preview the output\n!head {submission_file}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T19:02:59.704565Z","iopub.execute_input":"2025-05-29T19:02:59.704855Z","iopub.status.idle":"2025-05-29T19:02:59.877380Z","shell.execute_reply.started":"2025-05-29T19:02:59.704824Z","shell.execute_reply":"2025-05-29T19:02:59.876587Z"}},"outputs":[{"name":"stdout","text":"image_id,dataset,scene,image,rotation_matrix,translation_vector\nETs_another_et_another_et001.png_public,ETs,cluster1,another_et_another_et001.png,0.999900499;-0.004546591;0.013353670;0.004253223;0.999750770;0.021915910;-0.013449984;-0.021856934;0.999670632,-2.821980485;-1.954635645;2.691259529\nETs_another_et_another_et002.png_public,ETs,cluster1,another_et_another_et002.png,0.999996654;-0.002155317;-0.001430684;0.002152769;0.999996099;-0.001779683;0.001434514;0.001776597;0.999997393,-2.667183325;-1.174095968;1.161646146\nETs_another_et_another_et003.png_public,ETs,cluster1,another_et_another_et003.png,0.997924649;-0.041558941;0.049185869;0.044471566;0.997226206;-0.059683953;-0.046569036;0.061747461;0.997004802,-2.871951493;0.330101107;-0.586747551\nETs_another_et_another_et004.png_public,ETs,cluster1,another_et_another_et004.png,0.999313788;-0.011406743;0.035239727;0.006694985;0.991354761;0.131037835;-0.036429786;-0.130711986;0.990750850,-2.780167230;-1.443021207;-0.139345265\nETs_another_et_another_et005.png_public,ETs,cluster1,another_et_another_et005.png,0.995490898;0.002359050;0.094827778;-0.008519966;0.997873747;0.064617295;-0.094473715;-0.065133858;0.993394331,-3.306334827;-2.132141260;1.288168271\nETs_another_et_another_et006.png_public,ETs,cluster1,another_et_another_et006.png,0.920561916;0.194961756;-0.338460739;-0.220600100;0.974600041;-0.038605115;0.322337329;0.110202872;0.940188265,-0.596644361;-0.733861177;1.035569668\nETs_another_et_another_et007.png_public,ETs,cluster1,another_et_another_et007.png,0.782398857;0.266561201;-0.562847363;-0.312317048;0.949848199;0.015699062;0.538804315;0.163503899;0.826411753,1.099085061;-0.441275103;0.576884466\nETs_another_et_another_et008.png_public,ETs,cluster1,another_et_another_et008.png,0.570673045;0.314198720;-0.758690609;-0.395374738;0.914897423;0.081495530;0.719729874;0.253459799;0.646333535,2.793856456;-0.762657767;1.368296157\nETs_another_et_another_et009.png_public,ETs,cluster1,another_et_another_et009.png,0.320853822;0.349754743;-0.880184324;-0.492250874;0.855525424;0.160515811;0.809161233;0.381769392;0.446665680,4.451477969;-1.086274709;2.015268050\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# Definitely Compute results if running on the training set.\n# Do not do this when submitting a notebook for scoring. All you have to do is save your submission to /kaggle/working/submission.csv.\n\nif is_train:\n    t = time()\n    final_score, dataset_scores = metric.score(\n        gt_csv='/kaggle/input/image-matching-challenge-2025/train_labels.csv',\n        user_csv=submission_file,\n        thresholds_csv='/kaggle/input/image-matching-challenge-2025/train_thresholds.csv',\n        mask_csv=None if is_train else os.path.join(data_dir, 'mask.csv'),\n        inl_cf=0,\n        strict_cf=-1,\n        verbose=True,\n    )\n    print(f'Computed metric in: {time() - t:.02f} sec.')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T19:02:59.878398Z","iopub.execute_input":"2025-05-29T19:02:59.878751Z","iopub.status.idle":"2025-05-29T19:02:59.883646Z","shell.execute_reply.started":"2025-05-29T19:02:59.878713Z","shell.execute_reply":"2025-05-29T19:02:59.882648Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}