{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7483c44f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-06T06:02:45.788291Z",
     "iopub.status.busy": "2025-06-06T06:02:45.787577Z",
     "iopub.status.idle": "2025-06-06T06:02:47.464004Z",
     "shell.execute_reply": "2025-06-06T06:02:47.463451Z"
    },
    "papermill": {
     "duration": 1.682025,
     "end_time": "2025-06-06T06:02:47.465396",
     "exception": false,
     "start_time": "2025-06-06T06:02:45.783371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a443183",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T06:02:47.471645Z",
     "iopub.status.busy": "2025-06-06T06:02:47.471348Z",
     "iopub.status.idle": "2025-06-06T06:02:47.474298Z",
     "shell.execute_reply": "2025-06-06T06:02:47.473806Z"
    },
    "papermill": {
     "duration": 0.007041,
     "end_time": "2025-06-06T06:02:47.475333",
     "exception": false,
     "start_time": "2025-06-06T06:02:47.468292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! uv pip install --system jaxtyping rerun-sdk[notebook]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7eb05e",
   "metadata": {
    "papermill": {
     "duration": 0.002202,
     "end_time": "2025-06-06T06:02:47.480161",
     "exception": false,
     "start_time": "2025-06-06T06:02:47.477959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "155afb07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T06:02:47.485517Z",
     "iopub.status.busy": "2025-06-06T06:02:47.485321Z",
     "iopub.status.idle": "2025-06-06T06:02:47.488057Z",
     "shell.execute_reply": "2025-06-06T06:02:47.487565Z"
    },
    "papermill": {
     "duration": 0.006537,
     "end_time": "2025-06-06T06:02:47.489009",
     "exception": false,
     "start_time": "2025-06-06T06:02:47.482472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !dpkg -i --force-depends /kaggle/input/colmap-offline-installer/archives/*.deb >/dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19ebf55a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T06:02:47.494603Z",
     "iopub.status.busy": "2025-06-06T06:02:47.494199Z",
     "iopub.status.idle": "2025-06-06T06:02:47.616253Z",
     "shell.execute_reply": "2025-06-06T06:02:47.615490Z"
    },
    "papermill": {
     "duration": 0.126108,
     "end_time": "2025-06-06T06:02:47.617515",
     "exception": false,
     "start_time": "2025-06-06T06:02:47.491407",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf /kaggle/working/mast3r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "211c81a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T06:02:47.623707Z",
     "iopub.status.busy": "2025-06-06T06:02:47.623028Z",
     "iopub.status.idle": "2025-06-06T06:02:49.538832Z",
     "shell.execute_reply": "2025-06-06T06:02:49.538128Z"
    },
    "papermill": {
     "duration": 1.920183,
     "end_time": "2025-06-06T06:02:49.540182",
     "exception": false,
     "start_time": "2025-06-06T06:02:47.619999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n",
      "Cloning into 'mast3r'...\r\n",
      "remote: Enumerating objects: 248, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (181/181), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (78/78), done.\u001b[K\r\n",
      "remote: Total 248 (delta 129), reused 103 (delta 103), pack-reused 67 (from 1)\u001b[K\r\n",
      "Receiving objects: 100% (248/248), 3.58 MiB | 21.34 MiB/s, done.\r\n",
      "Resolving deltas: 100% (135/135), done.\r\n",
      "Submodule 'dust3r' (https://github.com/naver/dust3r) registered for path 'dust3r'\r\n",
      "Cloning into '/kaggle/working/mast3r/dust3r'...\r\n",
      "remote: Enumerating objects: 559, done.        \r\n",
      "remote: Counting objects: 100% (411/411), done.        \r\n",
      "remote: Compressing objects: 100% (213/213), done.        \r\n",
      "remote: Total 559 (delta 298), reused 199 (delta 198), pack-reused 148 (from 2)        \r\n",
      "Receiving objects: 100% (559/559), 735.09 KiB | 7.50 MiB/s, done.\r\n",
      "Resolving deltas: 100% (324/324), done.\r\n",
      "Submodule path 'dust3r': checked out 'c9e9336a6ba7c1f1873f9295852cea6dffaf770d'\r\n",
      "Submodule 'croco' (https://github.com/naver/croco) registered for path 'dust3r/croco'\r\n",
      "Cloning into '/kaggle/working/mast3r/dust3r/croco'...\r\n",
      "remote: Enumerating objects: 131, done.        \r\n",
      "remote: Counting objects: 100% (51/51), done.        \r\n",
      "remote: Compressing objects: 100% (24/24), done.        \r\n",
      "remote: Total 131 (delta 34), reused 27 (delta 27), pack-reused 80 (from 1)        \r\n",
      "Receiving objects: 100% (131/131), 385.58 KiB | 4.10 MiB/s, done.\r\n",
      "Resolving deltas: 100% (56/56), done.\r\n",
      "Submodule path 'dust3r/croco': checked out '743ee71a2a9bf57cea6832a9064a70a0597fcfcb'\r\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working\n",
    "!git clone --recursive https://github.com/naver/mast3r\n",
    "# cd mast3r\n",
    "# if you have already cloned mast3r:\n",
    "# git submodule update --init --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d42d0b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T06:02:49.549542Z",
     "iopub.status.busy": "2025-06-06T06:02:49.549050Z",
     "iopub.status.idle": "2025-06-06T06:06:15.378924Z",
     "shell.execute_reply": "2025-06-06T06:06:15.377726Z"
    },
    "papermill": {
     "duration": 205.835945,
     "end_time": "2025-06-06T06:06:15.380588",
     "exception": false,
     "start_time": "2025-06-06T06:02:49.544643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/mast3r\n",
      "\u001b[31mERROR: Ignored the following yanked versions: 3.27.4, 3.28.0, 3.29.0, 3.29.1, 3.31.0\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement cmake==3.14.0 (from versions: 0.1.0, 0.2.0, 0.4.0, 0.5.0, 0.6.0, 0.7.0, 0.7.1, 0.8.0, 0.9.0, 3.6.3, 3.6.3.post1, 3.7.2, 3.8.2, 3.9.6, 3.10.3, 3.11.0, 3.11.4, 3.11.4.post1, 3.12.0, 3.13.0, 3.13.1, 3.13.2, 3.13.2.post1, 3.14.3, 3.14.3.post1, 3.14.4, 3.14.4.post1, 3.15.3, 3.15.3.post1, 3.16.3, 3.16.3.post1, 3.16.5, 3.16.6, 3.16.7, 3.16.8, 3.17.0, 3.17.1, 3.17.2, 3.17.3, 3.18.0, 3.18.2, 3.18.2.post1, 3.18.4, 3.18.4.post1, 3.20.2, 3.20.3, 3.20.4, 3.20.5, 3.21.0, 3.21.1, 3.21.1.post1, 3.21.2, 3.21.3, 3.21.4, 3.22.0, 3.22.1, 3.22.2, 3.22.3, 3.22.4, 3.22.5, 3.22.6, 3.23.3, 3.24.0, 3.24.1, 3.24.1.1, 3.24.2, 3.24.3, 3.25.0, 3.25.2, 3.26.0, 3.26.1, 3.26.3, 3.26.4, 3.27.0, 3.27.1, 3.27.2, 3.27.4.1, 3.27.5, 3.27.6, 3.27.7, 3.27.9, 3.28.1, 3.28.3, 3.28.4, 3.29.0.1, 3.29.2, 3.29.3, 3.29.5, 3.29.5.1, 3.29.6, 3.30.0, 3.30.1, 3.30.2, 3.30.3, 3.30.4, 3.30.5, 3.31.0.1, 3.31.1, 3.31.2, 3.31.4, 3.31.6, 4.0.0, 4.0.2)\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for cmake==3.14.0\u001b[0m\u001b[31m\r\n",
      "\u001b[0mLooking in indexes: https://download.pytorch.org/whl/cu121\r\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\r\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\r\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\r\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\r\n",
      "Collecting torch\r\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torch-2.5.1%2Bcu121-cp311-cp311-linux_x86_64.whl (780.5 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.5/780.5 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\r\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m522.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting triton==3.1.0 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.9.41)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\r\n",
      "Collecting torchvision\r\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp311-cp311-linux_x86_64.whl (7.3 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\r\n",
      "Collecting torchaudio\r\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp311-cp311-linux_x86_64.whl (3.4 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2025.1.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2022.1.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2022.1.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.3.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision) (2024.2.0)\r\n",
      "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchaudio, torchvision\r\n",
      "  Attempting uninstall: triton\r\n",
      "    Found existing installation: triton 3.2.0\r\n",
      "    Uninstalling triton-3.2.0:\r\n",
      "      Successfully uninstalled triton-3.2.0\r\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\r\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.4.127\r\n",
      "    Uninstalling nvidia-nvtx-cu12-12.4.127:\r\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.10.19\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.10.19:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.4.0.6\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.4.0.6:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\r\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\r\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\r\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\r\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\r\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\r\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\r\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\r\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\r\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\r\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\r\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\r\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.9.0.13\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.9.0.13:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 2.6.0+cu124\r\n",
      "    Uninstalling torch-2.6.0+cu124:\r\n",
      "      Successfully uninstalled torch-2.6.0+cu124\r\n",
      "  Attempting uninstall: torchaudio\r\n",
      "    Found existing installation: torchaudio 2.6.0+cu124\r\n",
      "    Uninstalling torchaudio-2.6.0+cu124:\r\n",
      "      Successfully uninstalled torchaudio-2.6.0+cu124\r\n",
      "  Attempting uninstall: torchvision\r\n",
      "    Found existing installation: torchvision 0.21.0+cu124\r\n",
      "    Uninstalling torchvision-0.21.0+cu124:\r\n",
      "      Successfully uninstalled torchvision-0.21.0+cu124\r\n",
      "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nvtx-cu12-12.1.105 torch-2.5.1+cu121 torchaudio-2.5.1+cu121 torchvision-0.20.1+cu121 triton-3.1.0\r\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/mast3r\n",
    "\n",
    "# Install specific Python packages (Kaggle default Python version is ~3.10)\n",
    "!pip install cmake==3.14.0 --quiet\n",
    "\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24adefa",
   "metadata": {
    "papermill": {
     "duration": 0.077516,
     "end_time": "2025-06-06T06:06:15.536362",
     "exception": false,
     "start_time": "2025-06-06T06:06:15.458846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c6fb1f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T06:06:15.693390Z",
     "iopub.status.busy": "2025-06-06T06:06:15.692308Z",
     "iopub.status.idle": "2025-06-06T06:06:45.291971Z",
     "shell.execute_reply": "2025-06-06T06:06:45.290993Z"
    },
    "papermill": {
     "duration": 29.680514,
     "end_time": "2025-06-06T06:06:45.293486",
     "exception": false,
     "start_time": "2025-06-06T06:06:15.612972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.2/54.2 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.3/323.3 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m711.7/711.7 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m105.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m106.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.1/281.1 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.3/159.3 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.0/199.0 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m100.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Building wheel for PyOpenGL (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n"
     ]
    }
   ],
   "source": [
    "# Install your main and optional requirements\n",
    "!pip install -r requirements.txt --quiet\n",
    "!pip install -r dust3r/requirements.txt --quiet\n",
    "!pip install -r dust3r/requirements_optional.txt --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3e23e2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T06:06:45.448165Z",
     "iopub.status.busy": "2025-06-06T06:06:45.447223Z",
     "iopub.status.idle": "2025-06-06T06:06:48.458832Z",
     "shell.execute_reply": "2025-06-06T06:06:48.458086Z"
    },
    "papermill": {
     "duration": 3.089771,
     "end_time": "2025-06-06T06:06:48.460683",
     "exception": false,
     "start_time": "2025-06-06T06:06:45.370912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cython in /usr/local/lib/python3.11/dist-packages (3.0.12)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b41e941",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T06:06:48.612045Z",
     "iopub.status.busy": "2025-06-06T06:06:48.611783Z",
     "iopub.status.idle": "2025-06-06T06:07:04.757985Z",
     "shell.execute_reply": "2025-06-06T06:07:04.757117Z"
    },
    "papermill": {
     "duration": 16.222822,
     "end_time": "2025-06-06T06:07:04.759281",
     "exception": false,
     "start_time": "2025-06-06T06:06:48.536459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n",
      "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "build-essential is already the newest version (12.9ubuntu3).\r\n",
      "0 upgraded, 0 newly installed, 0 to remove and 181 not upgraded.\r\n",
      "Cloning into 'asmk'...\r\n",
      "remote: Enumerating objects: 138, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (138/138), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (75/75), done.\u001b[K\r\n",
      "remote: Total 138 (delta 78), reused 117 (delta 59), pack-reused 0 (from 0)\u001b[K\r\n",
      "Receiving objects: 100% (138/138), 152.04 KiB | 2.82 MiB/s, done.\r\n",
      "Resolving deltas: 100% (78/78), done.\r\n",
      "/kaggle/working/asmk/cython\n",
      "Compiling /kaggle/working/asmk/cython/hamming.pyx because it changed.\r\n",
      "[1/1] Cythonizing /kaggle/working/asmk/cython/hamming.pyx\r\n",
      "/kaggle/working/asmk\n",
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "# 1. 确保在 /kaggle/working 目录下\n",
    "%cd /kaggle/working\n",
    "\n",
    "# 2. 更新包列表并安装 build-essential (虽然您已经有了，但安全起见)\n",
    "!apt-get update -qq\n",
    "!apt-get install -y build-essential\n",
    "\n",
    "# 3. 重新克隆 asmk (以防万一，如果确定目录干净可以跳过)\n",
    "!rm -rf asmk\n",
    "!git clone https://github.com/jenicek/asmk\n",
    "\n",
    "# 4. 进入 asmk 的 cython 目录并 Cythonize\n",
    "%cd asmk/cython/\n",
    "!cythonize *.pyx\n",
    "\n",
    "# 5. 返回 asmk 根目录\n",
    "%cd ..\n",
    "\n",
    "# 6. 再次尝试安装 asmk 包\n",
    "!python3 setup.py build_ext --inplace \n",
    "\n",
    "# 7. 返回 /kaggle/working 目录 (可选)\n",
    "%cd ..\n",
    "\n",
    "# print(\"asmk installed successfully, hopefully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b26e87ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T06:07:04.913194Z",
     "iopub.status.busy": "2025-06-06T06:07:04.912929Z",
     "iopub.status.idle": "2025-06-06T06:10:09.177556Z",
     "shell.execute_reply": "2025-06-06T06:10:09.176686Z"
    },
    "papermill": {
     "duration": 184.341653,
     "end_time": "2025-06-06T06:10:09.178965",
     "exception": false,
     "start_time": "2025-06-06T06:07:04.837312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/mast3r/dust3r/croco/models/curope\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:416: UserWarning: The detected CUDA version (12.5) has a minor version mismatch with the version that was used to compile PyTorch (12.1). Most likely this shouldn't be a problem.\r\n",
      "  warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\r\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:426: UserWarning: There are no x86_64-linux-gnu-g++ version bounds defined for CUDA version 12.5\r\n",
      "  warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')\r\n",
      "Emitting ninja build file /kaggle/working/mast3r/dust3r/croco/models/curope/build/temp.linux-x86_64-cpython-311/build.ninja...\r\n",
      "Compiling objects...\r\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\r\n",
      "[1/2] c++ -MMD -MF /kaggle/working/mast3r/dust3r/croco/models/curope/build/temp.linux-x86_64-cpython-311/curope.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /kaggle/working/mast3r/dust3r/croco/models/curope/curope.cpp -o /kaggle/working/mast3r/dust3r/croco/models/curope/build/temp.linux-x86_64-cpython-311/curope.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=curope -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\r\n",
      "[2/2] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /kaggle/working/mast3r/dust3r/croco/models/curope/build/temp.linux-x86_64-cpython-311/kernels.o.d -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /kaggle/working/mast3r/dust3r/croco/models/curope/kernels.cu -o /kaggle/working/mast3r/dust3r/croco/models/curope/build/temp.linux-x86_64-cpython-311/kernels.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 --ptxas-options=-v --use_fast_math -gencode arch=compute_50,code=sm_50 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_90,code=sm_90 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=curope -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\r\n",
      "ptxas info    : 6 bytes gmem, 48 bytes cmem[4]\r\n",
      "ptxas info    : Compiling entry function '_Z19rope_2d_cuda_kernelIN3c104HalfEEvN2at27GenericPackedTensorAccessorIT_Lm4ENS2_17RestrictPtrTraitsEiEEPKlff' for 'sm_50'\r\n",
      "ptxas info    : Function properties for _Z19rope_2d_cuda_kernelIN3c104HalfEEvN2at27GenericPackedTensorAccessorIT_Lm4ENS2_17RestrictPtrTraitsEiEEPKlff\r\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\r\n",
      "ptxas info    : Used 28 registers, 376 bytes cmem[0]\r\n",
      "ptxas info    : Compiling entry function '_Z19rope_2d_cuda_kernelIfEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff' for 'sm_50'\r\n",
      "ptxas info    : Function properties for _Z19rope_2d_cuda_kernelIfEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff\r\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\r\n",
      "ptxas info    : Used 29 registers, 376 bytes cmem[0]\r\n",
      "ptxas info    : Compiling entry function '_Z19rope_2d_cuda_kernelIdEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff' for 'sm_50'\r\n",
      "ptxas info    : Function properties for _Z19rope_2d_cuda_kernelIdEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff\r\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\r\n",
      "ptxas info    : Used 30 registers, 376 bytes cmem[0], 8 bytes cmem[2]\r\n",
      "ptxas info    : 6 bytes gmem, 48 bytes cmem[4]\r\n",
      "ptxas info    : Compiling entry function '_Z19rope_2d_cuda_kernelIN3c104HalfEEvN2at27GenericPackedTensorAccessorIT_Lm4ENS2_17RestrictPtrTraitsEiEEPKlff' for 'sm_60'\r\n",
      "ptxas info    : Function properties for _Z19rope_2d_cuda_kernelIN3c104HalfEEvN2at27GenericPackedTensorAccessorIT_Lm4ENS2_17RestrictPtrTraitsEiEEPKlff\r\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\r\n",
      "ptxas info    : Used 28 registers, 376 bytes cmem[0]\r\n",
      "ptxas info    : Compiling entry function '_Z19rope_2d_cuda_kernelIfEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff' for 'sm_60'\r\n",
      "ptxas info    : Function properties for _Z19rope_2d_cuda_kernelIfEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff\r\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\r\n",
      "ptxas info    : Used 29 registers, 376 bytes cmem[0]\r\n",
      "ptxas info    : Compiling entry function '_Z19rope_2d_cuda_kernelIdEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff' for 'sm_60'\r\n",
      "ptxas info    : Function properties for _Z19rope_2d_cuda_kernelIdEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff\r\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\r\n",
      "ptxas info    : Used 28 registers, 376 bytes cmem[0], 8 bytes cmem[2]\r\n",
      "ptxas info    : 6 bytes gmem, 48 bytes cmem[4]\r\n",
      "ptxas info    : Compiling entry function '_Z19rope_2d_cuda_kernelIN3c104HalfEEvN2at27GenericPackedTensorAccessorIT_Lm4ENS2_17RestrictPtrTraitsEiEEPKlff' for 'sm_70'\r\n",
      "ptxas info    : Function properties for _Z19rope_2d_cuda_kernelIN3c104HalfEEvN2at27GenericPackedTensorAccessorIT_Lm4ENS2_17RestrictPtrTraitsEiEEPKlff\r\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\r\n",
      "ptxas info    : Used 30 registers, 408 bytes cmem[0]\r\n",
      "ptxas info    : Compiling entry function '_Z19rope_2d_cuda_kernelIfEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff' for 'sm_70'\r\n",
      "ptxas info    : Function properties for _Z19rope_2d_cuda_kernelIfEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff\r\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\r\n",
      "ptxas info    : Used 32 registers, 408 bytes cmem[0]\r\n",
      "ptxas info    : Compiling entry function '_Z19rope_2d_cuda_kernelIdEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff' for 'sm_70'\r\n",
      "ptxas info    : Function properties for _Z19rope_2d_cuda_kernelIdEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff\r\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\r\n",
      "ptxas info    : Used 30 registers, 408 bytes cmem[0], 8 bytes cmem[2]\r\n",
      "ptxas info    : 6 bytes gmem, 48 bytes cmem[4]\r\n",
      "ptxas info    : Compiling entry function '_Z19rope_2d_cuda_kernelIN3c104HalfEEvN2at27GenericPackedTensorAccessorIT_Lm4ENS2_17RestrictPtrTraitsEiEEPKlff' for 'sm_75'\r\n",
      "ptxas info    : Function properties for _Z19rope_2d_cuda_kernelIN3c104HalfEEvN2at27GenericPackedTensorAccessorIT_Lm4ENS2_17RestrictPtrTraitsEiEEPKlff\r\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\r\n",
      "ptxas info    : Used 32 registers, 408 bytes cmem[0]\r\n",
      "ptxas info    : Compiling entry function '_Z19rope_2d_cuda_kernelIfEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff' for 'sm_75'\r\n",
      "ptxas info    : Function properties for _Z19rope_2d_cuda_kernelIfEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff\r\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\r\n",
      "ptxas info    : Used 30 registers, 408 bytes cmem[0]\r\n",
      "ptxas info    : Compiling entry function '_Z19rope_2d_cuda_kernelIdEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff' for 'sm_75'\r\n",
      "ptxas info    : Function properties for _Z19rope_2d_cuda_kernelIdEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff\r\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\r\n",
      "ptxas info    : Used 32 registers, 408 bytes cmem[0], 8 bytes cmem[2]\r\n",
      "ptxas info    : 6 bytes gmem, 48 bytes cmem[4]\r\n",
      "ptxas info    : Compiling entry function '_Z19rope_2d_cuda_kernelIN3c104HalfEEvN2at27GenericPackedTensorAccessorIT_Lm4ENS2_17RestrictPtrTraitsEiEEPKlff' for 'sm_80'\r\n",
      "ptxas info    : Function properties for _Z19rope_2d_cuda_kernelIN3c104HalfEEvN2at27GenericPackedTensorAccessorIT_Lm4ENS2_17RestrictPtrTraitsEiEEPKlff\r\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\r\n",
      "ptxas info    : Used 26 registers, 408 bytes cmem[0]\r\n",
      "ptxas info    : Compiling entry function '_Z19rope_2d_cuda_kernelIfEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff' for 'sm_80'\r\n",
      "ptxas info    : Function properties for _Z19rope_2d_cuda_kernelIfEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff\r\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\r\n",
      "ptxas info    : Used 30 registers, 408 bytes cmem[0]\r\n",
      "ptxas info    : Compiling entry function '_Z19rope_2d_cuda_kernelIdEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff' for 'sm_80'\r\n",
      "ptxas info    : Function properties for _Z19rope_2d_cuda_kernelIdEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff\r\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\r\n",
      "ptxas info    : Used 30 registers, 408 bytes cmem[0], 8 bytes cmem[2]\r\n",
      "ptxas info    : 6 bytes gmem, 48 bytes cmem[4]\r\n",
      "ptxas info    : Compiling entry function '_Z19rope_2d_cuda_kernelIN3c104HalfEEvN2at27GenericPackedTensorAccessorIT_Lm4ENS2_17RestrictPtrTraitsEiEEPKlff' for 'sm_86'\r\n",
      "ptxas info    : Function properties for _Z19rope_2d_cuda_kernelIN3c104HalfEEvN2at27GenericPackedTensorAccessorIT_Lm4ENS2_17RestrictPtrTraitsEiEEPKlff\r\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\r\n",
      "ptxas info    : Used 27 registers, 408 bytes cmem[0]\r\n",
      "ptxas info    : Compiling entry function '_Z19rope_2d_cuda_kernelIfEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff' for 'sm_86'\r\n",
      "ptxas info    : Function properties for _Z19rope_2d_cuda_kernelIfEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff\r\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\r\n",
      "ptxas info    : Used 30 registers, 408 bytes cmem[0]\r\n",
      "ptxas info    : Compiling entry function '_Z19rope_2d_cuda_kernelIdEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff' for 'sm_86'\r\n",
      "ptxas info    : Function properties for _Z19rope_2d_cuda_kernelIdEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff\r\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\r\n",
      "ptxas info    : Used 32 registers, 408 bytes cmem[0], 8 bytes cmem[2]\r\n",
      "ptxas info    : 6 bytes gmem\r\n",
      "ptxas info    : Compiling entry function '_Z19rope_2d_cuda_kernelIN3c104HalfEEvN2at27GenericPackedTensorAccessorIT_Lm4ENS2_17RestrictPtrTraitsEiEEPKlff' for 'sm_90'\r\n",
      "ptxas info    : Function properties for _Z19rope_2d_cuda_kernelIN3c104HalfEEvN2at27GenericPackedTensorAccessorIT_Lm4ENS2_17RestrictPtrTraitsEiEEPKlff\r\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\r\n",
      "ptxas info    : Used 26 registers\r\n",
      "ptxas info    : Compiling entry function '_Z19rope_2d_cuda_kernelIfEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff' for 'sm_90'\r\n",
      "ptxas info    : Function properties for _Z19rope_2d_cuda_kernelIfEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff\r\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\r\n",
      "ptxas info    : Used 32 registers\r\n",
      "ptxas info    : Compiling entry function '_Z19rope_2d_cuda_kernelIdEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff' for 'sm_90'\r\n",
      "ptxas info    : Function properties for _Z19rope_2d_cuda_kernelIdEvN2at27GenericPackedTensorAccessorIT_Lm4ENS0_17RestrictPtrTraitsEiEEPKlff\r\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\r\n",
      "ptxas info    : Used 30 registers\r\n",
      "/kaggle/working/mast3r/dust3r/croco/models/curope/kernels.cu: In lambda function:\r\n",
      "/kaggle/working/mast3r/dust3r/croco/models/curope/kernels.cu:101:43: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\r\n",
      "  101 |     AT_DISPATCH_FLOATING_TYPES_AND_HALF(tokens.type(), \"rope_2d_cuda\", ([&] {\r\n",
      "      |                              ~~~~~~~~~~~~~^~\r\n",
      "/usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/TensorBody.h:225:1: note: declared here\r\n",
      "  225 |   DeprecatedTypeProperties & type() const {\r\n",
      "      | ^ ~~\r\n",
      "/kaggle/working/mast3r/dust3r/croco/models/curope/kernels.cu:101:149: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\r\n",
      "  101 |     AT_DISPATCH_FLOATING_TYPES_AND_HALF(tokens.type(), \"rope_2d_cuda\", ([&] {\r\n",
      "      |                                                                                                                                                     ^         \r\n",
      "/usr/local/lib/python3.11/dist-packages/torch/include/ATen/Dispatch.h:109:1: note: declared here\r\n",
      "  109 | inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\r\n",
      "      | ^~~~~~~~~~~\r\n",
      "/kaggle/working/mast3r\n"
     ]
    }
   ],
   "source": [
    "# DUST3R relies on RoPE positional embeddings for which you can compile some cuda kernels for faster runtime.\n",
    "%cd /kaggle/working/mast3r/dust3r/croco/models/curope/\n",
    "!python setup.py build_ext --inplace\n",
    "%cd ../../../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee8f5875",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T06:10:09.331029Z",
     "iopub.status.busy": "2025-06-06T06:10:09.330743Z",
     "iopub.status.idle": "2025-06-06T06:11:59.813531Z",
     "shell.execute_reply": "2025-06-06T06:11:59.812777Z"
    },
    "papermill": {
     "duration": 110.560011,
     "end_time": "2025-06-06T06:11:59.815163",
     "exception": false,
     "start_time": "2025-06-06T06:10:09.255152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/mast3r\n",
      "--2025-06-06 06:10:09--  https://download.europe.naverlabs.com/ComputerVision/MASt3R/MASt3R_ViTLarge_BaseDecoder_512_catmlpdpt_metric.pth\r\n",
      "Resolving download.europe.naverlabs.com (download.europe.naverlabs.com)... 110.234.56.25\r\n",
      "Connecting to download.europe.naverlabs.com (download.europe.naverlabs.com)|110.234.56.25|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 2754910614 (2.6G)\r\n",
      "Saving to: ‘checkpoints/MASt3R_ViTLarge_BaseDecoder_512_catmlpdpt_metric.pth’\r\n",
      "\r\n",
      "MASt3R_ViTLarge_Bas 100%[===================>]   2.57G  24.8MB/s    in 1m 50s  \r\n",
      "\r\n",
      "2025-06-06 06:11:59 (23.9 MB/s) - ‘checkpoints/MASt3R_ViTLarge_BaseDecoder_512_catmlpdpt_metric.pth’ saved [2754910614/2754910614]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/mast3r\n",
    "!mkdir -p checkpoints/\n",
    "!wget https://download.europe.naverlabs.com/ComputerVision/MASt3R/MASt3R_ViTLarge_BaseDecoder_512_catmlpdpt_metric.pth -P checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37ddc362",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T06:12:00.006471Z",
     "iopub.status.busy": "2025-06-06T06:12:00.006202Z",
     "iopub.status.idle": "2025-06-06T06:12:12.694493Z",
     "shell.execute_reply": "2025-06-06T06:12:12.693592Z"
    },
    "papermill": {
     "duration": 12.783907,
     "end_time": "2025-06-06T06:12:12.695896",
     "exception": false,
     "start_time": "2025-06-06T06:11:59.911989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/mast3r\n",
      "--2025-06-06 06:12:00--  https://download.europe.naverlabs.com/ComputerVision/MASt3R/MASt3R_ViTLarge_BaseDecoder_512_catmlpdpt_metric_retrieval_trainingfree.pth\r\n",
      "Resolving download.europe.naverlabs.com (download.europe.naverlabs.com)... 110.234.56.25\r\n",
      "Connecting to download.europe.naverlabs.com (download.europe.naverlabs.com)|110.234.56.25|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 8399111 (8.0M)\r\n",
      "Saving to: ‘checkpoints/MASt3R_ViTLarge_BaseDecoder_512_catmlpdpt_metric_retrieval_trainingfree.pth’\r\n",
      "\r\n",
      "MASt3R_ViTLarge_Bas 100%[===================>]   8.01M  7.25MB/s    in 1.1s    \r\n",
      "\r\n",
      "2025-06-06 06:12:01 (7.25 MB/s) - ‘checkpoints/MASt3R_ViTLarge_BaseDecoder_512_catmlpdpt_metric_retrieval_trainingfree.pth’ saved [8399111/8399111]\r\n",
      "\r\n",
      "--2025-06-06 06:12:01--  https://download.europe.naverlabs.com/ComputerVision/MASt3R/MASt3R_ViTLarge_BaseDecoder_512_catmlpdpt_metric_retrieval_codebook.pkl\r\n",
      "Resolving download.europe.naverlabs.com (download.europe.naverlabs.com)... 110.234.56.25\r\n",
      "Connecting to download.europe.naverlabs.com (download.europe.naverlabs.com)|110.234.56.25|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 268435691 (256M)\r\n",
      "Saving to: ‘checkpoints/MASt3R_ViTLarge_BaseDecoder_512_catmlpdpt_metric_retrieval_codebook.pkl’\r\n",
      "\r\n",
      "MASt3R_ViTLarge_Bas 100%[===================>] 256.00M  28.4MB/s    in 10s     \r\n",
      "\r\n",
      "2025-06-06 06:12:12 (25.5 MB/s) - ‘checkpoints/MASt3R_ViTLarge_BaseDecoder_512_catmlpdpt_metric_retrieval_codebook.pkl’ saved [268435691/268435691]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/mast3r\n",
    "!wget https://download.europe.naverlabs.com/ComputerVision/MASt3R/MASt3R_ViTLarge_BaseDecoder_512_catmlpdpt_metric_retrieval_trainingfree.pth -P checkpoints/\n",
    "!wget https://download.europe.naverlabs.com/ComputerVision/MASt3R/MASt3R_ViTLarge_BaseDecoder_512_catmlpdpt_metric_retrieval_codebook.pkl -P checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "115d3821",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T06:12:12.914111Z",
     "iopub.status.busy": "2025-06-06T06:12:12.913371Z",
     "iopub.status.idle": "2025-06-06T06:12:14.552337Z",
     "shell.execute_reply": "2025-06-06T06:12:14.551386Z"
    },
    "papermill": {
     "duration": 1.7564,
     "end_time": "2025-06-06T06:12:14.553692",
     "exception": false,
     "start_time": "2025-06-06T06:12:12.797292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement faiss (from versions: none)\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for faiss\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working\n",
    "!pip install faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71a204d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T06:12:14.759896Z",
     "iopub.status.busy": "2025-06-06T06:12:14.759129Z",
     "iopub.status.idle": "2025-06-06T06:12:27.675294Z",
     "shell.execute_reply": "2025-06-06T06:12:27.674508Z"
    },
    "papermill": {
     "duration": 13.017079,
     "end_time": "2025-06-06T06:12:27.676872",
     "exception": false,
     "start_time": "2025-06-06T06:12:14.659793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/mast3r\n",
      "/kaggle/working/mast3r/dust3r/dust3r/cloud_opt/base_opt.py:275: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\r\n",
      "  @torch.cuda.amp.autocast(enabled=False)\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/kaggle/working/mast3r/demo.py\", line 13, in <module>\r\n",
      "    from mast3r.demo import get_args_parser, main_demo\r\n",
      "  File \"/kaggle/working/mast3r/mast3r/demo.py\", line 23, in <module>\r\n",
      "    from mast3r.retrieval.processor import Retriever\r\n",
      "  File \"/kaggle/working/mast3r/mast3r/retrieval/processor.py\", line 16, in <module>\r\n",
      "    import faiss\r\n",
      "ModuleNotFoundError: No module named 'faiss'\r\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/mast3r\n",
    "!python3 demo.py --model_name MASt3R_ViTLarge_BaseDecoder_512_catmlpdpt_metric"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11655853,
     "sourceId": 91498,
     "sourceType": "competition"
    },
    {
     "sourceId": 238248914,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 587.545991,
   "end_time": "2025-06-06T06:12:28.248925",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-06T06:02:40.702934",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
