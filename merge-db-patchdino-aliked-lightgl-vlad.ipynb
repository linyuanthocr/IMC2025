{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9760256",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.007324,
     "end_time": "2025-05-30T07:01:23.316696",
     "exception": false,
     "start_time": "2025-05-30T07:01:23.309372",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Example submission\n",
    "\n",
    "Image Matching Challenge 2025: https://www.kaggle.com/competitions/image-matching-challenge-2025\n",
    "\n",
    "This notebook creates a simple submission using ALIKED and LightGlue, plus DINO for shortlisting, on GPU. Adapted from [last year](https://www.kaggle.com/code/oldufo/imc-2024-submission-example).\n",
    "\n",
    "Remember to select an accelerator on the sidebar to the right, and to disable internet access when submitting a notebook to the competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ee06fd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T07:01:23.330219Z",
     "iopub.status.busy": "2025-05-30T07:01:23.329958Z",
     "iopub.status.idle": "2025-05-30T07:01:29.612239Z",
     "shell.execute_reply": "2025-05-30T07:01:29.611005Z"
    },
    "papermill": {
     "duration": 6.29082,
     "end_time": "2025-05-30T07:01:29.614088",
     "exception": false,
     "start_time": "2025-05-30T07:01:23.323268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/imc2024-packages-lightglue-rerun-kornia/kornia-0.7.2-py2.py3-none-any.whl\r\n",
      "Processing /kaggle/input/imc2024-packages-lightglue-rerun-kornia/kornia_moons-0.2.9-py3-none-any.whl\r\n",
      "Processing /kaggle/input/imc2024-packages-lightglue-rerun-kornia/kornia_rs-0.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Processing /kaggle/input/imc2024-packages-lightglue-rerun-kornia/lightglue-0.0-py3-none-any.whl\r\n",
      "Processing /kaggle/input/imc2024-packages-lightglue-rerun-kornia/pycolmap-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Processing /kaggle/input/imc2024-packages-lightglue-rerun-kornia/rerun_sdk-0.15.0a2-cp38-abi3-manylinux_2_31_x86_64.whl\r\n",
      "Installing collected packages: rerun-sdk, pycolmap, lightglue, kornia-rs, kornia-moons, kornia\r\n",
      "  Attempting uninstall: kornia-rs\r\n",
      "    Found existing installation: kornia_rs 0.1.8\r\n",
      "    Uninstalling kornia_rs-0.1.8:\r\n",
      "      Successfully uninstalled kornia_rs-0.1.8\r\n",
      "  Attempting uninstall: kornia\r\n",
      "    Found existing installation: kornia 0.8.0\r\n",
      "    Uninstalling kornia-0.8.0:\r\n",
      "      Successfully uninstalled kornia-0.8.0\r\n",
      "Successfully installed kornia-0.7.2 kornia-moons-0.2.9 kornia-rs-0.1.2 lightglue-0.0 pycolmap-0.6.1 rerun-sdk-0.15.0a2\r\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT \n",
    "#Install dependencies and copy model weights to run the notebook without internet access when submitting to the competition.\n",
    "\n",
    "!pip install --no-index /kaggle/input/imc2024-packages-lightglue-rerun-kornia/* --no-deps\n",
    "!mkdir -p /root/.cache/torch/hub/checkpoints\n",
    "!cp /kaggle/input/aliked/pytorch/aliked-n16/1/aliked-n16.pth /root/.cache/torch/hub/checkpoints/\n",
    "!cp /kaggle/input/lightglue/pytorch/aliked/1/aliked_lightglue.pth /root/.cache/torch/hub/checkpoints/\n",
    "!cp /kaggle/input/lightglue/pytorch/aliked/1/aliked_lightglue.pth /root/.cache/torch/hub/checkpoints/aliked_lightglue_v0-1_arxiv-pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d7ccdfa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T07:01:29.628635Z",
     "iopub.status.busy": "2025-05-30T07:01:29.628351Z",
     "iopub.status.idle": "2025-05-30T07:01:31.106848Z",
     "shell.execute_reply": "2025-05-30T07:01:31.105560Z"
    },
    "papermill": {
     "duration": 1.487604,
     "end_time": "2025-05-30T07:01:31.108731",
     "exception": false,
     "start_time": "2025-05-30T07:01:29.621127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp /kaggle/input/disk-depth/disk_lightglue.pth /root/.cache/torch/hub/checkpoints/\n",
    "!cp /kaggle/input/disk-depth/disk_lightglue.pth /root/.cache/torch/hub/checkpoints/disk_lightglue_v0-1_arxiv-pth\n",
    "!cp /kaggle/input/disk-depth/depth-save.pth /root/.cache/torch/hub/checkpoints/depth-save.pth\n",
    "!cp /kaggle/input/disk-depth/depth-save.pth /root/.cache/torch/hub/checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43f9578d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T07:01:31.124189Z",
     "iopub.status.busy": "2025-05-30T07:01:31.123895Z",
     "iopub.status.idle": "2025-05-30T07:01:32.676354Z",
     "shell.execute_reply": "2025-05-30T07:01:32.675186Z"
    },
    "papermill": {
     "duration": 1.562114,
     "end_time": "2025-05-30T07:01:32.678180",
     "exception": false,
     "start_time": "2025-05-30T07:01:31.116066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp /kaggle/input/superpoint-lightglue/superpoint_lightglue.pth /root/.cache/torch/hub/checkpoints/\n",
    "!cp /kaggle/input/superpoint-lightglue/superpoint_lightglue.pth  /root/.cache/torch/hub/checkpoints/superpoint_lightglue_v0-1_arxiv-pth\n",
    "!cp /kaggle/input/superpoint-lightglue/superpoint_v1.pth /root/.cache/torch/hub/checkpoints/superpoint_v1.pth\n",
    "!cp /kaggle/input/superpoint-lightglue/superpoint_v1.pth /root/.cache/torch/hub/checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e114e77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T07:01:32.693100Z",
     "iopub.status.busy": "2025-05-30T07:01:32.692827Z",
     "iopub.status.idle": "2025-05-30T07:01:32.697070Z",
     "shell.execute_reply": "2025-05-30T07:01:32.696145Z"
    },
    "papermill": {
     "duration": 0.012897,
     "end_time": "2025-05-30T07:01:32.698235",
     "exception": false,
     "start_time": "2025-05-30T07:01:32.685338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.path.exists(\"/root/.cache/torch/hub/checkpoints/depth-save.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "775fc417",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T07:01:32.713178Z",
     "iopub.status.busy": "2025-05-30T07:01:32.712969Z",
     "iopub.status.idle": "2025-05-30T07:01:58.988023Z",
     "shell.execute_reply": "2025-05-30T07:01:58.987348Z"
    },
    "papermill": {
     "duration": 26.284443,
     "end_time": "2025-05-30T07:01:58.989765",
     "exception": false,
     "start_time": "2025-05-30T07:01:32.705322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/kornia/feature/lightglue.py:44: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n",
      "/usr/local/lib/python3.10/dist-packages/lightglue/lightglue.py:24: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from time import time, sleep\n",
    "import gc\n",
    "import numpy as np\n",
    "import h5py\n",
    "import dataclasses\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import kornia as K\n",
    "import kornia.feature as KF\n",
    "\n",
    "import torch\n",
    "from lightglue import match_pair\n",
    "from lightglue import ALIKED, LightGlue\n",
    "from lightglue.utils import load_image, rbd\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "\n",
    "# from lightglue import DISK\n",
    "from kornia.feature import LightGlueMatcher as KF_LightGlueMatcher\n",
    "from scipy.spatial import cKDTree # For efficient nearest neighbor search to remove duplicate keypoints\n",
    "\n",
    "# IMPORTANT Utilities: importing data into colmap and competition metric\n",
    "import pycolmap\n",
    "sys.path.append('/kaggle/input/imc25-utils')\n",
    "from database import *\n",
    "from h5_to_db import *\n",
    "import metric\n",
    "\n",
    "\n",
    "# LightGlue\n",
    "from lightglue import match_pair\n",
    "from lightglue import ALIKED, SuperPoint,DISK, DoGHardNet, LightGlue, SIFT\n",
    "from fastprogress import progress_bar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d78fac67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T07:01:59.005145Z",
     "iopub.status.busy": "2025-05-30T07:01:59.004654Z",
     "iopub.status.idle": "2025-05-30T07:01:59.007917Z",
     "shell.execute_reply": "2025-05-30T07:01:59.007306Z"
    },
    "papermill": {
     "duration": 0.011911,
     "end_time": "2025-05-30T07:01:59.009093",
     "exception": false,
     "start_time": "2025-05-30T07:01:58.997182",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "import concurrent.futures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f116ad2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T07:01:59.023343Z",
     "iopub.status.busy": "2025-05-30T07:01:59.023140Z",
     "iopub.status.idle": "2025-05-30T07:01:59.138697Z",
     "shell.execute_reply": "2025-05-30T07:01:59.137635Z"
    },
    "papermill": {
     "duration": 0.12437,
     "end_time": "2025-05-30T07:01:59.140198",
     "exception": false,
     "start_time": "2025-05-30T07:01:59.015828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu121\n",
      "Python version: 3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]\n",
      "CUDA available: True\n",
      "CUDA version: 12.1\n",
      "Device count: 2\n",
      "Current device: 0\n",
      "Device name: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "import sys\n",
    "print(\"Python version:\", sys.version)\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"Device count:\", torch.cuda.device_count())\n",
    "print(\"Current device:\", torch.cuda.current_device())\n",
    "print(\"Device name:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "391d1613",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T07:01:59.154782Z",
     "iopub.status.busy": "2025-05-30T07:01:59.154505Z",
     "iopub.status.idle": "2025-05-30T07:01:59.158547Z",
     "shell.execute_reply": "2025-05-30T07:01:59.157650Z"
    },
    "papermill": {
     "duration": 0.0127,
     "end_time": "2025-05-30T07:01:59.159865",
     "exception": false,
     "start_time": "2025-05-30T07:01:59.147165",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device=device(type='cuda', index=0)\n"
     ]
    }
   ],
   "source": [
    "# Do not forget to select an accelerator on the sidebar to the right.\n",
    "device = K.utils.get_cuda_device_if_available(0)\n",
    "print(f'{device=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2358bd0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T07:01:59.174069Z",
     "iopub.status.busy": "2025-05-30T07:01:59.173842Z",
     "iopub.status.idle": "2025-05-30T07:01:59.176641Z",
     "shell.execute_reply": "2025-05-30T07:01:59.176070Z"
    },
    "papermill": {
     "duration": 0.011084,
     "end_time": "2025-05-30T07:01:59.177752",
     "exception": false,
     "start_time": "2025-05-30T07:01:59.166668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "VERBOSE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c810a7c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T07:01:59.192246Z",
     "iopub.status.busy": "2025-05-30T07:01:59.192050Z",
     "iopub.status.idle": "2025-05-30T07:01:59.199440Z",
     "shell.execute_reply": "2025-05-30T07:01:59.198907Z"
    },
    "papermill": {
     "duration": 0.015973,
     "end_time": "2025-05-30T07:01:59.200646",
     "exception": false,
     "start_time": "2025-05-30T07:01:59.184673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CONFIG:\n",
    "    # DEBUG Settings\n",
    "    DRY_RUN = False\n",
    "    DRY_RUN_MAX_IMAGES = 10\n",
    "\n",
    "    # Pipeline settings\n",
    "    NUM_CORES = 2\n",
    "    \n",
    "    # COLMAP Reconstruction\n",
    "    CAMERA_MODEL = \"simple-radial\"\n",
    "    \n",
    "    # Rotation correction\n",
    "    ROTATION_CORRECTION = False\n",
    "    \n",
    "    # Keypoints handling\n",
    "    MERGE_PARAMS = {\n",
    "        \"min_matches\" : 15,\n",
    "        # When merging keypoints, it is enable to filtering matches with cv2.findFundamentalMatrix.\n",
    "        \"filter_FundamentalMatrix\" : True,\n",
    "        \"filter_iterations\" : 5,\n",
    "        \"filter_threshold\" : 4,\n",
    "    }\n",
    "    \n",
    "    # Keypoints Extraction\n",
    "    use_aliked_lightglue = True\n",
    "    use_doghardnet_lightglue = False\n",
    "    use_superpoint_lightglue = True\n",
    "    use_disk_lightglue = True\n",
    "    use_sift_lightglue = False\n",
    "    use_loftr = False\n",
    "    use_dkm = False\n",
    "    use_superglue = False\n",
    "    use_matchformer = False\n",
    "        \n",
    "    # Keypoints Extraction Parameters\n",
    "    params_aliked_lightglue = {\n",
    "        \"num_features\" : 8192,\n",
    "        \"detection_threshold\" : 0.1,\n",
    "        \"min_matches\" : 100,\n",
    "        \"resize_to\" : 2048,\n",
    "        \"match_confidence_threshold\":0.2\n",
    "    }\n",
    "    \n",
    "    params_doghardnet_lightglue = {\n",
    "        \"num_features\" : 8192,\n",
    "        \"detection_threshold\" : 0.001,\n",
    "        \"min_matches\" : 15,\n",
    "        \"resize_to\" : 1024,\n",
    "    }\n",
    "    \n",
    "    params_superpoint_lightglue = {\n",
    "        \"num_features\" : 8192,\n",
    "        \"detection_threshold\" : 0.1,\n",
    "        \"min_matches\" : 50,\n",
    "        \"resize_to\" : 2048,\n",
    "        \"match_confidence_threshold\":0.2\n",
    "    }\n",
    "    \n",
    "    params_disk_lightglue = {\n",
    "        \"num_features\" : 8192,\n",
    "        \"detection_threshold\" : 0.1,\n",
    "        \"min_matches\" : 100,\n",
    "        \"resize_to\" : 2048,\n",
    "        \"match_confidence_threshold\":0.2\n",
    "    }\n",
    "\n",
    "    params_sift_lightglue = {\n",
    "        \"num_features\" : 8192,\n",
    "        \"detection_threshold\" : 0.001,\n",
    "        \"min_matches\" : 15,\n",
    "        \"resize_to\" : 1024,\n",
    "    }\n",
    "\n",
    "    params_loftr = {\n",
    "        \"resize_small_edge_to\" : 750,\n",
    "        \"min_matches\" : 15,\n",
    "    }\n",
    "    \n",
    "    params_dkm = {\n",
    "        \"num_features\" : 2048,\n",
    "        \"detection_threshold\" : 0.4,\n",
    "        \"min_matches\" : 15,\n",
    "        \"resize_to\" : (540, 720),    \n",
    "    }\n",
    "    \n",
    "    # superpoint + superglue  ...  https://www.kaggle.com/competitions/image-matching-challenge-2023/discussion/416873\n",
    "    params_sg1 = {\n",
    "        \"sg_config\" : \n",
    "        {\n",
    "            \"superpoint\": {\n",
    "                \"nms_radius\": 4, \n",
    "                \"keypoint_threshold\": 0.005,\n",
    "                \"max_keypoints\": -1,\n",
    "            },\n",
    "            \"superglue\": {\n",
    "                \"weights\": \"outdoor\",\n",
    "                \"sinkhorn_iterations\": 20,\n",
    "                \"match_threshold\": 0.2,\n",
    "            },\n",
    "        },\n",
    "        \"resize_to\": 1088,\n",
    "        \"min_matches\": 15,\n",
    "    }\n",
    "    params_sg2 = {\n",
    "        \"sg_config\" : \n",
    "        {\n",
    "            \"superpoint\": {\n",
    "                \"nms_radius\": 4, \n",
    "                \"keypoint_threshold\": 0.005,\n",
    "                \"max_keypoints\": -1,\n",
    "            },\n",
    "            \"superglue\": {\n",
    "                \"weights\": \"outdoor\",\n",
    "                \"sinkhorn_iterations\": 20,\n",
    "                \"match_threshold\": 0.2,\n",
    "            },\n",
    "        },\n",
    "        \"resize_to\": 1280,\n",
    "        \"min_matches\": 15,\n",
    "    }\n",
    "    params_sg3 = {\n",
    "        \"sg_config\" : \n",
    "        {\n",
    "            \"superpoint\": {\n",
    "                \"nms_radius\": 4, \n",
    "                \"keypoint_threshold\": 0.005,\n",
    "                \"max_keypoints\": -1,\n",
    "            },\n",
    "            \"superglue\": {\n",
    "                \"weights\": \"outdoor\",\n",
    "                \"sinkhorn_iterations\": 20,\n",
    "                \"match_threshold\": 0.2,\n",
    "            },\n",
    "        },\n",
    "        \"resize_to\": 1376,\n",
    "        \"min_matches\": 15,\n",
    "    }\n",
    "    params_sgs = [params_sg1, params_sg2, params_sg3]\n",
    "    \n",
    "    params_matchformer = {\n",
    "        \"detection_threshold\" : 0.15,\n",
    "        \"resize_to\" : (560, 750),\n",
    "        \"num_features\" : 2000,\n",
    "        \"min_matches\" : 15, \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2b34f56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T07:01:59.215068Z",
     "iopub.status.busy": "2025-05-30T07:01:59.214869Z",
     "iopub.status.idle": "2025-05-30T07:01:59.269706Z",
     "shell.execute_reply": "2025-05-30T07:01:59.269099Z"
    },
    "papermill": {
     "duration": 0.063808,
     "end_time": "2025-05-30T07:01:59.271049",
     "exception": false,
     "start_time": "2025-05-30T07:01:59.207241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assume these are available from your environment or previous code\n",
    "# from .utils import load_torch_image # Assuming load_torch_image is defined elsewhere\n",
    "# from kornia.feature import ALIKED # Already in your detect_aliked\n",
    "# from kornia.feature import LightGlueMatcher as KF_LightGlueMatcher # Already in your match_with_lightglue\n",
    "# from kornia.geometry import laf_from_center_scale_ori # Already in your match_with_lightglue\n",
    "# from colmap_database import COLMAPDatabase, add_keypoints, add_matches # Already in your colmap_import\n",
    "\n",
    "# --- Helper function for image loading (if not already defined) ---\n",
    "def load_torch_image(fname, device=torch.device('cpu')):\n",
    "    img = K.io.load_image(fname, K.io.ImageLoadType.RGB32, device=device)[None, ...]\n",
    "    return img\n",
    "def get_dino_patch_features_for_keypoints(img_path, keypoints_xy, dino_processor, dino_model, patch_size=16, device=torch.device('cpu')):\n",
    "    \"\"\"\n",
    "    Extracts DINO patch features corresponding to given ALIKED keypoint locations.\n",
    "    It correctly infers the DINO patch grid dimensions from the processed input.\n",
    "\n",
    "    Args:\n",
    "        img_path (str): Path to the image file.\n",
    "        keypoints_xy (torch.Tensor): Nx2 tensor of (x, y) keypoint coordinates in image pixel space.\n",
    "                                     These keypoints are assumed to be in the original image's coordinate system.\n",
    "        dino_processor: HuggingFace AutoImageProcessor for DINO.\n",
    "        dino_model: HuggingFace AutoModel for DINO.\n",
    "        patch_size (int): The patch size used by the DINO model (e.g., 14 or 16).\n",
    "        device (torch.device): Device to run the models on.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: NxD_dino tensor of DINO patch features for each keypoint.\n",
    "                      Returns None if no keypoints or image loading fails.\n",
    "    \"\"\"\n",
    "    if len(keypoints_xy) == 0:\n",
    "        dino_feature_dim = dino_model.config.hidden_size # Get actual DINO hidden size\n",
    "        return torch.empty((0, dino_feature_dim), device=device)\n",
    "\n",
    "    # 1. Load the original image (ALIKED processed this size)\n",
    "    original_img = load_torch_image(img_path, device=device)\n",
    "    original_h, original_w = original_img.shape[-2], original_img.shape[-1]\n",
    "\n",
    "\n",
    "    # 2. Process the image with DINO's processor\n",
    "    #    This step performs resizing, padding, etc., as needed by the DINO model\n",
    "    with torch.inference_mode():\n",
    "        # dino_processor returns a BatchFeature object which includes pixel_values\n",
    "        # and potentially other information like `pixel_mask`\n",
    "        inputs = dino_processor(images=original_img, return_tensors=\"pt\", do_rescale=False).to(device)\n",
    "        outputs = dino_model(**inputs)\n",
    "\n",
    "        # Get the actual dimensions of the image as processed by the DINO model\n",
    "        # This is the crucial part: the actual H and W that produced `patch_tokens`\n",
    "        # We can infer this from the `pixel_values` shape\n",
    "        processed_h = inputs['pixel_values'].shape[-2]\n",
    "        processed_w = inputs['pixel_values'].shape[-1]\n",
    "\n",
    "        # Extract patch tokens (excluding the CLS token)\n",
    "        patch_tokens = outputs.last_hidden_state[:, 1:].squeeze(0) # Shape: (num_patches, hidden_size)\n",
    "\n",
    "        # Calculate the actual grid dimensions based on the *processed* image size\n",
    "        # and the model's patch size.\n",
    "        # This should perfectly match the number of patch_tokens if the model is well-behaved.\n",
    "        num_patches_h = processed_h // patch_size\n",
    "        num_patches_w = processed_w // patch_size\n",
    "\n",
    "        # Safety check: ensure calculated grid matches actual token count\n",
    "        expected_token_count = num_patches_h * num_patches_w\n",
    "        if patch_tokens.shape[0] != expected_token_count:\n",
    "            # This indicates a deeper issue with how the model's output tokens\n",
    "            # map to the spatial grid, or an unexpected patch size/model behavior.\n",
    "            # Some models might have slightly different patch token arrangements.\n",
    "            # DINOv2 typically aligns well.\n",
    "            raise ValueError(\n",
    "                f\"DINO patch token count ({patch_tokens.shape[0]}) does not match \"\n",
    "                f\"expected grid dimensions ({num_patches_h}x{num_patches_w} = {expected_token_count}) \"\n",
    "                f\"for processed image size {processed_w}x{processed_h} with patch size {patch_size}. \"\n",
    "                f\"Please verify DINO model and processor configuration.\"\n",
    "            )\n",
    "\n",
    "        # Reshape patch tokens into a 2D grid\n",
    "        patch_features_grid = patch_tokens.reshape(num_patches_h, num_patches_w, -1)\n",
    "        dino_feature_dim = patch_features_grid.shape[-1] # Actual feature dimension\n",
    "\n",
    "\n",
    "    dino_features_for_kpts = torch.zeros((len(keypoints_xy), dino_feature_dim), device=device)\n",
    "\n",
    "    # 3. Rescale ALIKED keypoints to the DINO *processed* image dimensions\n",
    "    #    ALIKED keypoints are in original_w x original_h coordinates.\n",
    "    #    DINO patches correspond to processed_w x processed_h coordinates.\n",
    "    scale_x = processed_w / original_w\n",
    "    scale_y = processed_h / original_h\n",
    "\n",
    "    scaled_keypoints_xy = keypoints_xy.clone()\n",
    "    scaled_keypoints_xy[:, 0] *= scale_x\n",
    "    scaled_keypoints_xy[:, 1] *= scale_y\n",
    "\n",
    "    # 4. Map scaled keypoints to DINO patch grid indices\n",
    "    keypoint_cols = (scaled_keypoints_xy[:, 0] / patch_size).long()\n",
    "    keypoint_rows = (scaled_keypoints_xy[:, 1] / patch_size).long()\n",
    "\n",
    "    # Clip indices to ensure they are within bounds of the patch grid\n",
    "    keypoint_rows = torch.clamp(keypoint_rows, 0, num_patches_h - 1)\n",
    "    keypoint_cols = torch.clamp(keypoint_cols, 0, num_patches_w - 1)\n",
    "\n",
    "    # Gather DINO features for each keypoint's corresponding patch\n",
    "    dino_features_for_kpts = patch_features_grid[keypoint_rows, keypoint_cols]\n",
    "\n",
    "    return dino_features_for_kpts\n",
    "\n",
    "\n",
    "def convert_coord(r, w, h, rotk):\n",
    "    if rotk == 0:\n",
    "        return r\n",
    "    elif rotk == 1:\n",
    "        rx = w-1-r[:, 1]\n",
    "        ry = r[:, 0]\n",
    "        return torch.concat([rx[None], ry[None]], dim=0).T\n",
    "    elif rotk == 2:\n",
    "        rx = w-1-r[:, 0]\n",
    "        ry = h-1-r[:, 1]\n",
    "        return torch.concat([rx[None], ry[None]], dim=0).T\n",
    "    elif rotk == 3:\n",
    "        rx = r[:, 1]\n",
    "        ry = h-1-r[:, 0]\n",
    "        return torch.concat([rx[None], ry[None]], dim=0).T\n",
    "\n",
    "def detect_common(img_fnames,\n",
    "                  model_name,\n",
    "                  rots,\n",
    "                  file_keypoints,\n",
    "                  feature_dir = '.featureout',\n",
    "                  num_features = 4096,\n",
    "                  resize_to = 1024,\n",
    "                  detection_threshold = 0.01,\n",
    "                  device=torch.device('cpu'),\n",
    "                  min_matches=15,\n",
    "                  match_confidence_threshold = 0.0,\n",
    "                  verbose=VERBOSE\n",
    "                 ):\n",
    "    if not os.path.isdir(feature_dir):\n",
    "        os.makedirs(feature_dir)\n",
    "\n",
    "    #####################################################\n",
    "    # Extract keypoints and descriptions\n",
    "    #####################################################\n",
    "    dict_model = {\n",
    "        \"aliked\" : ALIKED,\n",
    "        \"superpoint\" : SuperPoint,\n",
    "        \"doghardnet\" : DoGHardNet,\n",
    "        \"disk\" : DISK,\n",
    "        \"sift\" : SIFT,\n",
    "    }\n",
    "    extractor_class = dict_model[model_name]\n",
    "    dtype = torch.float32 # ALIKED has issues with float16\n",
    "    # extractor = extractor_class(max_num_keypoints=num_features, detection_threshold=detection_threshold, \n",
    "    #                             resize=resize_to).eval().to(device, dtype)\n",
    "    # if model_name == 'disk':\n",
    "    #     extractor = DISK(\n",
    "    #         max_num_keypoints=num_features,\n",
    "    #         detection_threshold=detection_threshold,\n",
    "    #         resize=resize_to\n",
    "    #     ).to(device).eval()\n",
    "    #     checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "    #     extractor.load_state_dict(checkpoint['model'])\n",
    "    # else:\n",
    "    #     extractor_class = dict_model[model_name]\n",
    "    #     extractor = extractor_class(\n",
    "    #         max_num_keypoints=num_features,\n",
    "    #         detection_threshold=detection_threshold,\n",
    "    #         resize=resize_to\n",
    "    #     ).to(device, dtype).eval()\n",
    "\n",
    "    extractor_class = dict_model[model_name]\n",
    "    extractor = extractor_class(\n",
    "        max_num_keypoints=num_features,\n",
    "        detection_threshold=detection_threshold,\n",
    "        resize=resize_to\n",
    "    ).to(device, dtype).eval()\n",
    "    dict_kpts_cuda = {}\n",
    "    dict_descs_cuda = {}\n",
    "    for (img_path, rot_k) in zip(img_fnames, rots):\n",
    "        img_fname = img_path.split('/')[-1]\n",
    "        key = img_fname\n",
    "        with torch.inference_mode():\n",
    "            image0 = load_torch_image(img_path, device=device).to(dtype)\n",
    "            h, w = image0.shape[2], image0.shape[3]\n",
    "            image1 = torch.rot90(image0, rot_k, [2, 3])\n",
    "            feats0 = extractor.extract(image1)  # auto-resize the image, disable with resize=None\n",
    "            kpts = feats0['keypoints'].reshape(-1, 2).detach()\n",
    "            descs = feats0['descriptors'].reshape(len(kpts), -1).detach()\n",
    "            kpts = convert_coord(kpts, w, h, rot_k)\n",
    "            dict_kpts_cuda[f\"{key}\"] = kpts\n",
    "            dict_descs_cuda[f\"{key}\"] = descs\n",
    "            if verbose:\n",
    "                print(f\"{model_name} > rot_k={rot_k}, kpts.shape={kpts.shape}, descs.shape={descs.shape}\")\n",
    "    del extractor\n",
    "    gc.collect()\n",
    "\n",
    "    #####################################################\n",
    "    # Matching keypoints\n",
    "    #####################################################\n",
    "    lg_matcher = KF.LightGlueMatcher(model_name, {\"width_confidence\": -1,\n",
    "                                            \"depth_confidence\": -1,\n",
    "                                            \"filter_threshold\":match_confidence_threshold,\n",
    "                                             \"mp\": True if 'cuda' in str(device) else False}).eval().to(device)\n",
    "    \n",
    "    cnt_pairs = 0\n",
    "    with h5py.File(file_keypoints, mode='w') as f_match:\n",
    "        for pair_idx in tqdm(index_pairs):\n",
    "            idx1, idx2 = pair_idx\n",
    "            fname1, fname2 = img_fnames[idx1], img_fnames[idx2]\n",
    "            \n",
    "            key1, key2 = fname1.split('/')[-1], fname2.split('/')[-1]\n",
    "            \n",
    "            kp1 = dict_kpts_cuda[key1]\n",
    "            kp2 = dict_kpts_cuda[key2]\n",
    "            desc1 = dict_descs_cuda[key1]\n",
    "            desc2 = dict_descs_cuda[key2]\n",
    "            with torch.inference_mode():\n",
    "                try:\n",
    "                    dists, idxs = lg_matcher(desc1,\n",
    "                                              desc2,\n",
    "                                              KF.laf_from_center_scale_ori(kp1[None]),\n",
    "                                              KF.laf_from_center_scale_ori(kp2[None]))\n",
    "                except Exception as e:\n",
    "                    print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "                    print(f\"LightGlueMatcher failed on {key1}-{key2}\")\n",
    "                    print(f\"desc1.shape={desc1.shape}, desc2.shape={desc2.shape}\")\n",
    "                    print(f\"kp1.shape={kp1.shape}, kp2.shape={kp2.shape}\")\n",
    "                    continue\n",
    "            if len(idxs)  == 0:\n",
    "                continue\n",
    "            len1 = len(idxs)\n",
    "            n_matches = len1\n",
    "            kp1 = kp1[idxs[:,0], :].cpu().numpy().reshape(-1, 2).astype(np.float32)\n",
    "            kp2 = kp2[idxs[:,1], :].cpu().numpy().reshape(-1, 2).astype(np.float32)\n",
    "            group  = f_match.require_group(key1)\n",
    "            if n_matches >= min_matches:\n",
    "                group.create_dataset(key2, data=np.concatenate([kp1, kp2], axis=1))\n",
    "                cnt_pairs+=1\n",
    "                if verbose:\n",
    "                    print (f'{model_name}> {key1}-{key2}: {n_matches} matches @ {cnt_pairs}th pair({model_name}+lightglue)')            \n",
    "            else:\n",
    "                pass\n",
    "                # if verbose:\n",
    "                #     print (f'{model_name}> {key1}-{key2}: {n_matches} matches --> skipped')\n",
    "    del lg_matcher\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    return\n",
    "\n",
    "def detect_lightglue_common(\n",
    "    img_fnames, model_name, index_pairs, feature_dir, device, file_keypoints, rots,\n",
    "    resize_to=1024,\n",
    "    detection_threshold=0.01, \n",
    "    num_features=4096, \n",
    "    min_matches=15,\n",
    "    match_confidence_threshold = 0.0\n",
    "):\n",
    "    t=time()\n",
    "    detect_common(\n",
    "        img_fnames, model_name, rots, file_keypoints, feature_dir, \n",
    "        resize_to=resize_to,\n",
    "        num_features=num_features, \n",
    "        detection_threshold=detection_threshold, \n",
    "        device=device,\n",
    "        min_matches=min_matches,\n",
    "        match_confidence_threshold = match_confidence_threshold\n",
    "    )\n",
    "    gc.collect()\n",
    "    t=time() -t \n",
    "    print(f'Features matched in  {t:.4f} sec ({model_name}+LightGlue)')\n",
    "    return t\n",
    "\n",
    "def get_unique_idxs(A, dim=0):\n",
    "    # https://stackoverflow.com/questions/72001505/how-to-get-unique-elements-and-their-firstly-appeared-indices-of-a-pytorch-tenso\n",
    "    unique, idx, counts = torch.unique(A, dim=dim, sorted=True, return_inverse=True, return_counts=True)\n",
    "    _, ind_sorted = torch.sort(idx, stable=True)\n",
    "    cum_sum = counts.cumsum(0)\n",
    "    cum_sum = torch.cat((torch.tensor([0],device=cum_sum.device), cum_sum[:-1]))\n",
    "    first_indices = ind_sorted[cum_sum]\n",
    "    return first_indices\n",
    "\n",
    "def get_keypoint_from_h5(fp, key1, key2):\n",
    "    rc = -1\n",
    "    try:\n",
    "        kpts = np.array(fp[key1][key2])\n",
    "        rc = 0\n",
    "        return (rc, kpts)\n",
    "    except:\n",
    "        return (rc, None)\n",
    "\n",
    "def get_keypoint_from_multi_h5(fps, key1, key2):\n",
    "    list_mkpts = []\n",
    "    for fp in fps:\n",
    "        rc, mkpts = get_keypoint_from_h5(fp, key1, key2)\n",
    "        if rc == 0:\n",
    "            list_mkpts.append(mkpts)\n",
    "    if len(list_mkpts) > 0:\n",
    "        list_mkpts = np.concatenate(list_mkpts, axis=0)\n",
    "    else:\n",
    "        list_mkpts = None\n",
    "    return list_mkpts\n",
    "\n",
    "def matches_merger(\n",
    "    img_fnames,\n",
    "    index_pairs,\n",
    "    files_keypoints,\n",
    "    save_file,\n",
    "    feature_dir = 'featureout',\n",
    "    filter_FundamentalMatrix = False,\n",
    "    filter_iterations = 10,\n",
    "    filter_threshold = 8,\n",
    "    verbose = VERBOSE\n",
    "):\n",
    "    # open h5 files\n",
    "    fps = [ h5py.File(file, mode=\"r\") for file in files_keypoints ]\n",
    "\n",
    "    with h5py.File(save_file, mode='w') as f_match:\n",
    "        counter = 0\n",
    "        for pair_idx in progress_bar(index_pairs):\n",
    "            idx1, idx2 = pair_idx\n",
    "            fname1, fname2 = img_fnames[idx1], img_fnames[idx2]\n",
    "            key1, key2 = fname1.split('/')[-1], fname2.split('/')[-1]\n",
    "\n",
    "            # extract keypoints\n",
    "            mkpts = get_keypoint_from_multi_h5(fps, key1, key2)\n",
    "            if mkpts is None:\n",
    "                # if verbose:\n",
    "                #     print(f\"skipped key1={key1}, key2={key2}\")\n",
    "                continue\n",
    "\n",
    "            ori_size = mkpts.shape[0]\n",
    "            if mkpts.shape[0] < CONFIG.MERGE_PARAMS[\"min_matches\"]:\n",
    "                continue\n",
    "            \n",
    "            if filter_FundamentalMatrix:\n",
    "                store_inliers = { idx:0 for idx in range(mkpts.shape[0]) }\n",
    "                idxs = np.array(range(mkpts.shape[0]))\n",
    "                for iter in range(filter_iterations):\n",
    "                    try:\n",
    "                        Fm, inliers = cv2.findFundamentalMat(\n",
    "                            mkpts[:,:2], mkpts[:,2:4], cv2.USAC_MAGSAC, 3, 0.9999, 20000)\n",
    "                        if Fm is not None:\n",
    "                            inliers = inliers > 0\n",
    "                            inlier_idxs = idxs[inliers[:, 0]]\n",
    "                            #print(inliers.shape, inlier_idxs[:5])\n",
    "                            for idx in inlier_idxs:\n",
    "                                store_inliers[idx] += 1\n",
    "                    except:\n",
    "                        print(f\"Failed to cv2.findFundamentalMat. mkpts.shape={mkpts.shape}\")\n",
    "                inliers = np.array([ count for (idx, count) in store_inliers.items() ]) >= filter_threshold\n",
    "                mkpts = mkpts[inliers]\n",
    "                if mkpts.shape[0] < 15:\n",
    "                    if verbose:\n",
    "                        print(f\"skipped key1={key1}, key2={key2}: mkpts.shape={mkpts.shape} after filtered.\")\n",
    "                    continue\n",
    "                if verbose:\n",
    "                    print(f\"filter_FundamentalMatrix: {len(store_inliers)} matches --> {mkpts.shape[0]} matches\")\n",
    "            \n",
    "            if verbose:\n",
    "                print (f'{key1}-{key2}: {ori_size} --> {mkpts.shape[0]} matches')            \n",
    "            # regist tmp file\n",
    "            group  = f_match.require_group(key1)\n",
    "            group.create_dataset(key2, data=mkpts)\n",
    "            counter += 1\n",
    "    print( f\"Ensembled pairs : {counter} pairs\" )\n",
    "    for fp in fps:\n",
    "        fp.close()\n",
    "\n",
    "def keypoints_merger(\n",
    "    img_fnames,\n",
    "    index_pairs,\n",
    "    files_keypoints,\n",
    "    feature_dir = 'featureout',\n",
    "    filter_FundamentalMatrix = False,\n",
    "    filter_iterations = 10,\n",
    "    filter_threshold = 8,\n",
    "):\n",
    "    save_file = f'{feature_dir}/merge_tmp.h5'\n",
    "    !rm -rf {save_file}\n",
    "    matches_merger(\n",
    "        img_fnames,\n",
    "        index_pairs,\n",
    "        files_keypoints,\n",
    "        save_file,\n",
    "        feature_dir = feature_dir,\n",
    "        filter_FundamentalMatrix = filter_FundamentalMatrix,\n",
    "        filter_iterations = filter_iterations,\n",
    "        filter_threshold = filter_threshold,\n",
    "    )\n",
    "        \n",
    "    # Let's find unique loftr pixels and group them together.\n",
    "    kpts = defaultdict(list)\n",
    "    match_indexes = defaultdict(dict)\n",
    "    total_kpts=defaultdict(int)\n",
    "    with h5py.File(save_file, mode='r') as f_match:\n",
    "        for k1 in f_match.keys():\n",
    "            group  = f_match[k1]\n",
    "            for k2 in group.keys():\n",
    "                matches = group[k2][...]\n",
    "                total_kpts[k1]\n",
    "                kpts[k1].append(matches[:, :2])\n",
    "                kpts[k2].append(matches[:, 2:])\n",
    "                current_match = torch.arange(len(matches)).reshape(-1, 1).repeat(1, 2)\n",
    "                current_match[:, 0]+=total_kpts[k1]\n",
    "                current_match[:, 1]+=total_kpts[k2]\n",
    "                total_kpts[k1]+=len(matches)\n",
    "                total_kpts[k2]+=len(matches)\n",
    "                match_indexes[k1][k2]=current_match\n",
    "\n",
    "    for k in kpts.keys():\n",
    "        kpts[k] = np.round(np.concatenate(kpts[k], axis=0))\n",
    "    unique_kpts = {}\n",
    "    unique_match_idxs = {}\n",
    "    out_match = defaultdict(dict)\n",
    "    for k in kpts.keys():\n",
    "        uniq_kps, uniq_reverse_idxs = torch.unique(torch.from_numpy(kpts[k]),dim=0, return_inverse=True)\n",
    "        unique_match_idxs[k] = uniq_reverse_idxs\n",
    "        unique_kpts[k] = uniq_kps.numpy()\n",
    "    for k1, group in match_indexes.items():\n",
    "        for k2, m in group.items():\n",
    "            m2 = deepcopy(m)\n",
    "            m2[:,0] = unique_match_idxs[k1][m2[:,0]]\n",
    "            m2[:,1] = unique_match_idxs[k2][m2[:,1]]\n",
    "            mkpts = np.concatenate([unique_kpts[k1][ m2[:,0]],\n",
    "                                    unique_kpts[k2][  m2[:,1]],\n",
    "                                   ],\n",
    "                                   axis=1)\n",
    "            unique_idxs_current = get_unique_idxs(torch.from_numpy(mkpts), dim=0)\n",
    "            m2_semiclean = m2[unique_idxs_current]\n",
    "            unique_idxs_current1 = get_unique_idxs(m2_semiclean[:, 0], dim=0)\n",
    "            m2_semiclean = m2_semiclean[unique_idxs_current1]\n",
    "            unique_idxs_current2 = get_unique_idxs(m2_semiclean[:, 1], dim=0)\n",
    "            m2_semiclean2 = m2_semiclean[unique_idxs_current2]\n",
    "            out_match[k1][k2] = m2_semiclean2.numpy()\n",
    "    with h5py.File(f'{feature_dir}/keypoints.h5', mode='w') as f_kp:\n",
    "        for k, kpts1 in unique_kpts.items():\n",
    "            f_kp[k] = kpts1\n",
    "    \n",
    "    with h5py.File(f'{feature_dir}/matches.h5', mode='w') as f_match:\n",
    "        for k1, gr in out_match.items():\n",
    "            group  = f_match.require_group(k1)\n",
    "            for k2, match in gr.items():\n",
    "                group[k2] = match\n",
    "                # print(f\"KKKKKKK KKKKKK {k1} - {k2}: {len(match)} matches\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4202fac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T07:01:59.285471Z",
     "iopub.status.busy": "2025-05-30T07:01:59.285244Z",
     "iopub.status.idle": "2025-05-30T07:01:59.288415Z",
     "shell.execute_reply": "2025-05-30T07:01:59.287573Z"
    },
    "papermill": {
     "duration": 0.011709,
     "end_time": "2025-05-30T07:01:59.289681",
     "exception": false,
     "start_time": "2025-05-30T07:01:59.277972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !rm -rf /kaggle/working/result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df9211b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T07:01:59.304275Z",
     "iopub.status.busy": "2025-05-30T07:01:59.304046Z",
     "iopub.status.idle": "2025-05-30T07:01:59.311351Z",
     "shell.execute_reply": "2025-05-30T07:01:59.310580Z"
    },
    "papermill": {
     "duration": 0.015909,
     "end_time": "2025-05-30T07:01:59.312544",
     "exception": false,
     "start_time": "2025-05-30T07:01:59.296635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- MODIFIED: Detect ALIKED and Combine with DINO Patch Features ---\n",
    "def detect_aliked_and_combine_with_dino(img_fnames,\n",
    "                                        feature_dir='.featureout',\n",
    "                                        num_features=4096,\n",
    "                                        resize_to=1024,\n",
    "                                        dino_processor=None,\n",
    "                                        dino_model=None,\n",
    "                                        dino_patch_size=16, # Typically 14 or 16 for DINO\n",
    "                                        device=torch.device('cpu')):\n",
    "    dtype = torch.float32 # ALIKED has issues with float16\n",
    "    aliked_extractor = ALIKED(max_num_keypoints=num_features, detection_threshold=0.1).eval().to(device, dtype)\n",
    "    aliked_extractor.preprocess_conf[\"resize\"] = resize_to\n",
    "    if not os.path.isdir(feature_dir):\n",
    "        os.makedirs(feature_dir)\n",
    "\n",
    "    with h5py.File(f'{feature_dir}/keypoints.h5', mode='w') as f_kp, \\\n",
    "         h5py.File(f'{feature_dir}/descriptors_aliked.h5', mode='w') as f_desc_aliked, \\\n",
    "         h5py.File(f'{feature_dir}/descriptors_combined.h5', mode='w') as f_desc_combined: # New HDF5 for combined features\n",
    "        for img_path in tqdm(img_fnames):\n",
    "            img_fname = img_path.split('/')[-1]\n",
    "            key = img_fname\n",
    "\n",
    "            with torch.inference_mode():\n",
    "                image0 = load_torch_image(img_path, device=device).to(dtype)\n",
    "                feats0 = aliked_extractor.extract(image0)\n",
    "                kpts = feats0['keypoints'].reshape(-1, 2).detach().cpu().numpy() # ALIKED keypoints (x,y)\n",
    "                descs_aliked = feats0['descriptors'].reshape(len(kpts), -1).detach().cpu().numpy() # ALIKED descriptors\n",
    "\n",
    "                # Get DINO patch features for these keypoints\n",
    "                kpts_torch = torch.from_numpy(kpts).to(device)\n",
    "                descs_dino_patch = get_dino_patch_features_for_keypoints(\n",
    "                    img_path, kpts_torch, dino_processor, dino_model, dino_patch_size, device\n",
    "                ).detach().cpu().numpy()\n",
    "\n",
    "                # Concatenate ALIKED and DINO features\n",
    "                if len(descs_aliked) > 0 and len(descs_dino_patch) > 0:\n",
    "                    combined_descs = np.concatenate((descs_aliked, descs_dino_patch), axis=1)\n",
    "                elif len(descs_aliked) > 0: # Only ALIKED if no DINO features (shouldn't happen often)\n",
    "                    combined_descs = descs_aliked\n",
    "                else: # No features found\n",
    "                    combined_descs = np.array([]) # Empty array\n",
    "\n",
    "                f_kp[key] = kpts\n",
    "                f_desc_aliked[key] = descs_aliked # Keep ALIKED descriptors for debugging or other uses\n",
    "                f_desc_combined[key] = combined_descs # Store the new combined descriptors\n",
    "    print(f\"Combined features saved to {feature_dir}/descriptors_combined.h5\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cab8a75e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T07:01:59.327038Z",
     "iopub.status.busy": "2025-05-30T07:01:59.326792Z",
     "iopub.status.idle": "2025-05-30T07:01:59.680317Z",
     "shell.execute_reply": "2025-05-30T07:01:59.679596Z"
    },
    "papermill": {
     "duration": 0.362603,
     "end_time": "2025-05-30T07:01:59.681991",
     "exception": false,
     "start_time": "2025-05-30T07:01:59.319388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans # MiniBatchKMeans is faster for large datasets\n",
    "\n",
    "# --- VLAD Aggregation Function ---\n",
    "def vlad_encode(descriptors, centroids):\n",
    "    \"\"\"\n",
    "    Performs VLAD encoding.\n",
    "\n",
    "    Args:\n",
    "        descriptors (np.ndarray): NxM array of local descriptors.\n",
    "        centroids (np.ndarray): KxM array of K-Means cluster centroids.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: 1x(K*M) VLAD descriptor.\n",
    "    \"\"\"\n",
    "    if descriptors.shape[0] == 0:\n",
    "        return np.zeros(centroids.shape[0] * centroids.shape[1], dtype=np.float32)\n",
    "\n",
    "    num_descriptors, desc_dim = descriptors.shape\n",
    "    num_centroids, _ = centroids.shape\n",
    "\n",
    "    # Assign each descriptor to its nearest centroid\n",
    "    # Using cdist for efficiency\n",
    "    distances = np.sqrt(np.sum((descriptors[:, None, :] - centroids[None, :, :])**2, axis=2))\n",
    "    # distances = cdist(descriptors, centroids, 'sqeuclidean') # Could use cdist for sqeuclidean\n",
    "    cluster_assignments = np.argmin(distances, axis=1)\n",
    "\n",
    "    # Initialize VLAD accumulator\n",
    "    vlad_accumulator = np.zeros((num_centroids, desc_dim), dtype=np.float32)\n",
    "\n",
    "    # Accumulate residuals\n",
    "    for i in range(num_descriptors):\n",
    "        cluster_idx = cluster_assignments[i]\n",
    "        residual = descriptors[i] - centroids[cluster_idx]\n",
    "        vlad_accumulator[cluster_idx] += residual\n",
    "\n",
    "    # Flatten and L2 normalize\n",
    "    vlad_descriptor = vlad_accumulator.flatten()\n",
    "    vlad_descriptor = F.normalize(torch.from_numpy(vlad_descriptor).unsqueeze(0), dim=1, p=2).squeeze(0).numpy()\n",
    "\n",
    "    return vlad_descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ef3f78e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T07:01:59.697820Z",
     "iopub.status.busy": "2025-05-30T07:01:59.697520Z",
     "iopub.status.idle": "2025-05-30T07:01:59.706429Z",
     "shell.execute_reply": "2025-05-30T07:01:59.705798Z"
    },
    "papermill": {
     "duration": 0.01811,
     "end_time": "2025-05-30T07:01:59.707584",
     "exception": false,
     "start_time": "2025-05-30T07:01:59.689474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- NEW: Get Global Descriptors using K-Means + VLAD ---\n",
    "def get_global_desc_vlad(fnames, feature_dir='.featureout', num_clusters=64, device=torch.device('cpu')):\n",
    "    \"\"\"\n",
    "    Generates global descriptors for images using K-Means + VLAD on combined ALIKED+DINO features.\n",
    "\n",
    "    Args:\n",
    "        fnames (list): List of image file paths.\n",
    "        feature_dir (str): Directory where combined descriptors are stored.\n",
    "        num_clusters (int): Number of clusters for K-Means (K in VLAD).\n",
    "        device (torch.device): Not directly used for VLAD computation, but passed for consistency.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Nx(K*M) tensor of global VLAD descriptors.\n",
    "    \"\"\"\n",
    "    all_local_descs = []\n",
    "    keys_order = [] # To maintain order of descriptors with respect to fnames\n",
    "\n",
    "    # 1. Load all combined local descriptors\n",
    "    with h5py.File(f'{feature_dir}/descriptors_combined.h5', mode='r') as f_desc_combined:\n",
    "        for img_path in tqdm(fnames, desc=\"Loading combined local descriptors for K-Means\"):\n",
    "            key = img_path.split('/')[-1]\n",
    "            if key in f_desc_combined:\n",
    "                descs = f_desc_combined[key][...]\n",
    "                if descs.shape[0] > 0:\n",
    "                    all_local_descs.append(descs)\n",
    "                    keys_order.append(key)\n",
    "\n",
    "    if not all_local_descs:\n",
    "        print(\"No combined local descriptors found. Cannot train K-Means or compute VLAD.\")\n",
    "        return torch.empty((0, num_clusters * 0), dtype=torch.float32) # Return empty tensor\n",
    "\n",
    "    # Concatenate all descriptors for K-Means training\n",
    "    all_local_descs_flat = np.concatenate(all_local_descs, axis=0)\n",
    "\n",
    "    # 2. Train K-Means on a subset of descriptors if the dataset is too large\n",
    "    # Or directly on all_local_descs_flat if memory permits\n",
    "    print(f\"Training K-Means with {num_clusters} clusters on {all_local_descs_flat.shape[0]} descriptors...\")\n",
    "    # Use MiniBatchKMeans for efficiency\n",
    "    kmeans = MiniBatchKMeans(n_clusters=num_clusters, random_state=0, n_init='auto', batch_size=256).fit(all_local_descs_flat)\n",
    "    centroids = kmeans.cluster_centers_\n",
    "    print(\"K-Means training complete.\")\n",
    "\n",
    "    # 3. Compute VLAD descriptor for each image\n",
    "    global_descs_vlad = []\n",
    "    # Re-iterate through original fnames to match the output order\n",
    "    with h5py.File(f'{feature_dir}/descriptors_combined.h5', mode='r') as f_desc_combined:\n",
    "        for img_path in tqdm(fnames, desc=\"Computing VLAD descriptors\"):\n",
    "            key = img_path.split('/')[-1]\n",
    "            if key in f_desc_combined:\n",
    "                descs = f_desc_combined[key][...]\n",
    "                vlad_desc = vlad_encode(descs, centroids)\n",
    "                global_descs_vlad.append(torch.from_numpy(vlad_desc).unsqueeze(0))\n",
    "            else:\n",
    "                # Handle cases where an image might not have any combined descriptors\n",
    "                # (e.g., no ALIKED keypoints detected). Append a zero vector of correct size.\n",
    "                print(f\"Warning: No combined descriptors for {key}. Appending zero VLAD descriptor.\")\n",
    "                # Determine descriptor dimension from centroids\n",
    "                desc_dim_per_cluster = centroids.shape[1] if centroids.shape[1] > 0 else 0 # Should not be 0 normally\n",
    "                zero_vlad = np.zeros(num_clusters * desc_dim_per_cluster, dtype=np.float32)\n",
    "                global_descs_vlad.append(torch.from_numpy(zero_vlad).unsqueeze(0))\n",
    "\n",
    "\n",
    "    if not global_descs_vlad:\n",
    "        return torch.empty((0, num_clusters * centroids.shape[1] if centroids.shape[1] > 0 else 0), dtype=torch.float32)\n",
    "\n",
    "    global_descs_vlad = torch.cat(global_descs_vlad, dim=0)\n",
    "    return global_descs_vlad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36582e4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T07:01:59.722266Z",
     "iopub.status.busy": "2025-05-30T07:01:59.722042Z",
     "iopub.status.idle": "2025-05-30T07:01:59.729592Z",
     "shell.execute_reply": "2025-05-30T07:01:59.728972Z"
    },
    "papermill": {
     "duration": 0.016247,
     "end_time": "2025-05-30T07:01:59.730920",
     "exception": false,
     "start_time": "2025-05-30T07:01:59.714673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- RE-DEFINED: get_image_pairs_shortlist to use the new VLAD global descriptor ---\n",
    "def get_image_pairs_shortlist_vlad(fnames,\n",
    "                                   sim_th=0.6, # should be strict\n",
    "                                   min_pairs=30,\n",
    "                                   exhaustive_if_less=20,\n",
    "                                   feature_dir='.featureout', # Pass feature_dir\n",
    "                                   num_clusters_vlad=64, # New parameter for VLAD\n",
    "                                   device=torch.device('cpu')):\n",
    "    num_imgs = len(fnames)\n",
    "    if num_imgs <= exhaustive_if_less:\n",
    "        return get_img_pairs_exhaustive(fnames) # You need to define get_img_pairs_exhaustive if not done.\n",
    "\n",
    "    # Use the new VLAD-based global descriptor\n",
    "    descs = get_global_desc_vlad(fnames, feature_dir=feature_dir, num_clusters=num_clusters_vlad, device=device)\n",
    "\n",
    "    if descs.shape[0] == 0:\n",
    "        print(\"No global descriptors generated. Returning empty matching list.\")\n",
    "        return []\n",
    "\n",
    "    dm = torch.cdist(descs, descs, p=2).detach().cpu().numpy()\n",
    "\n",
    "    # \n",
    "    triu_indices = np.triu_indices_from(dm, k=1)\n",
    "    dm_flat = dm[triu_indices]\n",
    "    \n",
    "    # \n",
    "    print(\"Distance Matrix Statistics:\")\n",
    "    print(f\"Min:  {dm_flat.min():.4f}\")\n",
    "    print(f\"Max:  {dm_flat.max():.4f}\")\n",
    "    print(f\"Mean: {dm_flat.mean():.4f}\")\n",
    "    print(f\"Std:  {dm_flat.std():.4f}\")\n",
    "    print(f\"20%:  {np.percentile(dm_flat, 20):.4f}\")\n",
    "    print(f\"25%:  {np.percentile(dm_flat, 25):.4f}\")\n",
    "    print(f\"USED 60%:  {np.percentile(dm_flat, 60):.4f}\")\n",
    "    print(f\"75%:  {np.percentile(dm_flat, 75):.4f}\")\n",
    "    threshold = np.percentile(dm_flat, 60) + np.sqrt(3) * dm_flat.std()\n",
    "\n",
    "    # removing half\n",
    "    mask = dm <= np.percentile(dm_flat, 60)\n",
    "    total = 0\n",
    "    matching_list = []\n",
    "    ar = np.arange(num_imgs)\n",
    "    already_there_set = set() # Use a set for faster lookup of already added pairs\n",
    "\n",
    "    for st_idx in range(num_imgs - 1):\n",
    "        mask_idx = mask[st_idx]\n",
    "        to_match = ar[mask_idx]\n",
    "        if len(to_match) < min_pairs:\n",
    "            to_match = np.argsort(dm[st_idx])[:min_pairs]\n",
    "\n",
    "        for idx in to_match:\n",
    "            if st_idx == idx:\n",
    "                continue\n",
    "            if dm[st_idx, idx] < threshold: # Ensure distance is not effectively infinite\n",
    "                pair = tuple(sorted((st_idx, idx.item())))\n",
    "                if pair not in already_there_set:\n",
    "                    matching_list.append(pair)\n",
    "                    already_there_set.add(pair)\n",
    "                    total += 1\n",
    "    matching_list = sorted(list(matching_list)) # Sort the list of tuples\n",
    "    return matching_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9d27054",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T07:01:59.745382Z",
     "iopub.status.busy": "2025-05-30T07:01:59.745142Z",
     "iopub.status.idle": "2025-05-30T07:01:59.748616Z",
     "shell.execute_reply": "2025-05-30T07:01:59.747984Z"
    },
    "papermill": {
     "duration": 0.012156,
     "end_time": "2025-05-30T07:01:59.750040",
     "exception": false,
     "start_time": "2025-05-30T07:01:59.737884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_img_pairs_exhaustive(img_fnames):\n",
    "    index_pairs = []\n",
    "    for i in range(len(img_fnames)):\n",
    "        for j in range(i+1, len(img_fnames)):\n",
    "            index_pairs.append((i,j))\n",
    "    return index_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71398231",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T07:01:59.766331Z",
     "iopub.status.busy": "2025-05-30T07:01:59.766108Z",
     "iopub.status.idle": "2025-05-30T07:01:59.776591Z",
     "shell.execute_reply": "2025-05-30T07:01:59.775979Z"
    },
    "papermill": {
     "duration": 0.019388,
     "end_time": "2025-05-30T07:01:59.777869",
     "exception": false,
     "start_time": "2025-05-30T07:01:59.758481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Must Use efficientnet global descriptor to get matching shortlists.\n",
    "def get_global_desc(fnames, device = torch.device('cpu')):\n",
    "    processor = AutoImageProcessor.from_pretrained('/kaggle/input/dinov2/pytorch/base/1')\n",
    "    model = AutoModel.from_pretrained('/kaggle/input/dinov2/pytorch/base/1')\n",
    "    model = model.eval()\n",
    "    model = model.to(device)\n",
    "    global_descs_dinov2 = []\n",
    "    for i, img_fname_full in tqdm(enumerate(fnames),total= len(fnames)):\n",
    "        key = os.path.splitext(os.path.basename(img_fname_full))[0]\n",
    "        timg = load_torch_image(img_fname_full)\n",
    "        with torch.inference_mode():\n",
    "            inputs = processor(images=timg, return_tensors=\"pt\", do_rescale=False).to(device)\n",
    "            outputs = model(**inputs)\n",
    "            dino_mac = F.normalize(outputs.last_hidden_state[:,1:].max(dim=1)[0], dim=1, p=2)\n",
    "        global_descs_dinov2.append(dino_mac.detach().cpu())\n",
    "    global_descs_dinov2 = torch.cat(global_descs_dinov2, dim=0)\n",
    "    return global_descs_dinov2\n",
    "\n",
    "\n",
    "def get_img_pairs_exhaustive(img_fnames):\n",
    "    index_pairs = []\n",
    "    for i in range(len(img_fnames)):\n",
    "        for j in range(i+1, len(img_fnames)):\n",
    "            index_pairs.append((i,j))\n",
    "    return index_pairs\n",
    "\n",
    "\n",
    "def get_image_pairs_shortlist(fnames,\n",
    "                              sim_th=0.6,\n",
    "                              min_pairs=30,\n",
    "                              max_pairs=100,  #  max_pairs \n",
    "                              exhaustive_if_less=20,\n",
    "                              device=torch.device('cpu')):\n",
    "    num_imgs = len(fnames)\n",
    "    if num_imgs <= exhaustive_if_less:\n",
    "        return get_img_pairs_exhaustive(fnames)\n",
    "\n",
    "    descs = get_global_desc(fnames, device=device)\n",
    "    dm = torch.cdist(descs, descs, p=2).detach().cpu().numpy()\n",
    "\n",
    "    # \n",
    "    triu_indices = np.triu_indices_from(dm, k=1)\n",
    "    dm_flat = dm[triu_indices]\n",
    "\n",
    "    print(\"Distance Matrix Statistics:\")\n",
    "    print(f\"Min:  {dm_flat.min():.4f}\")\n",
    "    print(f\"Max:  {dm_flat.max():.4f}\")\n",
    "    print(f\"Mean: {dm_flat.mean():.4f}\")\n",
    "    print(f\"Std:  {dm_flat.std():.4f}\")\n",
    "    print(f\"20%:  {np.percentile(dm_flat, 20):.4f}\")\n",
    "    print(f\"25%:  {np.percentile(dm_flat, 25):.4f}\")\n",
    "    print(f\"60%:  {np.percentile(dm_flat, 60):.4f}\")\n",
    "    print(f\"75%:  {np.percentile(dm_flat, 75):.4f}\")\n",
    "\n",
    "    threshold = np.percentile(dm_flat, 60) + np.sqrt(3) * dm_flat.std()\n",
    "    mask = dm <= np.percentile(dm_flat, 50)\n",
    "\n",
    "    ar = np.arange(num_imgs)\n",
    "    matching_set = set()\n",
    "\n",
    "    for st_idx in range(num_imgs):\n",
    "        mask_idx = mask[st_idx]\n",
    "        to_match = ar[mask_idx]\n",
    "\n",
    "        #  min_pairs \n",
    "        if len(to_match) < min_pairs:\n",
    "            to_match = np.argsort(dm[st_idx])[:min_pairs]\n",
    "\n",
    "        #  max_pairs\n",
    "        sorted_matches = sorted(\n",
    "            [(idx, dm[st_idx, idx]) for idx in to_match if idx != st_idx and dm[st_idx, idx] < threshold],\n",
    "            key=lambda x: x[1]\n",
    "        )\n",
    "        for idx, _ in sorted_matches[:max_pairs]:\n",
    "            pair = tuple(sorted((st_idx, idx)))\n",
    "            matching_set.add(pair)\n",
    "\n",
    "    matching_list = sorted(list(matching_set))\n",
    "    return matching_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eeddc411",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T07:01:59.792886Z",
     "iopub.status.busy": "2025-05-30T07:01:59.792641Z",
     "iopub.status.idle": "2025-05-30T07:01:59.813443Z",
     "shell.execute_reply": "2025-05-30T07:01:59.812592Z"
    },
    "papermill": {
     "duration": 0.029544,
     "end_time": "2025-05-30T07:01:59.814720",
     "exception": false,
     "start_time": "2025-05-30T07:01:59.785176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def wrapper_keypoints(\n",
    "    img_fnames, index_pairs, feature_dir, device, timings, rots\n",
    "):\n",
    "    #############################################################\n",
    "    # get keypoints\n",
    "    #############################################################\n",
    "    files_keypoints = []\n",
    "    \n",
    "    if CONFIG.use_superglue:\n",
    "        for params_sg in CONFIG.params_sgs:\n",
    "            resize_to = params_sg[\"resize_to\"]\n",
    "            file_keypoints = f\"{feature_dir}/matches_superglue_{resize_to}pix.h5\"\n",
    "            !rm -rf {file_keypoints}\n",
    "            t = detect_superglue(\n",
    "                img_fnames, index_pairs, feature_dir, device, \n",
    "                params_sg[\"sg_config\"], file_keypoints, \n",
    "                resize_to=params_sg[\"resize_to\"], \n",
    "                min_matches=params_sg[\"min_matches\"],\n",
    "            )\n",
    "            gc.collect()\n",
    "            files_keypoints.append( file_keypoints )\n",
    "            timings['feature_matching'].append(t)\n",
    "\n",
    "    if CONFIG.use_aliked_lightglue:\n",
    "        model_name = \"aliked\"\n",
    "        file_keypoints = f'{feature_dir}/matches_lightglue_{model_name}.h5'\n",
    "        t = detect_lightglue_common(\n",
    "            img_fnames, model_name, index_pairs, feature_dir, device, file_keypoints, rots,\n",
    "            resize_to=CONFIG.params_aliked_lightglue[\"resize_to\"],\n",
    "            detection_threshold=CONFIG.params_aliked_lightglue[\"detection_threshold\"],\n",
    "            num_features=CONFIG.params_aliked_lightglue[\"num_features\"],\n",
    "            min_matches=CONFIG.params_aliked_lightglue[\"min_matches\"],\n",
    "            match_confidence_threshold=CONFIG.params_aliked_lightglue[\"match_confidence_threshold\"]\n",
    "        )\n",
    "        gc.collect()\n",
    "        files_keypoints.append(file_keypoints)\n",
    "        timings['feature_matching'].append(t)\n",
    "\n",
    "    if CONFIG.use_doghardnet_lightglue:\n",
    "        model_name = \"doghardnet\"\n",
    "        file_keypoints = f'{feature_dir}/matches_lightglue_{model_name}.h5'\n",
    "        t = detect_lightglue_common(\n",
    "            img_fnames, model_name, index_pairs, feature_dir, device, file_keypoints, rots,\n",
    "            resize_to=CONFIG.params_doghardnet_lightglue[\"resize_to\"],\n",
    "            detection_threshold=CONFIG.params_doghardnet_lightglue[\"detection_threshold\"],\n",
    "            num_features=CONFIG.params_doghardnet_lightglue[\"num_features\"],\n",
    "            min_matches=CONFIG.params_doghardnet_lightglue[\"min_matches\"],\n",
    "        )\n",
    "        gc.collect()\n",
    "        files_keypoints.append(file_keypoints)\n",
    "        timings['feature_matching'].append(t)\n",
    "\n",
    "    if CONFIG.use_superpoint_lightglue:\n",
    "        model_name = \"superpoint\"\n",
    "        file_keypoints = f'{feature_dir}/matches_lightglue_{model_name}.h5'\n",
    "        t = detect_lightglue_common(\n",
    "            img_fnames, model_name, index_pairs, feature_dir, device, file_keypoints, rots,\n",
    "            resize_to=CONFIG.params_superpoint_lightglue[\"resize_to\"],\n",
    "            detection_threshold=CONFIG.params_superpoint_lightglue[\"detection_threshold\"],\n",
    "            num_features=CONFIG.params_superpoint_lightglue[\"num_features\"],\n",
    "            min_matches=CONFIG.params_superpoint_lightglue[\"min_matches\"],\n",
    "            match_confidence_threshold=CONFIG.params_superpoint_lightglue[\"match_confidence_threshold\"]\n",
    "        )\n",
    "        gc.collect()\n",
    "        files_keypoints.append(file_keypoints)\n",
    "        timings['feature_matching'].append(t)\n",
    "\n",
    "    if CONFIG.use_disk_lightglue:\n",
    "        model_name = \"disk\"\n",
    "        file_keypoints = f'{feature_dir}/matches_lightglue_{model_name}.h5'\n",
    "        t = detect_lightglue_common(\n",
    "            img_fnames, model_name, index_pairs, feature_dir, device, file_keypoints, rots,\n",
    "            resize_to=CONFIG.params_disk_lightglue[\"resize_to\"],\n",
    "            detection_threshold=CONFIG.params_disk_lightglue[\"detection_threshold\"],\n",
    "            num_features=CONFIG.params_disk_lightglue[\"num_features\"],\n",
    "            min_matches=CONFIG.params_disk_lightglue[\"min_matches\"],\n",
    "            match_confidence_threshold=CONFIG.params_disk_lightglue[\"match_confidence_threshold\"]\n",
    "        )\n",
    "        gc.collect()\n",
    "        files_keypoints.append(file_keypoints)\n",
    "        timings['feature_matching'].append(t)\n",
    "\n",
    "    if CONFIG.use_sift_lightglue:\n",
    "        model_name = \"sift\"\n",
    "        file_keypoints = f'{feature_dir}/matches_lightglue_{model_name}.h5'\n",
    "        t = detect_lightglue_common(\n",
    "            img_fnames, model_name, index_pairs, feature_dir, device, file_keypoints, rots,\n",
    "            resize_to=CONFIG.params_sift_lightglue[\"resize_to\"],\n",
    "            detection_threshold=CONFIG.params_sift_lightglue[\"detection_threshold\"],\n",
    "            num_features=CONFIG.params_sift_lightglue[\"num_features\"],\n",
    "            min_matches=CONFIG.params_sift_lightglue[\"min_matches\"],\n",
    "        )\n",
    "        gc.collect()\n",
    "        files_keypoints.append(file_keypoints)\n",
    "        timings['feature_matching'].append(t)\n",
    "\n",
    "    if CONFIG.use_loftr:\n",
    "        file_keypoints = f'{feature_dir}/matches_loftr_{CONFIG.params_loftr[\"resize_small_edge_to\"]}pix.h5'\n",
    "        t = detect_loftr(\n",
    "            img_fnames, index_pairs, feature_dir, device, file_keypoints,\n",
    "            resize_small_edge_to=CONFIG.params_loftr[\"resize_small_edge_to\"],\n",
    "            min_matches=CONFIG.params_loftr[\"min_matches\"],\n",
    "        )\n",
    "        gc.collect()\n",
    "        files_keypoints.append( file_keypoints )\n",
    "        timings['feature_matching'].append(t)\n",
    "\n",
    "    if CONFIG.use_dkm:\n",
    "        file_keypoints = f'{feature_dir}/matches_dkm.h5'\n",
    "        t = detect_dkm(\n",
    "            img_fnames, index_pairs, feature_dir, device, file_keypoints,\n",
    "            resize_to=CONFIG.params_dkm[\"resize_to\"], \n",
    "            detection_threshold=CONFIG.params_dkm[\"detection_threshold\"], \n",
    "            num_features=CONFIG.params_dkm[\"num_features\"], \n",
    "            min_matches=CONFIG.params_dkm[\"min_matches\"]\n",
    "        )\n",
    "        gc.collect()\n",
    "        files_keypoints.append(file_keypoints)\n",
    "        timings['feature_matching'].append(t)\n",
    "\n",
    "    if CONFIG.use_matchformer:\n",
    "        file_keypoints = f'{feature_dir}/matches_matchformer_{CONFIG.params_matchformer[\"resize_to\"]}pix.h5'\n",
    "        t = detect_matchformer(\n",
    "            img_fnames, index_pairs, feature_dir, device, file_keypoints,\n",
    "            resize_to=CONFIG.params_matchformer[\"resize_to\"],\n",
    "            num_features=CONFIG.params_matchformer[\"num_features\"], \n",
    "            min_matches=CONFIG.params_matchformer[\"min_matches\"]\n",
    "        )\n",
    "        gc.collect()\n",
    "        files_keypoints.append( file_keypoints )\n",
    "        timings['feature_matching'].append(t)\n",
    "\n",
    "    #############################################################\n",
    "    # merge keypoints\n",
    "    #############################################################\n",
    "    keypoints_merger(\n",
    "        img_fnames,\n",
    "        index_pairs,\n",
    "        files_keypoints,\n",
    "        feature_dir = feature_dir,\n",
    "        filter_FundamentalMatrix = CONFIG.MERGE_PARAMS[\"filter_FundamentalMatrix\"],\n",
    "        filter_iterations = CONFIG.MERGE_PARAMS[\"filter_iterations\"],\n",
    "        filter_threshold = CONFIG.MERGE_PARAMS[\"filter_threshold\"],\n",
    "    )    \n",
    "    return timings\n",
    "\n",
    "\n",
    "def import_into_colmap(img_dir, feature_dir ='.featureout', database_path = 'colmap.db'):\n",
    "    db = COLMAPDatabase.connect(database_path)\n",
    "    db.create_tables()\n",
    "    single_camera = False\n",
    "    fname_to_id = add_keypoints(db, feature_dir, img_dir, '', 'simple-pinhole', single_camera)\n",
    "    add_matches(\n",
    "        db,\n",
    "        feature_dir,\n",
    "        fname_to_id,\n",
    "    )\n",
    "    db.commit()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1eb5653e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T07:01:59.828977Z",
     "iopub.status.busy": "2025-05-30T07:01:59.828738Z",
     "iopub.status.idle": "2025-05-30T07:01:59.838032Z",
     "shell.execute_reply": "2025-05-30T07:01:59.837145Z"
    },
    "papermill": {
     "duration": 0.017862,
     "end_time": "2025-05-30T07:01:59.839244",
     "exception": false,
     "start_time": "2025-05-30T07:01:59.821382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def find_connected_components(pairs):\n",
    "    graph = defaultdict(set)\n",
    "    for i, j in pairs:\n",
    "        graph[i].add(j)\n",
    "        graph[j].add(i)\n",
    "\n",
    "    visited = set()\n",
    "    components = []\n",
    "\n",
    "    def dfs(u, comp):\n",
    "        visited.add(u)\n",
    "        comp.append(u)\n",
    "        for v in graph[u]:\n",
    "            if v not in visited:\n",
    "                dfs(v, comp)\n",
    "\n",
    "    for node in graph:\n",
    "        if node not in visited:\n",
    "            comp = []\n",
    "            dfs(node, comp)\n",
    "            components.append(comp)\n",
    "\n",
    "    return components\n",
    "\n",
    "\n",
    "def affine_matrix_from_points(v0, v1):\n",
    "    v0 = np.array(v0, dtype=np.float64, copy=True)\n",
    "    v1 = np.array(v1, dtype=np.float64, copy=True)\n",
    "    t0 = -np.mean(v0, axis=1)\n",
    "    t1 = -np.mean(v1, axis=1)\n",
    "    v0 += t0.reshape(3, 1)\n",
    "    v1 += t1.reshape(3, 1)\n",
    "    u, s, vh = np.linalg.svd(np.dot(v1, v0.T))\n",
    "    R = np.dot(u, vh)\n",
    "    if np.linalg.det(R) < 0:\n",
    "        R[:, -1] *= -1\n",
    "    scale = np.linalg.norm(v1) / np.linalg.norm(v0)\n",
    "    T = np.eye(4)\n",
    "    T[:3, :3] = scale * R\n",
    "    T[:3, 3] = np.mean(v1, axis=1) - np.dot(scale * R, np.mean(v0, axis=1))\n",
    "    return T\n",
    "\n",
    "\n",
    "def register_by_Horn(ev_coord, gt_coord, threshold=1.0):\n",
    "    if ev_coord.shape[1] < 3:\n",
    "        return None\n",
    "    T = affine_matrix_from_points(ev_coord, gt_coord)\n",
    "    transformed = (T[:3, :3] @ ev_coord) + T[:3, 3:4]\n",
    "    err = np.linalg.norm(transformed - gt_coord, axis=0)\n",
    "    inliers = err < threshold\n",
    "    if np.sum(inliers) < 3:\n",
    "        return None\n",
    "    T_refined = affine_matrix_from_points(ev_coord[:, inliers], gt_coord[:, inliers])\n",
    "    return T_refined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e3c60ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T07:01:59.853813Z",
     "iopub.status.busy": "2025-05-30T07:01:59.853577Z",
     "iopub.status.idle": "2025-05-30T07:01:59.865188Z",
     "shell.execute_reply": "2025-05-30T07:01:59.864538Z"
    },
    "papermill": {
     "duration": 0.020839,
     "end_time": "2025-05-30T07:01:59.867105",
     "exception": false,
     "start_time": "2025-05-30T07:01:59.846266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reconstruct_from_db(feature_dir, img_dir):\n",
    "    result = {}\n",
    "    local_timings = {'RANSAC': [], 'Reconstruction': []}\n",
    "    database_path = f'{feature_dir}/colmap.db'\n",
    "    if os.path.isfile(database_path):\n",
    "        os.remove(database_path)\n",
    "    gc.collect()\n",
    "    import_into_colmap(img_dir, feature_dir=feature_dir, database_path=database_path)\n",
    "    output_path = f'{feature_dir}/colmap_rec'\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    t = time()\n",
    "    pycolmap.match_exhaustive(database_path)\n",
    "    local_timings['RANSAC'].append(time() - t)\n",
    "\n",
    "    t = time()\n",
    "    mapper_options = pycolmap.IncrementalPipelineOptions()\n",
    "    mapper_options.min_model_size = 5\n",
    "    mapper_options.max_num_models = 12\n",
    "    maps = pycolmap.incremental_mapping(database_path=database_path, image_path=img_dir,\n",
    "                                        output_path=output_path, options=mapper_options)\n",
    "    print(\"Original results\")\n",
    "    print(maps)\n",
    "    local_timings['Reconstruction'].append(time() - t)\n",
    "\n",
    "    map_ids = list(maps.keys())\n",
    "    map_graph = {}\n",
    "    for i, j in combinations(map_ids, 2):\n",
    "        shared = []\n",
    "        for name in maps[i].images:\n",
    "            if name in maps[j].images:\n",
    "                C_i = -maps[i].images[name].cam_from_world.rotation.matrix().T @ maps[i].images[name].cam_from_world.translation\n",
    "                C_j = -maps[j].images[name].cam_from_world.rotation.matrix().T @ maps[j].images[name].cam_from_world.translation\n",
    "                shared.append((C_i.reshape(3, 1), C_j.reshape(3, 1)))\n",
    "        if len(shared) >= 3:\n",
    "            u, g = zip(*shared)\n",
    "            u = np.concatenate(u, axis=1)\n",
    "            g = np.concatenate(g, axis=1)\n",
    "            T_ij = register_by_Horn(u, g)\n",
    "            if T_ij is not None:\n",
    "                map_graph[(i, j)] = T_ij\n",
    "    print(map_graph)\n",
    "    connected_components = find_connected_components(map_graph.keys())\n",
    "    for group in connected_components:\n",
    "        transforms = {group[0]: np.eye(4)}\n",
    "        queue = [group[0]]\n",
    "        while queue:\n",
    "            current = queue.pop(0)\n",
    "            for other in group:\n",
    "                if other == current or other in transforms:\n",
    "                    continue\n",
    "                if (current, other) in map_graph:\n",
    "                    transforms[other] = map_graph[(current, other)] @ transforms[current]\n",
    "                    queue.append(other)\n",
    "                elif (other, current) in map_graph:\n",
    "                    transforms[other] = np.linalg.inv(map_graph[(other, current)]) @ transforms[current]\n",
    "                    queue.append(other)\n",
    "\n",
    "        for map_index in group:\n",
    "            result[map_index] = {}\n",
    "            T = transforms.get(map_index, np.eye(4))\n",
    "            for img_id, image in maps[map_index].images.items():\n",
    "                T_cam = np.eye(4)\n",
    "                T_cam[:3, :3] = image.cam_from_world.rotation.matrix()\n",
    "                T_cam[:3, 3] = image.cam_from_world.translation\n",
    "                T_global = T @ T_cam\n",
    "                result[map_index][image.name] = {\n",
    "                    'R': T_global[:3, :3].tolist(),\n",
    "                    't': T_global[:3, 3].tolist()\n",
    "                }\n",
    "\n",
    "    for map_index in maps:\n",
    "        if map_index not in result:\n",
    "            result[map_index] = {}\n",
    "            for img_id, image in maps[map_index].images.items():\n",
    "                result[map_index][image.name] = {\n",
    "                    'R': image.cam_from_world.rotation.matrix().tolist(),\n",
    "                    't': image.cam_from_world.translation.tolist()\n",
    "                }\n",
    "    if VERBOSE:\n",
    "        for map_index in maps:\n",
    "            for img_id, image in maps[map_index].images.items():\n",
    "                print(f\"map {map_index}:{image}\")\n",
    "    return result, local_timings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f94c12f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T07:01:59.881153Z",
     "iopub.status.busy": "2025-05-30T07:01:59.880952Z",
     "iopub.status.idle": "2025-05-30T07:02:00.042133Z",
     "shell.execute_reply": "2025-05-30T07:02:00.041285Z"
    },
    "papermill": {
     "duration": 0.169791,
     "end_time": "2025-05-30T07:02:00.043519",
     "exception": false,
     "start_time": "2025-05-30T07:01:59.873728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset \"imc2023_haiper\" -> num_images=54\n",
      "Dataset \"imc2023_heritage\" -> num_images=209\n",
      "Dataset \"imc2023_theather_imc2024_church\" -> num_images=76\n",
      "Dataset \"imc2024_dioscuri_baalshamin\" -> num_images=138\n",
      "Dataset \"imc2024_lizard_pond\" -> num_images=214\n",
      "Dataset \"pt_brandenburg_british_buckingham\" -> num_images=225\n",
      "Dataset \"pt_piazzasanmarco_grandplace\" -> num_images=168\n",
      "Dataset \"pt_sacrecoeur_trevi_tajmahal\" -> num_images=225\n",
      "Dataset \"pt_stpeters_stpauls\" -> num_images=200\n",
      "Dataset \"amy_gardens\" -> num_images=200\n",
      "Dataset \"fbk_vineyard\" -> num_images=163\n",
      "Dataset \"ETs\" -> num_images=22\n",
      "Dataset \"stairs\" -> num_images=51\n"
     ]
    }
   ],
   "source": [
    "# Collect vital info from the dataset\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class Prediction:\n",
    "    image_id: str | None  # A unique identifier for the row -- unused otherwise. Used only on the hidden test set.\n",
    "    dataset: str\n",
    "    filename: str\n",
    "    cluster_index: int | None = None\n",
    "    rotation: np.ndarray | None = None\n",
    "    translation: np.ndarray | None = None\n",
    "\n",
    "# Set is_train=True to run the notebook on the training data.\n",
    "# Set is_train=False if submitting an entry to the competition (test data is hidden, and different from what you see on the \"test\" folder).\n",
    "is_train = True\n",
    "data_dir = '/kaggle/input/image-matching-challenge-2025'\n",
    "workdir = '/kaggle/working/result/'\n",
    "os.makedirs(workdir, exist_ok=True)\n",
    "\n",
    "if is_train:\n",
    "    sample_submission_csv = os.path.join(data_dir, 'train_labels.csv')\n",
    "else:\n",
    "    sample_submission_csv = os.path.join(data_dir, 'sample_submission.csv')\n",
    "\n",
    "samples = {}\n",
    "competition_data = pd.read_csv(sample_submission_csv)\n",
    "for _, row in competition_data.iterrows():\n",
    "    # Note: For the test data, the \"scene\" column has no meaning, and the rotation_matrix and translation_vector columns are random.\n",
    "    if row.dataset not in samples:\n",
    "        samples[row.dataset] = []\n",
    "    samples[row.dataset].append(\n",
    "        Prediction(\n",
    "            image_id=None if is_train else row.image_id,\n",
    "            dataset=row.dataset,\n",
    "            filename=row.image\n",
    "        )\n",
    "    )\n",
    "\n",
    "for dataset in samples:\n",
    "    print(f'Dataset \"{dataset}\" -> num_images={len(samples[dataset])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d19213d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T07:02:00.058330Z",
     "iopub.status.busy": "2025-05-30T07:02:00.058114Z",
     "iopub.status.idle": "2025-05-30T07:02:00.073235Z",
     "shell.execute_reply": "2025-05-30T07:02:00.072583Z"
    },
    "papermill": {
     "duration": 0.024071,
     "end_time": "2025-05-30T07:02:00.074428",
     "exception": false,
     "start_time": "2025-05-30T07:02:00.050357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "\n",
    "def draw_keypoints_and_matches(images_input, unified_kp_path, remapped_matches_path, feature_dir='visualization_output'):\n",
    "    output_dir = os.path.join(feature_dir, 'visualization_output')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Load images and determine image_keys for HDF5 lookup\n",
    "    if isinstance(images_input[0], str):\n",
    "        loaded_images = [cv2.imread(img_path) for img_path in images_input]\n",
    "        image_keys = [os.path.basename(img_path) for img_path in images_input]\n",
    "    else:\n",
    "        loaded_images = images_input\n",
    "        # If images_input are already arrays, you need to provide the corresponding keys\n",
    "        # This part is crucial: image_keys MUST align with the HDF5 keys\n",
    "        image_keys = image_keys_in_h5 # Use the predefined list for the dummy case\n",
    "\n",
    "    # Load unified keypoints\n",
    "    keypoints_data = {}\n",
    "    with h5py.File(unified_kp_path, 'r') as f_kp:\n",
    "        for img_name_raw in f_kp.keys():\n",
    "            img_name = img_name_raw.decode('utf-8') if isinstance(img_name_raw, bytes) else img_name_raw\n",
    "            keypoints_data[img_name] = f_kp[img_name_raw][()] # Access with raw key if bytes\n",
    "\n",
    "    # Load remapped matches - CORRECTED LOGIC\n",
    "    # Store (img1_key, img2_key) directly with matches for robust iteration\n",
    "    matches_data_pairs = [] # Will store (img1_key, img2_key, matches_array)\n",
    "    with h5py.File(remapped_matches_path, 'r') as f_matches:\n",
    "        print(\"\\n--- Loading remapped matches from HDF5 ---\")\n",
    "        for img1_group_key_candidate in tqdm(f_matches.keys(), desc=\"Loading matches\"):\n",
    "            img1_key = img1_group_key_candidate.decode('utf-8') if isinstance(img1_group_key_candidate, bytes) else img1_group_key_candidate\n",
    "\n",
    "            img1_group = f_matches[img1_group_key_candidate] # Access with raw key\n",
    "\n",
    "            if isinstance(img1_group, h5py.Group):\n",
    "                for img2_dataset_key_candidate in img1_group.keys():\n",
    "                    img2_key = img2_dataset_key_candidate.decode('utf-8') if isinstance(img2_dataset_key_candidate, bytes) else img2_dataset_key_candidate\n",
    "\n",
    "                    try:\n",
    "                        matches_array = img1_group[img2_dataset_key_candidate][()]\n",
    "                        matches_data_pairs.append((img1_key, img2_key, matches_array))\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error loading matches for pair ({img1_key}, {img2_key}): {e}\")\n",
    "            else:\n",
    "                print(f\"Warning: Expected '{img1_key}' to be a group, but found {type(img1_group)}. Skipping its contents.\")\n",
    "\n",
    "\n",
    "    # --- Drawing Keypoints ---\n",
    "    print(\"\\n--- Drawing Keypoints ---\")\n",
    "    for i, img_key in enumerate(image_keys):\n",
    "        if img_key in keypoints_data:\n",
    "            img = loaded_images[i].copy()\n",
    "            kpts = keypoints_data[img_key]\n",
    "\n",
    "            for kp in kpts:\n",
    "                x, y = int(kp[0]), int(kp[1])\n",
    "                cv2.circle(img, (x, y), 3, (0, 255, 0), -1) # Green circle for keypoint\n",
    "\n",
    "            output_kp_path = os.path.join(output_dir, f\"keypoints_{img_key}\")\n",
    "            if len(img.shape) == 2:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "            cv2.imwrite(output_kp_path, img)\n",
    "            print(f\"Keypoints drawn on {img_key}, saved to {output_kp_path}\")\n",
    "        else:\n",
    "            print(f\"No keypoints found for {img_key} in unified keypoints file.\")\n",
    "\n",
    "    # --- Drawing Matches ---\n",
    "    print(\"\\n--- Drawing Matches ---\")\n",
    "    # Iterate through the (img1_key, img2_key, matches) tuples directly\n",
    "    for img_name1, img_name2, matches in matches_data_pairs:\n",
    "        # We no longer need to split img_pair_key, as we have img_name1 and img_name2 directly\n",
    "\n",
    "        # Find the actual image objects and their keypoints using image_keys list\n",
    "        try:\n",
    "            img1_idx = image_keys.index(img_name1)\n",
    "            img2_idx = image_keys.index(img_name2)\n",
    "        except ValueError:\n",
    "            print(f\"Skipping matches for {img_name1}-{img_name2}: One or both image names not found in the provided 'images' list/keys.\")\n",
    "            continue\n",
    "\n",
    "        img1 = loaded_images[img1_idx].copy()\n",
    "        img2 = loaded_images[img2_idx].copy()\n",
    "\n",
    "        kpts1 = keypoints_data.get(img_name1)\n",
    "        kpts2 = keypoints_data.get(img_name2)\n",
    "\n",
    "        if kpts1 is None or kpts2 is None:\n",
    "            print(f\"Skipping matches for {img_name1}-{img_name2}: keypoints not found for one or both images in unified keypoints.\")\n",
    "            continue\n",
    "        if len(matches) == 0:\n",
    "            print(f\"No matches to draw for {img_name1}-{img_name2}.\")\n",
    "            continue\n",
    "\n",
    "        # Ensure images are 3 channels for drawing lines\n",
    "        if len(img1.shape) == 2:\n",
    "            img1 = cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR)\n",
    "        if len(img2.shape) == 2:\n",
    "            img2 = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        # Create a concatenated image for drawing matches\n",
    "        h1, w1 = img1.shape[:2]\n",
    "        h2, w2 = img2.shape[:2]\n",
    "        max_h = max(h1, h2)\n",
    "        matched_img = np.zeros((max_h, w1 + w2, 3), dtype=np.uint8)\n",
    "        matched_img[0:h1, 0:w1] = img1\n",
    "        matched_img[0:h2, w1:w1+w2] = img2\n",
    "\n",
    "        num_matches_to_draw = min(len(matches), 200) # Draw up to 200 matches to avoid clutter, adjust as needed\n",
    "\n",
    "        for i in range(num_matches_to_draw):\n",
    "            match = matches[i]\n",
    "            kp1_idx, kp2_idx = int(match[0]), int(match[1])\n",
    "\n",
    "            # Bounds check for keypoint indices\n",
    "            if kp1_idx >= len(kpts1) or kp2_idx >= len(kpts2):\n",
    "                # print(f\"Warning: Match index out of bounds for {img_name1}-{img_name2}. Skipping match {kp1_idx}-{kp2_idx}.\")\n",
    "                continue\n",
    "\n",
    "            pt1 = tuple(map(int, kpts1[kp1_idx][:2]))\n",
    "            pt2 = tuple(map(int, kpts2[kp2_idx][:2]))\n",
    "\n",
    "            # Draw circles on the concatenated image\n",
    "            cv2.circle(matched_img, pt1, 5, (0, 0, 255), 2) # Red circle on img1 side\n",
    "            cv2.circle(matched_img, (pt2[0] + w1, pt2[1]), 5, (255, 0, 0), 2) # Blue circle on img2 side\n",
    "\n",
    "            # Draw a line connecting the matched keypoints\n",
    "            color = tuple(np.random.randint(0, 255, 3).tolist())\n",
    "            cv2.line(matched_img, pt1, (pt2[0] + w1, pt2[1]), color, 1)\n",
    "\n",
    "        output_match_path = os.path.join(output_dir, f\"matches_{img_name1}_{img_name2}.png\")\n",
    "        cv2.imwrite(output_match_path, matched_img)\n",
    "        print(f\"Matches drawn between {img_name1} and {img_name2}, saved to {output_match_path}\")\n",
    "\n",
    "\n",
    "# Example call (replace with your actual 'images' list)\n",
    "# If your 'images' are file paths:\n",
    "# images_file_paths = ['path/to/your/image1.jpg', 'path/to/your/image2.jpg', ...]\n",
    "# draw_keypoints_and_matches(images_file_paths, unified_kp_path, remapped_matches_path)\n",
    "\n",
    "# If your 'images' are loaded numpy arrays (as in the dummy example above):\n",
    "# draw_keypoints_and_matches(images, unified_kp_path, remapped_matches_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2789e85a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T07:02:00.088955Z",
     "iopub.status.busy": "2025-05-30T07:02:00.088744Z",
     "iopub.status.idle": "2025-05-30T07:30:22.269626Z",
     "shell.execute_reply": "2025-05-30T07:30:22.268630Z"
    },
    "papermill": {
     "duration": 1702.189877,
     "end_time": "2025-05-30T07:30:22.271202",
     "exception": false,
     "start_time": "2025-05-30T07:02:00.081325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DINOv2 model for patch feature extraction...\n",
      "DINOv2 model loaded.\n",
      "Skipping \"imc2023_haiper\"\n",
      "Skipping \"imc2023_heritage\"\n",
      "Skipping \"imc2023_theather_imc2024_church\"\n",
      "Skipping \"imc2024_dioscuri_baalshamin\"\n",
      "Skipping \"imc2024_lizard_pond\"\n",
      "Skipping \"pt_brandenburg_british_buckingham\"\n",
      "Skipping \"pt_piazzasanmarco_grandplace\"\n",
      "Skipping \"pt_sacrecoeur_trevi_tajmahal\"\n",
      "Skipping \"pt_stpeters_stpauls\"\n",
      "Skipping \"amy_gardens\"\n",
      "\n",
      "Processing dataset \"fbk_vineyard\": 163 images\n",
      "rotation_detection for 163 images : 0.0000 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 163/163 [00:13<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance Matrix Statistics:\n",
      "Min:  0.1510\n",
      "Max:  0.3338\n",
      "Mean: 0.2232\n",
      "Std:  0.0303\n",
      "20%:  0.1980\n",
      "25%:  0.2014\n",
      "60%:  0.2244\n",
      "75%:  0.2396\n",
      "Shortlisting. Number of pairs to match: 2277. Done in 14.2253 sec\n",
      "Generated 2277 image pairs using VLAD global descriptor.\n",
      "Shortlisting. Number of pairs to match: 2277. Done in 14.5322 sec\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5915, 2]), descs.shape=torch.Size([5915, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5543, 2]), descs.shape=torch.Size([5543, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5674, 2]), descs.shape=torch.Size([5674, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5897, 2]), descs.shape=torch.Size([5897, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5580, 2]), descs.shape=torch.Size([5580, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5513, 2]), descs.shape=torch.Size([5513, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5400, 2]), descs.shape=torch.Size([5400, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5919, 2]), descs.shape=torch.Size([5919, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5682, 2]), descs.shape=torch.Size([5682, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5604, 2]), descs.shape=torch.Size([5604, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5608, 2]), descs.shape=torch.Size([5608, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5520, 2]), descs.shape=torch.Size([5520, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5370, 2]), descs.shape=torch.Size([5370, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5967, 2]), descs.shape=torch.Size([5967, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5525, 2]), descs.shape=torch.Size([5525, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5751, 2]), descs.shape=torch.Size([5751, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5913, 2]), descs.shape=torch.Size([5913, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5677, 2]), descs.shape=torch.Size([5677, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5627, 2]), descs.shape=torch.Size([5627, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5710, 2]), descs.shape=torch.Size([5710, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5668, 2]), descs.shape=torch.Size([5668, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5398, 2]), descs.shape=torch.Size([5398, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5659, 2]), descs.shape=torch.Size([5659, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4772, 2]), descs.shape=torch.Size([4772, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5398, 2]), descs.shape=torch.Size([5398, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5653, 2]), descs.shape=torch.Size([5653, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5493, 2]), descs.shape=torch.Size([5493, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5671, 2]), descs.shape=torch.Size([5671, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5772, 2]), descs.shape=torch.Size([5772, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5746, 2]), descs.shape=torch.Size([5746, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5662, 2]), descs.shape=torch.Size([5662, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5662, 2]), descs.shape=torch.Size([5662, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5484, 2]), descs.shape=torch.Size([5484, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5681, 2]), descs.shape=torch.Size([5681, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5713, 2]), descs.shape=torch.Size([5713, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5462, 2]), descs.shape=torch.Size([5462, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5277, 2]), descs.shape=torch.Size([5277, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5172, 2]), descs.shape=torch.Size([5172, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5248, 2]), descs.shape=torch.Size([5248, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4924, 2]), descs.shape=torch.Size([4924, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5412, 2]), descs.shape=torch.Size([5412, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4711, 2]), descs.shape=torch.Size([4711, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([3824, 2]), descs.shape=torch.Size([3824, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4863, 2]), descs.shape=torch.Size([4863, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4838, 2]), descs.shape=torch.Size([4838, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4782, 2]), descs.shape=torch.Size([4782, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5807, 2]), descs.shape=torch.Size([5807, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([3926, 2]), descs.shape=torch.Size([3926, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5706, 2]), descs.shape=torch.Size([5706, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5238, 2]), descs.shape=torch.Size([5238, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5761, 2]), descs.shape=torch.Size([5761, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5706, 2]), descs.shape=torch.Size([5706, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5274, 2]), descs.shape=torch.Size([5274, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5456, 2]), descs.shape=torch.Size([5456, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5229, 2]), descs.shape=torch.Size([5229, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5340, 2]), descs.shape=torch.Size([5340, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5365, 2]), descs.shape=torch.Size([5365, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5405, 2]), descs.shape=torch.Size([5405, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5099, 2]), descs.shape=torch.Size([5099, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5258, 2]), descs.shape=torch.Size([5258, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5126, 2]), descs.shape=torch.Size([5126, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5028, 2]), descs.shape=torch.Size([5028, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5124, 2]), descs.shape=torch.Size([5124, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4976, 2]), descs.shape=torch.Size([4976, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5155, 2]), descs.shape=torch.Size([5155, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5155, 2]), descs.shape=torch.Size([5155, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4845, 2]), descs.shape=torch.Size([4845, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4950, 2]), descs.shape=torch.Size([4950, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5204, 2]), descs.shape=torch.Size([5204, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4948, 2]), descs.shape=torch.Size([4948, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5433, 2]), descs.shape=torch.Size([5433, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5204, 2]), descs.shape=torch.Size([5204, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5513, 2]), descs.shape=torch.Size([5513, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5039, 2]), descs.shape=torch.Size([5039, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5441, 2]), descs.shape=torch.Size([5441, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5763, 2]), descs.shape=torch.Size([5763, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5325, 2]), descs.shape=torch.Size([5325, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5460, 2]), descs.shape=torch.Size([5460, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4877, 2]), descs.shape=torch.Size([4877, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5281, 2]), descs.shape=torch.Size([5281, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5612, 2]), descs.shape=torch.Size([5612, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5137, 2]), descs.shape=torch.Size([5137, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5892, 2]), descs.shape=torch.Size([5892, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5267, 2]), descs.shape=torch.Size([5267, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5592, 2]), descs.shape=torch.Size([5592, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5531, 2]), descs.shape=torch.Size([5531, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4948, 2]), descs.shape=torch.Size([4948, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4935, 2]), descs.shape=torch.Size([4935, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5731, 2]), descs.shape=torch.Size([5731, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4821, 2]), descs.shape=torch.Size([4821, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4730, 2]), descs.shape=torch.Size([4730, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5396, 2]), descs.shape=torch.Size([5396, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5623, 2]), descs.shape=torch.Size([5623, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5204, 2]), descs.shape=torch.Size([5204, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5160, 2]), descs.shape=torch.Size([5160, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5130, 2]), descs.shape=torch.Size([5130, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4971, 2]), descs.shape=torch.Size([4971, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4983, 2]), descs.shape=torch.Size([4983, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5662, 2]), descs.shape=torch.Size([5662, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5176, 2]), descs.shape=torch.Size([5176, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5797, 2]), descs.shape=torch.Size([5797, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5174, 2]), descs.shape=torch.Size([5174, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5168, 2]), descs.shape=torch.Size([5168, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5250, 2]), descs.shape=torch.Size([5250, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5131, 2]), descs.shape=torch.Size([5131, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5658, 2]), descs.shape=torch.Size([5658, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5586, 2]), descs.shape=torch.Size([5586, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5843, 2]), descs.shape=torch.Size([5843, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4973, 2]), descs.shape=torch.Size([4973, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5159, 2]), descs.shape=torch.Size([5159, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5492, 2]), descs.shape=torch.Size([5492, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4673, 2]), descs.shape=torch.Size([4673, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5378, 2]), descs.shape=torch.Size([5378, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4839, 2]), descs.shape=torch.Size([4839, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4828, 2]), descs.shape=torch.Size([4828, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5204, 2]), descs.shape=torch.Size([5204, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5142, 2]), descs.shape=torch.Size([5142, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5441, 2]), descs.shape=torch.Size([5441, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5454, 2]), descs.shape=torch.Size([5454, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5518, 2]), descs.shape=torch.Size([5518, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5628, 2]), descs.shape=torch.Size([5628, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5570, 2]), descs.shape=torch.Size([5570, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5897, 2]), descs.shape=torch.Size([5897, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5412, 2]), descs.shape=torch.Size([5412, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5343, 2]), descs.shape=torch.Size([5343, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5043, 2]), descs.shape=torch.Size([5043, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5298, 2]), descs.shape=torch.Size([5298, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5439, 2]), descs.shape=torch.Size([5439, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5500, 2]), descs.shape=torch.Size([5500, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5320, 2]), descs.shape=torch.Size([5320, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5526, 2]), descs.shape=torch.Size([5526, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5431, 2]), descs.shape=torch.Size([5431, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5675, 2]), descs.shape=torch.Size([5675, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5746, 2]), descs.shape=torch.Size([5746, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5509, 2]), descs.shape=torch.Size([5509, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5661, 2]), descs.shape=torch.Size([5661, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5411, 2]), descs.shape=torch.Size([5411, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5491, 2]), descs.shape=torch.Size([5491, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5627, 2]), descs.shape=torch.Size([5627, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4941, 2]), descs.shape=torch.Size([4941, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5815, 2]), descs.shape=torch.Size([5815, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5396, 2]), descs.shape=torch.Size([5396, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5339, 2]), descs.shape=torch.Size([5339, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5332, 2]), descs.shape=torch.Size([5332, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5561, 2]), descs.shape=torch.Size([5561, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5157, 2]), descs.shape=torch.Size([5157, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5583, 2]), descs.shape=torch.Size([5583, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5632, 2]), descs.shape=torch.Size([5632, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5535, 2]), descs.shape=torch.Size([5535, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5549, 2]), descs.shape=torch.Size([5549, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5440, 2]), descs.shape=torch.Size([5440, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5539, 2]), descs.shape=torch.Size([5539, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5704, 2]), descs.shape=torch.Size([5704, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4989, 2]), descs.shape=torch.Size([4989, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5584, 2]), descs.shape=torch.Size([5584, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5658, 2]), descs.shape=torch.Size([5658, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5435, 2]), descs.shape=torch.Size([5435, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5442, 2]), descs.shape=torch.Size([5442, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5524, 2]), descs.shape=torch.Size([5524, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5155, 2]), descs.shape=torch.Size([5155, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5143, 2]), descs.shape=torch.Size([5143, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5354, 2]), descs.shape=torch.Size([5354, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([5552, 2]), descs.shape=torch.Size([5552, 128])\n",
      "Loaded LightGlue model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2277 [00:00<09:19,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1260.png-vineyard_split_2_frame_1225.png: 100 matches @ 1th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2277 [00:01<06:17,  6.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1260.png-vineyard_split_2_frame_1255.png: 2207 matches @ 2th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/2277 [00:01<05:50,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1260.png-vineyard_split_2_frame_1250.png: 640 matches @ 3th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11/2277 [00:01<05:47,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1260.png-vineyard_split_2_frame_1265.png: 1862 matches @ 4th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 30/2277 [00:04<05:27,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1225.png-vineyard_split_2_frame_1220.png: 2328 matches @ 5th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 34/2277 [00:05<05:25,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1225.png-vineyard_split_2_frame_1285.png: 141 matches @ 6th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 37/2277 [00:05<05:22,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1225.png-vineyard_split_2_frame_1230.png: 1415 matches @ 7th pair(aliked+lightglue)\n",
      "aliked> vineyard_split_2_frame_1225.png-vineyard_split_2_frame_1215.png: 450 matches @ 8th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 50/2277 [00:07<05:18,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1245.png-vineyard_split_2_frame_1240.png: 1635 matches @ 9th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 54/2277 [00:08<05:21,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1245.png-vineyard_split_2_frame_1250.png: 1688 matches @ 10th pair(aliked+lightglue)\n",
      "aliked> vineyard_split_2_frame_1245.png-vineyard_split_2_frame_1235.png: 578 matches @ 11th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 57/2277 [00:08<05:08,  7.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1245.png-vineyard_split_2_frame_1230.png: 151 matches @ 12th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 79/2277 [00:11<05:31,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1320.png-vineyard_split_2_frame_1305.png: 392 matches @ 13th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 82/2277 [00:12<05:33,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1320.png-vineyard_split_2_frame_1315.png: 1569 matches @ 14th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 100/2277 [00:14<05:12,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1205.png-vineyard_split_2_frame_1200.png: 1305 matches @ 15th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 105/2277 [00:15<05:09,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1205.png-vineyard_split_2_frame_1195.png: 582 matches @ 16th pair(aliked+lightglue)\n",
      "aliked> vineyard_split_2_frame_1205.png-vineyard_split_2_frame_1210.png: 2129 matches @ 17th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 110/2277 [00:16<05:08,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1205.png-vineyard_split_2_frame_1215.png: 766 matches @ 18th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|         | 135/2277 [00:19<05:06,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1240.png-vineyard_split_2_frame_1200.png: 256 matches @ 19th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|         | 137/2277 [00:20<05:11,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1240.png-vineyard_split_2_frame_1255.png: 103 matches @ 20th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|         | 144/2277 [00:21<05:06,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1240.png-vineyard_split_2_frame_1155.png: 129 matches @ 21th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|         | 148/2277 [00:21<05:01,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1240.png-vineyard_split_2_frame_1250.png: 462 matches @ 22th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 154/2277 [00:22<05:07,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1240.png-vineyard_split_2_frame_1235.png: 2024 matches @ 23th pair(aliked+lightglue)\n",
      "aliked> vineyard_split_2_frame_1240.png-vineyard_split_2_frame_1230.png: 923 matches @ 24th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|         | 207/2277 [00:30<05:02,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1170.png-vineyard_split_2_frame_1180.png: 1077 matches @ 25th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|         | 210/2277 [00:30<05:01,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1170.png-vineyard_split_2_frame_1165.png: 1985 matches @ 26th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|         | 212/2277 [00:30<04:56,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1170.png-vineyard_split_2_frame_1160.png: 740 matches @ 27th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|         | 215/2277 [00:31<04:45,  7.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1170.png-vineyard_split_2_frame_1175.png: 2376 matches @ 28th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 237/2277 [00:34<05:11,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1300.png-vineyard_split_2_frame_1305.png: 1909 matches @ 29th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|         | 252/2277 [00:36<05:12,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1300.png-vineyard_split_3_frame_1460.png: 111 matches @ 30th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|        | 263/2277 [00:38<05:06,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1290.png-vineyard_split_2_frame_1295.png: 2108 matches @ 31th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|        | 265/2277 [00:38<05:04,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1290.png-vineyard_split_2_frame_1305.png: 239 matches @ 32th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|        | 268/2277 [00:39<05:04,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1290.png-vineyard_split_2_frame_1285.png: 1238 matches @ 33th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|        | 282/2277 [00:41<04:54,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1310.png-vineyard_split_2_frame_1305.png: 1953 matches @ 34th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|        | 306/2277 [00:44<04:51,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1200.png-vineyard_split_2_frame_1155.png: 135 matches @ 35th pair(aliked+lightglue)\n",
      "aliked> vineyard_split_2_frame_1200.png-vineyard_split_2_frame_1195.png: 1798 matches @ 36th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 308/2277 [00:45<04:51,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1200.png-vineyard_split_2_frame_1210.png: 777 matches @ 37th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 310/2277 [00:45<04:56,  6.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1200.png-vineyard_split_2_frame_1185.png: 109 matches @ 38th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|        | 353/2277 [00:51<04:49,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1180.png-vineyard_split_2_frame_1165.png: 274 matches @ 39th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|        | 357/2277 [00:52<04:42,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1180.png-vineyard_split_2_frame_1185.png: 845 matches @ 40th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|        | 373/2277 [00:54<05:02,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1255.png-vineyard_split_2_frame_1250.png: 1709 matches @ 41th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|        | 376/2277 [00:55<05:10,  6.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1255.png-vineyard_split_2_frame_1265.png: 802 matches @ 42th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|        | 400/2277 [00:59<04:54,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1220.png-vineyard_split_2_frame_1285.png: 191 matches @ 43th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|        | 404/2277 [00:59<04:48,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1220.png-vineyard_split_2_frame_1235.png: 175 matches @ 44th pair(aliked+lightglue)\n",
      "aliked> vineyard_split_2_frame_1220.png-vineyard_split_2_frame_1230.png: 553 matches @ 45th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|        | 406/2277 [00:59<04:48,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1220.png-vineyard_split_2_frame_1215.png: 1181 matches @ 46th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|        | 422/2277 [01:02<04:47,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1165.png-vineyard_split_2_frame_1160.png: 1958 matches @ 47th pair(aliked+lightglue)\n",
      "aliked> vineyard_split_2_frame_1165.png-vineyard_split_2_frame_1155.png: 802 matches @ 48th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|        | 442/2277 [01:05<04:47,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1165.png-vineyard_split_1_frame_1080.png: 137 matches @ 49th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 448/2277 [01:06<04:52,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1275.png-vineyard_split_2_frame_1280.png: 2136 matches @ 50th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 450/2277 [01:06<04:49,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1275.png-vineyard_split_2_frame_1270.png: 1008 matches @ 51th pair(aliked+lightglue)\n",
      "aliked> vineyard_split_2_frame_1275.png-vineyard_split_2_frame_1285.png: 1006 matches @ 52th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 452/2277 [01:07<04:58,  6.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1275.png-vineyard_split_2_frame_1265.png: 149 matches @ 53th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|       | 525/2277 [01:18<04:33,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1160.png-vineyard_split_2_frame_1155.png: 1829 matches @ 54th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|       | 529/2277 [01:19<04:37,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1160.png-vineyard_split_2_frame_1175.png: 351 matches @ 55th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|       | 548/2277 [01:22<04:37,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1280.png-vineyard_split_2_frame_1285.png: 2129 matches @ 56th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|       | 568/2277 [01:25<04:34,  6.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1155.png-vineyard_split_2_frame_1150.png: 1879 matches @ 57th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|       | 581/2277 [01:27<04:26,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1195.png-vineyard_split_2_frame_1185.png: 1130 matches @ 58th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|       | 613/2277 [01:32<04:10,  6.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1270.png-vineyard_split_2_frame_1265.png: 1425 matches @ 59th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|       | 620/2277 [01:33<04:08,  6.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1210.png-vineyard_split_2_frame_1215.png: 1735 matches @ 60th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|       | 632/2277 [01:35<04:21,  6.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1250.png-vineyard_split_2_frame_1265.png: 145 matches @ 61th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|      | 717/2277 [01:48<04:08,  6.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1285.png-vineyard_split_1_frame_1015.png: 113 matches @ 62th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|      | 748/2277 [01:53<04:21,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1150.png-vineyard_split_2_frame_1235.png: 150 matches @ 63th pair(aliked+lightglue)\n",
      "aliked> vineyard_split_2_frame_1150.png-vineyard_split_2_frame_1230.png: 103 matches @ 64th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|      | 795/2277 [02:01<04:07,  6.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1235.png-vineyard_split_2_frame_1230.png: 1905 matches @ 65th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|      | 874/2277 [02:14<03:56,  5.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_2_frame_1215.png-vineyard_split_1_frame_1080.png: 111 matches @ 66th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|      | 881/2277 [02:15<03:45,  6.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_1395.png-vineyard_split_3_frame_1390.png: 1034 matches @ 67th pair(aliked+lightglue)\n",
      "aliked> vineyard_split_3_frame_1395.png-vineyard_split_3_frame_1405.png: 990 matches @ 68th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|      | 885/2277 [02:16<03:43,  6.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_1395.png-vineyard_split_3_frame_1400.png: 2031 matches @ 69th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|      | 887/2277 [02:16<03:42,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_1395.png-vineyard_split_3_frame_1420.png: 100 matches @ 70th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 907/2277 [02:19<03:29,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_1475.png-vineyard_split_3_frame_1460.png: 381 matches @ 71th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 912/2277 [02:20<03:27,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_1475.png-vineyard_split_3_frame_1470.png: 2353 matches @ 72th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|      | 924/2277 [02:22<03:14,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0255.png-vineyard_split_3_frame_0265.png: 1065 matches @ 73th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|      | 935/2277 [02:24<03:12,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0255.png-vineyard_split_3_frame_0245.png: 966 matches @ 74th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|      | 938/2277 [02:24<03:12,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0255.png-vineyard_split_3_frame_0240.png: 399 matches @ 75th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|     | 941/2277 [02:24<03:09,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0255.png-vineyard_split_3_frame_0260.png: 1915 matches @ 76th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|     | 948/2277 [02:25<03:21,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_1425.png-vineyard_split_3_frame_1405.png: 101 matches @ 77th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|     | 951/2277 [02:26<03:25,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_1425.png-vineyard_split_3_frame_1415.png: 572 matches @ 78th pair(aliked+lightglue)\n",
      "aliked> vineyard_split_3_frame_1425.png-vineyard_split_3_frame_1420.png: 1195 matches @ 79th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|     | 964/2277 [02:28<03:01,  7.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0125.png-vineyard_split_3_frame_0140.png: 188 matches @ 80th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|     | 972/2277 [02:29<02:58,  7.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0125.png-vineyard_split_3_frame_0120.png: 2149 matches @ 81th pair(aliked+lightglue)\n",
      "aliked> vineyard_split_3_frame_0125.png-vineyard_split_3_frame_0105.png: 316 matches @ 82th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|     | 976/2277 [02:29<02:54,  7.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0125.png-vineyard_split_3_frame_0110.png: 553 matches @ 83th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|     | 980/2277 [02:30<02:52,  7.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0125.png-vineyard_split_3_frame_0135.png: 772 matches @ 84th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|     | 1002/2277 [02:33<03:19,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_1480.png-vineyard_split_3_frame_1485.png: 1942 matches @ 85th pair(aliked+lightglue)\n",
      "aliked> vineyard_split_3_frame_1480.png-vineyard_split_3_frame_1470.png: 781 matches @ 86th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|     | 1013/2277 [02:35<02:55,  7.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0215.png-vineyard_split_3_frame_0225.png: 893 matches @ 87th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|     | 1015/2277 [02:35<02:50,  7.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0215.png-vineyard_split_3_frame_0205.png: 748 matches @ 88th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|     | 1022/2277 [02:36<02:45,  7.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0215.png-vineyard_split_3_frame_0220.png: 2025 matches @ 89th pair(aliked+lightglue)\n",
      "aliked> vineyard_split_3_frame_0215.png-vineyard_split_3_frame_0200.png: 150 matches @ 90th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|     | 1024/2277 [02:36<02:47,  7.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0215.png-vineyard_split_3_frame_0230.png: 169 matches @ 91th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|     | 1031/2277 [02:37<02:25,  8.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0295.png-vineyard_split_3_frame_0285.png: 698 matches @ 92th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|     | 1033/2277 [02:37<02:20,  8.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0295.png-vineyard_split_3_frame_0305.png: 779 matches @ 93th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|     | 1040/2277 [02:38<02:23,  8.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0295.png-vineyard_split_3_frame_0300.png: 1108 matches @ 94th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|     | 1046/2277 [02:39<02:44,  7.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0090.png-vineyard_split_3_frame_0080.png: 837 matches @ 95th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|     | 1052/2277 [02:40<02:42,  7.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0090.png-vineyard_split_3_frame_0085.png: 2038 matches @ 96th pair(aliked+lightglue)\n",
      "aliked> vineyard_split_3_frame_0090.png-vineyard_split_3_frame_0095.png: 1897 matches @ 97th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 1066/2277 [02:42<02:38,  7.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0190.png-vineyard_split_3_frame_0195.png: 1647 matches @ 98th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 1072/2277 [02:42<02:47,  7.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0190.png-vineyard_split_3_frame_0180.png: 543 matches @ 99th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 1079/2277 [02:43<02:42,  7.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0265.png-vineyard_split_3_frame_0270.png: 1451 matches @ 100th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 1081/2277 [02:44<02:38,  7.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0265.png-vineyard_split_3_frame_0275.png: 668 matches @ 101th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 1090/2277 [02:45<02:37,  7.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0265.png-vineyard_split_3_frame_0245.png: 178 matches @ 102th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 1095/2277 [02:46<02:34,  7.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0265.png-vineyard_split_3_frame_0260.png: 2015 matches @ 103th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 1098/2277 [02:46<02:55,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_1445.png-vineyard_split_3_frame_1450.png: 1341 matches @ 104th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 1103/2277 [02:47<03:14,  6.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_1445.png-vineyard_split_3_frame_1440.png: 1910 matches @ 105th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|     | 1106/2277 [02:47<03:18,  5.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_1445.png-vineyard_split_3_frame_1435.png: 185 matches @ 106th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 1129/2277 [02:51<03:08,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_1450.png-vineyard_split_3_frame_1465.png: 202 matches @ 107th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 1131/2277 [02:51<03:11,  5.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_1450.png-vineyard_split_3_frame_1440.png: 391 matches @ 108th pair(aliked+lightglue)\n",
      "aliked> vineyard_split_3_frame_1450.png-vineyard_split_3_frame_1460.png: 480 matches @ 109th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|     | 1164/2277 [02:56<02:50,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_1390.png-vineyard_split_3_frame_1400.png: 398 matches @ 110th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|    | 1191/2277 [03:00<02:58,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_1555.png-vineyard_split_3_frame_1545.png: 847 matches @ 111th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|    | 1193/2277 [03:01<03:00,  6.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_1555.png-vineyard_split_3_frame_1560.png: 1454 matches @ 112th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|    | 1204/2277 [03:03<02:55,  6.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_1550.png-vineyard_split_3_frame_1535.png: 586 matches @ 113th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|    | 1207/2277 [03:03<02:57,  6.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_1550.png-vineyard_split_3_frame_1545.png: 2049 matches @ 114th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|    | 1223/2277 [03:06<02:42,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0145.png-vineyard_split_3_frame_0235.png: 116 matches @ 115th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|    | 1225/2277 [03:06<02:38,  6.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0145.png-vineyard_split_3_frame_0130.png: 109 matches @ 116th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|    | 1235/2277 [03:08<02:44,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_1405.png-vineyard_split_3_frame_1410.png: 1782 matches @ 117th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|    | 1240/2277 [03:08<02:46,  6.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_1405.png-vineyard_split_3_frame_1400.png: 2228 matches @ 118th pair(aliked+lightglue)\n",
      "aliked> vineyard_split_3_frame_1405.png-vineyard_split_3_frame_1415.png: 751 matches @ 119th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|    | 1242/2277 [03:09<02:44,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_1405.png-vineyard_split_3_frame_1420.png: 133 matches @ 120th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|    | 1263/2277 [03:12<02:37,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0070.png-vineyard_split_3_frame_0075.png: 1547 matches @ 121th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|    | 1266/2277 [03:12<02:31,  6.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0070.png-vineyard_split_3_frame_0080.png: 918 matches @ 122th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|    | 1274/2277 [03:14<02:22,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0070.png-vineyard_split_3_frame_0085.png: 301 matches @ 123th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|    | 1282/2277 [03:15<02:27,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_1500.png-vineyard_split_3_frame_1490.png: 857 matches @ 124th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|    | 1322/2277 [03:21<02:26,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0075.png-vineyard_split_3_frame_0080.png: 2253 matches @ 125th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|    | 1329/2277 [03:22<02:20,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0075.png-vineyard_split_3_frame_0085.png: 918 matches @ 126th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|    | 1335/2277 [03:23<02:20,  6.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0160.png-vineyard_split_3_frame_0150.png: 666 matches @ 127th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|    | 1351/2277 [03:25<02:09,  7.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0160.png-vineyard_split_3_frame_0165.png: 2138 matches @ 128th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|    | 1354/2277 [03:25<02:11,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0160.png-vineyard_split_3_frame_0155.png: 1523 matches @ 129th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 1356/2277 [03:26<02:14,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0150.png-vineyard_split_3_frame_0140.png: 935 matches @ 130th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 1372/2277 [03:28<02:16,  6.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0150.png-vineyard_split_3_frame_0165.png: 271 matches @ 131th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 1376/2277 [03:29<02:14,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0150.png-vineyard_split_3_frame_0155.png: 1888 matches @ 132th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|    | 1393/2277 [03:31<02:07,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0140.png-vineyard_split_3_frame_0135.png: 1383 matches @ 133th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|   | 1405/2277 [03:33<02:04,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0270.png-vineyard_split_3_frame_0285.png: 1141 matches @ 134th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|   | 1407/2277 [03:33<02:02,  7.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0270.png-vineyard_split_3_frame_0280.png: 1600 matches @ 135th pair(aliked+lightglue)\n",
      "aliked> vineyard_split_3_frame_0270.png-vineyard_split_3_frame_0275.png: 1953 matches @ 136th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|   | 1419/2277 [03:35<01:58,  7.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0270.png-vineyard_split_3_frame_0260.png: 701 matches @ 137th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|   | 1426/2277 [03:36<02:02,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0170.png-vineyard_split_3_frame_0175.png: 1840 matches @ 138th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|   | 1432/2277 [03:37<01:59,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0170.png-vineyard_split_3_frame_0165.png: 1981 matches @ 139th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|   | 1434/2277 [03:37<01:59,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0170.png-vineyard_split_3_frame_0180.png: 843 matches @ 140th pair(aliked+lightglue)\n",
      "aliked> vineyard_split_3_frame_0285.png-vineyard_split_3_frame_0280.png: 2489 matches @ 141th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|   | 1436/2277 [03:37<01:57,  7.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0285.png-vineyard_split_3_frame_0275.png: 1584 matches @ 142th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|   | 1478/2277 [03:43<01:56,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_1490.png-vineyard_split_3_frame_1485.png: 1327 matches @ 143th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|   | 1509/2277 [03:48<01:51,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0280.png-vineyard_split_3_frame_0275.png: 2312 matches @ 144th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|   | 1531/2277 [03:51<01:39,  7.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0275.png-vineyard_split_3_frame_0260.png: 319 matches @ 145th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|   | 1540/2277 [03:52<01:40,  7.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0225.png-vineyard_split_3_frame_0210.png: 181 matches @ 146th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|   | 1543/2277 [03:53<01:39,  7.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0225.png-vineyard_split_3_frame_0220.png: 1528 matches @ 147th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|   | 1546/2277 [03:53<01:39,  7.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0225.png-vineyard_split_3_frame_0230.png: 1354 matches @ 148th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|   | 1555/2277 [03:55<01:40,  7.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0080.png-vineyard_split_3_frame_0085.png: 1572 matches @ 149th pair(aliked+lightglue)\n",
      "aliked> vineyard_split_3_frame_0080.png-vineyard_split_3_frame_0095.png: 375 matches @ 150th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|   | 1561/2277 [03:55<01:43,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0250.png-vineyard_split_3_frame_0235.png: 506 matches @ 151th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|   | 1568/2277 [03:56<01:47,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_1495.png-vineyard_split_3_frame_1505.png: 508 matches @ 152th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 1583/2277 [03:59<01:45,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0120.png-vineyard_split_3_frame_0105.png: 696 matches @ 153th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 1586/2277 [03:59<01:38,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0120.png-vineyard_split_3_frame_0110.png: 1177 matches @ 154th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 1590/2277 [04:00<01:40,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0120.png-vineyard_split_3_frame_0135.png: 569 matches @ 155th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 1599/2277 [04:01<01:44,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_1510.png-vineyard_split_3_frame_1520.png: 1149 matches @ 156th pair(aliked+lightglue)\n",
      "aliked> vineyard_split_3_frame_1510.png-vineyard_split_3_frame_1525.png: 132 matches @ 157th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 1602/2277 [04:02<01:45,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_1510.png-vineyard_split_3_frame_1515.png: 2516 matches @ 158th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|   | 1616/2277 [04:04<01:33,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0105.png-vineyard_split_3_frame_0110.png: 2376 matches @ 159th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|   | 1619/2277 [04:04<01:29,  7.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0105.png-vineyard_split_3_frame_0100.png: 1135 matches @ 160th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|  | 1623/2277 [04:05<01:28,  7.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0105.png-vineyard_split_3_frame_0095.png: 339 matches @ 161th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|  | 1627/2277 [04:05<01:39,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_1535.png-vineyard_split_3_frame_1530.png: 1251 matches @ 162th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|  | 1634/2277 [04:06<01:46,  6.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_1540.png-vineyard_split_3_frame_1545.png: 2456 matches @ 163th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|  | 1648/2277 [04:09<01:32,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0205.png-vineyard_split_3_frame_0195.png: 451 matches @ 164th pair(aliked+lightglue)\n",
      "aliked> vineyard_split_3_frame_0205.png-vineyard_split_3_frame_0210.png: 1878 matches @ 165th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|  | 1653/2277 [04:09<01:30,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0205.png-vineyard_split_3_frame_0220.png: 366 matches @ 166th pair(aliked+lightglue)\n",
      "aliked> vineyard_split_3_frame_0205.png-vineyard_split_3_frame_0200.png: 1502 matches @ 167th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|  | 1664/2277 [04:11<01:36,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_1410.png-vineyard_split_3_frame_1415.png: 2087 matches @ 168th pair(aliked+lightglue)\n",
      "aliked> vineyard_split_3_frame_1410.png-vineyard_split_3_frame_1420.png: 878 matches @ 169th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|  | 1676/2277 [04:13<01:22,  7.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0305.png-vineyard_split_3_frame_0300.png: 2625 matches @ 170th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|  | 1701/2277 [04:17<01:24,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0175.png-vineyard_split_3_frame_0185.png: 585 matches @ 171th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|  | 1726/2277 [04:21<01:29,  6.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_1520.png-vineyard_split_3_frame_1525.png: 1221 matches @ 172th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|  | 1731/2277 [04:22<01:29,  6.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_1465.png-vineyard_split_3_frame_1460.png: 2820 matches @ 173th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|  | 1734/2277 [04:22<01:27,  6.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_1465.png-vineyard_split_3_frame_1470.png: 1276 matches @ 174th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|  | 1743/2277 [04:24<01:25,  6.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_1525.png-vineyard_split_3_frame_1530.png: 1846 matches @ 175th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|  | 1755/2277 [04:25<01:14,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0110.png-vineyard_split_3_frame_0100.png: 700 matches @ 176th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|  | 1763/2277 [04:26<01:10,  7.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0110.png-vineyard_split_3_frame_0115.png: 2072 matches @ 177th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|  | 1771/2277 [04:28<01:08,  7.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0195.png-vineyard_split_3_frame_0200.png: 1629 matches @ 178th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|  | 1778/2277 [04:29<01:15,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_1570.png-vineyard_split_3_frame_1560.png: 980 matches @ 179th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|  | 1784/2277 [04:30<01:23,  5.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_1570.png-vineyard_split_3_frame_1565.png: 2103 matches @ 180th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|  | 1795/2277 [04:31<01:09,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0210.png-vineyard_split_3_frame_0220.png: 900 matches @ 181th pair(aliked+lightglue)\n",
      "aliked> vineyard_split_3_frame_0210.png-vineyard_split_3_frame_0200.png: 563 matches @ 182th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|  | 1808/2277 [04:33<01:01,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0100.png-vineyard_split_3_frame_0085.png: 394 matches @ 183th pair(aliked+lightglue)\n",
      "aliked> vineyard_split_3_frame_0100.png-vineyard_split_3_frame_0095.png: 1656 matches @ 184th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 1813/2277 [04:34<01:10,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_1560.png-vineyard_split_3_frame_1565.png: 2047 matches @ 185th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 1820/2277 [04:35<01:13,  6.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_1430.png-vineyard_split_3_frame_1435.png: 1907 matches @ 186th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 1829/2277 [04:36<01:06,  6.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0245.png-vineyard_split_3_frame_0240.png: 2129 matches @ 187th pair(aliked+lightglue)\n",
      "aliked> vineyard_split_3_frame_0245.png-vineyard_split_3_frame_0260.png: 347 matches @ 188th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|  | 1834/2277 [04:37<01:06,  6.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0130.png-vineyard_split_3_frame_0115.png: 425 matches @ 189th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%| | 1856/2277 [04:40<01:06,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_1440.png-vineyard_split_3_frame_1435.png: 1828 matches @ 190th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%| | 1864/2277 [04:42<01:03,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0240.png-vineyard_split_3_frame_0230.png: 1065 matches @ 191th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%| | 1873/2277 [04:43<01:07,  6.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_1460.png-vineyard_split_3_frame_1470.png: 857 matches @ 192th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%| | 1895/2277 [04:46<00:55,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0165.png-vineyard_split_3_frame_0155.png: 898 matches @ 193th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%| | 1921/2277 [04:50<00:57,  6.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_1415.png-vineyard_split_3_frame_1420.png: 1954 matches @ 194th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%| | 1976/2277 [04:59<00:43,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_3_frame_0085.png-vineyard_split_3_frame_0095.png: 1016 matches @ 195th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%| | 2017/2277 [05:06<00:42,  6.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_1_frame_0950.png-vineyard_split_1_frame_0960.png: 776 matches @ 196th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%| | 2024/2277 [05:07<00:40,  6.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_1_frame_1005.png-vineyard_split_1_frame_0995.png: 688 matches @ 197th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%| | 2034/2277 [05:08<00:41,  5.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_1_frame_0915.png-vineyard_split_1_frame_0910.png: 2771 matches @ 198th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%| | 2036/2277 [05:09<00:40,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_1_frame_0915.png-vineyard_split_1_frame_0920.png: 1405 matches @ 199th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 2045/2277 [05:10<00:36,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_1_frame_1070.png-vineyard_split_1_frame_1055.png: 181 matches @ 200th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 2049/2277 [05:11<00:36,  6.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_1_frame_1070.png-vineyard_split_1_frame_1065.png: 1275 matches @ 201th pair(aliked+lightglue)\n",
      "aliked> vineyard_split_1_frame_1070.png-vineyard_split_1_frame_1080.png: 511 matches @ 202th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 2053/2277 [05:11<00:34,  6.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_1_frame_1070.png-vineyard_split_1_frame_1075.png: 1369 matches @ 203th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%| | 2066/2277 [05:13<00:30,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_1_frame_1015.png-vineyard_split_1_frame_1020.png: 2022 matches @ 204th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%| | 2069/2277 [05:14<00:30,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_1_frame_1015.png-vineyard_split_1_frame_1010.png: 1260 matches @ 205th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|| 2079/2277 [05:15<00:30,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_1_frame_0990.png-vineyard_split_1_frame_0980.png: 673 matches @ 206th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|| 2083/2277 [05:16<00:29,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_1_frame_0990.png-vineyard_split_1_frame_1000.png: 806 matches @ 207th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|| 2089/2277 [05:17<00:28,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_1_frame_0990.png-vineyard_split_1_frame_0985.png: 1838 matches @ 208th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|| 2091/2277 [05:17<00:28,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_1_frame_0990.png-vineyard_split_1_frame_0975.png: 161 matches @ 209th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|| 2097/2277 [05:18<00:28,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_1_frame_1055.png-vineyard_split_1_frame_1065.png: 736 matches @ 210th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|| 2099/2277 [05:18<00:28,  6.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_1_frame_1055.png-vineyard_split_1_frame_1045.png: 576 matches @ 211th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|| 2101/2277 [05:19<00:27,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_1_frame_1055.png-vineyard_split_1_frame_1040.png: 242 matches @ 212th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|| 2113/2277 [05:21<00:25,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_1_frame_1055.png-vineyard_split_1_frame_1050.png: 1895 matches @ 213th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|| 2115/2277 [05:21<00:25,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_1_frame_0965.png-vineyard_split_1_frame_0960.png: 1423 matches @ 214th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|| 2126/2277 [05:23<00:23,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_1_frame_0935.png-vineyard_split_1_frame_0940.png: 1886 matches @ 215th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|| 2131/2277 [05:23<00:23,  6.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_1_frame_0970.png-vineyard_split_1_frame_0960.png: 451 matches @ 216th pair(aliked+lightglue)\n",
      "aliked> vineyard_split_1_frame_0970.png-vineyard_split_1_frame_0980.png: 1115 matches @ 217th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|| 2138/2277 [05:24<00:21,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_1_frame_0970.png-vineyard_split_1_frame_0985.png: 345 matches @ 218th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|| 2140/2277 [05:25<00:21,  6.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_1_frame_0970.png-vineyard_split_1_frame_0975.png: 2040 matches @ 219th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|| 2142/2277 [05:25<00:21,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_1_frame_0960.png-vineyard_split_1_frame_0955.png: 1979 matches @ 220th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|| 2150/2277 [05:26<00:20,  6.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_1_frame_1095.png-vineyard_split_1_frame_1080.png: 103 matches @ 221th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|| 2152/2277 [05:27<00:20,  6.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_1_frame_1095.png-vineyard_split_1_frame_1100.png: 2198 matches @ 222th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|| 2156/2277 [05:27<00:19,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_1_frame_1095.png-vineyard_split_1_frame_1105.png: 1575 matches @ 223th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|| 2159/2277 [05:28<00:19,  6.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_1_frame_0945.png-vineyard_split_1_frame_0955.png: 739 matches @ 224th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|| 2164/2277 [05:29<00:18,  6.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_1_frame_0945.png-vineyard_split_1_frame_0940.png: 1727 matches @ 225th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|| 2172/2277 [05:30<00:16,  6.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_1_frame_0905.png-vineyard_split_1_frame_0900.png: 1572 matches @ 226th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|| 2174/2277 [05:30<00:16,  6.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_1_frame_0905.png-vineyard_split_1_frame_0920.png: 172 matches @ 227th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|| 2179/2277 [05:31<00:15,  6.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_1_frame_1085.png-vineyard_split_1_frame_1090.png: 1831 matches @ 228th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|| 2188/2277 [05:32<00:13,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_1_frame_0955.png-vineyard_split_1_frame_0940.png: 189 matches @ 229th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 2213/2277 [05:36<00:10,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_1_frame_0980.png-vineyard_split_1_frame_0985.png: 2018 matches @ 230th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 2215/2277 [05:37<00:09,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_1_frame_0980.png-vineyard_split_1_frame_0975.png: 2454 matches @ 231th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 2217/2277 [05:37<00:09,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_1_frame_1045.png-vineyard_split_1_frame_1040.png: 1741 matches @ 232th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 2219/2277 [05:37<00:08,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_1_frame_1045.png-vineyard_split_1_frame_1035.png: 985 matches @ 233th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 2221/2277 [05:38<00:08,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_1_frame_1045.png-vineyard_split_1_frame_1050.png: 1256 matches @ 234th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 2223/2277 [05:38<00:08,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_1_frame_1080.png-vineyard_split_1_frame_1075.png: 1861 matches @ 235th pair(aliked+lightglue)\n",
      "aliked> vineyard_split_1_frame_1040.png-vineyard_split_1_frame_1035.png: 2015 matches @ 236th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 2227/2277 [05:39<00:07,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_1_frame_1040.png-vineyard_split_1_frame_1030.png: 993 matches @ 237th pair(aliked+lightglue)\n",
      "aliked> vineyard_split_1_frame_1040.png-vineyard_split_1_frame_1050.png: 619 matches @ 238th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 2229/2277 [05:39<00:07,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_1_frame_1110.png-vineyard_split_1_frame_1100.png: 1798 matches @ 239th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 2231/2277 [05:39<00:07,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_1_frame_1110.png-vineyard_split_1_frame_1105.png: 2030 matches @ 240th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 2238/2277 [05:40<00:05,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_1_frame_1020.png-vineyard_split_1_frame_1010.png: 602 matches @ 241th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 2241/2277 [05:41<00:05,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_1_frame_1020.png-vineyard_split_1_frame_1030.png: 715 matches @ 242th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|| 2244/2277 [05:41<00:05,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_1_frame_1000.png-vineyard_split_1_frame_1010.png: 544 matches @ 243th pair(aliked+lightglue)\n",
      "aliked> vineyard_split_1_frame_1000.png-vineyard_split_1_frame_0985.png: 120 matches @ 244th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|| 2250/2277 [05:42<00:04,  6.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_1_frame_1035.png-vineyard_split_1_frame_1030.png: 1715 matches @ 245th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|| 2254/2277 [05:43<00:03,  6.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_1_frame_1100.png-vineyard_split_1_frame_1105.png: 2528 matches @ 246th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|| 2259/2277 [05:44<00:02,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_1_frame_0940.png-vineyard_split_1_frame_0925.png: 418 matches @ 247th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2267/2277 [05:45<00:01,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_1_frame_0925.png-vineyard_split_1_frame_0930.png: 2004 matches @ 248th pair(aliked+lightglue)\n",
      "aliked> vineyard_split_1_frame_0925.png-vineyard_split_1_frame_0920.png: 1594 matches @ 249th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2270/2277 [05:45<00:01,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_1_frame_0985.png-vineyard_split_1_frame_0975.png: 1238 matches @ 250th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2273/2277 [05:46<00:00,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> vineyard_split_1_frame_1030.png-vineyard_split_1_frame_1025.png: 2288 matches @ 251th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2277/2277 [05:46<00:00,  6.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features matched in  355.8618 sec (aliked+LightGlue)\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([184, 2]), descs.shape=torch.Size([184, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([178, 2]), descs.shape=torch.Size([178, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([250, 2]), descs.shape=torch.Size([250, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([285, 2]), descs.shape=torch.Size([285, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([293, 2]), descs.shape=torch.Size([293, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([260, 2]), descs.shape=torch.Size([260, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([235, 2]), descs.shape=torch.Size([235, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([259, 2]), descs.shape=torch.Size([259, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([288, 2]), descs.shape=torch.Size([288, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([270, 2]), descs.shape=torch.Size([270, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([283, 2]), descs.shape=torch.Size([283, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([248, 2]), descs.shape=torch.Size([248, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([320, 2]), descs.shape=torch.Size([320, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([209, 2]), descs.shape=torch.Size([209, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([161, 2]), descs.shape=torch.Size([161, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([238, 2]), descs.shape=torch.Size([238, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([218, 2]), descs.shape=torch.Size([218, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([270, 2]), descs.shape=torch.Size([270, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([233, 2]), descs.shape=torch.Size([233, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([252, 2]), descs.shape=torch.Size([252, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([226, 2]), descs.shape=torch.Size([226, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([279, 2]), descs.shape=torch.Size([279, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([293, 2]), descs.shape=torch.Size([293, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([168, 2]), descs.shape=torch.Size([168, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([236, 2]), descs.shape=torch.Size([236, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([205, 2]), descs.shape=torch.Size([205, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([299, 2]), descs.shape=torch.Size([299, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([246, 2]), descs.shape=torch.Size([246, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([193, 2]), descs.shape=torch.Size([193, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([279, 2]), descs.shape=torch.Size([279, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([262, 2]), descs.shape=torch.Size([262, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([235, 2]), descs.shape=torch.Size([235, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([291, 2]), descs.shape=torch.Size([291, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([263, 2]), descs.shape=torch.Size([263, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([221, 2]), descs.shape=torch.Size([221, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([299, 2]), descs.shape=torch.Size([299, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([370, 2]), descs.shape=torch.Size([370, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([341, 2]), descs.shape=torch.Size([341, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([242, 2]), descs.shape=torch.Size([242, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([299, 2]), descs.shape=torch.Size([299, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([328, 2]), descs.shape=torch.Size([328, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([359, 2]), descs.shape=torch.Size([359, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([404, 2]), descs.shape=torch.Size([404, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([358, 2]), descs.shape=torch.Size([358, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([317, 2]), descs.shape=torch.Size([317, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([355, 2]), descs.shape=torch.Size([355, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([228, 2]), descs.shape=torch.Size([228, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([349, 2]), descs.shape=torch.Size([349, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([260, 2]), descs.shape=torch.Size([260, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([273, 2]), descs.shape=torch.Size([273, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([209, 2]), descs.shape=torch.Size([209, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([200, 2]), descs.shape=torch.Size([200, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([348, 2]), descs.shape=torch.Size([348, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([294, 2]), descs.shape=torch.Size([294, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([310, 2]), descs.shape=torch.Size([310, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([275, 2]), descs.shape=torch.Size([275, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([222, 2]), descs.shape=torch.Size([222, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([334, 2]), descs.shape=torch.Size([334, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([329, 2]), descs.shape=torch.Size([329, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([331, 2]), descs.shape=torch.Size([331, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([304, 2]), descs.shape=torch.Size([304, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([381, 2]), descs.shape=torch.Size([381, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([307, 2]), descs.shape=torch.Size([307, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([358, 2]), descs.shape=torch.Size([358, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([296, 2]), descs.shape=torch.Size([296, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([366, 2]), descs.shape=torch.Size([366, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([387, 2]), descs.shape=torch.Size([387, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([339, 2]), descs.shape=torch.Size([339, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([378, 2]), descs.shape=torch.Size([378, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([300, 2]), descs.shape=torch.Size([300, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([252, 2]), descs.shape=torch.Size([252, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([354, 2]), descs.shape=torch.Size([354, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([313, 2]), descs.shape=torch.Size([313, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([313, 2]), descs.shape=torch.Size([313, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([200, 2]), descs.shape=torch.Size([200, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([170, 2]), descs.shape=torch.Size([170, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([337, 2]), descs.shape=torch.Size([337, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([268, 2]), descs.shape=torch.Size([268, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([415, 2]), descs.shape=torch.Size([415, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([331, 2]), descs.shape=torch.Size([331, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([275, 2]), descs.shape=torch.Size([275, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([334, 2]), descs.shape=torch.Size([334, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([198, 2]), descs.shape=torch.Size([198, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([332, 2]), descs.shape=torch.Size([332, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([238, 2]), descs.shape=torch.Size([238, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([259, 2]), descs.shape=torch.Size([259, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([301, 2]), descs.shape=torch.Size([301, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([305, 2]), descs.shape=torch.Size([305, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([236, 2]), descs.shape=torch.Size([236, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([330, 2]), descs.shape=torch.Size([330, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([352, 2]), descs.shape=torch.Size([352, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([243, 2]), descs.shape=torch.Size([243, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([212, 2]), descs.shape=torch.Size([212, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([314, 2]), descs.shape=torch.Size([314, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([373, 2]), descs.shape=torch.Size([373, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([390, 2]), descs.shape=torch.Size([390, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([400, 2]), descs.shape=torch.Size([400, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([293, 2]), descs.shape=torch.Size([293, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([207, 2]), descs.shape=torch.Size([207, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([300, 2]), descs.shape=torch.Size([300, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([239, 2]), descs.shape=torch.Size([239, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([406, 2]), descs.shape=torch.Size([406, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([344, 2]), descs.shape=torch.Size([344, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([358, 2]), descs.shape=torch.Size([358, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([313, 2]), descs.shape=torch.Size([313, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([301, 2]), descs.shape=torch.Size([301, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([285, 2]), descs.shape=torch.Size([285, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([221, 2]), descs.shape=torch.Size([221, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([374, 2]), descs.shape=torch.Size([374, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([335, 2]), descs.shape=torch.Size([335, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([263, 2]), descs.shape=torch.Size([263, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([462, 2]), descs.shape=torch.Size([462, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([307, 2]), descs.shape=torch.Size([307, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([344, 2]), descs.shape=torch.Size([344, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([337, 2]), descs.shape=torch.Size([337, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([345, 2]), descs.shape=torch.Size([345, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([312, 2]), descs.shape=torch.Size([312, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([220, 2]), descs.shape=torch.Size([220, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([289, 2]), descs.shape=torch.Size([289, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([240, 2]), descs.shape=torch.Size([240, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([266, 2]), descs.shape=torch.Size([266, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([256, 2]), descs.shape=torch.Size([256, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([239, 2]), descs.shape=torch.Size([239, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([310, 2]), descs.shape=torch.Size([310, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([289, 2]), descs.shape=torch.Size([289, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([306, 2]), descs.shape=torch.Size([306, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([343, 2]), descs.shape=torch.Size([343, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([260, 2]), descs.shape=torch.Size([260, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([258, 2]), descs.shape=torch.Size([258, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([282, 2]), descs.shape=torch.Size([282, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([277, 2]), descs.shape=torch.Size([277, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([238, 2]), descs.shape=torch.Size([238, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([283, 2]), descs.shape=torch.Size([283, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([256, 2]), descs.shape=torch.Size([256, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([245, 2]), descs.shape=torch.Size([245, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([225, 2]), descs.shape=torch.Size([225, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([288, 2]), descs.shape=torch.Size([288, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([326, 2]), descs.shape=torch.Size([326, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([329, 2]), descs.shape=torch.Size([329, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([320, 2]), descs.shape=torch.Size([320, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([207, 2]), descs.shape=torch.Size([207, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([314, 2]), descs.shape=torch.Size([314, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([226, 2]), descs.shape=torch.Size([226, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([310, 2]), descs.shape=torch.Size([310, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([290, 2]), descs.shape=torch.Size([290, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([368, 2]), descs.shape=torch.Size([368, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([238, 2]), descs.shape=torch.Size([238, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([326, 2]), descs.shape=torch.Size([326, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([231, 2]), descs.shape=torch.Size([231, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([218, 2]), descs.shape=torch.Size([218, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([271, 2]), descs.shape=torch.Size([271, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([295, 2]), descs.shape=torch.Size([295, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([332, 2]), descs.shape=torch.Size([332, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([294, 2]), descs.shape=torch.Size([294, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([293, 2]), descs.shape=torch.Size([293, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([315, 2]), descs.shape=torch.Size([315, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([289, 2]), descs.shape=torch.Size([289, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([280, 2]), descs.shape=torch.Size([280, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([283, 2]), descs.shape=torch.Size([283, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([285, 2]), descs.shape=torch.Size([285, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([283, 2]), descs.shape=torch.Size([283, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([229, 2]), descs.shape=torch.Size([229, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([330, 2]), descs.shape=torch.Size([330, 256])\n",
      "Loaded LightGlue model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 35/2277 [00:00<00:56, 39.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_2_frame_1225.png-vineyard_split_2_frame_1220.png: 53 matches @ 1th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 56/2277 [00:01<00:56, 38.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_2_frame_1245.png-vineyard_split_2_frame_1240.png: 53 matches @ 2th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 85/2277 [00:02<00:55, 39.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_2_frame_1320.png-vineyard_split_2_frame_1315.png: 71 matches @ 3th pair(superpoint+lightglue)\n",
      "superpoint> vineyard_split_2_frame_1320.png-vineyard_split_3_frame_1400.png: 50 matches @ 4th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 109/2277 [00:02<00:55, 39.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_2_frame_1205.png-vineyard_split_2_frame_1210.png: 70 matches @ 5th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 157/2277 [00:04<00:54, 38.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_2_frame_1240.png-vineyard_split_2_frame_1235.png: 68 matches @ 6th pair(superpoint+lightglue)\n",
      "superpoint> vineyard_split_2_frame_1240.png-vineyard_split_2_frame_1230.png: 59 matches @ 7th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|         | 214/2277 [00:05<00:55, 37.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_2_frame_1170.png-vineyard_split_2_frame_1165.png: 64 matches @ 8th pair(superpoint+lightglue)\n",
      "superpoint> vineyard_split_2_frame_1170.png-vineyard_split_2_frame_1175.png: 92 matches @ 9th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|         | 242/2277 [00:06<00:52, 38.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_2_frame_1300.png-vineyard_split_2_frame_1305.png: 67 matches @ 10th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|        | 266/2277 [00:06<00:51, 39.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_2_frame_1290.png-vineyard_split_2_frame_1295.png: 72 matches @ 11th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|        | 286/2277 [00:07<00:51, 38.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_2_frame_1310.png-vineyard_split_2_frame_1305.png: 56 matches @ 12th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 310/2277 [00:07<00:50, 39.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_2_frame_1200.png-vineyard_split_2_frame_1195.png: 59 matches @ 13th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|        | 427/2277 [00:11<00:47, 38.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_2_frame_1165.png-vineyard_split_2_frame_1160.png: 57 matches @ 14th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 452/2277 [00:11<00:44, 40.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_2_frame_1275.png-vineyard_split_2_frame_1280.png: 65 matches @ 15th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|       | 551/2277 [00:14<00:44, 38.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_2_frame_1280.png-vineyard_split_2_frame_1285.png: 69 matches @ 16th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|       | 571/2277 [00:14<00:43, 39.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_2_frame_1155.png-vineyard_split_2_frame_1150.png: 68 matches @ 17th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|       | 625/2277 [00:16<00:42, 39.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_2_frame_1210.png-vineyard_split_2_frame_1215.png: 51 matches @ 18th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|      | 801/2277 [00:20<00:37, 38.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_2_frame_1235.png-vineyard_split_2_frame_1230.png: 81 matches @ 19th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|      | 890/2277 [00:22<00:35, 38.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_3_frame_1395.png-vineyard_split_3_frame_1400.png: 93 matches @ 20th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|      | 898/2277 [00:23<00:35, 38.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_3_frame_1395.png-vineyard_split_1_frame_1020.png: 61 matches @ 21th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 915/2277 [00:23<00:34, 39.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_3_frame_1475.png-vineyard_split_3_frame_1470.png: 96 matches @ 22th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|     | 947/2277 [00:24<00:33, 39.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_3_frame_0255.png-vineyard_split_3_frame_0260.png: 94 matches @ 23th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|     | 976/2277 [00:25<00:33, 38.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_3_frame_0125.png-vineyard_split_3_frame_0120.png: 89 matches @ 24th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|     | 1008/2277 [00:25<00:32, 38.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_3_frame_1480.png-vineyard_split_3_frame_1485.png: 71 matches @ 25th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|     | 1016/2277 [00:26<00:32, 38.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_3_frame_0215.png-vineyard_split_3_frame_0225.png: 50 matches @ 26th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|     | 1028/2277 [00:26<00:32, 38.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_3_frame_0215.png-vineyard_split_3_frame_0220.png: 115 matches @ 27th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|     | 1044/2277 [00:26<00:31, 39.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_3_frame_0295.png-vineyard_split_3_frame_0300.png: 80 matches @ 28th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|     | 1057/2277 [00:27<00:30, 39.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_3_frame_0090.png-vineyard_split_3_frame_0085.png: 134 matches @ 29th pair(superpoint+lightglue)\n",
      "superpoint> vineyard_split_3_frame_0090.png-vineyard_split_3_frame_0095.png: 90 matches @ 30th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 1070/2277 [00:27<00:30, 39.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_3_frame_0190.png-vineyard_split_3_frame_0195.png: 79 matches @ 31th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 1083/2277 [00:27<00:29, 39.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_3_frame_0265.png-vineyard_split_3_frame_0270.png: 69 matches @ 32th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 1099/2277 [00:28<00:29, 39.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_3_frame_0265.png-vineyard_split_3_frame_0260.png: 91 matches @ 33th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|     | 1107/2277 [00:28<00:29, 39.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_3_frame_1445.png-vineyard_split_3_frame_1440.png: 67 matches @ 34th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|    | 1240/2277 [00:31<00:26, 38.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_3_frame_1405.png-vineyard_split_3_frame_1410.png: 57 matches @ 35th pair(superpoint+lightglue)\n",
      "superpoint> vineyard_split_3_frame_1405.png-vineyard_split_3_frame_1400.png: 93 matches @ 36th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|    | 1268/2277 [00:32<00:25, 39.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_3_frame_0070.png-vineyard_split_3_frame_0075.png: 69 matches @ 37th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|    | 1325/2277 [00:34<00:24, 39.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_3_frame_0075.png-vineyard_split_3_frame_0080.png: 112 matches @ 38th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|    | 1354/2277 [00:34<00:23, 39.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_3_frame_0160.png-vineyard_split_3_frame_0165.png: 104 matches @ 39th pair(superpoint+lightglue)\n",
      "superpoint> vineyard_split_3_frame_0160.png-vineyard_split_3_frame_0155.png: 82 matches @ 40th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|    | 1382/2277 [00:35<00:22, 39.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_3_frame_0150.png-vineyard_split_3_frame_0155.png: 94 matches @ 41th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|   | 1398/2277 [00:35<00:22, 39.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_3_frame_0140.png-vineyard_split_3_frame_0135.png: 74 matches @ 42th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|   | 1410/2277 [00:36<00:22, 39.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_3_frame_0270.png-vineyard_split_3_frame_0280.png: 78 matches @ 43th pair(superpoint+lightglue)\n",
      "superpoint> vineyard_split_3_frame_0270.png-vineyard_split_3_frame_0275.png: 104 matches @ 44th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|   | 1430/2277 [00:36<00:21, 39.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_3_frame_0170.png-vineyard_split_3_frame_0175.png: 92 matches @ 45th pair(superpoint+lightglue)\n",
      "superpoint> vineyard_split_3_frame_0170.png-vineyard_split_3_frame_0165.png: 83 matches @ 46th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|   | 1438/2277 [00:36<00:21, 38.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_3_frame_0285.png-vineyard_split_3_frame_0280.png: 135 matches @ 47th pair(superpoint+lightglue)\n",
      "superpoint> vineyard_split_3_frame_0285.png-vineyard_split_3_frame_0275.png: 108 matches @ 48th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|   | 1483/2277 [00:38<00:20, 39.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_3_frame_1490.png-vineyard_split_3_frame_1485.png: 57 matches @ 49th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|   | 1515/2277 [00:38<00:20, 38.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_3_frame_0280.png-vineyard_split_3_frame_0275.png: 144 matches @ 50th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|   | 1547/2277 [00:39<00:19, 37.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_3_frame_0225.png-vineyard_split_3_frame_0220.png: 87 matches @ 51th pair(superpoint+lightglue)\n",
      "superpoint> vineyard_split_3_frame_0225.png-vineyard_split_3_frame_0230.png: 66 matches @ 52th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|   | 1559/2277 [00:40<00:19, 36.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_3_frame_0080.png-vineyard_split_3_frame_0085.png: 77 matches @ 53th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 1591/2277 [00:40<00:17, 39.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_3_frame_0120.png-vineyard_split_3_frame_0110.png: 60 matches @ 54th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|   | 1607/2277 [00:41<00:17, 39.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_3_frame_1510.png-vineyard_split_3_frame_1515.png: 116 matches @ 55th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|   | 1615/2277 [00:41<00:17, 38.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_3_frame_1510.png-vineyard_split_1_frame_1010.png: 59 matches @ 56th pair(superpoint+lightglue)\n",
      "superpoint> vineyard_split_3_frame_0105.png-vineyard_split_3_frame_0110.png: 106 matches @ 57th pair(superpoint+lightglue)\n",
      "superpoint> vineyard_split_3_frame_0105.png-vineyard_split_3_frame_0100.png: 66 matches @ 58th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|  | 1639/2277 [00:42<00:16, 39.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_3_frame_1540.png-vineyard_split_3_frame_1545.png: 54 matches @ 59th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|  | 1655/2277 [00:42<00:15, 39.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_3_frame_0205.png-vineyard_split_3_frame_0210.png: 93 matches @ 60th pair(superpoint+lightglue)\n",
      "superpoint> vineyard_split_3_frame_0205.png-vineyard_split_3_frame_0200.png: 71 matches @ 61th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|  | 1667/2277 [00:42<00:15, 38.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_3_frame_1410.png-vineyard_split_3_frame_1415.png: 71 matches @ 62th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|  | 1679/2277 [00:43<00:15, 39.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_3_frame_0305.png-vineyard_split_3_frame_0300.png: 185 matches @ 63th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|  | 1736/2277 [00:44<00:14, 37.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_3_frame_1465.png-vineyard_split_3_frame_1460.png: 87 matches @ 64th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|  | 1748/2277 [00:45<00:14, 37.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_3_frame_1525.png-vineyard_split_3_frame_1530.png: 66 matches @ 65th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|  | 1768/2277 [00:45<00:13, 38.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_3_frame_0110.png-vineyard_split_3_frame_0115.png: 117 matches @ 66th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|  | 1776/2277 [00:45<00:12, 38.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_3_frame_0195.png-vineyard_split_3_frame_0200.png: 65 matches @ 67th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|  | 1788/2277 [00:46<00:12, 39.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_3_frame_1570.png-vineyard_split_3_frame_1565.png: 72 matches @ 68th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|  | 1800/2277 [00:46<00:12, 39.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_3_frame_0210.png-vineyard_split_3_frame_0220.png: 51 matches @ 69th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 1812/2277 [00:46<00:12, 38.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_3_frame_0100.png-vineyard_split_3_frame_0095.png: 94 matches @ 70th pair(superpoint+lightglue)\n",
      "superpoint> vineyard_split_3_frame_1560.png-vineyard_split_3_frame_1565.png: 58 matches @ 71th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 1832/2277 [00:47<00:11, 38.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_3_frame_0245.png-vineyard_split_3_frame_0240.png: 84 matches @ 72th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%| | 1860/2277 [00:47<00:10, 39.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_3_frame_1440.png-vineyard_split_3_frame_1435.png: 52 matches @ 73th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%| | 1924/2277 [00:49<00:09, 38.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_3_frame_1415.png-vineyard_split_3_frame_1420.png: 72 matches @ 74th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%| | 1980/2277 [00:51<00:07, 38.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_3_frame_0085.png-vineyard_split_3_frame_0095.png: 69 matches @ 75th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 2040/2277 [00:52<00:06, 38.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_1_frame_0915.png-vineyard_split_1_frame_0910.png: 77 matches @ 76th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%| | 2069/2277 [00:53<00:05, 39.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_1_frame_1015.png-vineyard_split_1_frame_1020.png: 94 matches @ 77th pair(superpoint+lightglue)\n",
      "superpoint> vineyard_split_1_frame_1015.png-vineyard_split_1_frame_1100.png: 56 matches @ 78th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|| 2083/2277 [00:53<00:04, 39.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_1_frame_0990.png-vineyard_split_1_frame_0980.png: 50 matches @ 79th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|| 2092/2277 [00:54<00:04, 38.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_1_frame_0990.png-vineyard_split_1_frame_0985.png: 84 matches @ 80th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|| 2116/2277 [00:54<00:03, 40.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_1_frame_1055.png-vineyard_split_1_frame_1050.png: 79 matches @ 81th pair(superpoint+lightglue)\n",
      "superpoint> vineyard_split_1_frame_0965.png-vineyard_split_1_frame_0960.png: 51 matches @ 82th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|| 2131/2277 [00:54<00:03, 40.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_1_frame_0935.png-vineyard_split_1_frame_0940.png: 64 matches @ 83th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|| 2145/2277 [00:55<00:03, 39.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_1_frame_0970.png-vineyard_split_1_frame_0975.png: 97 matches @ 84th pair(superpoint+lightglue)\n",
      "superpoint> vineyard_split_1_frame_0960.png-vineyard_split_1_frame_0955.png: 70 matches @ 85th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|| 2157/2277 [00:55<00:03, 39.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_1_frame_1095.png-vineyard_split_1_frame_1100.png: 82 matches @ 86th pair(superpoint+lightglue)\n",
      "superpoint> vineyard_split_1_frame_1095.png-vineyard_split_1_frame_1105.png: 51 matches @ 87th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|| 2169/2277 [00:55<00:02, 38.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_1_frame_0945.png-vineyard_split_1_frame_0940.png: 60 matches @ 88th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|| 2177/2277 [00:56<00:02, 39.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_1_frame_0905.png-vineyard_split_1_frame_0900.png: 54 matches @ 89th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 2218/2277 [00:57<00:01, 38.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_1_frame_0980.png-vineyard_split_1_frame_0985.png: 87 matches @ 90th pair(superpoint+lightglue)\n",
      "superpoint> vineyard_split_1_frame_0980.png-vineyard_split_1_frame_0975.png: 131 matches @ 91th pair(superpoint+lightglue)\n",
      "superpoint> vineyard_split_1_frame_1045.png-vineyard_split_1_frame_1040.png: 71 matches @ 92th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 2230/2277 [00:57<00:01, 36.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_1_frame_1040.png-vineyard_split_1_frame_1035.png: 91 matches @ 93th pair(superpoint+lightglue)\n",
      "superpoint> vineyard_split_1_frame_1110.png-vineyard_split_1_frame_1100.png: 50 matches @ 94th pair(superpoint+lightglue)\n",
      "superpoint> vineyard_split_1_frame_1110.png-vineyard_split_1_frame_1105.png: 52 matches @ 95th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|| 2254/2277 [00:58<00:00, 38.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_1_frame_1035.png-vineyard_split_1_frame_1030.png: 66 matches @ 96th pair(superpoint+lightglue)\n",
      "superpoint> vineyard_split_1_frame_1100.png-vineyard_split_1_frame_1105.png: 118 matches @ 97th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2270/2277 [00:58<00:00, 38.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> vineyard_split_1_frame_0925.png-vineyard_split_1_frame_0930.png: 96 matches @ 98th pair(superpoint+lightglue)\n",
      "superpoint> vineyard_split_1_frame_0925.png-vineyard_split_1_frame_0920.png: 54 matches @ 99th pair(superpoint+lightglue)\n",
      "superpoint> vineyard_split_1_frame_0985.png-vineyard_split_1_frame_0975.png: 69 matches @ 100th pair(superpoint+lightglue)\n",
      "superpoint> vineyard_split_1_frame_1030.png-vineyard_split_1_frame_1025.png: 79 matches @ 101th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2277/2277 [00:58<00:00, 38.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features matched in  65.7530 sec (superpoint+LightGlue)\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8128, 2]), descs.shape=torch.Size([8128, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([7383, 2]), descs.shape=torch.Size([7383, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8058, 2]), descs.shape=torch.Size([8058, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([7421, 2]), descs.shape=torch.Size([7421, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([7934, 2]), descs.shape=torch.Size([7934, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8134, 2]), descs.shape=torch.Size([8134, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8103, 2]), descs.shape=torch.Size([8103, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8183, 2]), descs.shape=torch.Size([8183, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8024, 2]), descs.shape=torch.Size([8024, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8157, 2]), descs.shape=torch.Size([8157, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "Loaded LightGlue model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2277 [00:01<11:56,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_2_frame_1260.png-vineyard_split_2_frame_1255.png: 3550 matches @ 1th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/2277 [00:03<12:00,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_2_frame_1260.png-vineyard_split_2_frame_1265.png: 3276 matches @ 2th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 29/2277 [00:09<11:57,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_2_frame_1225.png-vineyard_split_2_frame_1220.png: 4098 matches @ 3th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 36/2277 [00:11<11:51,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_2_frame_1225.png-vineyard_split_2_frame_1230.png: 2402 matches @ 4th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 49/2277 [00:15<11:42,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_2_frame_1245.png-vineyard_split_2_frame_1240.png: 2899 matches @ 5th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 53/2277 [00:16<11:39,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_2_frame_1245.png-vineyard_split_2_frame_1250.png: 2951 matches @ 6th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 81/2277 [00:25<11:24,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_2_frame_1320.png-vineyard_split_2_frame_1315.png: 2980 matches @ 7th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 99/2277 [00:31<11:13,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_2_frame_1205.png-vineyard_split_2_frame_1200.png: 2377 matches @ 8th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 105/2277 [00:32<11:06,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_2_frame_1205.png-vineyard_split_2_frame_1210.png: 3939 matches @ 9th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 109/2277 [00:34<11:05,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_2_frame_1205.png-vineyard_split_2_frame_1215.png: 463 matches @ 10th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 153/2277 [00:47<10:48,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_2_frame_1240.png-vineyard_split_2_frame_1235.png: 3560 matches @ 11th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 154/2277 [00:47<10:47,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_2_frame_1240.png-vineyard_split_2_frame_1230.png: 758 matches @ 12th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|         | 206/2277 [01:03<10:41,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_2_frame_1170.png-vineyard_split_2_frame_1180.png: 1071 matches @ 13th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|         | 209/2277 [01:04<10:40,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_2_frame_1170.png-vineyard_split_2_frame_1165.png: 3369 matches @ 14th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|         | 214/2277 [01:06<10:41,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_2_frame_1170.png-vineyard_split_2_frame_1175.png: 4428 matches @ 15th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 236/2277 [01:13<10:36,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_2_frame_1300.png-vineyard_split_2_frame_1305.png: 3644 matches @ 16th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|        | 262/2277 [01:21<10:29,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_2_frame_1290.png-vineyard_split_2_frame_1295.png: 3760 matches @ 17th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|        | 267/2277 [01:22<10:29,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_2_frame_1290.png-vineyard_split_2_frame_1285.png: 2314 matches @ 18th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|        | 281/2277 [01:27<10:23,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_2_frame_1310.png-vineyard_split_2_frame_1305.png: 3860 matches @ 19th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|        | 306/2277 [01:34<10:14,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_2_frame_1200.png-vineyard_split_2_frame_1195.png: 3565 matches @ 20th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|        | 356/2277 [01:50<09:55,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_2_frame_1180.png-vineyard_split_2_frame_1185.png: 1445 matches @ 21th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|        | 372/2277 [01:55<09:47,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_2_frame_1255.png-vineyard_split_2_frame_1250.png: 2832 matches @ 22th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|        | 404/2277 [02:05<09:39,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_2_frame_1220.png-vineyard_split_2_frame_1230.png: 109 matches @ 23th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|        | 405/2277 [02:05<09:40,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_2_frame_1220.png-vineyard_split_2_frame_1215.png: 2115 matches @ 24th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|        | 421/2277 [02:10<09:34,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_2_frame_1165.png-vineyard_split_2_frame_1160.png: 3503 matches @ 25th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 447/2277 [02:18<09:26,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_2_frame_1275.png-vineyard_split_2_frame_1280.png: 3794 matches @ 26th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 449/2277 [02:19<09:27,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_2_frame_1275.png-vineyard_split_2_frame_1270.png: 1748 matches @ 27th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|       | 524/2277 [02:42<09:06,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_2_frame_1160.png-vineyard_split_2_frame_1155.png: 3417 matches @ 28th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|       | 547/2277 [02:49<08:59,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_2_frame_1280.png-vineyard_split_2_frame_1285.png: 3782 matches @ 29th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|       | 567/2277 [02:55<08:52,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_2_frame_1155.png-vineyard_split_2_frame_1150.png: 3629 matches @ 30th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|       | 580/2277 [02:59<08:46,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_2_frame_1195.png-vineyard_split_2_frame_1185.png: 2280 matches @ 31th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|       | 612/2277 [03:09<08:36,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_2_frame_1270.png-vineyard_split_2_frame_1265.png: 2810 matches @ 32th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|       | 619/2277 [03:11<08:34,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_2_frame_1210.png-vineyard_split_2_frame_1215.png: 3021 matches @ 33th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|      | 794/2277 [04:06<07:39,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_2_frame_1235.png-vineyard_split_2_frame_1230.png: 3161 matches @ 34th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|      | 880/2277 [04:32<07:15,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_1395.png-vineyard_split_3_frame_1390.png: 2161 matches @ 35th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|      | 881/2277 [04:33<07:15,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_1395.png-vineyard_split_3_frame_1405.png: 2128 matches @ 36th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|      | 884/2277 [04:34<07:13,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_1395.png-vineyard_split_3_frame_1400.png: 3951 matches @ 37th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 911/2277 [04:42<07:05,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_1475.png-vineyard_split_3_frame_1470.png: 4259 matches @ 38th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|      | 923/2277 [04:46<06:52,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0255.png-vineyard_split_3_frame_0265.png: 2219 matches @ 39th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|      | 934/2277 [04:49<06:56,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0255.png-vineyard_split_3_frame_0245.png: 1764 matches @ 40th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|     | 940/2277 [04:51<06:53,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0255.png-vineyard_split_3_frame_0260.png: 3756 matches @ 41th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|     | 951/2277 [04:54<06:51,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_1425.png-vineyard_split_3_frame_1420.png: 2425 matches @ 42th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|     | 971/2277 [05:01<06:45,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0125.png-vineyard_split_3_frame_0120.png: 4297 matches @ 43th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|     | 975/2277 [05:02<06:45,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0125.png-vineyard_split_3_frame_0110.png: 592 matches @ 44th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|     | 979/2277 [05:03<06:42,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0125.png-vineyard_split_3_frame_0135.png: 1857 matches @ 45th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|     | 1001/2277 [05:10<06:36,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_1480.png-vineyard_split_3_frame_1485.png: 3575 matches @ 46th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|     | 1002/2277 [05:10<06:35,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_1480.png-vineyard_split_3_frame_1470.png: 1679 matches @ 47th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|     | 1012/2277 [05:13<06:31,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0215.png-vineyard_split_3_frame_0225.png: 1796 matches @ 48th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|     | 1014/2277 [05:14<06:31,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0215.png-vineyard_split_3_frame_0205.png: 1823 matches @ 49th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|     | 1021/2277 [05:16<06:26,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0215.png-vineyard_split_3_frame_0220.png: 4170 matches @ 50th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|     | 1030/2277 [05:19<06:02,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0295.png-vineyard_split_3_frame_0285.png: 1400 matches @ 51th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|     | 1032/2277 [05:19<05:56,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0295.png-vineyard_split_3_frame_0305.png: 1443 matches @ 52th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|     | 1039/2277 [05:21<05:50,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0295.png-vineyard_split_3_frame_0300.png: 2330 matches @ 53th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|     | 1045/2277 [05:23<06:17,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0090.png-vineyard_split_3_frame_0080.png: 1890 matches @ 54th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|     | 1051/2277 [05:25<06:21,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0090.png-vineyard_split_3_frame_0085.png: 4407 matches @ 55th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|     | 1052/2277 [05:25<06:18,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0090.png-vineyard_split_3_frame_0095.png: 3985 matches @ 56th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 1065/2277 [05:29<06:15,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0190.png-vineyard_split_3_frame_0195.png: 3406 matches @ 57th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 1071/2277 [05:31<06:12,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0190.png-vineyard_split_3_frame_0180.png: 1254 matches @ 58th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 1078/2277 [05:33<06:09,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0265.png-vineyard_split_3_frame_0270.png: 2956 matches @ 59th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 1080/2277 [05:34<06:08,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0265.png-vineyard_split_3_frame_0275.png: 1739 matches @ 60th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 1094/2277 [05:38<06:02,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0265.png-vineyard_split_3_frame_0260.png: 4030 matches @ 61th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 1097/2277 [05:39<06:03,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_1445.png-vineyard_split_3_frame_1450.png: 2424 matches @ 62th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 1102/2277 [05:41<06:04,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_1445.png-vineyard_split_3_frame_1440.png: 3426 matches @ 63th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|     | 1163/2277 [06:00<05:46,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_1390.png-vineyard_split_3_frame_1400.png: 354 matches @ 64th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|    | 1192/2277 [06:08<05:37,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_1555.png-vineyard_split_3_frame_1560.png: 2779 matches @ 65th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|    | 1206/2277 [06:13<05:32,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_1550.png-vineyard_split_3_frame_1545.png: 3696 matches @ 66th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|    | 1234/2277 [06:22<05:21,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_1405.png-vineyard_split_3_frame_1410.png: 3359 matches @ 67th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|    | 1239/2277 [06:23<05:21,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_1405.png-vineyard_split_3_frame_1400.png: 4134 matches @ 68th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|    | 1262/2277 [06:30<05:14,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0070.png-vineyard_split_3_frame_0075.png: 2478 matches @ 69th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|    | 1265/2277 [06:31<05:15,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0070.png-vineyard_split_3_frame_0080.png: 464 matches @ 70th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|    | 1281/2277 [06:36<05:09,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_1500.png-vineyard_split_3_frame_1490.png: 1431 matches @ 71th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|    | 1321/2277 [06:48<04:56,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0075.png-vineyard_split_3_frame_0080.png: 4106 matches @ 72th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|    | 1328/2277 [06:51<04:55,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0075.png-vineyard_split_3_frame_0085.png: 1823 matches @ 73th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|    | 1350/2277 [06:57<04:48,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0160.png-vineyard_split_3_frame_0165.png: 4289 matches @ 74th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|    | 1353/2277 [06:58<04:45,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0160.png-vineyard_split_3_frame_0155.png: 3333 matches @ 75th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 1355/2277 [06:59<04:45,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0150.png-vineyard_split_3_frame_0140.png: 2061 matches @ 76th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 1375/2277 [07:05<04:39,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0150.png-vineyard_split_3_frame_0155.png: 3660 matches @ 77th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|    | 1392/2277 [07:11<04:35,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0140.png-vineyard_split_3_frame_0135.png: 3055 matches @ 78th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|   | 1404/2277 [07:14<04:31,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0270.png-vineyard_split_3_frame_0285.png: 1510 matches @ 79th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|   | 1406/2277 [07:15<04:31,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0270.png-vineyard_split_3_frame_0280.png: 3310 matches @ 80th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|   | 1407/2277 [07:15<04:30,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0270.png-vineyard_split_3_frame_0275.png: 4090 matches @ 81th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|   | 1418/2277 [07:19<04:26,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0270.png-vineyard_split_3_frame_0260.png: 1549 matches @ 82th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|   | 1425/2277 [07:21<04:24,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0170.png-vineyard_split_3_frame_0175.png: 3898 matches @ 83th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|   | 1431/2277 [07:23<04:22,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0170.png-vineyard_split_3_frame_0165.png: 3768 matches @ 84th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|   | 1433/2277 [07:23<04:21,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0170.png-vineyard_split_3_frame_0180.png: 1620 matches @ 85th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|   | 1434/2277 [07:24<04:21,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0285.png-vineyard_split_3_frame_0280.png: 4739 matches @ 86th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|   | 1435/2277 [07:24<04:20,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0285.png-vineyard_split_3_frame_0275.png: 3345 matches @ 87th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|   | 1477/2277 [07:37<04:09,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_1490.png-vineyard_split_3_frame_1485.png: 2598 matches @ 88th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|   | 1508/2277 [07:46<03:57,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0280.png-vineyard_split_3_frame_0275.png: 4615 matches @ 89th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|   | 1542/2277 [07:57<03:47,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0225.png-vineyard_split_3_frame_0220.png: 2928 matches @ 90th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|   | 1545/2277 [07:58<03:47,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0225.png-vineyard_split_3_frame_0230.png: 2684 matches @ 91th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|   | 1554/2277 [08:01<03:45,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0080.png-vineyard_split_3_frame_0085.png: 3400 matches @ 92th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|   | 1582/2277 [08:09<03:34,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0120.png-vineyard_split_3_frame_0105.png: 420 matches @ 93th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 1585/2277 [08:10<03:33,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0120.png-vineyard_split_3_frame_0110.png: 2535 matches @ 94th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 1598/2277 [08:14<03:30,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_1510.png-vineyard_split_3_frame_1520.png: 1993 matches @ 95th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 1601/2277 [08:15<03:28,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_1510.png-vineyard_split_3_frame_1515.png: 4062 matches @ 96th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|   | 1615/2277 [08:20<03:25,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0105.png-vineyard_split_3_frame_0110.png: 4592 matches @ 97th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|   | 1618/2277 [08:21<03:24,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0105.png-vineyard_split_3_frame_0100.png: 2379 matches @ 98th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|   | 1622/2277 [08:22<03:22,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0105.png-vineyard_split_3_frame_0095.png: 261 matches @ 99th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|  | 1626/2277 [08:23<03:22,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_1535.png-vineyard_split_3_frame_1530.png: 1965 matches @ 100th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|  | 1633/2277 [08:25<03:19,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_1540.png-vineyard_split_3_frame_1545.png: 4264 matches @ 101th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|  | 1647/2277 [08:30<03:15,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0205.png-vineyard_split_3_frame_0195.png: 910 matches @ 102th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|  | 1648/2277 [08:30<03:15,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0205.png-vineyard_split_3_frame_0210.png: 3757 matches @ 103th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|  | 1652/2277 [08:31<03:13,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0205.png-vineyard_split_3_frame_0220.png: 296 matches @ 104th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|  | 1653/2277 [08:31<03:13,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0205.png-vineyard_split_3_frame_0200.png: 2976 matches @ 105th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|  | 1663/2277 [08:34<03:07,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_1410.png-vineyard_split_3_frame_1415.png: 3759 matches @ 106th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|  | 1664/2277 [08:35<03:07,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_1410.png-vineyard_split_3_frame_1420.png: 1663 matches @ 107th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|  | 1675/2277 [08:38<03:05,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0305.png-vineyard_split_3_frame_0300.png: 4849 matches @ 108th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|  | 1700/2277 [08:46<02:58,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0175.png-vineyard_split_3_frame_0185.png: 1395 matches @ 109th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|  | 1725/2277 [08:54<02:51,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_1520.png-vineyard_split_3_frame_1525.png: 2413 matches @ 110th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|  | 1730/2277 [08:55<02:49,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_1465.png-vineyard_split_3_frame_1460.png: 4715 matches @ 111th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|  | 1733/2277 [08:56<02:49,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_1465.png-vineyard_split_3_frame_1470.png: 1829 matches @ 112th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|  | 1742/2277 [08:59<02:45,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_1525.png-vineyard_split_3_frame_1530.png: 3434 matches @ 113th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|  | 1754/2277 [09:03<02:42,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0110.png-vineyard_split_3_frame_0100.png: 1684 matches @ 114th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|  | 1762/2277 [09:05<02:39,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0110.png-vineyard_split_3_frame_0115.png: 4298 matches @ 115th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|  | 1770/2277 [09:08<02:36,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0195.png-vineyard_split_3_frame_0200.png: 3534 matches @ 116th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|  | 1777/2277 [09:10<02:34,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_1570.png-vineyard_split_3_frame_1560.png: 672 matches @ 117th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|  | 1783/2277 [09:12<02:33,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_1570.png-vineyard_split_3_frame_1565.png: 3816 matches @ 118th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|  | 1794/2277 [09:15<02:29,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0210.png-vineyard_split_3_frame_0220.png: 2144 matches @ 119th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|  | 1795/2277 [09:15<02:29,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0210.png-vineyard_split_3_frame_0200.png: 1470 matches @ 120th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|  | 1808/2277 [09:19<02:24,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0100.png-vineyard_split_3_frame_0095.png: 3417 matches @ 121th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 1812/2277 [09:21<02:23,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_1560.png-vineyard_split_3_frame_1565.png: 3644 matches @ 122th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 1819/2277 [09:23<02:21,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_1430.png-vineyard_split_3_frame_1435.png: 3149 matches @ 123th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 1828/2277 [09:26<02:19,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0245.png-vineyard_split_3_frame_0240.png: 4080 matches @ 124th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%| | 1855/2277 [09:34<02:11,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_1440.png-vineyard_split_3_frame_1435.png: 2690 matches @ 125th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%| | 1863/2277 [09:36<02:08,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0240.png-vineyard_split_3_frame_0230.png: 1709 matches @ 126th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%| | 1894/2277 [09:46<01:58,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0165.png-vineyard_split_3_frame_0155.png: 1846 matches @ 127th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%| | 1920/2277 [09:54<01:50,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_1415.png-vineyard_split_3_frame_1420.png: 3826 matches @ 128th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%| | 1975/2277 [10:11<01:33,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_3_frame_0085.png-vineyard_split_3_frame_0095.png: 2319 matches @ 129th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%| | 2023/2277 [10:26<01:18,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_1_frame_1005.png-vineyard_split_1_frame_0995.png: 1223 matches @ 130th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%| | 2033/2277 [10:29<01:15,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_1_frame_0915.png-vineyard_split_1_frame_0910.png: 4846 matches @ 131th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%| | 2035/2277 [10:30<01:14,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_1_frame_0915.png-vineyard_split_1_frame_0920.png: 2762 matches @ 132th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 2048/2277 [10:34<01:11,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_1_frame_1070.png-vineyard_split_1_frame_1065.png: 2535 matches @ 133th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 2049/2277 [10:34<01:10,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_1_frame_1070.png-vineyard_split_1_frame_1080.png: 231 matches @ 134th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 2052/2277 [10:35<01:09,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_1_frame_1070.png-vineyard_split_1_frame_1075.png: 2525 matches @ 135th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%| | 2065/2277 [10:39<01:05,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_1_frame_1015.png-vineyard_split_1_frame_1020.png: 3859 matches @ 136th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%| | 2068/2277 [10:40<01:04,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_1_frame_1015.png-vineyard_split_1_frame_1010.png: 2597 matches @ 137th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|| 2082/2277 [10:44<01:00,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_1_frame_0990.png-vineyard_split_1_frame_1000.png: 433 matches @ 138th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|| 2088/2277 [10:46<00:58,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_1_frame_0990.png-vineyard_split_1_frame_0985.png: 3935 matches @ 139th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|| 2096/2277 [10:48<00:56,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_1_frame_1055.png-vineyard_split_1_frame_1065.png: 132 matches @ 140th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|| 2098/2277 [10:49<00:55,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_1_frame_1055.png-vineyard_split_1_frame_1045.png: 726 matches @ 141th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|| 2112/2277 [10:53<00:51,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_1_frame_1055.png-vineyard_split_1_frame_1050.png: 3583 matches @ 142th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|| 2114/2277 [10:54<00:50,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_1_frame_0965.png-vineyard_split_1_frame_0960.png: 2809 matches @ 143th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|| 2125/2277 [10:57<00:47,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_1_frame_0935.png-vineyard_split_1_frame_0940.png: 3794 matches @ 144th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|| 2131/2277 [10:59<00:45,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_1_frame_0970.png-vineyard_split_1_frame_0980.png: 2014 matches @ 145th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|| 2139/2277 [11:02<00:42,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_1_frame_0970.png-vineyard_split_1_frame_0975.png: 3841 matches @ 146th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|| 2141/2277 [11:02<00:42,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_1_frame_0960.png-vineyard_split_1_frame_0955.png: 3722 matches @ 147th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|| 2151/2277 [11:06<00:38,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_1_frame_1095.png-vineyard_split_1_frame_1100.png: 4066 matches @ 148th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|| 2155/2277 [11:07<00:37,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_1_frame_1095.png-vineyard_split_1_frame_1105.png: 3071 matches @ 149th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|| 2158/2277 [11:08<00:36,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_1_frame_0945.png-vineyard_split_1_frame_0955.png: 1307 matches @ 150th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|| 2163/2277 [11:09<00:35,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_1_frame_0945.png-vineyard_split_1_frame_0940.png: 3001 matches @ 151th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|| 2171/2277 [11:12<00:32,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_1_frame_0905.png-vineyard_split_1_frame_0900.png: 2966 matches @ 152th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|| 2178/2277 [11:14<00:30,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_1_frame_1085.png-vineyard_split_1_frame_1090.png: 3370 matches @ 153th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 2212/2277 [11:24<00:20,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_1_frame_0980.png-vineyard_split_1_frame_0985.png: 3799 matches @ 154th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 2214/2277 [11:25<00:19,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_1_frame_0980.png-vineyard_split_1_frame_0975.png: 4344 matches @ 155th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 2216/2277 [11:26<00:18,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_1_frame_1045.png-vineyard_split_1_frame_1040.png: 3461 matches @ 156th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 2218/2277 [11:26<00:18,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_1_frame_1045.png-vineyard_split_1_frame_1035.png: 1851 matches @ 157th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 2220/2277 [11:27<00:17,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_1_frame_1045.png-vineyard_split_1_frame_1050.png: 2660 matches @ 158th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 2222/2277 [11:27<00:17,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_1_frame_1080.png-vineyard_split_1_frame_1075.png: 3132 matches @ 159th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 2223/2277 [11:28<00:16,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_1_frame_1040.png-vineyard_split_1_frame_1035.png: 3745 matches @ 160th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 2226/2277 [11:29<00:15,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_1_frame_1040.png-vineyard_split_1_frame_1030.png: 1007 matches @ 161th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 2228/2277 [11:29<00:15,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_1_frame_1110.png-vineyard_split_1_frame_1100.png: 3349 matches @ 162th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 2230/2277 [11:30<00:14,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_1_frame_1110.png-vineyard_split_1_frame_1105.png: 3678 matches @ 163th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 2237/2277 [11:32<00:12,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_1_frame_1020.png-vineyard_split_1_frame_1010.png: 260 matches @ 164th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 2240/2277 [11:33<00:11,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_1_frame_1020.png-vineyard_split_1_frame_1030.png: 964 matches @ 165th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|| 2249/2277 [11:36<00:08,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_1_frame_1035.png-vineyard_split_1_frame_1030.png: 3460 matches @ 166th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|| 2253/2277 [11:37<00:07,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_1_frame_1100.png-vineyard_split_1_frame_1105.png: 4440 matches @ 167th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2266/2277 [11:41<00:03,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_1_frame_0925.png-vineyard_split_1_frame_0930.png: 3813 matches @ 168th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2267/2277 [11:41<00:03,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_1_frame_0925.png-vineyard_split_1_frame_0920.png: 2969 matches @ 169th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2269/2277 [11:42<00:02,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_1_frame_0985.png-vineyard_split_1_frame_0975.png: 2174 matches @ 170th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2272/2277 [11:43<00:01,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> vineyard_split_1_frame_1030.png-vineyard_split_1_frame_1025.png: 4161 matches @ 171th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2277/2277 [11:45<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features matched in  732.5375 sec (disk+LightGlue)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='2277' class='' max='2277' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [2277/2277 00:06&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filter_FundamentalMatrix: 100 matches --> 96 matches\n",
      "vineyard_split_2_frame_1260.png-vineyard_split_2_frame_1225.png: 100 --> 96 matches\n",
      "filter_FundamentalMatrix: 5757 matches --> 5756 matches\n",
      "vineyard_split_2_frame_1260.png-vineyard_split_2_frame_1255.png: 5757 --> 5756 matches\n",
      "filter_FundamentalMatrix: 640 matches --> 639 matches\n",
      "vineyard_split_2_frame_1260.png-vineyard_split_2_frame_1250.png: 640 --> 639 matches\n",
      "filter_FundamentalMatrix: 5138 matches --> 5136 matches\n",
      "vineyard_split_2_frame_1260.png-vineyard_split_2_frame_1265.png: 5138 --> 5136 matches\n",
      "filter_FundamentalMatrix: 6479 matches --> 6473 matches\n",
      "vineyard_split_2_frame_1225.png-vineyard_split_2_frame_1220.png: 6479 --> 6473 matches\n",
      "filter_FundamentalMatrix: 141 matches --> 141 matches\n",
      "vineyard_split_2_frame_1225.png-vineyard_split_2_frame_1285.png: 141 --> 141 matches\n",
      "filter_FundamentalMatrix: 3817 matches --> 3814 matches\n",
      "vineyard_split_2_frame_1225.png-vineyard_split_2_frame_1230.png: 3817 --> 3814 matches\n",
      "filter_FundamentalMatrix: 450 matches --> 447 matches\n",
      "vineyard_split_2_frame_1225.png-vineyard_split_2_frame_1215.png: 450 --> 447 matches\n",
      "filter_FundamentalMatrix: 4587 matches --> 4578 matches\n",
      "vineyard_split_2_frame_1245.png-vineyard_split_2_frame_1240.png: 4587 --> 4578 matches\n",
      "filter_FundamentalMatrix: 4639 matches --> 4637 matches\n",
      "vineyard_split_2_frame_1245.png-vineyard_split_2_frame_1250.png: 4639 --> 4637 matches\n",
      "filter_FundamentalMatrix: 578 matches --> 575 matches\n",
      "vineyard_split_2_frame_1245.png-vineyard_split_2_frame_1235.png: 578 --> 575 matches\n",
      "filter_FundamentalMatrix: 151 matches --> 146 matches\n",
      "vineyard_split_2_frame_1245.png-vineyard_split_2_frame_1230.png: 151 --> 146 matches\n",
      "filter_FundamentalMatrix: 392 matches --> 392 matches\n",
      "vineyard_split_2_frame_1320.png-vineyard_split_2_frame_1305.png: 392 --> 392 matches\n",
      "filter_FundamentalMatrix: 4620 matches --> 4612 matches\n",
      "vineyard_split_2_frame_1320.png-vineyard_split_2_frame_1315.png: 4620 --> 4612 matches\n",
      "filter_FundamentalMatrix: 50 matches --> 30 matches\n",
      "vineyard_split_2_frame_1320.png-vineyard_split_3_frame_1400.png: 50 --> 30 matches\n",
      "filter_FundamentalMatrix: 3682 matches --> 3672 matches\n",
      "vineyard_split_2_frame_1205.png-vineyard_split_2_frame_1200.png: 3682 --> 3672 matches\n",
      "filter_FundamentalMatrix: 582 matches --> 581 matches\n",
      "vineyard_split_2_frame_1205.png-vineyard_split_2_frame_1195.png: 582 --> 581 matches\n",
      "filter_FundamentalMatrix: 6138 matches --> 6137 matches\n",
      "vineyard_split_2_frame_1205.png-vineyard_split_2_frame_1210.png: 6138 --> 6137 matches\n",
      "filter_FundamentalMatrix: 1229 matches --> 1221 matches\n",
      "vineyard_split_2_frame_1205.png-vineyard_split_2_frame_1215.png: 1229 --> 1221 matches\n",
      "filter_FundamentalMatrix: 256 matches --> 249 matches\n",
      "vineyard_split_2_frame_1240.png-vineyard_split_2_frame_1200.png: 256 --> 249 matches\n",
      "filter_FundamentalMatrix: 103 matches --> 99 matches\n",
      "vineyard_split_2_frame_1240.png-vineyard_split_2_frame_1255.png: 103 --> 99 matches\n",
      "filter_FundamentalMatrix: 129 matches --> 122 matches\n",
      "vineyard_split_2_frame_1240.png-vineyard_split_2_frame_1155.png: 129 --> 122 matches\n",
      "filter_FundamentalMatrix: 462 matches --> 461 matches\n",
      "vineyard_split_2_frame_1240.png-vineyard_split_2_frame_1250.png: 462 --> 461 matches\n",
      "filter_FundamentalMatrix: 5652 matches --> 5646 matches\n",
      "vineyard_split_2_frame_1240.png-vineyard_split_2_frame_1235.png: 5652 --> 5646 matches\n",
      "filter_FundamentalMatrix: 1740 matches --> 1730 matches\n",
      "vineyard_split_2_frame_1240.png-vineyard_split_2_frame_1230.png: 1740 --> 1730 matches\n",
      "filter_FundamentalMatrix: 2148 matches --> 2146 matches\n",
      "vineyard_split_2_frame_1170.png-vineyard_split_2_frame_1180.png: 2148 --> 2146 matches\n",
      "filter_FundamentalMatrix: 5418 matches --> 5411 matches\n",
      "vineyard_split_2_frame_1170.png-vineyard_split_2_frame_1165.png: 5418 --> 5411 matches\n",
      "filter_FundamentalMatrix: 740 matches --> 735 matches\n",
      "vineyard_split_2_frame_1170.png-vineyard_split_2_frame_1160.png: 740 --> 735 matches\n",
      "filter_FundamentalMatrix: 6896 matches --> 6894 matches\n",
      "vineyard_split_2_frame_1170.png-vineyard_split_2_frame_1175.png: 6896 --> 6894 matches\n",
      "filter_FundamentalMatrix: 5620 matches --> 5612 matches\n",
      "vineyard_split_2_frame_1300.png-vineyard_split_2_frame_1305.png: 5620 --> 5612 matches\n",
      "filter_FundamentalMatrix: 111 matches --> 110 matches\n",
      "vineyard_split_2_frame_1300.png-vineyard_split_3_frame_1460.png: 111 --> 110 matches\n",
      "filter_FundamentalMatrix: 5940 matches --> 5938 matches\n",
      "vineyard_split_2_frame_1290.png-vineyard_split_2_frame_1295.png: 5940 --> 5938 matches\n",
      "filter_FundamentalMatrix: 239 matches --> 237 matches\n",
      "vineyard_split_2_frame_1290.png-vineyard_split_2_frame_1305.png: 239 --> 237 matches\n",
      "filter_FundamentalMatrix: 3552 matches --> 3548 matches\n",
      "vineyard_split_2_frame_1290.png-vineyard_split_2_frame_1285.png: 3552 --> 3548 matches\n",
      "filter_FundamentalMatrix: 5869 matches --> 5864 matches\n",
      "vineyard_split_2_frame_1310.png-vineyard_split_2_frame_1305.png: 5869 --> 5864 matches\n",
      "filter_FundamentalMatrix: 135 matches --> 128 matches\n",
      "vineyard_split_2_frame_1200.png-vineyard_split_2_frame_1155.png: 135 --> 128 matches\n",
      "filter_FundamentalMatrix: 5422 matches --> 5413 matches\n",
      "vineyard_split_2_frame_1200.png-vineyard_split_2_frame_1195.png: 5422 --> 5413 matches\n",
      "filter_FundamentalMatrix: 777 matches --> 775 matches\n",
      "vineyard_split_2_frame_1200.png-vineyard_split_2_frame_1210.png: 777 --> 775 matches\n",
      "filter_FundamentalMatrix: 109 matches --> 109 matches\n",
      "vineyard_split_2_frame_1200.png-vineyard_split_2_frame_1185.png: 109 --> 109 matches\n",
      "filter_FundamentalMatrix: 274 matches --> 273 matches\n",
      "vineyard_split_2_frame_1180.png-vineyard_split_2_frame_1165.png: 274 --> 273 matches\n",
      "filter_FundamentalMatrix: 2290 matches --> 2286 matches\n",
      "vineyard_split_2_frame_1180.png-vineyard_split_2_frame_1185.png: 2290 --> 2286 matches\n",
      "filter_FundamentalMatrix: 4541 matches --> 4540 matches\n",
      "vineyard_split_2_frame_1255.png-vineyard_split_2_frame_1250.png: 4541 --> 4540 matches\n",
      "filter_FundamentalMatrix: 802 matches --> 796 matches\n",
      "vineyard_split_2_frame_1255.png-vineyard_split_2_frame_1265.png: 802 --> 796 matches\n",
      "filter_FundamentalMatrix: 191 matches --> 188 matches\n",
      "vineyard_split_2_frame_1220.png-vineyard_split_2_frame_1285.png: 191 --> 188 matches\n",
      "filter_FundamentalMatrix: 175 matches --> 166 matches\n",
      "vineyard_split_2_frame_1220.png-vineyard_split_2_frame_1235.png: 175 --> 166 matches\n",
      "filter_FundamentalMatrix: 662 matches --> 652 matches\n",
      "vineyard_split_2_frame_1220.png-vineyard_split_2_frame_1230.png: 662 --> 652 matches\n",
      "filter_FundamentalMatrix: 3296 matches --> 3291 matches\n",
      "vineyard_split_2_frame_1220.png-vineyard_split_2_frame_1215.png: 3296 --> 3291 matches\n",
      "filter_FundamentalMatrix: 5518 matches --> 5511 matches\n",
      "vineyard_split_2_frame_1165.png-vineyard_split_2_frame_1160.png: 5518 --> 5511 matches\n",
      "filter_FundamentalMatrix: 802 matches --> 801 matches\n",
      "vineyard_split_2_frame_1165.png-vineyard_split_2_frame_1155.png: 802 --> 801 matches\n",
      "filter_FundamentalMatrix: 137 matches --> 130 matches\n",
      "vineyard_split_2_frame_1165.png-vineyard_split_1_frame_1080.png: 137 --> 130 matches\n",
      "filter_FundamentalMatrix: 5995 matches --> 5991 matches\n",
      "vineyard_split_2_frame_1275.png-vineyard_split_2_frame_1280.png: 5995 --> 5991 matches\n",
      "filter_FundamentalMatrix: 2756 matches --> 2750 matches\n",
      "vineyard_split_2_frame_1275.png-vineyard_split_2_frame_1270.png: 2756 --> 2750 matches\n",
      "filter_FundamentalMatrix: 1006 matches --> 1006 matches\n",
      "vineyard_split_2_frame_1275.png-vineyard_split_2_frame_1285.png: 1006 --> 1006 matches\n",
      "filter_FundamentalMatrix: 149 matches --> 148 matches\n",
      "vineyard_split_2_frame_1275.png-vineyard_split_2_frame_1265.png: 149 --> 148 matches\n",
      "filter_FundamentalMatrix: 5246 matches --> 5244 matches\n",
      "vineyard_split_2_frame_1160.png-vineyard_split_2_frame_1155.png: 5246 --> 5244 matches\n",
      "filter_FundamentalMatrix: 351 matches --> 348 matches\n",
      "vineyard_split_2_frame_1160.png-vineyard_split_2_frame_1175.png: 351 --> 348 matches\n",
      "filter_FundamentalMatrix: 5980 matches --> 5972 matches\n",
      "vineyard_split_2_frame_1280.png-vineyard_split_2_frame_1285.png: 5980 --> 5972 matches\n",
      "filter_FundamentalMatrix: 5576 matches --> 5566 matches\n",
      "vineyard_split_2_frame_1155.png-vineyard_split_2_frame_1150.png: 5576 --> 5566 matches\n",
      "filter_FundamentalMatrix: 3410 matches --> 3407 matches\n",
      "vineyard_split_2_frame_1195.png-vineyard_split_2_frame_1185.png: 3410 --> 3407 matches\n",
      "filter_FundamentalMatrix: 4235 matches --> 4227 matches\n",
      "vineyard_split_2_frame_1270.png-vineyard_split_2_frame_1265.png: 4235 --> 4227 matches\n",
      "filter_FundamentalMatrix: 4807 matches --> 4803 matches\n",
      "vineyard_split_2_frame_1210.png-vineyard_split_2_frame_1215.png: 4807 --> 4803 matches\n",
      "filter_FundamentalMatrix: 145 matches --> 144 matches\n",
      "vineyard_split_2_frame_1250.png-vineyard_split_2_frame_1265.png: 145 --> 144 matches\n",
      "filter_FundamentalMatrix: 113 matches --> 86 matches\n",
      "vineyard_split_2_frame_1285.png-vineyard_split_1_frame_1015.png: 113 --> 86 matches\n",
      "filter_FundamentalMatrix: 150 matches --> 147 matches\n",
      "vineyard_split_2_frame_1150.png-vineyard_split_2_frame_1235.png: 150 --> 147 matches\n",
      "filter_FundamentalMatrix: 103 matches --> 94 matches\n",
      "vineyard_split_2_frame_1150.png-vineyard_split_2_frame_1230.png: 103 --> 94 matches\n",
      "filter_FundamentalMatrix: 5147 matches --> 5141 matches\n",
      "vineyard_split_2_frame_1235.png-vineyard_split_2_frame_1230.png: 5147 --> 5141 matches\n",
      "filter_FundamentalMatrix: 111 matches --> 108 matches\n",
      "vineyard_split_2_frame_1215.png-vineyard_split_1_frame_1080.png: 111 --> 108 matches\n",
      "filter_FundamentalMatrix: 3195 matches --> 3192 matches\n",
      "vineyard_split_3_frame_1395.png-vineyard_split_3_frame_1390.png: 3195 --> 3192 matches\n",
      "filter_FundamentalMatrix: 3118 matches --> 3108 matches\n",
      "vineyard_split_3_frame_1395.png-vineyard_split_3_frame_1405.png: 3118 --> 3108 matches\n",
      "filter_FundamentalMatrix: 6075 matches --> 6064 matches\n",
      "vineyard_split_3_frame_1395.png-vineyard_split_3_frame_1400.png: 6075 --> 6064 matches\n",
      "filter_FundamentalMatrix: 100 matches --> 94 matches\n",
      "vineyard_split_3_frame_1395.png-vineyard_split_3_frame_1420.png: 100 --> 94 matches\n",
      "filter_FundamentalMatrix: 61 matches --> 40 matches\n",
      "vineyard_split_3_frame_1395.png-vineyard_split_1_frame_1020.png: 61 --> 40 matches\n",
      "filter_FundamentalMatrix: 381 matches --> 379 matches\n",
      "vineyard_split_3_frame_1475.png-vineyard_split_3_frame_1460.png: 381 --> 379 matches\n",
      "filter_FundamentalMatrix: 6708 matches --> 6704 matches\n",
      "vineyard_split_3_frame_1475.png-vineyard_split_3_frame_1470.png: 6708 --> 6704 matches\n",
      "filter_FundamentalMatrix: 3284 matches --> 3279 matches\n",
      "vineyard_split_3_frame_0255.png-vineyard_split_3_frame_0265.png: 3284 --> 3279 matches\n",
      "filter_FundamentalMatrix: 2730 matches --> 2726 matches\n",
      "vineyard_split_3_frame_0255.png-vineyard_split_3_frame_0245.png: 2730 --> 2726 matches\n",
      "filter_FundamentalMatrix: 399 matches --> 399 matches\n",
      "vineyard_split_3_frame_0255.png-vineyard_split_3_frame_0240.png: 399 --> 399 matches\n",
      "filter_FundamentalMatrix: 5765 matches --> 5765 matches\n",
      "vineyard_split_3_frame_0255.png-vineyard_split_3_frame_0260.png: 5765 --> 5765 matches\n",
      "filter_FundamentalMatrix: 101 matches --> 96 matches\n",
      "vineyard_split_3_frame_1425.png-vineyard_split_3_frame_1405.png: 101 --> 96 matches\n",
      "filter_FundamentalMatrix: 572 matches --> 572 matches\n",
      "vineyard_split_3_frame_1425.png-vineyard_split_3_frame_1415.png: 572 --> 572 matches\n",
      "filter_FundamentalMatrix: 3620 matches --> 3618 matches\n",
      "vineyard_split_3_frame_1425.png-vineyard_split_3_frame_1420.png: 3620 --> 3618 matches\n",
      "filter_FundamentalMatrix: 188 matches --> 188 matches\n",
      "vineyard_split_3_frame_0125.png-vineyard_split_3_frame_0140.png: 188 --> 188 matches\n",
      "filter_FundamentalMatrix: 6535 matches --> 6533 matches\n",
      "vineyard_split_3_frame_0125.png-vineyard_split_3_frame_0120.png: 6535 --> 6533 matches\n",
      "filter_FundamentalMatrix: 316 matches --> 311 matches\n",
      "vineyard_split_3_frame_0125.png-vineyard_split_3_frame_0105.png: 316 --> 311 matches\n",
      "filter_FundamentalMatrix: 1145 matches --> 1140 matches\n",
      "vineyard_split_3_frame_0125.png-vineyard_split_3_frame_0110.png: 1145 --> 1140 matches\n",
      "filter_FundamentalMatrix: 2629 matches --> 2628 matches\n",
      "vineyard_split_3_frame_0125.png-vineyard_split_3_frame_0135.png: 2629 --> 2628 matches\n",
      "filter_FundamentalMatrix: 5588 matches --> 5582 matches\n",
      "vineyard_split_3_frame_1480.png-vineyard_split_3_frame_1485.png: 5588 --> 5582 matches\n",
      "filter_FundamentalMatrix: 2460 matches --> 2454 matches\n",
      "vineyard_split_3_frame_1480.png-vineyard_split_3_frame_1470.png: 2460 --> 2454 matches\n",
      "filter_FundamentalMatrix: 2739 matches --> 2727 matches\n",
      "vineyard_split_3_frame_0215.png-vineyard_split_3_frame_0225.png: 2739 --> 2727 matches\n",
      "filter_FundamentalMatrix: 2571 matches --> 2564 matches\n",
      "vineyard_split_3_frame_0215.png-vineyard_split_3_frame_0205.png: 2571 --> 2564 matches\n",
      "filter_FundamentalMatrix: 6310 matches --> 6309 matches\n",
      "vineyard_split_3_frame_0215.png-vineyard_split_3_frame_0220.png: 6310 --> 6309 matches\n",
      "filter_FundamentalMatrix: 150 matches --> 143 matches\n",
      "vineyard_split_3_frame_0215.png-vineyard_split_3_frame_0200.png: 150 --> 143 matches\n",
      "filter_FundamentalMatrix: 169 matches --> 167 matches\n",
      "vineyard_split_3_frame_0215.png-vineyard_split_3_frame_0230.png: 169 --> 167 matches\n",
      "filter_FundamentalMatrix: 2098 matches --> 2089 matches\n",
      "vineyard_split_3_frame_0295.png-vineyard_split_3_frame_0285.png: 2098 --> 2089 matches\n",
      "filter_FundamentalMatrix: 2222 matches --> 2212 matches\n",
      "vineyard_split_3_frame_0295.png-vineyard_split_3_frame_0305.png: 2222 --> 2212 matches\n",
      "filter_FundamentalMatrix: 3518 matches --> 3510 matches\n",
      "vineyard_split_3_frame_0295.png-vineyard_split_3_frame_0300.png: 3518 --> 3510 matches\n",
      "filter_FundamentalMatrix: 2727 matches --> 2723 matches\n",
      "vineyard_split_3_frame_0090.png-vineyard_split_3_frame_0080.png: 2727 --> 2723 matches\n",
      "filter_FundamentalMatrix: 6579 matches --> 6575 matches\n",
      "vineyard_split_3_frame_0090.png-vineyard_split_3_frame_0085.png: 6579 --> 6575 matches\n",
      "filter_FundamentalMatrix: 5972 matches --> 5968 matches\n",
      "vineyard_split_3_frame_0090.png-vineyard_split_3_frame_0095.png: 5972 --> 5968 matches\n",
      "filter_FundamentalMatrix: 5132 matches --> 5125 matches\n",
      "vineyard_split_3_frame_0190.png-vineyard_split_3_frame_0195.png: 5132 --> 5125 matches\n",
      "filter_FundamentalMatrix: 1797 matches --> 1794 matches\n",
      "vineyard_split_3_frame_0190.png-vineyard_split_3_frame_0180.png: 1797 --> 1794 matches\n",
      "filter_FundamentalMatrix: 4476 matches --> 4471 matches\n",
      "vineyard_split_3_frame_0265.png-vineyard_split_3_frame_0270.png: 4476 --> 4471 matches\n",
      "filter_FundamentalMatrix: 2407 matches --> 2404 matches\n",
      "vineyard_split_3_frame_0265.png-vineyard_split_3_frame_0275.png: 2407 --> 2404 matches\n",
      "filter_FundamentalMatrix: 178 matches --> 174 matches\n",
      "vineyard_split_3_frame_0265.png-vineyard_split_3_frame_0245.png: 178 --> 174 matches\n",
      "filter_FundamentalMatrix: 6136 matches --> 6134 matches\n",
      "vineyard_split_3_frame_0265.png-vineyard_split_3_frame_0260.png: 6136 --> 6134 matches\n",
      "filter_FundamentalMatrix: 3765 matches --> 3764 matches\n",
      "vineyard_split_3_frame_1445.png-vineyard_split_3_frame_1450.png: 3765 --> 3764 matches\n",
      "filter_FundamentalMatrix: 5403 matches --> 5398 matches\n",
      "vineyard_split_3_frame_1445.png-vineyard_split_3_frame_1440.png: 5403 --> 5398 matches\n",
      "filter_FundamentalMatrix: 185 matches --> 181 matches\n",
      "vineyard_split_3_frame_1445.png-vineyard_split_3_frame_1435.png: 185 --> 181 matches\n",
      "filter_FundamentalMatrix: 202 matches --> 201 matches\n",
      "vineyard_split_3_frame_1450.png-vineyard_split_3_frame_1465.png: 202 --> 201 matches\n",
      "filter_FundamentalMatrix: 391 matches --> 390 matches\n",
      "vineyard_split_3_frame_1450.png-vineyard_split_3_frame_1440.png: 391 --> 390 matches\n",
      "filter_FundamentalMatrix: 480 matches --> 478 matches\n",
      "vineyard_split_3_frame_1450.png-vineyard_split_3_frame_1460.png: 480 --> 478 matches\n",
      "filter_FundamentalMatrix: 752 matches --> 745 matches\n",
      "vineyard_split_3_frame_1390.png-vineyard_split_3_frame_1400.png: 752 --> 745 matches\n",
      "filter_FundamentalMatrix: 847 matches --> 845 matches\n",
      "vineyard_split_3_frame_1555.png-vineyard_split_3_frame_1545.png: 847 --> 845 matches\n",
      "filter_FundamentalMatrix: 4233 matches --> 4227 matches\n",
      "vineyard_split_3_frame_1555.png-vineyard_split_3_frame_1560.png: 4233 --> 4227 matches\n",
      "filter_FundamentalMatrix: 586 matches --> 584 matches\n",
      "vineyard_split_3_frame_1550.png-vineyard_split_3_frame_1535.png: 586 --> 584 matches\n",
      "filter_FundamentalMatrix: 5745 matches --> 5738 matches\n",
      "vineyard_split_3_frame_1550.png-vineyard_split_3_frame_1545.png: 5745 --> 5738 matches\n",
      "filter_FundamentalMatrix: 116 matches --> 112 matches\n",
      "vineyard_split_3_frame_0145.png-vineyard_split_3_frame_0235.png: 116 --> 112 matches\n",
      "filter_FundamentalMatrix: 109 matches --> 107 matches\n",
      "vineyard_split_3_frame_0145.png-vineyard_split_3_frame_0130.png: 109 --> 107 matches\n",
      "filter_FundamentalMatrix: 5198 matches --> 5196 matches\n",
      "vineyard_split_3_frame_1405.png-vineyard_split_3_frame_1410.png: 5198 --> 5196 matches\n",
      "filter_FundamentalMatrix: 6455 matches --> 6445 matches\n",
      "vineyard_split_3_frame_1405.png-vineyard_split_3_frame_1400.png: 6455 --> 6445 matches\n",
      "filter_FundamentalMatrix: 751 matches --> 747 matches\n",
      "vineyard_split_3_frame_1405.png-vineyard_split_3_frame_1415.png: 751 --> 747 matches\n",
      "filter_FundamentalMatrix: 133 matches --> 130 matches\n",
      "vineyard_split_3_frame_1405.png-vineyard_split_3_frame_1420.png: 133 --> 130 matches\n",
      "filter_FundamentalMatrix: 4094 matches --> 4089 matches\n",
      "vineyard_split_3_frame_0070.png-vineyard_split_3_frame_0075.png: 4094 --> 4089 matches\n",
      "filter_FundamentalMatrix: 1382 matches --> 1381 matches\n",
      "vineyard_split_3_frame_0070.png-vineyard_split_3_frame_0080.png: 1382 --> 1381 matches\n",
      "filter_FundamentalMatrix: 301 matches --> 294 matches\n",
      "vineyard_split_3_frame_0070.png-vineyard_split_3_frame_0085.png: 301 --> 294 matches\n",
      "filter_FundamentalMatrix: 2288 matches --> 2278 matches\n",
      "vineyard_split_3_frame_1500.png-vineyard_split_3_frame_1490.png: 2288 --> 2278 matches\n",
      "filter_FundamentalMatrix: 6471 matches --> 6469 matches\n",
      "vineyard_split_3_frame_0075.png-vineyard_split_3_frame_0080.png: 6471 --> 6469 matches\n",
      "filter_FundamentalMatrix: 2741 matches --> 2739 matches\n",
      "vineyard_split_3_frame_0075.png-vineyard_split_3_frame_0085.png: 2741 --> 2739 matches\n",
      "filter_FundamentalMatrix: 666 matches --> 662 matches\n",
      "vineyard_split_3_frame_0160.png-vineyard_split_3_frame_0150.png: 666 --> 662 matches\n",
      "filter_FundamentalMatrix: 6531 matches --> 6530 matches\n",
      "vineyard_split_3_frame_0160.png-vineyard_split_3_frame_0165.png: 6531 --> 6530 matches\n",
      "filter_FundamentalMatrix: 4938 matches --> 4926 matches\n",
      "vineyard_split_3_frame_0160.png-vineyard_split_3_frame_0155.png: 4938 --> 4926 matches\n",
      "filter_FundamentalMatrix: 2996 matches --> 2993 matches\n",
      "vineyard_split_3_frame_0150.png-vineyard_split_3_frame_0140.png: 2996 --> 2993 matches\n",
      "filter_FundamentalMatrix: 271 matches --> 271 matches\n",
      "vineyard_split_3_frame_0150.png-vineyard_split_3_frame_0165.png: 271 --> 271 matches\n",
      "filter_FundamentalMatrix: 5642 matches --> 5631 matches\n",
      "vineyard_split_3_frame_0150.png-vineyard_split_3_frame_0155.png: 5642 --> 5631 matches\n",
      "filter_FundamentalMatrix: 4512 matches --> 4500 matches\n",
      "vineyard_split_3_frame_0140.png-vineyard_split_3_frame_0135.png: 4512 --> 4500 matches\n",
      "filter_FundamentalMatrix: 2651 matches --> 2642 matches\n",
      "vineyard_split_3_frame_0270.png-vineyard_split_3_frame_0285.png: 2651 --> 2642 matches\n",
      "filter_FundamentalMatrix: 4988 matches --> 4976 matches\n",
      "vineyard_split_3_frame_0270.png-vineyard_split_3_frame_0280.png: 4988 --> 4976 matches\n",
      "filter_FundamentalMatrix: 6147 matches --> 6144 matches\n",
      "vineyard_split_3_frame_0270.png-vineyard_split_3_frame_0275.png: 6147 --> 6144 matches\n",
      "filter_FundamentalMatrix: 2250 matches --> 2245 matches\n",
      "vineyard_split_3_frame_0270.png-vineyard_split_3_frame_0260.png: 2250 --> 2245 matches\n",
      "filter_FundamentalMatrix: 5830 matches --> 5826 matches\n",
      "vineyard_split_3_frame_0170.png-vineyard_split_3_frame_0175.png: 5830 --> 5826 matches\n",
      "filter_FundamentalMatrix: 5832 matches --> 5830 matches\n",
      "vineyard_split_3_frame_0170.png-vineyard_split_3_frame_0165.png: 5832 --> 5830 matches\n",
      "filter_FundamentalMatrix: 2463 matches --> 2459 matches\n",
      "vineyard_split_3_frame_0170.png-vineyard_split_3_frame_0180.png: 2463 --> 2459 matches\n",
      "filter_FundamentalMatrix: 7363 matches --> 7361 matches\n",
      "vineyard_split_3_frame_0285.png-vineyard_split_3_frame_0280.png: 7363 --> 7361 matches\n",
      "filter_FundamentalMatrix: 5037 matches --> 5015 matches\n",
      "vineyard_split_3_frame_0285.png-vineyard_split_3_frame_0275.png: 5037 --> 5015 matches\n",
      "filter_FundamentalMatrix: 3982 matches --> 3969 matches\n",
      "vineyard_split_3_frame_1490.png-vineyard_split_3_frame_1485.png: 3982 --> 3969 matches\n",
      "filter_FundamentalMatrix: 7071 matches --> 7070 matches\n",
      "vineyard_split_3_frame_0280.png-vineyard_split_3_frame_0275.png: 7071 --> 7070 matches\n",
      "filter_FundamentalMatrix: 319 matches --> 319 matches\n",
      "vineyard_split_3_frame_0275.png-vineyard_split_3_frame_0260.png: 319 --> 319 matches\n",
      "filter_FundamentalMatrix: 181 matches --> 177 matches\n",
      "vineyard_split_3_frame_0225.png-vineyard_split_3_frame_0210.png: 181 --> 177 matches\n",
      "filter_FundamentalMatrix: 4543 matches --> 4539 matches\n",
      "vineyard_split_3_frame_0225.png-vineyard_split_3_frame_0220.png: 4543 --> 4539 matches\n",
      "filter_FundamentalMatrix: 4104 matches --> 4098 matches\n",
      "vineyard_split_3_frame_0225.png-vineyard_split_3_frame_0230.png: 4104 --> 4098 matches\n",
      "filter_FundamentalMatrix: 5049 matches --> 5044 matches\n",
      "vineyard_split_3_frame_0080.png-vineyard_split_3_frame_0085.png: 5049 --> 5044 matches\n",
      "filter_FundamentalMatrix: 375 matches --> 374 matches\n",
      "vineyard_split_3_frame_0080.png-vineyard_split_3_frame_0095.png: 375 --> 374 matches\n",
      "filter_FundamentalMatrix: 506 matches --> 504 matches\n",
      "vineyard_split_3_frame_0250.png-vineyard_split_3_frame_0235.png: 506 --> 504 matches\n",
      "filter_FundamentalMatrix: 508 matches --> 508 matches\n",
      "vineyard_split_3_frame_1495.png-vineyard_split_3_frame_1505.png: 508 --> 508 matches\n",
      "filter_FundamentalMatrix: 1116 matches --> 1111 matches\n",
      "vineyard_split_3_frame_0120.png-vineyard_split_3_frame_0105.png: 1116 --> 1111 matches\n",
      "filter_FundamentalMatrix: 3772 matches --> 3764 matches\n",
      "vineyard_split_3_frame_0120.png-vineyard_split_3_frame_0110.png: 3772 --> 3764 matches\n",
      "filter_FundamentalMatrix: 569 matches --> 568 matches\n",
      "vineyard_split_3_frame_0120.png-vineyard_split_3_frame_0135.png: 569 --> 568 matches\n",
      "filter_FundamentalMatrix: 3142 matches --> 3131 matches\n",
      "vineyard_split_3_frame_1510.png-vineyard_split_3_frame_1520.png: 3142 --> 3131 matches\n",
      "filter_FundamentalMatrix: 132 matches --> 131 matches\n",
      "vineyard_split_3_frame_1510.png-vineyard_split_3_frame_1525.png: 132 --> 131 matches\n",
      "filter_FundamentalMatrix: 6694 matches --> 6688 matches\n",
      "vineyard_split_3_frame_1510.png-vineyard_split_3_frame_1515.png: 6694 --> 6688 matches\n",
      "filter_FundamentalMatrix: 59 matches --> 41 matches\n",
      "vineyard_split_3_frame_1510.png-vineyard_split_1_frame_1010.png: 59 --> 41 matches\n",
      "filter_FundamentalMatrix: 7074 matches --> 7074 matches\n",
      "vineyard_split_3_frame_0105.png-vineyard_split_3_frame_0110.png: 7074 --> 7074 matches\n",
      "filter_FundamentalMatrix: 3580 matches --> 3569 matches\n",
      "vineyard_split_3_frame_0105.png-vineyard_split_3_frame_0100.png: 3580 --> 3569 matches\n",
      "filter_FundamentalMatrix: 600 matches --> 596 matches\n",
      "vineyard_split_3_frame_0105.png-vineyard_split_3_frame_0095.png: 600 --> 596 matches\n",
      "filter_FundamentalMatrix: 3216 matches --> 3197 matches\n",
      "vineyard_split_3_frame_1535.png-vineyard_split_3_frame_1530.png: 3216 --> 3197 matches\n",
      "filter_FundamentalMatrix: 6774 matches --> 6768 matches\n",
      "vineyard_split_3_frame_1540.png-vineyard_split_3_frame_1545.png: 6774 --> 6768 matches\n",
      "filter_FundamentalMatrix: 1361 matches --> 1354 matches\n",
      "vineyard_split_3_frame_0205.png-vineyard_split_3_frame_0195.png: 1361 --> 1354 matches\n",
      "filter_FundamentalMatrix: 5728 matches --> 5724 matches\n",
      "vineyard_split_3_frame_0205.png-vineyard_split_3_frame_0210.png: 5728 --> 5724 matches\n",
      "filter_FundamentalMatrix: 662 matches --> 649 matches\n",
      "vineyard_split_3_frame_0205.png-vineyard_split_3_frame_0220.png: 662 --> 649 matches\n",
      "filter_FundamentalMatrix: 4549 matches --> 4543 matches\n",
      "vineyard_split_3_frame_0205.png-vineyard_split_3_frame_0200.png: 4549 --> 4543 matches\n",
      "filter_FundamentalMatrix: 5917 matches --> 5914 matches\n",
      "vineyard_split_3_frame_1410.png-vineyard_split_3_frame_1415.png: 5917 --> 5914 matches\n",
      "filter_FundamentalMatrix: 2541 matches --> 2527 matches\n",
      "vineyard_split_3_frame_1410.png-vineyard_split_3_frame_1420.png: 2541 --> 2527 matches\n",
      "filter_FundamentalMatrix: 7659 matches --> 7657 matches\n",
      "vineyard_split_3_frame_0305.png-vineyard_split_3_frame_0300.png: 7659 --> 7657 matches\n",
      "filter_FundamentalMatrix: 1980 matches --> 1973 matches\n",
      "vineyard_split_3_frame_0175.png-vineyard_split_3_frame_0185.png: 1980 --> 1973 matches\n",
      "filter_FundamentalMatrix: 3634 matches --> 3628 matches\n",
      "vineyard_split_3_frame_1520.png-vineyard_split_3_frame_1525.png: 3634 --> 3628 matches\n",
      "filter_FundamentalMatrix: 7622 matches --> 7619 matches\n",
      "vineyard_split_3_frame_1465.png-vineyard_split_3_frame_1460.png: 7622 --> 7619 matches\n",
      "filter_FundamentalMatrix: 3105 matches --> 3094 matches\n",
      "vineyard_split_3_frame_1465.png-vineyard_split_3_frame_1470.png: 3105 --> 3094 matches\n",
      "filter_FundamentalMatrix: 5346 matches --> 5330 matches\n",
      "vineyard_split_3_frame_1525.png-vineyard_split_3_frame_1530.png: 5346 --> 5330 matches\n",
      "filter_FundamentalMatrix: 2384 matches --> 2372 matches\n",
      "vineyard_split_3_frame_0110.png-vineyard_split_3_frame_0100.png: 2384 --> 2372 matches\n",
      "filter_FundamentalMatrix: 6487 matches --> 6485 matches\n",
      "vineyard_split_3_frame_0110.png-vineyard_split_3_frame_0115.png: 6487 --> 6485 matches\n",
      "filter_FundamentalMatrix: 5228 matches --> 5225 matches\n",
      "vineyard_split_3_frame_0195.png-vineyard_split_3_frame_0200.png: 5228 --> 5225 matches\n",
      "filter_FundamentalMatrix: 1652 matches --> 1642 matches\n",
      "vineyard_split_3_frame_1570.png-vineyard_split_3_frame_1560.png: 1652 --> 1642 matches\n",
      "filter_FundamentalMatrix: 5991 matches --> 5986 matches\n",
      "vineyard_split_3_frame_1570.png-vineyard_split_3_frame_1565.png: 5991 --> 5986 matches\n",
      "filter_FundamentalMatrix: 3095 matches --> 3071 matches\n",
      "vineyard_split_3_frame_0210.png-vineyard_split_3_frame_0220.png: 3095 --> 3071 matches\n",
      "filter_FundamentalMatrix: 2033 matches --> 2024 matches\n",
      "vineyard_split_3_frame_0210.png-vineyard_split_3_frame_0200.png: 2033 --> 2024 matches\n",
      "filter_FundamentalMatrix: 394 matches --> 391 matches\n",
      "vineyard_split_3_frame_0100.png-vineyard_split_3_frame_0085.png: 394 --> 391 matches\n",
      "filter_FundamentalMatrix: 5167 matches --> 5167 matches\n",
      "vineyard_split_3_frame_0100.png-vineyard_split_3_frame_0095.png: 5167 --> 5167 matches\n",
      "filter_FundamentalMatrix: 5749 matches --> 5746 matches\n",
      "vineyard_split_3_frame_1560.png-vineyard_split_3_frame_1565.png: 5749 --> 5746 matches\n",
      "filter_FundamentalMatrix: 5056 matches --> 5056 matches\n",
      "vineyard_split_3_frame_1430.png-vineyard_split_3_frame_1435.png: 5056 --> 5056 matches\n",
      "filter_FundamentalMatrix: 6293 matches --> 6282 matches\n",
      "vineyard_split_3_frame_0245.png-vineyard_split_3_frame_0240.png: 6293 --> 6282 matches\n",
      "filter_FundamentalMatrix: 347 matches --> 347 matches\n",
      "vineyard_split_3_frame_0245.png-vineyard_split_3_frame_0260.png: 347 --> 347 matches\n",
      "filter_FundamentalMatrix: 425 matches --> 423 matches\n",
      "vineyard_split_3_frame_0130.png-vineyard_split_3_frame_0115.png: 425 --> 423 matches\n",
      "filter_FundamentalMatrix: 4570 matches --> 4552 matches\n",
      "vineyard_split_3_frame_1440.png-vineyard_split_3_frame_1435.png: 4570 --> 4552 matches\n",
      "filter_FundamentalMatrix: 2774 matches --> 2770 matches\n",
      "vineyard_split_3_frame_0240.png-vineyard_split_3_frame_0230.png: 2774 --> 2770 matches\n",
      "filter_FundamentalMatrix: 857 matches --> 853 matches\n",
      "vineyard_split_3_frame_1460.png-vineyard_split_3_frame_1470.png: 857 --> 853 matches\n",
      "filter_FundamentalMatrix: 2744 matches --> 2732 matches\n",
      "vineyard_split_3_frame_0165.png-vineyard_split_3_frame_0155.png: 2744 --> 2732 matches\n",
      "filter_FundamentalMatrix: 5852 matches --> 5845 matches\n",
      "vineyard_split_3_frame_1415.png-vineyard_split_3_frame_1420.png: 5852 --> 5845 matches\n",
      "filter_FundamentalMatrix: 3404 matches --> 3395 matches\n",
      "vineyard_split_3_frame_0085.png-vineyard_split_3_frame_0095.png: 3404 --> 3395 matches\n",
      "filter_FundamentalMatrix: 776 matches --> 775 matches\n",
      "vineyard_split_1_frame_0950.png-vineyard_split_1_frame_0960.png: 776 --> 775 matches\n",
      "filter_FundamentalMatrix: 1911 matches --> 1908 matches\n",
      "vineyard_split_1_frame_1005.png-vineyard_split_1_frame_0995.png: 1911 --> 1908 matches\n",
      "filter_FundamentalMatrix: 7694 matches --> 7689 matches\n",
      "vineyard_split_1_frame_0915.png-vineyard_split_1_frame_0910.png: 7694 --> 7689 matches\n",
      "filter_FundamentalMatrix: 4167 matches --> 4160 matches\n",
      "vineyard_split_1_frame_0915.png-vineyard_split_1_frame_0920.png: 4167 --> 4160 matches\n",
      "filter_FundamentalMatrix: 181 matches --> 179 matches\n",
      "vineyard_split_1_frame_1070.png-vineyard_split_1_frame_1055.png: 181 --> 179 matches\n",
      "filter_FundamentalMatrix: 3810 matches --> 3810 matches\n",
      "vineyard_split_1_frame_1070.png-vineyard_split_1_frame_1065.png: 3810 --> 3810 matches\n",
      "filter_FundamentalMatrix: 742 matches --> 734 matches\n",
      "vineyard_split_1_frame_1070.png-vineyard_split_1_frame_1080.png: 742 --> 734 matches\n",
      "filter_FundamentalMatrix: 3894 matches --> 3890 matches\n",
      "vineyard_split_1_frame_1070.png-vineyard_split_1_frame_1075.png: 3894 --> 3890 matches\n",
      "filter_FundamentalMatrix: 5975 matches --> 5965 matches\n",
      "vineyard_split_1_frame_1015.png-vineyard_split_1_frame_1020.png: 5975 --> 5965 matches\n",
      "filter_FundamentalMatrix: 56 matches --> 39 matches\n",
      "vineyard_split_1_frame_1015.png-vineyard_split_1_frame_1100.png: 56 --> 39 matches\n",
      "filter_FundamentalMatrix: 3857 matches --> 3850 matches\n",
      "vineyard_split_1_frame_1015.png-vineyard_split_1_frame_1010.png: 3857 --> 3850 matches\n",
      "filter_FundamentalMatrix: 723 matches --> 706 matches\n",
      "vineyard_split_1_frame_0990.png-vineyard_split_1_frame_0980.png: 723 --> 706 matches\n",
      "filter_FundamentalMatrix: 1239 matches --> 1233 matches\n",
      "vineyard_split_1_frame_0990.png-vineyard_split_1_frame_1000.png: 1239 --> 1233 matches\n",
      "filter_FundamentalMatrix: 5857 matches --> 5848 matches\n",
      "vineyard_split_1_frame_0990.png-vineyard_split_1_frame_0985.png: 5857 --> 5848 matches\n",
      "filter_FundamentalMatrix: 161 matches --> 160 matches\n",
      "vineyard_split_1_frame_0990.png-vineyard_split_1_frame_0975.png: 161 --> 160 matches\n",
      "filter_FundamentalMatrix: 868 matches --> 865 matches\n",
      "vineyard_split_1_frame_1055.png-vineyard_split_1_frame_1065.png: 868 --> 865 matches\n",
      "filter_FundamentalMatrix: 1302 matches --> 1295 matches\n",
      "vineyard_split_1_frame_1055.png-vineyard_split_1_frame_1045.png: 1302 --> 1295 matches\n",
      "filter_FundamentalMatrix: 242 matches --> 240 matches\n",
      "vineyard_split_1_frame_1055.png-vineyard_split_1_frame_1040.png: 242 --> 240 matches\n",
      "filter_FundamentalMatrix: 5557 matches --> 5555 matches\n",
      "vineyard_split_1_frame_1055.png-vineyard_split_1_frame_1050.png: 5557 --> 5555 matches\n",
      "filter_FundamentalMatrix: 4283 matches --> 4277 matches\n",
      "vineyard_split_1_frame_0965.png-vineyard_split_1_frame_0960.png: 4283 --> 4277 matches\n",
      "filter_FundamentalMatrix: 5744 matches --> 5739 matches\n",
      "vineyard_split_1_frame_0935.png-vineyard_split_1_frame_0940.png: 5744 --> 5739 matches\n",
      "filter_FundamentalMatrix: 451 matches --> 451 matches\n",
      "vineyard_split_1_frame_0970.png-vineyard_split_1_frame_0960.png: 451 --> 451 matches\n",
      "filter_FundamentalMatrix: 3129 matches --> 3122 matches\n",
      "vineyard_split_1_frame_0970.png-vineyard_split_1_frame_0980.png: 3129 --> 3122 matches\n",
      "filter_FundamentalMatrix: 345 matches --> 342 matches\n",
      "vineyard_split_1_frame_0970.png-vineyard_split_1_frame_0985.png: 345 --> 342 matches\n",
      "filter_FundamentalMatrix: 5978 matches --> 5977 matches\n",
      "vineyard_split_1_frame_0970.png-vineyard_split_1_frame_0975.png: 5978 --> 5977 matches\n",
      "filter_FundamentalMatrix: 5771 matches --> 5762 matches\n",
      "vineyard_split_1_frame_0960.png-vineyard_split_1_frame_0955.png: 5771 --> 5762 matches\n",
      "filter_FundamentalMatrix: 103 matches --> 97 matches\n",
      "vineyard_split_1_frame_1095.png-vineyard_split_1_frame_1080.png: 103 --> 97 matches\n",
      "filter_FundamentalMatrix: 6346 matches --> 6341 matches\n",
      "vineyard_split_1_frame_1095.png-vineyard_split_1_frame_1100.png: 6346 --> 6341 matches\n",
      "filter_FundamentalMatrix: 4697 matches --> 4693 matches\n",
      "vineyard_split_1_frame_1095.png-vineyard_split_1_frame_1105.png: 4697 --> 4693 matches\n",
      "filter_FundamentalMatrix: 2046 matches --> 2037 matches\n",
      "vineyard_split_1_frame_0945.png-vineyard_split_1_frame_0955.png: 2046 --> 2037 matches\n",
      "filter_FundamentalMatrix: 4788 matches --> 4777 matches\n",
      "vineyard_split_1_frame_0945.png-vineyard_split_1_frame_0940.png: 4788 --> 4777 matches\n",
      "filter_FundamentalMatrix: 4592 matches --> 4578 matches\n",
      "vineyard_split_1_frame_0905.png-vineyard_split_1_frame_0900.png: 4592 --> 4578 matches\n",
      "filter_FundamentalMatrix: 172 matches --> 172 matches\n",
      "vineyard_split_1_frame_0905.png-vineyard_split_1_frame_0920.png: 172 --> 172 matches\n",
      "filter_FundamentalMatrix: 5201 matches --> 5201 matches\n",
      "vineyard_split_1_frame_1085.png-vineyard_split_1_frame_1090.png: 5201 --> 5201 matches\n",
      "filter_FundamentalMatrix: 189 matches --> 184 matches\n",
      "vineyard_split_1_frame_0955.png-vineyard_split_1_frame_0940.png: 189 --> 184 matches\n",
      "filter_FundamentalMatrix: 5904 matches --> 5901 matches\n",
      "vineyard_split_1_frame_0980.png-vineyard_split_1_frame_0985.png: 5904 --> 5901 matches\n",
      "filter_FundamentalMatrix: 6929 matches --> 6928 matches\n",
      "vineyard_split_1_frame_0980.png-vineyard_split_1_frame_0975.png: 6929 --> 6928 matches\n",
      "filter_FundamentalMatrix: 5273 matches --> 5267 matches\n",
      "vineyard_split_1_frame_1045.png-vineyard_split_1_frame_1040.png: 5273 --> 5267 matches\n",
      "filter_FundamentalMatrix: 2836 matches --> 2822 matches\n",
      "vineyard_split_1_frame_1045.png-vineyard_split_1_frame_1035.png: 2836 --> 2822 matches\n",
      "filter_FundamentalMatrix: 3916 matches --> 3916 matches\n",
      "vineyard_split_1_frame_1045.png-vineyard_split_1_frame_1050.png: 3916 --> 3916 matches\n",
      "filter_FundamentalMatrix: 4993 matches --> 4993 matches\n",
      "vineyard_split_1_frame_1080.png-vineyard_split_1_frame_1075.png: 4993 --> 4993 matches\n",
      "filter_FundamentalMatrix: 5851 matches --> 5850 matches\n",
      "vineyard_split_1_frame_1040.png-vineyard_split_1_frame_1035.png: 5851 --> 5850 matches\n",
      "filter_FundamentalMatrix: 2000 matches --> 1994 matches\n",
      "vineyard_split_1_frame_1040.png-vineyard_split_1_frame_1030.png: 2000 --> 1994 matches\n",
      "filter_FundamentalMatrix: 619 matches --> 617 matches\n",
      "vineyard_split_1_frame_1040.png-vineyard_split_1_frame_1050.png: 619 --> 617 matches\n",
      "filter_FundamentalMatrix: 5197 matches --> 5178 matches\n",
      "vineyard_split_1_frame_1110.png-vineyard_split_1_frame_1100.png: 5197 --> 5178 matches\n",
      "filter_FundamentalMatrix: 5760 matches --> 5748 matches\n",
      "vineyard_split_1_frame_1110.png-vineyard_split_1_frame_1105.png: 5760 --> 5748 matches\n",
      "filter_FundamentalMatrix: 862 matches --> 849 matches\n",
      "vineyard_split_1_frame_1020.png-vineyard_split_1_frame_1010.png: 862 --> 849 matches\n",
      "filter_FundamentalMatrix: 1679 matches --> 1666 matches\n",
      "vineyard_split_1_frame_1020.png-vineyard_split_1_frame_1030.png: 1679 --> 1666 matches\n",
      "filter_FundamentalMatrix: 544 matches --> 544 matches\n",
      "vineyard_split_1_frame_1000.png-vineyard_split_1_frame_1010.png: 544 --> 544 matches\n",
      "filter_FundamentalMatrix: 120 matches --> 112 matches\n",
      "vineyard_split_1_frame_1000.png-vineyard_split_1_frame_0985.png: 120 --> 112 matches\n",
      "filter_FundamentalMatrix: 5241 matches --> 5236 matches\n",
      "vineyard_split_1_frame_1035.png-vineyard_split_1_frame_1030.png: 5241 --> 5236 matches\n",
      "filter_FundamentalMatrix: 7086 matches --> 7082 matches\n",
      "vineyard_split_1_frame_1100.png-vineyard_split_1_frame_1105.png: 7086 --> 7082 matches\n",
      "filter_FundamentalMatrix: 418 matches --> 413 matches\n",
      "vineyard_split_1_frame_0940.png-vineyard_split_1_frame_0925.png: 418 --> 413 matches\n",
      "filter_FundamentalMatrix: 5913 matches --> 5908 matches\n",
      "vineyard_split_1_frame_0925.png-vineyard_split_1_frame_0930.png: 5913 --> 5908 matches\n",
      "filter_FundamentalMatrix: 4617 matches --> 4606 matches\n",
      "vineyard_split_1_frame_0925.png-vineyard_split_1_frame_0920.png: 4617 --> 4606 matches\n",
      "filter_FundamentalMatrix: 3481 matches --> 3453 matches\n",
      "vineyard_split_1_frame_0985.png-vineyard_split_1_frame_0975.png: 3481 --> 3453 matches\n",
      "filter_FundamentalMatrix: 6528 matches --> 6523 matches\n",
      "vineyard_split_1_frame_1030.png-vineyard_split_1_frame_1025.png: 6528 --> 6523 matches\n",
      "Ensembled pairs : 255 pairs\n",
      "Local feature extracting and matching. Done in 1174.7288 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 159/159 [00:01<00:00, 95.06it/s] \n",
      "  4%|         | 255/6786 [00:00<00:02, 3086.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original results\n",
      "{0: Reconstruction(num_reg_images=44, num_cameras=44, num_points3D=52928, num_observations=202207), 1: Reconstruction(num_reg_images=5, num_cameras=5, num_points3D=6856, num_observations=25406), 2: Reconstruction(num_reg_images=20, num_cameras=20, num_points3D=16299, num_observations=55543), 3: Reconstruction(num_reg_images=16, num_cameras=16, num_points3D=12026, num_observations=42192), 4: Reconstruction(num_reg_images=13, num_cameras=13, num_points3D=10110, num_observations=32167), 5: Reconstruction(num_reg_images=10, num_cameras=10, num_points3D=6140, num_observations=20090), 6: Reconstruction(num_reg_images=36, num_cameras=36, num_points3D=30772, num_observations=100146)}\n",
      "{}\n",
      "map 0:Image(image_id=77, camera_id=77, name=\"vineyard_split_3_frame_0070.png\", triangulated=2164/4306)\n",
      "map 0:Image(image_id=78, camera_id=78, name=\"vineyard_split_3_frame_0075.png\", triangulated=4700/8771)\n",
      "map 0:Image(image_id=79, camera_id=79, name=\"vineyard_split_3_frame_0080.png\", triangulated=6245/9279)\n",
      "map 0:Image(image_id=80, camera_id=80, name=\"vineyard_split_3_frame_0085.png\", triangulated=7362/9749)\n",
      "map 0:Image(image_id=81, camera_id=81, name=\"vineyard_split_3_frame_0090.png\", triangulated=7045/9682)\n",
      "map 0:Image(image_id=82, camera_id=82, name=\"vineyard_split_3_frame_0095.png\", triangulated=5914/9136)\n",
      "map 0:Image(image_id=83, camera_id=83, name=\"vineyard_split_3_frame_0100.png\", triangulated=5200/7966)\n",
      "map 0:Image(image_id=84, camera_id=84, name=\"vineyard_split_3_frame_0105.png\", triangulated=6263/8779)\n",
      "map 0:Image(image_id=85, camera_id=85, name=\"vineyard_split_3_frame_0110.png\", triangulated=7154/10021)\n",
      "map 0:Image(image_id=86, camera_id=86, name=\"vineyard_split_3_frame_0115.png\", triangulated=5001/6554)\n",
      "map 0:Image(image_id=87, camera_id=87, name=\"vineyard_split_3_frame_0120.png\", triangulated=4874/8556)\n",
      "map 0:Image(image_id=88, camera_id=88, name=\"vineyard_split_3_frame_0125.png\", triangulated=3685/8062)\n",
      "map 0:Image(image_id=89, camera_id=89, name=\"vineyard_split_3_frame_0130.png\", triangulated=165/530)\n",
      "map 0:Image(image_id=90, camera_id=90, name=\"vineyard_split_3_frame_0135.png\", triangulated=2177/6582)\n",
      "map 0:Image(image_id=91, camera_id=91, name=\"vineyard_split_3_frame_0140.png\", triangulated=1977/6779)\n",
      "map 0:Image(image_id=93, camera_id=93, name=\"vineyard_split_3_frame_0150.png\", triangulated=3496/7528)\n",
      "map 0:Image(image_id=94, camera_id=94, name=\"vineyard_split_3_frame_0155.png\", triangulated=4991/8411)\n",
      "map 0:Image(image_id=95, camera_id=95, name=\"vineyard_split_3_frame_0160.png\", triangulated=6181/8453)\n",
      "map 0:Image(image_id=96, camera_id=96, name=\"vineyard_split_3_frame_0165.png\", triangulated=6541/9330)\n",
      "map 0:Image(image_id=97, camera_id=97, name=\"vineyard_split_3_frame_0170.png\", triangulated=5781/9261)\n",
      "map 0:Image(image_id=98, camera_id=98, name=\"vineyard_split_3_frame_0175.png\", triangulated=3835/6920)\n",
      "map 0:Image(image_id=99, camera_id=99, name=\"vineyard_split_3_frame_0180.png\", triangulated=2047/4026)\n",
      "map 0:Image(image_id=100, camera_id=100, name=\"vineyard_split_3_frame_0185.png\", triangulated=636/1933)\n",
      "map 0:Image(image_id=101, camera_id=101, name=\"vineyard_split_3_frame_0190.png\", triangulated=2042/6587)\n",
      "map 0:Image(image_id=102, camera_id=102, name=\"vineyard_split_3_frame_0195.png\", triangulated=3387/8385)\n",
      "map 0:Image(image_id=103, camera_id=103, name=\"vineyard_split_3_frame_0200.png\", triangulated=4948/8323)\n",
      "map 0:Image(image_id=104, camera_id=104, name=\"vineyard_split_3_frame_0205.png\", triangulated=5436/8803)\n",
      "map 0:Image(image_id=105, camera_id=105, name=\"vineyard_split_3_frame_0210.png\", triangulated=5269/7554)\n",
      "map 0:Image(image_id=106, camera_id=106, name=\"vineyard_split_3_frame_0215.png\", triangulated=5563/7830)\n",
      "map 0:Image(image_id=107, camera_id=107, name=\"vineyard_split_3_frame_0220.png\", triangulated=5612/8826)\n",
      "map 0:Image(image_id=108, camera_id=108, name=\"vineyard_split_3_frame_0225.png\", triangulated=3977/8045)\n",
      "map 0:Image(image_id=109, camera_id=109, name=\"vineyard_split_3_frame_0230.png\", triangulated=2344/6230)\n",
      "map 0:Image(image_id=111, camera_id=111, name=\"vineyard_split_3_frame_0240.png\", triangulated=2463/7845)\n",
      "map 0:Image(image_id=112, camera_id=112, name=\"vineyard_split_3_frame_0245.png\", triangulated=2716/7739)\n",
      "map 0:Image(image_id=114, camera_id=114, name=\"vineyard_split_3_frame_0255.png\", triangulated=4774/7890)\n",
      "map 0:Image(image_id=115, camera_id=115, name=\"vineyard_split_3_frame_0260.png\", triangulated=5597/9280)\n",
      "map 0:Image(image_id=116, camera_id=116, name=\"vineyard_split_3_frame_0265.png\", triangulated=6431/9200)\n",
      "map 0:Image(image_id=117, camera_id=117, name=\"vineyard_split_3_frame_0270.png\", triangulated=7412/9449)\n",
      "map 0:Image(image_id=118, camera_id=118, name=\"vineyard_split_3_frame_0275.png\", triangulated=7935/9476)\n",
      "map 0:Image(image_id=119, camera_id=119, name=\"vineyard_split_3_frame_0280.png\", triangulated=7698/9902)\n",
      "map 0:Image(image_id=120, camera_id=120, name=\"vineyard_split_3_frame_0285.png\", triangulated=6876/8853)\n",
      "map 0:Image(image_id=121, camera_id=121, name=\"vineyard_split_3_frame_0295.png\", triangulated=3605/5687)\n",
      "map 0:Image(image_id=122, camera_id=122, name=\"vineyard_split_3_frame_0300.png\", triangulated=2353/9029)\n",
      "map 0:Image(image_id=123, camera_id=123, name=\"vineyard_split_3_frame_0305.png\", triangulated=2335/8013)\n",
      "map 1:Image(image_id=36, camera_id=36, name=\"vineyard_split_1_frame_1080.png\", triangulated=51/5259)\n",
      "map 1:Image(image_id=39, camera_id=39, name=\"vineyard_split_1_frame_1095.png\", triangulated=5444/7212)\n",
      "map 1:Image(image_id=40, camera_id=40, name=\"vineyard_split_1_frame_1100.png\", triangulated=7422/9752)\n",
      "map 1:Image(image_id=41, camera_id=41, name=\"vineyard_split_1_frame_1105.png\", triangulated=6735/9370)\n",
      "map 1:Image(image_id=42, camera_id=42, name=\"vineyard_split_1_frame_1110.png\", triangulated=5754/7077)\n",
      "map 2:Image(image_id=1, camera_id=1, name=\"vineyard_split_1_frame_0900.png\", triangulated=62/4456)\n",
      "map 2:Image(image_id=2, camera_id=2, name=\"vineyard_split_1_frame_0905.png\", triangulated=141/4535)\n",
      "map 2:Image(image_id=3, camera_id=3, name=\"vineyard_split_1_frame_0910.png\", triangulated=1875/7431)\n",
      "map 2:Image(image_id=4, camera_id=4, name=\"vineyard_split_1_frame_0915.png\", triangulated=2344/9520)\n",
      "map 2:Image(image_id=5, camera_id=5, name=\"vineyard_split_1_frame_0920.png\", triangulated=3841/7740)\n",
      "map 2:Image(image_id=6, camera_id=6, name=\"vineyard_split_1_frame_0925.png\", triangulated=2598/8535)\n",
      "map 2:Image(image_id=7, camera_id=7, name=\"vineyard_split_1_frame_0930.png\", triangulated=1953/5788)\n",
      "map 2:Image(image_id=8, camera_id=8, name=\"vineyard_split_1_frame_0935.png\", triangulated=2256/5609)\n",
      "map 2:Image(image_id=9, camera_id=9, name=\"vineyard_split_1_frame_0940.png\", triangulated=2495/8241)\n",
      "map 2:Image(image_id=10, camera_id=10, name=\"vineyard_split_1_frame_0945.png\", triangulated=2622/6311)\n",
      "map 2:Image(image_id=11, camera_id=11, name=\"vineyard_split_1_frame_0950.png\", triangulated=537/775)\n",
      "map 2:Image(image_id=12, camera_id=12, name=\"vineyard_split_1_frame_0955.png\", triangulated=2789/7124)\n",
      "map 2:Image(image_id=13, camera_id=13, name=\"vineyard_split_1_frame_0960.png\", triangulated=2752/8468)\n",
      "map 2:Image(image_id=14, camera_id=14, name=\"vineyard_split_1_frame_0965.png\", triangulated=1763/4178)\n",
      "map 2:Image(image_id=15, camera_id=15, name=\"vineyard_split_1_frame_0970.png\", triangulated=4245/6903)\n",
      "map 2:Image(image_id=16, camera_id=16, name=\"vineyard_split_1_frame_0975.png\", triangulated=6164/9768)\n",
      "map 2:Image(image_id=17, camera_id=17, name=\"vineyard_split_1_frame_0980.png\", triangulated=7264/9856)\n",
      "map 2:Image(image_id=18, camera_id=18, name=\"vineyard_split_1_frame_0985.png\", triangulated=5694/9287)\n",
      "map 2:Image(image_id=19, camera_id=19, name=\"vineyard_split_1_frame_0990.png\", triangulated=3596/6625)\n",
      "map 2:Image(image_id=21, camera_id=21, name=\"vineyard_split_1_frame_1000.png\", triangulated=552/1808)\n",
      "map 3:Image(image_id=21, camera_id=21, name=\"vineyard_split_1_frame_1000.png\", triangulated=96/1808)\n",
      "map 3:Image(image_id=23, camera_id=23, name=\"vineyard_split_1_frame_1010.png\", triangulated=1504/4501)\n",
      "map 3:Image(image_id=24, camera_id=24, name=\"vineyard_split_1_frame_1015.png\", triangulated=1897/8305)\n",
      "map 3:Image(image_id=25, camera_id=25, name=\"vineyard_split_1_frame_1020.png\", triangulated=2861/7346)\n",
      "map 3:Image(image_id=26, camera_id=26, name=\"vineyard_split_1_frame_1025.png\", triangulated=3655/6332)\n",
      "map 3:Image(image_id=27, camera_id=27, name=\"vineyard_split_1_frame_1030.png\", triangulated=5343/9055)\n",
      "map 3:Image(image_id=28, camera_id=28, name=\"vineyard_split_1_frame_1035.png\", triangulated=6178/8749)\n",
      "map 3:Image(image_id=29, camera_id=29, name=\"vineyard_split_1_frame_1040.png\", triangulated=5811/8866)\n",
      "map 3:Image(image_id=30, camera_id=30, name=\"vineyard_split_1_frame_1045.png\", triangulated=5096/8214)\n",
      "map 3:Image(image_id=31, camera_id=31, name=\"vineyard_split_1_frame_1050.png\", triangulated=2850/8149)\n",
      "map 3:Image(image_id=32, camera_id=32, name=\"vineyard_split_1_frame_1055.png\", triangulated=1816/6542)\n",
      "map 3:Image(image_id=33, camera_id=33, name=\"vineyard_split_1_frame_1065.png\", triangulated=722/4504)\n",
      "map 3:Image(image_id=34, camera_id=34, name=\"vineyard_split_1_frame_1070.png\", triangulated=1628/7311)\n",
      "map 3:Image(image_id=35, camera_id=35, name=\"vineyard_split_1_frame_1075.png\", triangulated=1556/7646)\n",
      "map 3:Image(image_id=36, camera_id=36, name=\"vineyard_split_1_frame_1080.png\", triangulated=1145/5259)\n",
      "map 3:Image(image_id=69, camera_id=69, name=\"vineyard_split_2_frame_1285.png\", triangulated=34/8544)\n",
      "map 4:Image(image_id=147, camera_id=147, name=\"vineyard_split_3_frame_1510.png\", triangulated=2294/7427)\n",
      "map 4:Image(image_id=148, camera_id=148, name=\"vineyard_split_3_frame_1515.png\", triangulated=2087/6479)\n",
      "map 4:Image(image_id=149, camera_id=149, name=\"vineyard_split_3_frame_1520.png\", triangulated=3280/5865)\n",
      "map 4:Image(image_id=150, camera_id=150, name=\"vineyard_split_3_frame_1525.png\", triangulated=2282/7578)\n",
      "map 4:Image(image_id=151, camera_id=151, name=\"vineyard_split_3_frame_1530.png\", triangulated=1813/7652)\n",
      "map 4:Image(image_id=152, camera_id=152, name=\"vineyard_split_3_frame_1535.png\", triangulated=971/3566)\n",
      "map 4:Image(image_id=153, camera_id=153, name=\"vineyard_split_3_frame_1540.png\", triangulated=2667/6583)\n",
      "map 4:Image(image_id=154, camera_id=154, name=\"vineyard_split_3_frame_1545.png\", triangulated=3248/9634)\n",
      "map 4:Image(image_id=155, camera_id=155, name=\"vineyard_split_3_frame_1550.png\", triangulated=3043/5793)\n",
      "map 4:Image(image_id=156, camera_id=156, name=\"vineyard_split_3_frame_1555.png\", triangulated=1836/4883)\n",
      "map 4:Image(image_id=157, camera_id=157, name=\"vineyard_split_3_frame_1560.png\", triangulated=3147/8916)\n",
      "map 4:Image(image_id=158, camera_id=158, name=\"vineyard_split_3_frame_1565.png\", triangulated=3056/9190)\n",
      "map 4:Image(image_id=159, camera_id=159, name=\"vineyard_split_3_frame_1570.png\", triangulated=2443/6207)\n",
      "map 5:Image(image_id=72, camera_id=72, name=\"vineyard_split_2_frame_1300.png\", triangulated=85/5510)\n",
      "map 5:Image(image_id=136, camera_id=136, name=\"vineyard_split_3_frame_1450.png\", triangulated=337/4320)\n",
      "map 5:Image(image_id=137, camera_id=137, name=\"vineyard_split_3_frame_1460.png\", triangulated=2493/7967)\n",
      "map 5:Image(image_id=138, camera_id=138, name=\"vineyard_split_3_frame_1465.png\", triangulated=2812/8605)\n",
      "map 5:Image(image_id=139, camera_id=139, name=\"vineyard_split_3_frame_1470.png\", triangulated=4530/8625)\n",
      "map 5:Image(image_id=140, camera_id=140, name=\"vineyard_split_3_frame_1475.png\", triangulated=3272/6676)\n",
      "map 5:Image(image_id=141, camera_id=141, name=\"vineyard_split_3_frame_1480.png\", triangulated=3075/7255)\n",
      "map 5:Image(image_id=142, camera_id=142, name=\"vineyard_split_3_frame_1485.png\", triangulated=1871/8221)\n",
      "map 5:Image(image_id=143, camera_id=143, name=\"vineyard_split_3_frame_1490.png\", triangulated=1285/5701)\n",
      "map 5:Image(image_id=145, camera_id=145, name=\"vineyard_split_3_frame_1500.png\", triangulated=330/2214)\n",
      "map 6:Image(image_id=24, camera_id=24, name=\"vineyard_split_1_frame_1015.png\", triangulated=34/8305)\n",
      "map 6:Image(image_id=43, camera_id=43, name=\"vineyard_split_2_frame_1150.png\", triangulated=107/5534)\n",
      "map 6:Image(image_id=44, camera_id=44, name=\"vineyard_split_2_frame_1155.png\", triangulated=81/8907)\n",
      "map 6:Image(image_id=45, camera_id=45, name=\"vineyard_split_2_frame_1160.png\", triangulated=3237/8888)\n",
      "map 6:Image(image_id=46, camera_id=46, name=\"vineyard_split_2_frame_1165.png\", triangulated=5069/9220)\n",
      "map 6:Image(image_id=47, camera_id=47, name=\"vineyard_split_2_frame_1170.png\", triangulated=4939/9691)\n",
      "map 6:Image(image_id=48, camera_id=48, name=\"vineyard_split_2_frame_1175.png\", triangulated=3781/6849)\n",
      "map 6:Image(image_id=49, camera_id=49, name=\"vineyard_split_2_frame_1180.png\", triangulated=2227/4209)\n",
      "map 6:Image(image_id=50, camera_id=50, name=\"vineyard_split_2_frame_1185.png\", triangulated=1572/5142)\n",
      "map 6:Image(image_id=51, camera_id=51, name=\"vineyard_split_2_frame_1195.png\", triangulated=2753/7542)\n",
      "map 6:Image(image_id=52, camera_id=52, name=\"vineyard_split_2_frame_1200.png\", triangulated=3554/7782)\n",
      "map 6:Image(image_id=53, camera_id=53, name=\"vineyard_split_2_frame_1205.png\", triangulated=4016/8288)\n",
      "map 6:Image(image_id=54, camera_id=54, name=\"vineyard_split_2_frame_1210.png\", triangulated=3748/9015)\n",
      "map 6:Image(image_id=55, camera_id=55, name=\"vineyard_split_2_frame_1215.png\", triangulated=3605/7648)\n",
      "map 6:Image(image_id=56, camera_id=56, name=\"vineyard_split_2_frame_1220.png\", triangulated=3130/8615)\n",
      "map 6:Image(image_id=57, camera_id=57, name=\"vineyard_split_2_frame_1225.png\", triangulated=3283/8989)\n",
      "map 6:Image(image_id=58, camera_id=58, name=\"vineyard_split_2_frame_1230.png\", triangulated=4339/8597)\n",
      "map 6:Image(image_id=59, camera_id=59, name=\"vineyard_split_2_frame_1235.png\", triangulated=4456/8887)\n",
      "map 6:Image(image_id=60, camera_id=60, name=\"vineyard_split_2_frame_1240.png\", triangulated=4697/9087)\n",
      "map 6:Image(image_id=61, camera_id=61, name=\"vineyard_split_2_frame_1245.png\", triangulated=3268/8212)\n",
      "map 6:Image(image_id=62, camera_id=62, name=\"vineyard_split_2_frame_1250.png\", triangulated=3227/8320)\n",
      "map 6:Image(image_id=63, camera_id=63, name=\"vineyard_split_2_frame_1255.png\", triangulated=3810/8774)\n",
      "map 6:Image(image_id=64, camera_id=64, name=\"vineyard_split_2_frame_1260.png\", triangulated=3905/9184)\n",
      "map 6:Image(image_id=65, camera_id=65, name=\"vineyard_split_2_frame_1265.png\", triangulated=2972/8301)\n",
      "map 6:Image(image_id=66, camera_id=66, name=\"vineyard_split_2_frame_1270.png\", triangulated=1992/6467)\n",
      "map 6:Image(image_id=67, camera_id=67, name=\"vineyard_split_2_frame_1275.png\", triangulated=3789/8128)\n",
      "map 6:Image(image_id=68, camera_id=68, name=\"vineyard_split_2_frame_1280.png\", triangulated=4192/8830)\n",
      "map 6:Image(image_id=69, camera_id=69, name=\"vineyard_split_2_frame_1285.png\", triangulated=4103/8544)\n",
      "map 6:Image(image_id=70, camera_id=70, name=\"vineyard_split_2_frame_1290.png\", triangulated=1922/8407)\n",
      "map 6:Image(image_id=71, camera_id=71, name=\"vineyard_split_2_frame_1295.png\", triangulated=994/5774)\n",
      "map 6:Image(image_id=72, camera_id=72, name=\"vineyard_split_2_frame_1300.png\", triangulated=2155/5510)\n",
      "map 6:Image(image_id=73, camera_id=73, name=\"vineyard_split_2_frame_1305.png\", triangulated=2398/9149)\n",
      "map 6:Image(image_id=74, camera_id=74, name=\"vineyard_split_2_frame_1310.png\", triangulated=2191/5689)\n",
      "map 6:Image(image_id=75, camera_id=75, name=\"vineyard_split_2_frame_1315.png\", triangulated=215/4473)\n",
      "map 6:Image(image_id=76, camera_id=76, name=\"vineyard_split_2_frame_1320.png\", triangulated=346/4689)\n",
      "map 6:Image(image_id=137, camera_id=137, name=\"vineyard_split_3_frame_1460.png\", triangulated=39/7967)\n",
      "Dataset  fbk_vineyard -> Registered 144 / 163 images with 7 clusters\n",
      "Skipping \"ETs\"\n",
      "\n",
      "Processing dataset \"stairs\": 51 images\n",
      "rotation_detection for 51 images : 0.0000 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 51/51 [00:10<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance Matrix Statistics:\n",
      "Min:  0.1598\n",
      "Max:  0.4240\n",
      "Mean: 0.2807\n",
      "Std:  0.0451\n",
      "20%:  0.2433\n",
      "25%:  0.2499\n",
      "60%:  0.2868\n",
      "75%:  0.3089\n",
      "Shortlisting. Number of pairs to match: 564. Done in 10.5614 sec\n",
      "Generated 564 image pairs using VLAD global descriptor.\n",
      "Shortlisting. Number of pairs to match: 564. Done in 10.8589 sec\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([632, 2]), descs.shape=torch.Size([632, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([970, 2]), descs.shape=torch.Size([970, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([440, 2]), descs.shape=torch.Size([440, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([976, 2]), descs.shape=torch.Size([976, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([1257, 2]), descs.shape=torch.Size([1257, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([2208, 2]), descs.shape=torch.Size([2208, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([2303, 2]), descs.shape=torch.Size([2303, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([1486, 2]), descs.shape=torch.Size([1486, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([806, 2]), descs.shape=torch.Size([806, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([851, 2]), descs.shape=torch.Size([851, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([1128, 2]), descs.shape=torch.Size([1128, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([544, 2]), descs.shape=torch.Size([544, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([1933, 2]), descs.shape=torch.Size([1933, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([1467, 2]), descs.shape=torch.Size([1467, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([1514, 2]), descs.shape=torch.Size([1514, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([3646, 2]), descs.shape=torch.Size([3646, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([1017, 2]), descs.shape=torch.Size([1017, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([1209, 2]), descs.shape=torch.Size([1209, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([392, 2]), descs.shape=torch.Size([392, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([885, 2]), descs.shape=torch.Size([885, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([1430, 2]), descs.shape=torch.Size([1430, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([1327, 2]), descs.shape=torch.Size([1327, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([2183, 2]), descs.shape=torch.Size([2183, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([1172, 2]), descs.shape=torch.Size([1172, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([597, 2]), descs.shape=torch.Size([597, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([1025, 2]), descs.shape=torch.Size([1025, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([1702, 2]), descs.shape=torch.Size([1702, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([238, 2]), descs.shape=torch.Size([238, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([1450, 2]), descs.shape=torch.Size([1450, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([2413, 2]), descs.shape=torch.Size([2413, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([2404, 2]), descs.shape=torch.Size([2404, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([1319, 2]), descs.shape=torch.Size([1319, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([1729, 2]), descs.shape=torch.Size([1729, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([3269, 2]), descs.shape=torch.Size([3269, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([2769, 2]), descs.shape=torch.Size([2769, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([1897, 2]), descs.shape=torch.Size([1897, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([2382, 2]), descs.shape=torch.Size([2382, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([4333, 2]), descs.shape=torch.Size([4333, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([1054, 2]), descs.shape=torch.Size([1054, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([2995, 2]), descs.shape=torch.Size([2995, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([2149, 2]), descs.shape=torch.Size([2149, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([2114, 2]), descs.shape=torch.Size([2114, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([2111, 2]), descs.shape=torch.Size([2111, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([2257, 2]), descs.shape=torch.Size([2257, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([1541, 2]), descs.shape=torch.Size([1541, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([2563, 2]), descs.shape=torch.Size([2563, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([1133, 2]), descs.shape=torch.Size([1133, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([3735, 2]), descs.shape=torch.Size([3735, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([3395, 2]), descs.shape=torch.Size([3395, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([1181, 2]), descs.shape=torch.Size([1181, 128])\n",
      "aliked > rot_k=0, kpts.shape=torch.Size([1078, 2]), descs.shape=torch.Size([1078, 128])\n",
      "Loaded LightGlue model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 15/564 [00:00<00:15, 34.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> stairs_split_1_1710453963274.png-stairs_split_1_1710453643106.png: 131 matches @ 1th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 31/564 [00:00<00:14, 35.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> stairs_split_1_1710453947066.png-stairs_split_1_1710453990286.png: 135 matches @ 2th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|         | 43/564 [00:01<00:14, 36.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> stairs_split_1_1710453947066.png-stairs_split_1_1710453659313.png: 145 matches @ 3th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|         | 63/564 [00:01<00:13, 38.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> stairs_split_1_1710453985484.png-stairs_split_1_1710453612890.png: 141 matches @ 4th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|        | 75/564 [00:02<00:12, 37.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> stairs_split_1_1710453930259.png-stairs_split_1_1710453651110.png: 165 matches @ 5th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|        | 83/564 [00:02<00:13, 36.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> stairs_split_1_1710453901046.png-stairs_split_1_1710453704934.png: 266 matches @ 6th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|        | 99/564 [00:02<00:12, 37.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> stairs_split_1_1710453901046.png-stairs_split_2_1710453862225.png: 115 matches @ 7th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|       | 135/564 [00:04<00:17, 24.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> stairs_split_1_1710453689727.png-stairs_split_2_1710453871430.png: 113 matches @ 8th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|       | 165/564 [00:05<00:14, 27.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> stairs_split_1_1710453704934.png-stairs_split_2_1710453790978.png: 164 matches @ 9th pair(aliked+lightglue)\n",
      "aliked> stairs_split_1_1710453704934.png-stairs_split_2_1710453745156.png: 246 matches @ 10th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|      | 201/564 [00:06<00:09, 37.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> stairs_split_1_1710453606287.png-stairs_split_1_1710453990286.png: 144 matches @ 11th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|     | 257/564 [00:07<00:09, 32.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> stairs_split_1_1710453668718.png-stairs_split_1_1710453651110.png: 141 matches @ 12th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 273/564 [00:08<00:09, 31.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> stairs_split_1_1710453601885.png-stairs_split_1_1710453576271.png: 163 matches @ 13th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|    | 291/564 [00:09<00:10, 25.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> stairs_split_1_1710453955270.png-stairs_split_1_1710453651110.png: 201 matches @ 14th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|  | 444/564 [00:14<00:03, 30.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> stairs_split_2_1710453871430.png-stairs_split_2_1710453783374.png: 146 matches @ 15th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 451/564 [00:14<00:04, 24.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> stairs_split_2_1710453871430.png-stairs_split_2_1710453739354.png: 628 matches @ 16th pair(aliked+lightglue)\n",
      "aliked> stairs_split_2_1710453871430.png-stairs_split_2_1710453736752.png: 431 matches @ 17th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%| | 492/564 [00:16<00:03, 23.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> stairs_split_2_1710453786375.png-stairs_split_2_1710453783374.png: 541 matches @ 18th pair(aliked+lightglue)\n",
      "aliked> stairs_split_2_1710453786375.png-stairs_split_2_1710453720741.png: 654 matches @ 19th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%| | 495/564 [00:16<00:03, 21.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> stairs_split_2_1710453786375.png-stairs_split_2_1710453740954.png: 661 matches @ 20th pair(aliked+lightglue)\n",
      "aliked> stairs_split_2_1710453786375.png-stairs_split_2_1710453739354.png: 110 matches @ 21th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%| | 501/564 [00:16<00:03, 17.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> stairs_split_2_1710453786375.png-stairs_split_2_1710453759963.png: 430 matches @ 22th pair(aliked+lightglue)\n",
      "aliked> stairs_split_2_1710453786375.png-stairs_split_2_1710453805788.png: 174 matches @ 23th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 506/564 [00:16<00:03, 18.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> stairs_split_2_1710453783374.png-stairs_split_2_1710453739354.png: 116 matches @ 24th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%| | 511/564 [00:17<00:02, 19.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> stairs_split_2_1710453783374.png-stairs_split_2_1710453805788.png: 257 matches @ 25th pair(aliked+lightglue)\n",
      "aliked> stairs_split_2_1710453790978.png-stairs_split_2_1710453745156.png: 263 matches @ 26th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|| 533/564 [00:18<00:01, 23.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> stairs_split_2_1710453740954.png-stairs_split_2_1710453739354.png: 740 matches @ 27th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|| 539/564 [00:18<00:01, 20.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> stairs_split_2_1710453740954.png-stairs_split_2_1710453759963.png: 372 matches @ 28th pair(aliked+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 564/564 [00:19<00:00, 28.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliked> stairs_split_2_1710453759963.png-stairs_split_2_1710453805788.png: 171 matches @ 29th pair(aliked+lightglue)\n",
      "Features matched in  24.3673 sec (aliked+LightGlue)\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([135, 2]), descs.shape=torch.Size([135, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([97, 2]), descs.shape=torch.Size([97, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([55, 2]), descs.shape=torch.Size([55, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([65, 2]), descs.shape=torch.Size([65, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([208, 2]), descs.shape=torch.Size([208, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([136, 2]), descs.shape=torch.Size([136, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([247, 2]), descs.shape=torch.Size([247, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([164, 2]), descs.shape=torch.Size([164, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([49, 2]), descs.shape=torch.Size([49, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([117, 2]), descs.shape=torch.Size([117, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([102, 2]), descs.shape=torch.Size([102, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([68, 2]), descs.shape=torch.Size([68, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([218, 2]), descs.shape=torch.Size([218, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([69, 2]), descs.shape=torch.Size([69, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([163, 2]), descs.shape=torch.Size([163, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([176, 2]), descs.shape=torch.Size([176, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([84, 2]), descs.shape=torch.Size([84, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([122, 2]), descs.shape=torch.Size([122, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([87, 2]), descs.shape=torch.Size([87, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([157, 2]), descs.shape=torch.Size([157, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([177, 2]), descs.shape=torch.Size([177, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([193, 2]), descs.shape=torch.Size([193, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([296, 2]), descs.shape=torch.Size([296, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([122, 2]), descs.shape=torch.Size([122, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([70, 2]), descs.shape=torch.Size([70, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([129, 2]), descs.shape=torch.Size([129, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([94, 2]), descs.shape=torch.Size([94, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([4, 2]), descs.shape=torch.Size([4, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([158, 2]), descs.shape=torch.Size([158, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([218, 2]), descs.shape=torch.Size([218, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([140, 2]), descs.shape=torch.Size([140, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([152, 2]), descs.shape=torch.Size([152, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([179, 2]), descs.shape=torch.Size([179, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([120, 2]), descs.shape=torch.Size([120, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([130, 2]), descs.shape=torch.Size([130, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([170, 2]), descs.shape=torch.Size([170, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([300, 2]), descs.shape=torch.Size([300, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([163, 2]), descs.shape=torch.Size([163, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([181, 2]), descs.shape=torch.Size([181, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([143, 2]), descs.shape=torch.Size([143, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([318, 2]), descs.shape=torch.Size([318, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([103, 2]), descs.shape=torch.Size([103, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([206, 2]), descs.shape=torch.Size([206, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([263, 2]), descs.shape=torch.Size([263, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([191, 2]), descs.shape=torch.Size([191, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([255, 2]), descs.shape=torch.Size([255, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([300, 2]), descs.shape=torch.Size([300, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([137, 2]), descs.shape=torch.Size([137, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([119, 2]), descs.shape=torch.Size([119, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([116, 2]), descs.shape=torch.Size([116, 256])\n",
      "superpoint > rot_k=0, kpts.shape=torch.Size([204, 2]), descs.shape=torch.Size([204, 256])\n",
      "Loaded LightGlue model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 28/564 [00:00<00:15, 35.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> stairs_split_1_1710453947066.png-stairs_split_1_1710453990286.png: 51 matches @ 1th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|        | 84/564 [00:02<00:12, 37.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> stairs_split_1_1710453901046.png-stairs_split_1_1710453704934.png: 54 matches @ 2th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 167/564 [00:04<00:10, 39.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> stairs_split_1_1710453704934.png-stairs_split_2_1710453790978.png: 60 matches @ 3th pair(superpoint+lightglue)\n",
      "superpoint> stairs_split_1_1710453704934.png-stairs_split_2_1710453745156.png: 69 matches @ 4th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|    | 298/564 [00:07<00:07, 37.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> stairs_split_1_1710453955270.png-stairs_split_2_1710453871430.png: 53 matches @ 5th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|  | 458/564 [00:11<00:02, 39.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> stairs_split_2_1710453871430.png-stairs_split_2_1710453736752.png: 51 matches @ 6th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%| | 500/564 [00:12<00:01, 39.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> stairs_split_2_1710453786375.png-stairs_split_2_1710453740954.png: 64 matches @ 7th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|| 516/564 [00:13<00:01, 39.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> stairs_split_2_1710453790978.png-stairs_split_2_1710453745156.png: 75 matches @ 8th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|| 540/564 [00:13<00:00, 39.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> stairs_split_2_1710453740954.png-stairs_split_2_1710453759963.png: 58 matches @ 9th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 564/564 [00:14<00:00, 38.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpoint> stairs_split_2_1710453725143.png-stairs_split_2_1710453765165.png: 50 matches @ 10th pair(superpoint+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features matched in  19.0180 sec (superpoint+LightGlue)\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([7425, 2]), descs.shape=torch.Size([7425, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([7973, 2]), descs.shape=torch.Size([7973, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8111, 2]), descs.shape=torch.Size([8111, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([5898, 2]), descs.shape=torch.Size([5898, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([7994, 2]), descs.shape=torch.Size([7994, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([7698, 2]), descs.shape=torch.Size([7698, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8156, 2]), descs.shape=torch.Size([8156, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "disk > rot_k=0, kpts.shape=torch.Size([8192, 2]), descs.shape=torch.Size([8192, 128])\n",
      "Loaded LightGlue model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|         | 34/564 [00:10<02:46,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_1_1710453947066.png-stairs_split_1_1710453651110.png: 440 matches @ 1th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|         | 36/564 [00:11<02:46,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_1_1710453947066.png-stairs_split_1_1710453659313.png: 378 matches @ 2th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|         | 48/564 [00:14<02:43,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_1_1710453985484.png-stairs_split_1_1710453606287.png: 301 matches @ 3th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 56/564 [00:17<02:41,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_1_1710453985484.png-stairs_split_1_1710453612890.png: 831 matches @ 4th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|        | 64/564 [00:20<02:37,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_1_1710453930259.png-stairs_split_1_1710453668718.png: 492 matches @ 5th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|        | 68/564 [00:21<02:33,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_1_1710453930259.png-stairs_split_1_1710453651110.png: 176 matches @ 6th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 78/564 [00:24<02:30,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_1_1710453901046.png-stairs_split_1_1710453704934.png: 1474 matches @ 7th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|        | 100/564 [00:30<02:13,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_1_1710453901046.png-stairs_split_2_1710453745156.png: 141 matches @ 8th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 110/564 [00:33<02:14,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_1_1710453693529.png-stairs_split_1_1710453651110.png: 114 matches @ 9th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 113/564 [00:34<02:16,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_1_1710453693529.png-stairs_split_2_1710453871430.png: 125 matches @ 10th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|       | 123/564 [00:37<02:16,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_1_1710453693529.png-stairs_split_2_1710453759963.png: 224 matches @ 11th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|       | 132/564 [00:40<02:10,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_1_1710453689727.png-stairs_split_2_1710453871430.png: 265 matches @ 12th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|       | 147/564 [00:44<02:07,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_1_1710453704934.png-stairs_split_1_1710453675921.png: 191 matches @ 13th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|       | 160/564 [00:48<02:03,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_1_1710453704934.png-stairs_split_2_1710453790978.png: 518 matches @ 14th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|       | 165/564 [00:50<02:02,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_1_1710453704934.png-stairs_split_2_1710453745156.png: 563 matches @ 15th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|       | 174/564 [00:53<01:53,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_1_1710453675921.png-stairs_split_1_1710453678922.png: 219 matches @ 16th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|      | 194/564 [00:59<01:52,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_1_1710453606287.png-stairs_split_1_1710453990286.png: 905 matches @ 17th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|      | 202/564 [01:01<01:42,  3.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_1_1710453990286.png-stairs_split_1_1710453601885.png: 890 matches @ 18th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|     | 254/564 [01:17<01:34,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_1_1710453668718.png-stairs_split_2_1710453871430.png: 713 matches @ 19th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|     | 256/564 [01:17<01:34,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_1_1710453668718.png-stairs_split_2_1710453786375.png: 146 matches @ 20th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|     | 260/564 [01:19<01:33,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_1_1710453668718.png-stairs_split_2_1710453739354.png: 148 matches @ 21th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 264/564 [01:20<01:32,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_1_1710453668718.png-stairs_split_2_1710453759963.png: 195 matches @ 22th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 268/564 [01:21<01:17,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_1_1710453601885.png-stairs_split_1_1710453576271.png: 388 matches @ 23th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|     | 275/564 [01:23<01:09,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_1_1710453601885.png-stairs_split_2_1710453786375.png: 109 matches @ 24th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|     | 278/564 [01:23<01:08,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_1_1710453601885.png-stairs_split_2_1710453740954.png: 182 matches @ 25th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|     | 287/564 [01:26<01:19,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_1_1710453955270.png-stairs_split_1_1710453651110.png: 291 matches @ 26th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|    | 308/564 [01:32<01:20,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_1_1710453616892.png-stairs_split_1_1710453620694.png: 437 matches @ 27th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 336/564 [01:41<01:11,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_1_1710453626698.png-stairs_split_1_1710453620694.png: 247 matches @ 28th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|   | 379/564 [01:54<00:56,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_1_1710453651110.png-stairs_split_2_1710453871430.png: 186 matches @ 29th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|   | 387/564 [01:57<00:54,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_1_1710453651110.png-stairs_split_2_1710453740954.png: 126 matches @ 30th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|   | 389/564 [01:57<00:54,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_1_1710453651110.png-stairs_split_2_1710453739354.png: 232 matches @ 31th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 393/564 [01:59<00:52,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_1_1710453651110.png-stairs_split_2_1710453759963.png: 228 matches @ 32th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|  | 439/564 [02:13<00:37,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_2_1710453862225.png-stairs_split_2_1710453745156.png: 146 matches @ 33th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|  | 443/564 [02:14<00:36,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_2_1710453871430.png-stairs_split_2_1710453786375.png: 232 matches @ 34th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|  | 444/564 [02:14<00:35,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_2_1710453871430.png-stairs_split_2_1710453783374.png: 1564 matches @ 35th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|  | 448/564 [02:15<00:34,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_2_1710453871430.png-stairs_split_2_1710453739354.png: 2986 matches @ 36th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 451/564 [02:16<00:33,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_2_1710453871430.png-stairs_split_2_1710453736752.png: 1574 matches @ 37th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 453/564 [02:17<00:32,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_2_1710453871430.png-stairs_split_2_1710453805788.png: 139 matches @ 38th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%| | 465/564 [02:21<00:30,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_2_1710453801783.png-stairs_split_2_1710453736752.png: 187 matches @ 39th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%| | 479/564 [02:25<00:26,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_2_1710453793579.png-stairs_split_2_1710453790978.png: 251 matches @ 40th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%| | 490/564 [02:28<00:22,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_2_1710453786375.png-stairs_split_2_1710453783374.png: 310 matches @ 41th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%| | 491/564 [02:29<00:22,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_2_1710453786375.png-stairs_split_2_1710453790978.png: 302 matches @ 42th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%| | 492/564 [02:29<00:22,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_2_1710453786375.png-stairs_split_2_1710453720741.png: 1044 matches @ 43th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%| | 493/564 [02:29<00:21,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_2_1710453786375.png-stairs_split_2_1710453740954.png: 862 matches @ 44th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%| | 494/564 [02:30<00:21,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_2_1710453786375.png-stairs_split_2_1710453739354.png: 128 matches @ 45th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%| | 498/564 [02:31<00:20,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_2_1710453786375.png-stairs_split_2_1710453759963.png: 528 matches @ 46th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%| | 499/564 [02:31<00:19,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_2_1710453786375.png-stairs_split_2_1710453805788.png: 594 matches @ 47th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%| | 503/564 [02:32<00:18,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_2_1710453783374.png-stairs_split_2_1710453739354.png: 362 matches @ 48th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 508/564 [02:34<00:17,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_2_1710453783374.png-stairs_split_2_1710453805788.png: 1008 matches @ 49th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%| | 512/564 [02:35<00:15,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_2_1710453790978.png-stairs_split_2_1710453745156.png: 838 matches @ 50th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|| 526/564 [02:39<00:11,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_2_1710453720741.png-stairs_split_2_1710453725143.png: 485 matches @ 51th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|| 527/564 [02:40<00:11,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_2_1710453720741.png-stairs_split_2_1710453805788.png: 233 matches @ 52th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|| 529/564 [02:40<00:10,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_2_1710453728949.png-stairs_split_2_1710453725143.png: 150 matches @ 53th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|| 532/564 [02:41<00:09,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_2_1710453740954.png-stairs_split_2_1710453739354.png: 2431 matches @ 54th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|| 536/564 [02:42<00:08,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_2_1710453740954.png-stairs_split_2_1710453759963.png: 768 matches @ 55th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|| 537/564 [02:43<00:08,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_2_1710453740954.png-stairs_split_2_1710453805788.png: 335 matches @ 56th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 546/564 [02:46<00:05,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_2_1710453739354.png-stairs_split_2_1710453759963.png: 445 matches @ 57th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 547/564 [02:46<00:05,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_2_1710453739354.png-stairs_split_2_1710453805788.png: 237 matches @ 58th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|| 558/564 [02:49<00:01,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_2_1710453725143.png-stairs_split_2_1710453765165.png: 108 matches @ 59th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 563/564 [02:51<00:00,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk> stairs_split_2_1710453759963.png-stairs_split_2_1710453805788.png: 378 matches @ 60th pair(disk+lightglue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 564/564 [02:51<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features matched in  185.3365 sec (disk+LightGlue)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='564' class='' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [564/564 00:01&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filter_FundamentalMatrix: 131 matches --> 128 matches\n",
      "stairs_split_1_1710453963274.png-stairs_split_1_1710453643106.png: 131 --> 128 matches\n",
      "filter_FundamentalMatrix: 186 matches --> 140 matches\n",
      "stairs_split_1_1710453947066.png-stairs_split_1_1710453990286.png: 186 --> 140 matches\n",
      "filter_FundamentalMatrix: 440 matches --> 401 matches\n",
      "stairs_split_1_1710453947066.png-stairs_split_1_1710453651110.png: 440 --> 401 matches\n",
      "filter_FundamentalMatrix: 523 matches --> 463 matches\n",
      "stairs_split_1_1710453947066.png-stairs_split_1_1710453659313.png: 523 --> 463 matches\n",
      "filter_FundamentalMatrix: 301 matches --> 284 matches\n",
      "stairs_split_1_1710453985484.png-stairs_split_1_1710453606287.png: 301 --> 284 matches\n",
      "filter_FundamentalMatrix: 972 matches --> 921 matches\n",
      "stairs_split_1_1710453985484.png-stairs_split_1_1710453612890.png: 972 --> 921 matches\n",
      "filter_FundamentalMatrix: 492 matches --> 359 matches\n",
      "stairs_split_1_1710453930259.png-stairs_split_1_1710453668718.png: 492 --> 359 matches\n",
      "filter_FundamentalMatrix: 341 matches --> 222 matches\n",
      "stairs_split_1_1710453930259.png-stairs_split_1_1710453651110.png: 341 --> 222 matches\n",
      "filter_FundamentalMatrix: 1794 matches --> 1604 matches\n",
      "stairs_split_1_1710453901046.png-stairs_split_1_1710453704934.png: 1794 --> 1604 matches\n",
      "filter_FundamentalMatrix: 115 matches --> 63 matches\n",
      "stairs_split_1_1710453901046.png-stairs_split_2_1710453862225.png: 115 --> 63 matches\n",
      "filter_FundamentalMatrix: 141 matches --> 99 matches\n",
      "stairs_split_1_1710453901046.png-stairs_split_2_1710453745156.png: 141 --> 99 matches\n",
      "filter_FundamentalMatrix: 114 matches --> 90 matches\n",
      "stairs_split_1_1710453693529.png-stairs_split_1_1710453651110.png: 114 --> 90 matches\n",
      "filter_FundamentalMatrix: 125 matches --> 107 matches\n",
      "stairs_split_1_1710453693529.png-stairs_split_2_1710453871430.png: 125 --> 107 matches\n",
      "filter_FundamentalMatrix: 224 matches --> 206 matches\n",
      "stairs_split_1_1710453693529.png-stairs_split_2_1710453759963.png: 224 --> 206 matches\n",
      "filter_FundamentalMatrix: 378 matches --> 231 matches\n",
      "stairs_split_1_1710453689727.png-stairs_split_2_1710453871430.png: 378 --> 231 matches\n",
      "filter_FundamentalMatrix: 191 matches --> 159 matches\n",
      "stairs_split_1_1710453704934.png-stairs_split_1_1710453675921.png: 191 --> 159 matches\n",
      "filter_FundamentalMatrix: 742 matches --> 605 matches\n",
      "stairs_split_1_1710453704934.png-stairs_split_2_1710453790978.png: 742 --> 605 matches\n",
      "filter_FundamentalMatrix: 878 matches --> 757 matches\n",
      "stairs_split_1_1710453704934.png-stairs_split_2_1710453745156.png: 878 --> 757 matches\n",
      "filter_FundamentalMatrix: 219 matches --> 212 matches\n",
      "stairs_split_1_1710453675921.png-stairs_split_1_1710453678922.png: 219 --> 212 matches\n",
      "filter_FundamentalMatrix: 1049 matches --> 965 matches\n",
      "stairs_split_1_1710453606287.png-stairs_split_1_1710453990286.png: 1049 --> 965 matches\n",
      "filter_FundamentalMatrix: 890 matches --> 776 matches\n",
      "stairs_split_1_1710453990286.png-stairs_split_1_1710453601885.png: 890 --> 776 matches\n",
      "filter_FundamentalMatrix: 141 matches --> 133 matches\n",
      "stairs_split_1_1710453668718.png-stairs_split_1_1710453651110.png: 141 --> 133 matches\n",
      "filter_FundamentalMatrix: 713 matches --> 651 matches\n",
      "stairs_split_1_1710453668718.png-stairs_split_2_1710453871430.png: 713 --> 651 matches\n",
      "filter_FundamentalMatrix: 146 matches --> 117 matches\n",
      "stairs_split_1_1710453668718.png-stairs_split_2_1710453786375.png: 146 --> 117 matches\n",
      "filter_FundamentalMatrix: 148 matches --> 135 matches\n",
      "stairs_split_1_1710453668718.png-stairs_split_2_1710453739354.png: 148 --> 135 matches\n",
      "filter_FundamentalMatrix: 195 matches --> 152 matches\n",
      "stairs_split_1_1710453668718.png-stairs_split_2_1710453759963.png: 195 --> 152 matches\n",
      "filter_FundamentalMatrix: 551 matches --> 495 matches\n",
      "stairs_split_1_1710453601885.png-stairs_split_1_1710453576271.png: 551 --> 495 matches\n",
      "filter_FundamentalMatrix: 109 matches --> 98 matches\n",
      "stairs_split_1_1710453601885.png-stairs_split_2_1710453786375.png: 109 --> 98 matches\n",
      "filter_FundamentalMatrix: 182 matches --> 156 matches\n",
      "stairs_split_1_1710453601885.png-stairs_split_2_1710453740954.png: 182 --> 156 matches\n",
      "filter_FundamentalMatrix: 492 matches --> 439 matches\n",
      "stairs_split_1_1710453955270.png-stairs_split_1_1710453651110.png: 492 --> 439 matches\n",
      "filter_FundamentalMatrix: 53 matches --> 36 matches\n",
      "stairs_split_1_1710453955270.png-stairs_split_2_1710453871430.png: 53 --> 36 matches\n",
      "filter_FundamentalMatrix: 437 matches --> 369 matches\n",
      "stairs_split_1_1710453616892.png-stairs_split_1_1710453620694.png: 437 --> 369 matches\n",
      "filter_FundamentalMatrix: 247 matches --> 235 matches\n",
      "stairs_split_1_1710453626698.png-stairs_split_1_1710453620694.png: 247 --> 235 matches\n",
      "filter_FundamentalMatrix: 186 matches --> 150 matches\n",
      "stairs_split_1_1710453651110.png-stairs_split_2_1710453871430.png: 186 --> 150 matches\n",
      "filter_FundamentalMatrix: 126 matches --> 106 matches\n",
      "stairs_split_1_1710453651110.png-stairs_split_2_1710453740954.png: 126 --> 106 matches\n",
      "filter_FundamentalMatrix: 232 matches --> 189 matches\n",
      "stairs_split_1_1710453651110.png-stairs_split_2_1710453739354.png: 232 --> 189 matches\n",
      "filter_FundamentalMatrix: 228 matches --> 190 matches\n",
      "stairs_split_1_1710453651110.png-stairs_split_2_1710453759963.png: 228 --> 190 matches\n",
      "filter_FundamentalMatrix: 146 matches --> 129 matches\n",
      "stairs_split_2_1710453862225.png-stairs_split_2_1710453745156.png: 146 --> 129 matches\n",
      "filter_FundamentalMatrix: 232 matches --> 201 matches\n",
      "stairs_split_2_1710453871430.png-stairs_split_2_1710453786375.png: 232 --> 201 matches\n",
      "filter_FundamentalMatrix: 1710 matches --> 1444 matches\n",
      "stairs_split_2_1710453871430.png-stairs_split_2_1710453783374.png: 1710 --> 1444 matches\n",
      "filter_FundamentalMatrix: 3614 matches --> 3435 matches\n",
      "stairs_split_2_1710453871430.png-stairs_split_2_1710453739354.png: 3614 --> 3435 matches\n",
      "filter_FundamentalMatrix: 2056 matches --> 1864 matches\n",
      "stairs_split_2_1710453871430.png-stairs_split_2_1710453736752.png: 2056 --> 1864 matches\n",
      "filter_FundamentalMatrix: 139 matches --> 101 matches\n",
      "stairs_split_2_1710453871430.png-stairs_split_2_1710453805788.png: 139 --> 101 matches\n",
      "filter_FundamentalMatrix: 187 matches --> 174 matches\n",
      "stairs_split_2_1710453801783.png-stairs_split_2_1710453736752.png: 187 --> 174 matches\n",
      "filter_FundamentalMatrix: 251 matches --> 226 matches\n",
      "stairs_split_2_1710453793579.png-stairs_split_2_1710453790978.png: 251 --> 226 matches\n",
      "filter_FundamentalMatrix: 851 matches --> 723 matches\n",
      "stairs_split_2_1710453786375.png-stairs_split_2_1710453783374.png: 851 --> 723 matches\n",
      "filter_FundamentalMatrix: 302 matches --> 228 matches\n",
      "stairs_split_2_1710453786375.png-stairs_split_2_1710453790978.png: 302 --> 228 matches\n",
      "filter_FundamentalMatrix: 1698 matches --> 1406 matches\n",
      "stairs_split_2_1710453786375.png-stairs_split_2_1710453720741.png: 1698 --> 1406 matches\n",
      "filter_FundamentalMatrix: 1587 matches --> 1450 matches\n",
      "stairs_split_2_1710453786375.png-stairs_split_2_1710453740954.png: 1587 --> 1450 matches\n",
      "filter_FundamentalMatrix: 238 matches --> 147 matches\n",
      "stairs_split_2_1710453786375.png-stairs_split_2_1710453739354.png: 238 --> 147 matches\n",
      "filter_FundamentalMatrix: 958 matches --> 581 matches\n",
      "stairs_split_2_1710453786375.png-stairs_split_2_1710453759963.png: 958 --> 581 matches\n",
      "filter_FundamentalMatrix: 768 matches --> 638 matches\n",
      "stairs_split_2_1710453786375.png-stairs_split_2_1710453805788.png: 768 --> 638 matches\n",
      "filter_FundamentalMatrix: 478 matches --> 387 matches\n",
      "stairs_split_2_1710453783374.png-stairs_split_2_1710453739354.png: 478 --> 387 matches\n",
      "filter_FundamentalMatrix: 1265 matches --> 1212 matches\n",
      "stairs_split_2_1710453783374.png-stairs_split_2_1710453805788.png: 1265 --> 1212 matches\n",
      "filter_FundamentalMatrix: 1176 matches --> 1059 matches\n",
      "stairs_split_2_1710453790978.png-stairs_split_2_1710453745156.png: 1176 --> 1059 matches\n",
      "filter_FundamentalMatrix: 485 matches --> 420 matches\n",
      "stairs_split_2_1710453720741.png-stairs_split_2_1710453725143.png: 485 --> 420 matches\n",
      "filter_FundamentalMatrix: 233 matches --> 197 matches\n",
      "stairs_split_2_1710453720741.png-stairs_split_2_1710453805788.png: 233 --> 197 matches\n",
      "filter_FundamentalMatrix: 150 matches --> 139 matches\n",
      "stairs_split_2_1710453728949.png-stairs_split_2_1710453725143.png: 150 --> 139 matches\n",
      "filter_FundamentalMatrix: 3171 matches --> 2975 matches\n",
      "stairs_split_2_1710453740954.png-stairs_split_2_1710453739354.png: 3171 --> 2975 matches\n",
      "filter_FundamentalMatrix: 1198 matches --> 873 matches\n",
      "stairs_split_2_1710453740954.png-stairs_split_2_1710453759963.png: 1198 --> 873 matches\n",
      "filter_FundamentalMatrix: 335 matches --> 219 matches\n",
      "stairs_split_2_1710453740954.png-stairs_split_2_1710453805788.png: 335 --> 219 matches\n",
      "filter_FundamentalMatrix: 445 matches --> 414 matches\n",
      "stairs_split_2_1710453739354.png-stairs_split_2_1710453759963.png: 445 --> 414 matches\n",
      "filter_FundamentalMatrix: 237 matches --> 164 matches\n",
      "stairs_split_2_1710453739354.png-stairs_split_2_1710453805788.png: 237 --> 164 matches\n",
      "filter_FundamentalMatrix: 158 matches --> 114 matches\n",
      "stairs_split_2_1710453725143.png-stairs_split_2_1710453765165.png: 158 --> 114 matches\n",
      "filter_FundamentalMatrix: 549 matches --> 384 matches\n",
      "stairs_split_2_1710453759963.png-stairs_split_2_1710453805788.png: 549 --> 384 matches\n",
      "Ensembled pairs : 65 pairs\n",
      "Local feature extracting and matching. Done in 231.8461 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 40/40 [00:01<00:00, 21.63it/s]\n",
      " 15%|        | 65/435 [00:00<00:00, 3534.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original results\n",
      "{0: Reconstruction(num_reg_images=16, num_cameras=16, num_points3D=2628, num_observations=6016), 1: Reconstruction(num_reg_images=6, num_cameras=6, num_points3D=772, num_observations=1958)}\n",
      "{}\n",
      "map 0:Image(image_id=2, camera_id=2, name=\"stairs_split_1_1710453601885.png\", triangulated=35/1288)\n",
      "map 0:Image(image_id=9, camera_id=9, name=\"stairs_split_1_1710453651110.png\", triangulated=188/1548)\n",
      "map 0:Image(image_id=11, camera_id=11, name=\"stairs_split_1_1710453668718.png\", triangulated=154/1200)\n",
      "map 0:Image(image_id=14, camera_id=14, name=\"stairs_split_1_1710453689727.png\", triangulated=139/231)\n",
      "map 0:Image(image_id=15, camera_id=15, name=\"stairs_split_1_1710453693529.png\", triangulated=21/321)\n",
      "map 0:Image(image_id=18, camera_id=18, name=\"stairs_split_1_1710453930259.png\", triangulated=69/571)\n",
      "map 0:Image(image_id=20, camera_id=20, name=\"stairs_split_1_1710453955270.png\", triangulated=62/472)\n",
      "map 0:Image(image_id=24, camera_id=24, name=\"stairs_split_2_1710453720741.png\", triangulated=476/1900)\n",
      "map 0:Image(image_id=27, camera_id=27, name=\"stairs_split_2_1710453736752.png\", triangulated=264/1947)\n",
      "map 0:Image(image_id=28, camera_id=28, name=\"stairs_split_2_1710453739354.png\", triangulated=1578/5508)\n",
      "map 0:Image(image_id=29, camera_id=29, name=\"stairs_split_2_1710453740954.png\", triangulated=356/4656)\n",
      "map 0:Image(image_id=31, camera_id=31, name=\"stairs_split_2_1710453759963.png\", triangulated=54/1859)\n",
      "map 0:Image(image_id=33, camera_id=33, name=\"stairs_split_2_1710453783374.png\", triangulated=256/2904)\n",
      "map 0:Image(image_id=34, camera_id=34, name=\"stairs_split_2_1710453786375.png\", triangulated=647/3623)\n",
      "map 0:Image(image_id=38, camera_id=38, name=\"stairs_split_2_1710453805788.png\", triangulated=383/2184)\n",
      "map 0:Image(image_id=40, camera_id=40, name=\"stairs_split_2_1710453871430.png\", triangulated=1334/4849)\n",
      "map 1:Image(image_id=16, camera_id=16, name=\"stairs_split_1_1710453704934.png\", triangulated=524/2381)\n",
      "map 1:Image(image_id=17, camera_id=17, name=\"stairs_split_1_1710453901046.png\", triangulated=224/1672)\n",
      "map 1:Image(image_id=30, camera_id=30, name=\"stairs_split_2_1710453745156.png\", triangulated=305/1645)\n",
      "map 1:Image(image_id=34, camera_id=34, name=\"stairs_split_2_1710453786375.png\", triangulated=52/3623)\n",
      "map 1:Image(image_id=35, camera_id=35, name=\"stairs_split_2_1710453790978.png\", triangulated=639/1732)\n",
      "map 1:Image(image_id=36, camera_id=36, name=\"stairs_split_2_1710453793579.png\", triangulated=214/226)\n",
      "Dataset  stairs -> Registered 22 / 51 images with 2 clusters\n",
      "\n",
      "Results\n",
      "Dataset  fbk_vineyard -> Registered 144 / 163 images with 7 clusters\n",
      "Dataset  stairs -> Registered 22 / 51 images with 2 clusters\n",
      "\n",
      "Timings\n",
      "rotation_detection -> total=0.00 sec.\n",
      "global feature extraction -> total=0.00 sec.\n",
      "shortlisting -> total=50.18 sec.\n",
      "feature_detection -> total=0.00 sec.\n",
      "feature_matching -> total=1382.87 sec.\n",
      "RANSAC -> total=3.86 sec.\n",
      "Reconstruction -> total=252.86 sec.\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "\n",
    "max_images = None  # Used For debugging only. Set to None to disable.\n",
    "datasets_to_process = None  # Not the best convention, but None means all datasets.\n",
    "\n",
    "if is_train:\n",
    "    # max_images = 5\n",
    "\n",
    "    # Note: When running on the training dataset, the notebook will hit the time limit and die. Use this filter to run on a few specific datasets.\n",
    "    datasets_to_process = [\n",
    "    \t# New data.\n",
    "    \t# 'amy_gardens',\n",
    "    \t# 'ETs',\n",
    "    \t'fbk_vineyard',\n",
    "    \t'stairs',\n",
    "    \t# Data from IMC 2023 and 2024.\n",
    "    \t# 'imc2024_dioscuri_baalshamin',\n",
    "    \t# 'imc2023_theather_imc2024_church',\n",
    "    \t# 'imc2023_heritage',\n",
    "    \t# 'imc2023_haiper',\n",
    "    \t# 'imc2024_lizard_pond',\n",
    "    \t# Crowdsourced PhotoTourism data.\n",
    "    \t# # 'pt_stpeters_stpauls',\n",
    "    \t# # 'pt_brandenburg_british_buckingham',\n",
    "    \t# # 'pt_piazzasanmarco_grandplace',\n",
    "    \t# # 'pt_sacrecoeur_trevi_tajmahal',\n",
    "    ]\n",
    "\n",
    "timings = {\n",
    "    'rotation_detection':[],\n",
    "    \"global feature extraction\":[],\n",
    "    \"shortlisting\":[],\n",
    "    \"feature_detection\": [],\n",
    "    \"feature_matching\":[],\n",
    "    \"RANSAC\": [],\n",
    "    \"Reconstruction\": [],\n",
    "}\n",
    "mapping_result_strs = []\n",
    "\n",
    "# Load DINOv2 model (for feature extraction, not global descriptor here)\n",
    "print(\"Loading DINOv2 model for patch feature extraction...\")\n",
    "dino_processor = AutoImageProcessor.from_pretrained('/kaggle/input/dinov2/pytorch/base/1')\n",
    "dino_model = AutoModel.from_pretrained('/kaggle/input/dinov2/pytorch/base/1')\n",
    "dino_model = dino_model.eval().to(device)\n",
    "print(\"DINOv2 model loaded.\")\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=CONFIG.NUM_CORES) as executors:\n",
    "    # print (f\"Extracting on device {device}\")\n",
    "    for dataset, predictions in samples.items():\n",
    "        if datasets_to_process and dataset not in datasets_to_process:\n",
    "            print(f'Skipping \"{dataset}\"')\n",
    "            continue\n",
    "        \n",
    "        images_dir = os.path.join(data_dir, 'train' if is_train else 'test', dataset)\n",
    "        images = [os.path.join(images_dir, p.filename) for p in predictions]\n",
    "        if max_images is not None:\n",
    "            images = images[:max_images]\n",
    "    \n",
    "        print(f'\\nProcessing dataset \"{dataset}\": {len(images)} images')\n",
    "    \n",
    "        filename_to_index = {p.filename: idx for idx, p in enumerate(predictions)}\n",
    "    \n",
    "        feature_dir = os.path.join(workdir, 'featureout', dataset)\n",
    "        os.makedirs(feature_dir, exist_ok=True)\n",
    "    \n",
    "        # Wrap algos in try-except blocks so we can populate a submission even if one scene crashes.\n",
    "        try:\n",
    "            # --- Pipeline Execution ---\n",
    "            \n",
    "            #############################################################\n",
    "            # get image rotations\n",
    "            #############################################################\n",
    "            t = time()\n",
    "            # if CONFIG.ROTATION_CORRECTION:\n",
    "            #     rots = exec_rotation_detection(images, device)\n",
    "            # else:\n",
    "            #     rots = [ 0 for fname in images ]\n",
    "            rots = [ 0 for fname in images ]\n",
    "            t = time()-t\n",
    "            timings['rotation_detection'].append(t)\n",
    "            print(f'rotation_detection for {len(images)} images : {t:.4f} sec')\n",
    "            # print(\"!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "            gc.collect()\n",
    "            #############################################################\n",
    "            # get image pairs\n",
    "            #############################################################\n",
    "            # 1. Detect ALIKED features and combine with DINO patch features\n",
    "            t = time()\n",
    "            index_pairs = get_image_pairs_shortlist(\n",
    "                images,\n",
    "                sim_th = 0.3, # should be strict\n",
    "                min_pairs = 10, # we should select at least min_pairs PER IMAGE with biggest similarity\n",
    "                max_pairs = 20,\n",
    "                exhaustive_if_less = 20,\n",
    "                device=device\n",
    "            )\n",
    "            timings['shortlisting'].append(time() - t)\n",
    "            print (f'Shortlisting. Number of pairs to match: {len(index_pairs)}. Done in {time() - t:.4f} sec')\n",
    "            gc.collect()\n",
    "            # print(\"\\n--- Step 1: Detecting ALIKED and Combining with DINO Patch Features ---\")\n",
    "            # detect_aliked_and_combine_with_dino(\n",
    "            #     img_fnames=images,\n",
    "            #     feature_dir=feature_dir,\n",
    "            #     num_features=4096,\n",
    "            #     resize_to=1024,\n",
    "            #     dino_processor=dino_processor,\n",
    "            #     dino_model=dino_model,\n",
    "            #     dino_patch_size=14, # Adjust based on your DINO model's patch size (e.g., 14 for DINOv2 base)\n",
    "            #     device=device\n",
    "            # )\n",
    "            # timings['global feature extraction'].append(time() - t)\n",
    "            # print (f'Gloabl feature extracting. Done in {time() - t:.4f} sec')\n",
    "            # gc.collect()\n",
    "            \n",
    "            # # 2. Get image pairs shortlist using VLAD global descriptors\n",
    "            # print(\"\\n--- Step 2: Generating Image Pair Shortlist using VLAD ---\")\n",
    "            # # Adjust num_clusters_vlad as needed (e.g., 64, 128, 256)\n",
    "            # # Higher clusters mean higher dimensionality for global descriptor.\n",
    "            # index_pairs = get_image_pairs_shortlist_vlad(\n",
    "            #     fnames=images,\n",
    "            #     sim_th=0.5,\n",
    "            #     min_pairs=20,\n",
    "            #     exhaustive_if_less=20,\n",
    "            #     feature_dir=feature_dir,\n",
    "            #     num_clusters_vlad=128, # Example: 128 clusters for VLAD\n",
    "            #     device=device\n",
    "            # )\n",
    "            # index_pairs = get_img_pairs_exhaustive(images)\n",
    "            \n",
    "            print(f\"Generated {len(index_pairs)} image pairs using VLAD global descriptor.\")\n",
    "            timings['shortlisting'].append(time() - t)\n",
    "            print (f'Shortlisting. Number of pairs to match: {len(index_pairs)}. Done in {time() - t:.4f} sec')\n",
    "            gc.collect()\n",
    "            #############################################################\n",
    "            # get keypoints\n",
    "            #############################################################    \n",
    "            t=time()\n",
    "            keypoints_timings = wrapper_keypoints(\n",
    "                images, index_pairs, feature_dir, device, timings, rots\n",
    "            )\n",
    "            timings['feature_matching'] = keypoints_timings['feature_matching']\n",
    "            gc.collect()\n",
    "            print (f'Local feature extracting and matching. Done in {time() - t:.4f} sec')\n",
    "            #############################################################\n",
    "            # kick COLMAP reconstruction\n",
    "            #############################################################            \n",
    "            future = executors.submit(\n",
    "                reconstruct_from_db, \n",
    "                feature_dir, images_dir)\n",
    "            maps, local_timings = future.result()\n",
    "            #  timings\n",
    "            for k in local_timings:\n",
    "                timings[k].extend(local_timings[k])\n",
    "            # clear_output(wait=False)\n",
    "            registered = 0\n",
    "            for map_index, cur_map in maps.items():  # cur_map: image_name  {'R': list, 't': list}\n",
    "                for image_name, pose in cur_map.items():\n",
    "                    idx = filename_to_index[image_name]\n",
    "                    pred = predictions[idx]\n",
    "                    pred.cluster_index = map_index\n",
    "                    pred.rotation = np.array(pose['R'])  # convert back to np.ndarray\n",
    "                    pred.translation = np.array(pose['t'])\n",
    "                    registered += 1\n",
    "            mapping_result_str = f\"Dataset  {dataset} -> Registered {registered} / {len(images)} images with {len(maps)} clusters\"\n",
    "            mapping_result_strs.append(mapping_result_str)\n",
    "            print(mapping_result_str)\n",
    "\n",
    "            gc.collect()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            # raise e\n",
    "            mapping_result_str = f'Dataset \"{dataset}\" -> Failed!'\n",
    "            mapping_result_strs.append(mapping_result_str)\n",
    "            print(mapping_result_str)\n",
    "\n",
    "print('\\nResults')\n",
    "for s in mapping_result_strs:\n",
    "    print(s)\n",
    "\n",
    "print('\\nTimings')\n",
    "for k, v in timings.items():\n",
    "    print(f'{k} -> total={sum(v):.02f} sec.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "665a6092",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T07:30:22.979793Z",
     "iopub.status.busy": "2025-05-30T07:30:22.979412Z",
     "iopub.status.idle": "2025-05-30T07:30:23.154268Z",
     "shell.execute_reply": "2025-05-30T07:30:23.153126Z"
    },
    "papermill": {
     "duration": 0.55592,
     "end_time": "2025-05-30T07:30:23.155728",
     "exception": false,
     "start_time": "2025-05-30T07:30:22.599808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset,scene,image,rotation_matrix,translation_vector\r\n",
      "imc2023_haiper,outliers,fountain_image_116.png,nan;nan;nan;nan;nan;nan;nan;nan;nan,nan;nan;nan\r\n",
      "imc2023_haiper,outliers,fountain_image_108.png,nan;nan;nan;nan;nan;nan;nan;nan;nan,nan;nan;nan\r\n",
      "imc2023_haiper,outliers,fountain_image_101.png,nan;nan;nan;nan;nan;nan;nan;nan;nan,nan;nan;nan\r\n",
      "imc2023_haiper,outliers,fountain_image_082.png,nan;nan;nan;nan;nan;nan;nan;nan;nan,nan;nan;nan\r\n",
      "imc2023_haiper,outliers,fountain_image_071.png,nan;nan;nan;nan;nan;nan;nan;nan;nan,nan;nan;nan\r\n",
      "imc2023_haiper,outliers,fountain_image_025.png,nan;nan;nan;nan;nan;nan;nan;nan;nan,nan;nan;nan\r\n",
      "imc2023_haiper,outliers,fountain_image_000.png,nan;nan;nan;nan;nan;nan;nan;nan;nan,nan;nan;nan\r\n",
      "imc2023_haiper,outliers,fountain_image_007.png,nan;nan;nan;nan;nan;nan;nan;nan;nan,nan;nan;nan\r\n",
      "imc2023_haiper,outliers,fountain_image_012.png,nan;nan;nan;nan;nan;nan;nan;nan;nan,nan;nan;nan\r\n"
     ]
    }
   ],
   "source": [
    "# Helpers\n",
    "array_to_str = lambda array: ';'.join([f\"{x:.09f}\" for x in array])\n",
    "none_to_str = lambda n: ';'.join(['nan'] * n)\n",
    "\n",
    "submission_file = '/kaggle/working/submission.csv'\n",
    "with open(submission_file, 'w') as f:\n",
    "    if is_train:\n",
    "        f.write('dataset,scene,image,rotation_matrix,translation_vector\\n')\n",
    "        for dataset, predictions in samples.items():\n",
    "            for prediction in predictions:\n",
    "                cluster_name = 'outliers' if prediction.cluster_index is None else f'cluster{prediction.cluster_index}'\n",
    "\n",
    "                #  `rotation` is a list of lists, flatten it\n",
    "                if prediction.rotation is None:\n",
    "                    rotation_str = none_to_str(9)\n",
    "                else:\n",
    "                    rotation_flat =  prediction.rotation.flatten()  # flatten 3x3 list -> 9 elems\n",
    "                    rotation_str = array_to_str(rotation_flat)\n",
    "\n",
    "                #  `translation` is a flat list\n",
    "                if prediction.translation is None:\n",
    "                    translation_str = none_to_str(3)\n",
    "                else:\n",
    "                    translation_str = array_to_str(prediction.translation)\n",
    "\n",
    "                f.write(f'{prediction.dataset},{cluster_name},{prediction.filename},{rotation_str},{translation_str}\\n')\n",
    "    else:\n",
    "        f.write('image_id,dataset,scene,image,rotation_matrix,translation_vector\\n')\n",
    "        for dataset, predictions in samples.items():\n",
    "            for prediction in predictions:\n",
    "                cluster_name = 'outliers' if prediction.cluster_index is None else f'cluster{prediction.cluster_index}'\n",
    "\n",
    "                if prediction.rotation is None:\n",
    "                    rotation_str = none_to_str(9)\n",
    "                else:\n",
    "                    rotation_flat =  prediction.rotation.flatten()\n",
    "                    rotation_str = array_to_str(rotation_flat)\n",
    "\n",
    "                if prediction.translation is None:\n",
    "                    translation_str = none_to_str(3)\n",
    "                else:\n",
    "                    translation_str = array_to_str(prediction.translation)\n",
    "\n",
    "                f.write(f'{prediction.image_id},{prediction.dataset},{cluster_name},{prediction.filename},{rotation_str},{translation_str}\\n')\n",
    "\n",
    "# Preview the output\n",
    "!head {submission_file}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b815cc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T07:30:23.848620Z",
     "iopub.status.busy": "2025-05-30T07:30:23.848257Z",
     "iopub.status.idle": "2025-05-30T07:30:51.082246Z",
     "shell.execute_reply": "2025-05-30T07:30:51.081347Z"
    },
    "papermill": {
     "duration": 27.597034,
     "end_time": "2025-05-30T07:30:51.083660",
     "exception": false,
     "start_time": "2025-05-30T07:30:23.486626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imc2023_haiper: score=0.00% (mAA=0.00%, clusterness=100.00%)\n",
      "imc2023_heritage: score=0.00% (mAA=0.00%, clusterness=100.00%)\n",
      "imc2023_theather_imc2024_church: score=0.00% (mAA=0.00%, clusterness=100.00%)\n",
      "imc2024_dioscuri_baalshamin: score=0.00% (mAA=0.00%, clusterness=100.00%)\n",
      "imc2024_lizard_pond: score=0.00% (mAA=0.00%, clusterness=100.00%)\n",
      "pt_brandenburg_british_buckingham: score=0.00% (mAA=0.00%, clusterness=100.00%)\n",
      "pt_piazzasanmarco_grandplace: score=0.00% (mAA=0.00%, clusterness=100.00%)\n",
      "pt_sacrecoeur_trevi_tajmahal: score=0.00% (mAA=0.00%, clusterness=100.00%)\n",
      "pt_stpeters_stpauls: score=0.00% (mAA=0.00%, clusterness=100.00%)\n",
      "amy_gardens: score=0.00% (mAA=0.00%, clusterness=100.00%)\n",
      "fbk_vineyard: score=46.92% (mAA=30.84%, clusterness=97.98%)\n",
      "ETs: score=0.00% (mAA=0.00%, clusterness=100.00%)\n",
      "stairs: score=0.00% (mAA=0.00%, clusterness=50.00%)\n",
      "Average over all datasets: score=3.61% (mAA=2.37%, clusterness=96.00%)\n",
      "Computed metric in: 27.23 sec.\n"
     ]
    }
   ],
   "source": [
    "# Definitely Compute results if running on the training set.\n",
    "# Do not do this when submitting a notebook for scoring. All you have to do is save your submission to /kaggle/working/submission.csv.\n",
    "\n",
    "if is_train:\n",
    "    t = time()\n",
    "    final_score, dataset_scores = metric.score(\n",
    "        gt_csv='/kaggle/input/image-matching-challenge-2025/train_labels.csv',\n",
    "        user_csv=submission_file,\n",
    "        thresholds_csv='/kaggle/input/image-matching-challenge-2025/train_thresholds.csv',\n",
    "        mask_csv=None if is_train else os.path.join(data_dir, 'mask.csv'),\n",
    "        inl_cf=0,\n",
    "        strict_cf=-1,\n",
    "        verbose=True,\n",
    "    )\n",
    "    print(f'Computed metric in: {time() - t:.02f} sec.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d13e15",
   "metadata": {
    "papermill": {
     "duration": 0.327198,
     "end_time": "2025-05-30T07:30:51.786428",
     "exception": false,
     "start_time": "2025-05-30T07:30:51.459230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11655853,
     "sourceId": 91498,
     "sourceType": "competition"
    },
    {
     "datasetId": 4628051,
     "sourceId": 7884485,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6988459,
     "sourceId": 11924468,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7505602,
     "sourceId": 11938492,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7542297,
     "sourceId": 11991336,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 986,
     "modelInstanceId": 3326,
     "sourceId": 4534,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 21716,
     "modelInstanceId": 14317,
     "sourceId": 17191,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 22086,
     "modelInstanceId": 14611,
     "sourceId": 17555,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1775.850954,
   "end_time": "2025-05-30T07:30:56.128990",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-30T07:01:20.278036",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
