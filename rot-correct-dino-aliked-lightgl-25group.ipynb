{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":91498,"databundleVersionId":11655853,"sourceType":"competition"},{"sourceId":7884485,"sourceType":"datasetVersion","datasetId":4628051},{"sourceId":11924468,"sourceType":"datasetVersion","datasetId":6988459},{"sourceId":11938492,"sourceType":"datasetVersion","datasetId":7505602},{"sourceId":176463227,"sourceType":"kernelVersion"},{"sourceId":4534,"sourceType":"modelInstanceVersion","modelInstanceId":3326,"modelId":986},{"sourceId":17191,"sourceType":"modelInstanceVersion","modelInstanceId":14317,"modelId":21716},{"sourceId":17555,"sourceType":"modelInstanceVersion","modelInstanceId":14611,"modelId":22086}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Example submission\n\nImage Matching Challenge 2025: https://www.kaggle.com/competitions/image-matching-challenge-2025\n\nThis notebook creates a simple submission using ALIKED and LightGlue, plus DINO for shortlisting, on GPU. Adapted from [last year](https://www.kaggle.com/code/oldufo/imc-2024-submission-example).\n\nRemember to select an accelerator on the sidebar to the right, and to disable internet access when submitting a notebook to the competition.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"# IMPORTANT \n#Install dependencies and copy model weights to run the notebook without internet access when submitting to the competition.\n\n!pip install --no-index /kaggle/input/imc2024-packages-lightglue-rerun-kornia/* --no-deps\n!mkdir -p /root/.cache/torch/hub/checkpoints\n!cp /kaggle/input/aliked/pytorch/aliked-n16/1/aliked-n16.pth /root/.cache/torch/hub/checkpoints/\n!cp /kaggle/input/lightglue/pytorch/aliked/1/aliked_lightglue.pth /root/.cache/torch/hub/checkpoints/\n!cp /kaggle/input/lightglue/pytorch/aliked/1/aliked_lightglue.pth /root/.cache/torch/hub/checkpoints/aliked_lightglue_v0-1_arxiv-pth","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T22:54:40.707524Z","iopub.execute_input":"2025-06-10T22:54:40.707924Z","iopub.status.idle":"2025-06-10T22:54:42.682333Z","shell.execute_reply.started":"2025-06-10T22:54:40.707892Z","shell.execute_reply":"2025-06-10T22:54:42.681296Z"}},"outputs":[{"name":"stdout","text":"Processing /kaggle/input/imc2024-packages-lightglue-rerun-kornia/kornia-0.7.2-py2.py3-none-any.whl\nProcessing /kaggle/input/imc2024-packages-lightglue-rerun-kornia/kornia_moons-0.2.9-py3-none-any.whl\nProcessing /kaggle/input/imc2024-packages-lightglue-rerun-kornia/kornia_rs-0.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nProcessing /kaggle/input/imc2024-packages-lightglue-rerun-kornia/lightglue-0.0-py3-none-any.whl\nProcessing /kaggle/input/imc2024-packages-lightglue-rerun-kornia/pycolmap-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nProcessing /kaggle/input/imc2024-packages-lightglue-rerun-kornia/rerun_sdk-0.15.0a2-cp38-abi3-manylinux_2_31_x86_64.whl\nkornia is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\nkornia-moons is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\nkornia-rs is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\nlightglue is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\npycolmap is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\nrerun-sdk is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!cp /kaggle/input/disk-depth/disk_lightglue.pth /root/.cache/torch/hub/checkpoints/\n!cp /kaggle/input/disk-depth/disk_lightglue.pth /root/.cache/torch/hub/checkpoints/disk_lightglue_v0-1_arxiv-pth\n!cp /kaggle/input/disk-depth/disk_lightglue.pth /root/.cache/torch/hub/checkpoints/depth-save.pth","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T22:54:42.683546Z","iopub.execute_input":"2025-06-10T22:54:42.683838Z","iopub.status.idle":"2025-06-10T22:54:43.276168Z","shell.execute_reply.started":"2025-06-10T22:54:42.683811Z","shell.execute_reply":"2025-06-10T22:54:43.274943Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import os\nprint(os.path.exists(\"/root/.cache/torch/hub/checkpoints/disk_lightglue_v0-1_arxiv-pth\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T22:54:43.278363Z","iopub.execute_input":"2025-06-10T22:54:43.278784Z","iopub.status.idle":"2025-06-10T22:54:43.579675Z","shell.execute_reply.started":"2025-06-10T22:54:43.278747Z","shell.execute_reply":"2025-06-10T22:54:43.578770Z"}},"outputs":[{"name":"stdout","text":"True\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!rm -rf /kaggle/working/tta_debug_vis\n!rm -rf /kaggle/working/visualization_output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T22:54:43.581332Z","iopub.execute_input":"2025-06-10T22:54:43.581735Z","iopub.status.idle":"2025-06-10T22:54:43.960726Z","shell.execute_reply.started":"2025-06-10T22:54:43.581687Z","shell.execute_reply":"2025-06-10T22:54:43.959430Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import sys\nimport os\nfrom tqdm import tqdm\nfrom time import time, sleep\nimport gc\nimport numpy as np\nimport h5py\nimport dataclasses\nimport pandas as pd\nfrom IPython.display import clear_output\nfrom collections import defaultdict\nfrom copy import deepcopy\nfrom PIL import Image\n\nimport cv2\nimport torch\nimport torch.nn.functional as F\nimport kornia as K\nimport kornia.feature as KF\n\nimport torch\nfrom lightglue import match_pair\nfrom lightglue import ALIKED, LightGlue\nfrom lightglue.utils import load_image, rbd\nfrom transformers import AutoImageProcessor, AutoModel\n\n# from lightglue import DISK\nfrom kornia.feature import LightGlueMatcher as KF_LightGlueMatcher\nfrom scipy.spatial import cKDTree # For efficient nearest neighbor search to remove duplicate keypoints\n\n# IMPORTANT Utilities: importing data into colmap and competition metric\nimport pycolmap\nsys.path.append('/kaggle/input/imc25-utils')\nfrom database import *\nfrom h5_to_db import *\nimport metric\n\n\n# LightGlue\nfrom lightglue import match_pair\nfrom lightglue import ALIKED, SuperPoint,DISK, DoGHardNet, LightGlue, SIFT\nfrom fastprogress import progress_bar\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T22:54:43.962169Z","iopub.execute_input":"2025-06-10T22:54:43.962567Z","iopub.status.idle":"2025-06-10T22:54:51.208882Z","shell.execute_reply.started":"2025-06-10T22:54:43.962529Z","shell.execute_reply":"2025-06-10T22:54:51.207888Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/kornia/feature/lightglue.py:44: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n/usr/local/lib/python3.10/dist-packages/lightglue/lightglue.py:24: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from collections import defaultdict\nfrom copy import deepcopy\nimport concurrent.futures\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T22:54:51.209901Z","iopub.execute_input":"2025-06-10T22:54:51.210499Z","iopub.status.idle":"2025-06-10T22:54:51.214512Z","shell.execute_reply.started":"2025-06-10T22:54:51.210470Z","shell.execute_reply":"2025-06-10T22:54:51.213622Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"\nprint(\"PyTorch version:\", torch.__version__)\nimport sys\nprint(\"Python version:\", sys.version)\n\nprint(\"CUDA available:\", torch.cuda.is_available())\nprint(\"CUDA version:\", torch.version.cuda)\nprint(\"Device count:\", torch.cuda.device_count())\nprint(\"Current device:\", torch.cuda.current_device())\nprint(\"Device name:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T22:54:51.215501Z","iopub.execute_input":"2025-06-10T22:54:51.215809Z","iopub.status.idle":"2025-06-10T22:54:51.316811Z","shell.execute_reply.started":"2025-06-10T22:54:51.215785Z","shell.execute_reply":"2025-06-10T22:54:51.315888Z"}},"outputs":[{"name":"stdout","text":"PyTorch version: 2.5.1+cu121\nPython version: 3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]\nCUDA available: True\nCUDA version: 12.1\nDevice count: 2\nCurrent device: 0\nDevice name: Tesla T4\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Do not forget to select an accelerator on the sidebar to the right.\ndevice = K.utils.get_cuda_device_if_available(0)\nprint(f'{device=}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T22:54:51.319231Z","iopub.execute_input":"2025-06-10T22:54:51.319479Z","iopub.status.idle":"2025-06-10T22:54:51.324279Z","shell.execute_reply.started":"2025-06-10T22:54:51.319458Z","shell.execute_reply":"2025-06-10T22:54:51.323401Z"}},"outputs":[{"name":"stdout","text":"device=device(type='cuda', index=0)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import random\nimport os\nimport numpy as np\nimport torch\n\ndef seed_everything(seed: int = 42):\n    \"\"\"Set seed for reproducibility across random, numpy, torch (CPU + CUDA).\"\"\"\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)  # for multi-GPU\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nseed_everything()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T22:54:51.325816Z","iopub.execute_input":"2025-06-10T22:54:51.326039Z","iopub.status.idle":"2025-06-10T22:54:51.341564Z","shell.execute_reply.started":"2025-06-10T22:54:51.326020Z","shell.execute_reply":"2025-06-10T22:54:51.340879Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"VERBOSE = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T22:54:51.342533Z","iopub.execute_input":"2025-06-10T22:54:51.342851Z","iopub.status.idle":"2025-06-10T22:54:51.355483Z","shell.execute_reply.started":"2025-06-10T22:54:51.342826Z","shell.execute_reply":"2025-06-10T22:54:51.354697Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"class CONFIG:\n    # DEBUG Settings\n    DRY_RUN = False\n    DRY_RUN_MAX_IMAGES = 10\n\n    # Pipeline settings\n    NUM_CORES = 2\n    \n    # COLMAP Reconstruction\n    CAMERA_MODEL = \"simple-radial\"\n    \n    # Rotation correction\n    ROTATION_CORRECTION = True\n    \n    # Keypoints handling\n    MERGE_PARAMS = {\n        \"min_matches\" : 15,\n        # When merging keypoints, it is enable to filtering matches with cv2.findFundamentalMatrix.\n        \"filter_FundamentalMatrix\" : False,\n        \"filter_iterations\" : 10,\n        \"filter_threshold\" : 8,\n    }\n    \n    # Keypoints Extraction\n    use_aliked_lightglue = True\n    use_doghardnet_lightglue = False\n    use_superpoint_lightglue = False\n    use_disk_lightglue = False\n    use_sift_lightglue = False\n    use_loftr = False\n    use_dkm = False\n    use_superglue = False\n    use_matchformer = False\n        \n    # Keypoints Extraction Parameters\n    params_aliked_lightglue = {\n        \"num_features\" : 8192,\n        \"detection_threshold\" : 0.05,\n        \"min_matches\" : 100,\n        \"resize_to\" : 2048,\n    }\n\n    params_rot_detection_aliked_lightglue={\n        \"num_features\" : 4096,\n        \"resize_to\":960,\n        \"min_matches\":60,\n        \"min_inliers\":40\n        }\n    \n    params_doghardnet_lightglue = {\n        \"num_features\" : 8192,\n        \"detection_threshold\" : 0.001,\n        \"min_matches\" : 15,\n        \"resize_to\" : 1024,\n    }\n    \n    params_superpoint_lightglue = {\n        \"num_features\" : 4096,\n        \"detection_threshold\" : 0.005,\n        \"min_matches\" : 15,\n        \"resize_to\" : 1024,\n    }\n    \n    params_disk_lightglue = {\n        \"num_features\" : 4096,\n        \"detection_threshold\" : 0.3,\n        \"min_matches\" : 100,\n        \"resize_to\" : 1024,\n    }\n\n    params_sift_lightglue = {\n        \"num_features\" : 8192,\n        \"detection_threshold\" : 0.001,\n        \"min_matches\" : 15,\n        \"resize_to\" : 1024,\n    }\n\n    params_loftr = {\n        \"resize_small_edge_to\" : 750,\n        \"min_matches\" : 15,\n    }\n    \n    params_dkm = {\n        \"num_features\" : 2048,\n        \"detection_threshold\" : 0.4,\n        \"min_matches\" : 15,\n        \"resize_to\" : (540, 720),    \n    }\n    \n    # superpoint + superglue  ...  https://www.kaggle.com/competitions/image-matching-challenge-2023/discussion/416873\n    params_sg1 = {\n        \"sg_config\" : \n        {\n            \"superpoint\": {\n                \"nms_radius\": 4, \n                \"keypoint_threshold\": 0.005,\n                \"max_keypoints\": -1,\n            },\n            \"superglue\": {\n                \"weights\": \"outdoor\",\n                \"sinkhorn_iterations\": 20,\n                \"match_threshold\": 0.2,\n            },\n        },\n        \"resize_to\": 1088,\n        \"min_matches\": 15,\n    }\n    params_sg2 = {\n        \"sg_config\" : \n        {\n            \"superpoint\": {\n                \"nms_radius\": 4, \n                \"keypoint_threshold\": 0.005,\n                \"max_keypoints\": -1,\n            },\n            \"superglue\": {\n                \"weights\": \"outdoor\",\n                \"sinkhorn_iterations\": 20,\n                \"match_threshold\": 0.2,\n            },\n        },\n        \"resize_to\": 1280,\n        \"min_matches\": 15,\n    }\n    params_sg3 = {\n        \"sg_config\" : \n        {\n            \"superpoint\": {\n                \"nms_radius\": 4, \n                \"keypoint_threshold\": 0.005,\n                \"max_keypoints\": -1,\n            },\n            \"superglue\": {\n                \"weights\": \"outdoor\",\n                \"sinkhorn_iterations\": 20,\n                \"match_threshold\": 0.2,\n            },\n        },\n        \"resize_to\": 1376,\n        \"min_matches\": 15,\n    }\n    params_sgs = [params_sg1, params_sg2, params_sg3]\n    \n    params_matchformer = {\n        \"detection_threshold\" : 0.15,\n        \"resize_to\" : (560, 750),\n        \"num_features\" : 2000,\n        \"min_matches\" : 15, \n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T22:54:51.356379Z","iopub.execute_input":"2025-06-10T22:54:51.356627Z","iopub.status.idle":"2025-06-10T22:54:51.365856Z","shell.execute_reply.started":"2025-06-10T22:54:51.356607Z","shell.execute_reply":"2025-06-10T22:54:51.365075Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# --- Helper function for image loading (if not already defined) ---\ndef load_torch_image(fname, device=torch.device('cpu')):\n    img = K.io.load_image(fname, K.io.ImageLoadType.RGB32, device=device)[None, ...]\n    return img","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T22:54:51.366683Z","iopub.execute_input":"2025-06-10T22:54:51.366955Z","iopub.status.idle":"2025-06-10T22:54:51.378434Z","shell.execute_reply.started":"2025-06-10T22:54:51.366934Z","shell.execute_reply":"2025-06-10T22:54:51.377697Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def init_cache_from_imglist(img_fnames, n_rotations=4, n_groups=5):\n    \"\"\"\n    Initializes a nested defaultdict cache structure for each image and rotation.\n    Structure: cache[image_key][rotation][index] = dict()\n    \"\"\"\n    cache = defaultdict(lambda: [[] for _ in range(n_rotations)])\n    for fname in img_fnames:\n        key = fname.split('/')[-1]  # use basename\n        for r in range(n_rotations):\n            cache[key][r] = [dict() for _ in range(n_groups)]\n    return cache","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T22:54:51.379294Z","iopub.execute_input":"2025-06-10T22:54:51.379560Z","iopub.status.idle":"2025-06-10T22:54:51.389660Z","shell.execute_reply.started":"2025-06-10T22:54:51.379540Z","shell.execute_reply":"2025-06-10T22:54:51.388828Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"from collections import defaultdict\nfrom PIL import Image\nfrom torchvision import transforms\n\nclass RotationEstimator:\n    def __init__(self, device='cuda'):\n        self.device = torch.device(device)\n        self.extractor = ALIKED(weights=f\"/kaggle/input/aliked/pytorch/aliked-n16/1/aliked-n16.pth\", \n                                # detection_threshold=CONFIG.params_rot_detection_aliked_lightglue[\"detection_threshold\"],\n                                num_features=CONFIG.params_rot_detection_aliked_lightglue[\"num_features\"],\n                                min_matches=CONFIG.params_rot_detection_aliked_lightglue[\"min_matches\"]\n                               ).to(self.device, dtype = torch.float32).eval()\n        lg_cfg = {\n            \"features\": \"aliked\",\n            \"depth_confidence\": -1,         # 禁用深度置信度过滤\n            \"width_confidence\": -1,         # 禁用宽度置信度过滤\n            \"filter_threshold\": 0.1,        # 设置匹配分数阈值\n            \"mp\": True                     # 禁用多进程加速\n        }\n        self.lightglue = LightGlue(**lg_cfg).eval().to(self.device)\n        self.verbose = VERBOSE\n        \n    def extract(self, img):\n        with torch.inference_mode():\n            return self.extractor.extract(img, resize=CONFIG.params_rot_detection_aliked_lightglue[\"resize_to\"])\n\n    def match_and_filter(self, desc0, desc1, kpts0, kpts1):\n        data = {\n            \"image0\": {\"keypoints\": kpts0, \"descriptors\": desc0},\n            \"image1\": {\"keypoints\": kpts1, \"descriptors\": desc1},\n        }\n        with torch.inference_mode():\n            pred = self.lightglue(data)\n        matches0 = pred[\"matches0\"][0].cpu().numpy()\n        valid = matches0 > -1\n        if np.sum(valid) == 0:\n            return 0\n        pts0 = kpts0[0][valid].cpu().numpy()\n        pts1 = kpts1[0][matches0[valid]].cpu().numpy()\n        try:\n            _, inliers = cv2.findFundamentalMat(pts0, pts1, cv2.USAC_MAGSAC, 5, 0.9999, 50000)\n            return int(np.sum(inliers)) if inliers is not None else 0\n        except:\n            return 0\n\n    def run(self,img_fnames, index_pairs):\n        rot_dict = defaultdict(dict)\n        for idx1, idx2 in tqdm(index_pairs, desc=\"Finding valid rotations\"):\n            fname1, fname2 = img_fnames[idx1], img_fnames[idx2]\n            key1, key2 = os.path.basename(fname1), os.path.basename(fname2)\n            try:\n                img0 = load_torch_image(fname1, device = self.device)\n                img1 = load_torch_image(fname2, device = self.device)\n            except Exception as e:\n                print(f\"Failed to load image: {fname1}, {fname2}, reason: {e}\")\n                continue\n\n            desc0 = self.extract(img0)\n            kpts0, desc0 = desc0[\"keypoints\"], desc0[\"descriptors\"]\n\n            for rot in range(4):  # 0, 90, 180, 270 degrees\n                rotated_img1 = torch.rot90(img1, k=rot, dims=[2, 3])\n                desc1 = self.extract(rotated_img1)\n                kpts1, desc1 = desc1[\"keypoints\"], desc1[\"descriptors\"]\n\n                inliers = self.match_and_filter(desc0, desc1, kpts0, kpts1)\n                if inliers > CONFIG.params_rot_detection_aliked_lightglue['min_inliers']:\n                    rot_dict[key1][key2] = rot\n                    # if self.verbose:\n                    #     print(f\"matching {key1}-{key2} with {inliers} inliers!\")\n                    break\n        del self.extractor\n        gc.collect()\n        del self.lightglue\n        gc.collect()    \n        return dict(rot_dict)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T22:54:51.390442Z","iopub.execute_input":"2025-06-10T22:54:51.390705Z","iopub.status.idle":"2025-06-10T22:54:51.405808Z","shell.execute_reply.started":"2025-06-10T22:54:51.390685Z","shell.execute_reply":"2025-06-10T22:54:51.405104Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"import numpy as np\nimport h5py\nfrom collections import defaultdict\n\ndef merge_and_save_keypoints_matches(\n    unique_kpts,\n    out_match,\n    rot_dict,\n    feature_dir\n):\n    # Step 1: Merge all keypoints per image (across rotations)\n    merged_kpts = {}\n    kpt_offset = {}\n\n    for img_name, rot_kpts_dict in unique_kpts.items():\n        merged = []\n        offset = {}\n        total = 0\n        for rot in sorted(rot_kpts_dict):  # rot 0,1,2,3\n            kpts = rot_kpts_dict[rot]\n            offset[rot] = total\n            total += len(kpts)\n            merged.append(kpts)\n        if total == 0:\n            continue\n        merged_kpts[img_name] = np.concatenate(merged, axis=0)\n        kpt_offset[img_name] = offset\n\n    # Step 2: Remap match indices based on offset\n    updated_out_match = defaultdict(dict)\n\n    for k1, match_group in out_match.items():\n        for k2, match_data in match_group.items():\n            matches = match_data[\"matches\"]\n            rot = match_data[\"rot\"]\n            if len(matches) == 0:\n                continue\n\n            offset0 = kpt_offset[k1][rot]\n            offset1 = kpt_offset[k2][0]  # image2 is always rot 0\n\n            updated_matches = matches.copy()\n            updated_matches[:, 0] += offset0\n            updated_matches[:, 1] += offset1\n            updated_out_match[k1][k2] = updated_matches.astype(np.int32)\n\n    unified_kp_path = f'{feature_dir}/keypoints.h5'\n    remapped_matches_path = f'{feature_dir}/matches.h5'\n    # Step 3: Save merged keypoints\n    with h5py.File(f'{feature_dir}/keypoints.h5', mode='w') as f_kp:\n        for img_name, kpts in merged_kpts.items():\n            f_kp[img_name] = kpts.astype(np.float32)  # shape (N, 2)\n\n    # Step 4: Save remapped matches\n    with h5py.File(f'{feature_dir}/matches.h5', mode='w') as f_match:\n        for k1, match_group in updated_out_match.items():\n            g = f_match.require_group(k1)\n            for k2, matches in match_group.items():\n                if len(matches) > 0:\n                    g[k2] = matches  # shape (M, 2), dtype=int32\n\n    # print(\"✔ Merged keypoints and remapped matches saved.\")\n    return unified_kp_path, remapped_matches_path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T22:54:51.406538Z","iopub.execute_input":"2025-06-10T22:54:51.406775Z","iopub.status.idle":"2025-06-10T22:54:51.421476Z","shell.execute_reply.started":"2025-06-10T22:54:51.406755Z","shell.execute_reply":"2025-06-10T22:54:51.420808Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"import os\nimport numpy as np\nimport cv2\nimport torch\n\ndef draw_one_match_pair(\n    img0_tensor, img1_tensor,\n    group_pred,\n    i0, i1,\n    key1, key2,\n    output_dir=\"tta_matches_vis\"\n):\n    os.makedirs(output_dir, exist_ok=True)\n\n    def tensor_to_image(t):\n        img = t[0].detach().cpu().permute(1, 2, 0).numpy()\n        img = (img * 255).clip(0, 255).astype(np.uint8)\n        return img\n\n    img0 = tensor_to_image(img0_tensor)\n    img1 = tensor_to_image(img1_tensor)\n\n    kpts0 = group_pred[\"keypoints0\"][0].detach().cpu().numpy()\n    kpts1 = group_pred[\"keypoints1\"][0].detach().cpu().numpy()\n    matches0 = group_pred[\"matches0\"][0].detach().cpu().numpy()\n\n    valid = matches0 > -1\n    if np.sum(valid) == 0:\n        print(f\"No matches for TTA ({i0}, {i1}) | {key1} vs. {key2}\")\n        return\n\n    match_pairs = np.stack([np.where(valid)[0], matches0[valid]], axis=1)\n\n    # Compose canvas\n    h0, w0 = img0.shape[:2]\n    h1, w1 = img1.shape[:2]\n    canvas = np.zeros((max(h0, h1), w0 + w1, 3), dtype=np.uint8)\n    canvas[:h0, :w0] = img0\n    canvas[:h1, w0:] = img1\n\n    for pt0_idx, pt1_idx in match_pairs:\n        pt0 = tuple(np.round(kpts0[pt0_idx]).astype(int))\n        pt1 = tuple(np.round(kpts1[pt1_idx]).astype(int) + np.array([w0, 0]))\n        cv2.line(canvas, pt0, pt1, color=(0, 255, 0), thickness=1)\n\n    # Sanitize filenames to avoid slashes etc.\n    key1_safe = key1.replace(\"/\", \"_\")\n    key2_safe = key2.replace(\"/\", \"_\")\n\n    out_path = os.path.join(output_dir, f\"{key1_safe}_vs_{key2_safe}_TTA_{i0}_{i1}.jpg\")\n    cv2.imwrite(out_path, canvas)\n    print(f\"Saved: {out_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T22:54:51.422469Z","iopub.execute_input":"2025-06-10T22:54:51.422832Z","iopub.status.idle":"2025-06-10T22:54:51.435557Z","shell.execute_reply.started":"2025-06-10T22:54:51.422798Z","shell.execute_reply":"2025-06-10T22:54:51.434882Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"from pathlib import Path  # for creating output dir","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T22:54:51.436415Z","iopub.execute_input":"2025-06-10T22:54:51.436624Z","iopub.status.idle":"2025-06-10T22:54:51.447459Z","shell.execute_reply.started":"2025-06-10T22:54:51.436594Z","shell.execute_reply":"2025-06-10T22:54:51.446546Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"class LightGlueCustomMatching_sep(torch.nn.Module):\n    def __init__(self, device=None, extractor_cfg=None):\n        super().__init__()\n        self.device=device\n        self.extractor = ALIKED(weights=f\"/kaggle/input/aliked/pytorch/aliked-n16/1/aliked-n16.pth\", \\\n                                **extractor_cfg).to(self.device, dtype = torch.float32).eval()\n        lg_cfg = {\n            \"features\": \"aliked\",\n            \"depth_confidence\": -1,         # 禁用深度置信度过滤\n            \"width_confidence\": -1,         # 禁用宽度置信度过滤\n            \"filter_threshold\": 0.2,        # 设置匹配分数阈值\n            \"mp\": False                     # 禁用多进程加速\n        }\n        self.lightglue = LightGlue(**lg_cfg).eval().to(self.device)\n        self.ttas = list(range(5))\n        self.tta2id = {k: i for i, k in enumerate(self.ttas)}\n        self.tta_combination = [[i, j] for i in range(5) for j in range(5)]\n\n    def forward_flat(self, data, cache_args):\n        # print(\"in forward\")\n        pred = {}        \n        cache, key1, key2, quad = cache_args # quad: Rotation times of image1. 0:No rotation, 1:90deg, 2:180deg, 3:270deg\n        img_key_list = [key1,key2]\n        data[\"image0\"] = {\"image\": data[\"image0\"]}\n        data[\"image1\"] = {\"image\": data[\"image1\"]}\n        keypoints_dict, descriptors_dict = {}, {}\n        for i, img_key in enumerate(['image0', 'image1']):\n            keypoints_list, descriptors_list = [], []\n            if i == 0:\n                _quad = 0\n            else:\n                _quad = quad\n            if \"pred\" not in cache[img_key_list[i]][_quad][0]:\n                no_cache = True\n            else:\n                no_cache = False\n            # Get ALIKED descriptors\n            for j, img in enumerate(data[img_key][\"image\"]):\n                if no_cache:\n                    img = img.unsqueeze(0)\n                    cache[img_key_list[i]][_quad][j][\"pred\"] = self.extractor.extract(img, resize=None)\n                    # print(f\"aliked extraction done {j}\")\n                pred = cache[img_key_list[i]][_quad][j][\"pred\"]\n                keypoints_list.append(pred['keypoints'])\n                descriptors_list.append(pred['descriptors'])\n            keypoints_dict[img_key] = keypoints_list\n            descriptors_dict[img_key] = descriptors_list\n        # print(\"get keypoints and descirptions\")\n        # Prepare data for LightGlue and run matching one by one\n        group_pred_list = []\n        for tta_group in self.tta_combination:\n            group_idx = self.tta2id[tta_group[0]], self.tta2id[tta_group[1]]\n            i0, i1 = group_idx[0], group_idx[1]\n            data[\"image0\"][\"keypoints\"], data[\"image0\"][\"descriptors\"]= keypoints_dict['image0'][i0], descriptors_dict['image0'][i0]\n            data[\"image1\"][\"keypoints\"], data[\"image1\"][\"descriptors\"]= keypoints_dict['image1'][i1], descriptors_dict['image1'][i1]\n            group_pred = self.lightglue(data)\n            group_pred.update({\"keypoints0\":data['image0'][\"keypoints\"],\n                                \"keypoints1\":data['image1'][\"keypoints\"]})\n            group_pred_list.append(group_pred)\n        # print(\"out forward\")\n        return group_pred_list, cache\n\n    def forward_flat_draw(self, data, cache_args):\n        output_dir = \"tta_debug_vis\"\n        Path(output_dir).mkdir(parents=True, exist_ok=True)\n    \n        group_pred_list = []\n        cache, key1, key2, quad = cache_args\n        img_key_list = [key1, key2]\n        data[\"image0\"] = {\"image\": data[\"image0\"]}\n        data[\"image1\"] = {\"image\": data[\"image1\"]}\n    \n        keypoints_dict, descriptors_dict = {}, {}\n        for i, img_key in enumerate([\"image0\", \"image1\"]):\n            keypoints_list, descriptors_list = [], []\n            _quad = 0 if i == 0 else quad\n            no_cache = \"pred\" not in cache[img_key_list[i]][_quad][0]\n            for j, img in enumerate(data[img_key][\"image\"]):\n                if no_cache:\n                    img = img.unsqueeze(0)\n                    cache[img_key_list[i]][_quad][j][\"pred\"] = self.extractor.extract(img, resize=None)\n                pred = cache[img_key_list[i]][_quad][j][\"pred\"]\n                keypoints_list.append(pred[\"keypoints\"])\n                descriptors_list.append(pred[\"descriptors\"])\n            keypoints_dict[img_key] = keypoints_list\n            descriptors_dict[img_key] = descriptors_list\n    \n        # Match and optionally visualize\n        for tta_group in self.tta_combination:\n            i0, i1 = self.tta2id[tta_group[0]], self.tta2id[tta_group[1]]\n            data[\"image0\"][\"keypoints\"] = keypoints_dict[\"image0\"][i0]\n            data[\"image0\"][\"descriptors\"] = descriptors_dict[\"image0\"][i0]\n            data[\"image1\"][\"keypoints\"] = keypoints_dict[\"image1\"][i1]\n            data[\"image1\"][\"descriptors\"] = descriptors_dict[\"image1\"][i1]\n    \n            group_pred = self.lightglue(data)\n            group_pred.update({\n                \"keypoints0\": data[\"image0\"][\"keypoints\"],\n                \"keypoints1\": data[\"image1\"][\"keypoints\"]\n            })\n            group_pred_list.append(group_pred)\n    \n            # Check match count and visualize if > 50\n            matches0 = group_pred[\"matches0\"][0].detach().cpu().numpy()\n            valid = matches0 > -1\n            num_matches = np.sum(valid)\n            if num_matches > 50:\n                draw_one_match_pair(\n                    img0_tensor=data[\"image0\"][\"image\"][i0].unsqueeze(0),\n                    img1_tensor=data[\"image1\"][\"image\"][i1].unsqueeze(0),\n                    group_pred=group_pred,\n                    i0=i0,\n                    i1=i1,\n                    key1=key1,\n                    key2=key2,\n                    output_dir=output_dir\n                )\n        return group_pred_list, cache\n\n\n# class LightGlueMatcherPipeline_sep:\n#     def __init__(self, device=None, conf_th=None, extractor_cfg=None, lg_cfg=None):\n#         self.device = device\n#         self.extractor_cfg = extractor_cfg\n#         self.lg_cfg = lg_cfg\n#         self._lightglue_matcher = LightGlueCustomMatching_sep(\n#             device=self.device, extractor_cfg=self.extractor_cfg)\n#         self.conf_thresh = conf_th\n#         self.tta_combination = self._lightglue_matcher.tta_combination\n\n#     def prep_img(self, img, long_side=None):\n#         \"\"\"Resize the tensor image to a specified long side.\"\"\"\n#         img = img.clone()\n#         if long_side is not None:\n#             scale = long_side / max(img.shape[2], img.shape[3])\n#             w = int(img.shape[3] * scale)\n#             h = int(img.shape[2] * scale)\n#             img = torch.nn.functional.interpolate(img, size=(h, w), mode='bilinear', align_corners=False)\n#         else:\n#             scale = 1.0\n#         return img, scale\n\n#     def split_image(self, image):\n#         \"\"\"Split the image into 4 quadrants and return them along with a resized version.\"\"\"\n#         h, w = image.shape[2], image.shape[3]\n#         if h % 2 != 0:\n#             h = h - 1\n#         if w % 2 != 0:\n#             w = w - 1\n#         image = image[:, :, :h, :w]\n#         return [image[:, :, :h//2, :w//2], \n#             image[:, :, :h//2, w//2:], \n#             image[:, :, h//2:, :w//2], \n#             image[:, :, h//2:, w//2:],\n#             transforms.functional.resize(image, size=(h//2,w//2))]\n\n#     def reconstruct_coords(self, coords, quadrant, w, h):\n#         \"\"\"Reconstruct coordinates based on the separation quadrant.\"\"\"\n#         if quadrant == 1:\n#             coords[:, 0] += w//2\n#         elif quadrant == 2:\n#             coords[:, 1] += h//2\n#         elif quadrant == 3:\n#             coords[:, 0] += w//2\n#             coords[:, 1] += h//2\n#         elif quadrant == 4:\n#             coords = [[y*2, x*2] for y, x in coords]            \n#         return coords\n\n#     def __call__(self, img_ts0, img_ts1, cache_args, input_longside=None):\n#         with torch.no_grad():\n#             img_ts0, scale0 = self.prep_img(img_ts0, input_longside)\n#             img_ts1, scale1 = self.prep_img(img_ts1, input_longside)\n#             img_parts0 = self.split_image(img_ts0) \n#             img_parts1 = self.split_image(img_ts1)\n#             cat_mkpts0, cat_mkpts1 = [], []\n#             pred, cache = self._lightglue_matcher.forward_flat(\n#                 data={\n#                     \"image0\": torch.cat(img_parts0),\n#                     \"image1\": torch.cat(img_parts1),\n#                 },\n#             cache_args=cache_args)\n#             # print(\"self._lightglue_matcher.forward_flat done\")\n#         kpts0_all, kpts1_all = [], []  # Reserve original keypoints\n#         cat_kpts0_all, cat_kpts1_all = [], []\n#         matched_kpts0, matched_kpts1 = [], []\n#         matched_ids = []\n#         for idx, [i0, i1] in enumerate(self.tta_combination):\n#             group_pred = pred[idx]\n#             pred_aug = {}\n#             use_keys = [\"keypoints0\", \"keypoints1\", \"matches0\", \"matching_scores0\"]\n#             for k in use_keys:\n#                 v = group_pred[k]\n#                 if isinstance(v, torch.Tensor):\n#                     pred_aug[k] = v[0].detach().cpu().numpy().squeeze()\n#                 else:\n#                     pred_aug[k] = v\n        \n#             kpts0, kpts1 = pred_aug[\"keypoints0\"], pred_aug[\"keypoints1\"]\n#             matches = pred_aug[\"matches0\"]\n#             valid = matches > -1\n        \n#             if np.sum(valid) == 0:\n#                 continue\n        \n#             kpts0_all.append(self.reconstruct_coords(kpts0, i0, img_ts0.shape[3], img_ts0.shape[2]))\n#             kpts1_all.append(self.reconstruct_coords(kpts1, i1, img_ts1.shape[3], img_ts1.shape[2]))\n\n#             # print(f\"cur_len1:{cur_len1}, cur_len2:{cur_len2}\")\n\n#             # Keep matched coords\n#             matched_kpts0.append(self.reconstruct_coords(kpts0[valid], i0, img_ts0.shape[3], img_ts0.shape[2]))\n#             matched_kpts1.append(self.reconstruct_coords(kpts1[matches[valid]], i1, img_ts1.shape[3], img_ts1.shape[2]))\n        \n#             # Keep index pairs\n#             matched_ids.append(np.stack([np.where(valid)[0], matches[valid]], axis=1))\n\n            \n#         if len(matched_kpts0) == 0:\n#             _, key1, key2, _ = cache_args\n#             print(f\"No matches at {key1} vs. {key2}\")\n#             return np.empty((0, 2)), np.empty((0, 2)), np.empty((0, 2), dtype=np.int32), cache\n        \n#         cat_mkpts0 = np.concatenate(matched_kpts0)\n#         cat_mkpts1 = np.concatenate(matched_kpts1)\n#         cat_kpts0_all = np.concatenate(kpts0_all) \n#         cat_kpts1_all = np.concatenate(kpts1_all) \n        \n#         matched_ids = np.concatenate(matched_ids).astype(np.int32)\n#         # print(\"before ransac\")\n#         # Apply RANSAC\n#         try:\n#             _, inliers = cv2.findFundamentalMat(cat_mkpts0, cat_mkpts1, cv2.USAC_MAGSAC, ransacReprojThreshold=5, confidence=0.9999, maxIters=50000)\n#             inliers = inliers.ravel() > 0\n#             cat_mkpts0 = cat_mkpts0[inliers]\n#             cat_mkpts1 = cat_mkpts1[inliers]\n#             matched_ids = matched_ids[inliers]\n#         except Exception:\n#             _, key1, key2, _ = cache_args\n#             print(f\"Error in findFundamentalMat: {key1}-{key2}\")\n#             return np.empty((0, 2)), np.empty((0, 2)), np.empty((0, 2), dtype=np.int32), cache\n        \n#         # Bounds check\n#         mask0 = (cat_mkpts0[:, 0] >= 0) & (cat_mkpts0[:, 0] < img_ts0.shape[3]) & \\\n#                 (cat_mkpts0[:, 1] >= 0) & (cat_mkpts0[:, 1] < img_ts0.shape[2])\n#         mask1 = (cat_mkpts1[:, 0] >= 0) & (cat_mkpts1[:, 0] < img_ts1.shape[3]) & \\\n#                 (cat_mkpts1[:, 1] >= 0) & (cat_mkpts1[:, 1] < img_ts1.shape[2])\n#         mask = mask0 & mask1\n        \n#         return cat_kpts0_all/scale0, \\\n#                cat_kpts1_all/scale1, \\\n#                matched_ids[mask], \\\n#                cache","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T22:54:51.448394Z","iopub.execute_input":"2025-06-10T22:54:51.448668Z","iopub.status.idle":"2025-06-10T22:54:51.467478Z","shell.execute_reply.started":"2025-06-10T22:54:51.448616Z","shell.execute_reply":"2025-06-10T22:54:51.466610Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"class LightGlueMatcherPipeline_sep:\n    def __init__(self, device=None, conf_th=None, extractor_cfg=None, lg_cfg=None):\n        self.device = device\n        self.extractor_cfg = extractor_cfg\n        self.lg_cfg = lg_cfg\n        self._lightglue_matcher = LightGlueCustomMatching_sep(\n            device=self.device, extractor_cfg=self.extractor_cfg)\n        self.conf_thresh = conf_th\n        self.tta_combination = self._lightglue_matcher.tta_combination\n\n    def prep_img(self, img, long_side=None):\n        img = img.clone()\n        if long_side is not None:\n            scale = long_side / max(img.shape[2], img.shape[3])\n            h, w = int(img.shape[2] * scale), int(img.shape[3] * scale)\n            img = torch.nn.functional.interpolate(img, size=(h, w), mode='bilinear', align_corners=False)\n        else:\n            scale = 1.0\n        return img, scale\n\n    def split_image(self, image):\n        h, w = image.shape[2], image.shape[3]\n        h, w = h - h % 2, w - w % 2\n        image = image[:, :, :h, :w]\n        return [\n            image[:, :, :h//2, :w//2], \n            image[:, :, :h//2, w//2:], \n            image[:, :, h//2:, :w//2], \n            image[:, :, h//2:, w//2:],\n            transforms.functional.resize(image, size=(h//2, w//2))\n        ]\n\n    def reconstruct_coords(self, coords, quadrant, w, h):\n        coords = np.array(coords).copy()\n        if quadrant == 1:\n            coords[:, 0] += w // 2\n        elif quadrant == 2:\n            coords[:, 1] += h // 2\n        elif quadrant == 3:\n            coords[:, 0] += w // 2\n            coords[:, 1] += h // 2\n        elif quadrant == 4:\n            coords *= 2  # correct scale, no swap\n        return coords\n\n    def __call__(self, img_ts0, img_ts1, cache_args, input_longside=None):\n        with torch.no_grad():\n            img_ts0, scale0 = self.prep_img(img_ts0, input_longside)\n            img_ts1, scale1 = self.prep_img(img_ts1, input_longside)\n            img_parts0 = self.split_image(img_ts0) \n            img_parts1 = self.split_image(img_ts1)\n            pred, cache = self._lightglue_matcher.forward_flat_draw(\n                data={\n                    \"image0\": torch.cat(img_parts0),\n                    \"image1\": torch.cat(img_parts1),\n                },\n                cache_args=cache_args\n            )\n\n        kpts0_all, kpts1_all = [], []\n        matched_kpts0, matched_kpts1 = [], []\n        matched_ids = []\n\n        offset0, offset1 = 0, 0\n\n        for idx, (i0, i1) in enumerate(self.tta_combination):\n            group_pred = pred[idx]\n            pred_aug = {}\n            for k in [\"keypoints0\", \"keypoints1\", \"matches0\", \"matching_scores0\"]:\n                v = group_pred[k]\n                pred_aug[k] = v[0].detach().cpu().numpy().squeeze() if isinstance(v, torch.Tensor) else v\n\n            kpts0 = pred_aug[\"keypoints0\"]\n            kpts1 = pred_aug[\"keypoints1\"]\n            matches = pred_aug[\"matches0\"]\n            valid = matches > -1\n\n            if np.sum(valid) == 0:\n                continue\n\n            # Bound check to avoid out-of-index\n            target_idx = matches[valid]\n            valid_mask = target_idx < len(kpts1)\n            src_pts = kpts0[valid][valid_mask]\n            tgt_pts = kpts1[target_idx[valid_mask]]\n\n            matched_kpts0.append(self.reconstruct_coords(src_pts, i0, img_ts0.shape[3], img_ts0.shape[2]))\n            matched_kpts1.append(self.reconstruct_coords(tgt_pts, i1, img_ts1.shape[3], img_ts1.shape[2]))\n\n            kpts0_all.append(self.reconstruct_coords(kpts0, i0, img_ts0.shape[3], img_ts0.shape[2]))\n            kpts1_all.append(self.reconstruct_coords(kpts1, i1, img_ts1.shape[3], img_ts1.shape[2]))\n\n            matched_ids.append(np.stack([\n                np.where(valid)[0][valid_mask] + offset0,\n                matches[valid][valid_mask] + offset1\n            ], axis=1))\n\n            offset0 += len(kpts0)\n            offset1 += len(kpts1)\n\n        if not matched_kpts0:\n            _, key1, key2, _ = cache_args\n            print(f\"No matches at {key1} vs. {key2}\")\n            return np.empty((0, 2)), np.empty((0, 2)), np.empty((0, 2), dtype=np.int32), cache\n\n        cat_mkpts0 = np.concatenate(matched_kpts0)\n        cat_mkpts1 = np.concatenate(matched_kpts1)\n        cat_kpts0_all = np.concatenate(kpts0_all)\n        cat_kpts1_all = np.concatenate(kpts1_all)\n        match_counts = [len(match) for match in matched_ids]\n        matched_ids = np.concatenate(matched_ids).astype(np.int32)\n        _, key1, key2, _ = cache_args\n        print(f\"before ransac the original number of key1 {key1}, key2{key2}: {len(cat_kpts0_all)} and {len(cat_kpts1_all)},\\\n              matches len is {len(matched_ids)}: {match_counts}\" )\n        \n        # RANSAC\n        try:\n            _, inliers = cv2.findFundamentalMat(\n                cat_mkpts0, cat_mkpts1,\n                cv2.USAC_MAGSAC, ransacReprojThreshold=5,\n                confidence=0.9999, maxIters=50000\n            )\n            inliers = (inliers.ravel() > 0) if inliers is not None else np.zeros(len(cat_mkpts0), dtype=bool)\n        except Exception:\n            _, key1, key2, _ = cache_args\n            print(f\"Error in findFundamentalMat: {key1}-{key2}\")\n            return np.empty((0, 2)), np.empty((0, 2)), np.empty((0, 2), dtype=np.int32), cache\n\n        # Bounds check after RANSAC\n        cat_mkpts0 = cat_mkpts0[inliers]\n        cat_mkpts1 = cat_mkpts1[inliers]\n        matched_ids = matched_ids[inliers]\n\n        h0, w0 = img_ts0.shape[2:]\n        h1, w1 = img_ts1.shape[2:]\n        mask0 = (cat_mkpts0[:, 0] >= 0) & (cat_mkpts0[:, 0] < w0) & \\\n                (cat_mkpts0[:, 1] >= 0) & (cat_mkpts0[:, 1] < h0)\n        mask1 = (cat_mkpts1[:, 0] >= 0) & (cat_mkpts1[:, 0] < w1) & \\\n                (cat_mkpts1[:, 1] >= 0) & (cat_mkpts1[:, 1] < h1)\n        mask = mask0 & mask1\n\n        print(f\"after ransac the matches length is {len(matched_ids[mask])}\")\n\n        return cat_kpts0_all / scale0, cat_kpts1_all / scale1, matched_ids[mask], cache\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T22:54:51.468489Z","iopub.execute_input":"2025-06-10T22:54:51.468836Z","iopub.status.idle":"2025-06-10T22:54:51.489533Z","shell.execute_reply.started":"2025-06-10T22:54:51.468804Z","shell.execute_reply":"2025-06-10T22:54:51.488714Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"def save_keypoints_and_matches_split(\n    img_fnames, rot_dict, matcher_pip, feature_dir,\n    device = \"cuda\",\n    verbose=VERBOSE\n):\n    os.makedirs(feature_dir, exist_ok=True)\n    \n    cache = init_cache_from_imglist(img_fnames)\n    # print(\"cache initializetion done\")\n    unique_kpts = {}\n    out_match = {}\n    for key1 in tqdm(rot_dict, desc=\"Matching and storing\"):\n        fname1 = next((f for f in img_fnames if os.path.basename(f) == key1), None)\n        if fname1 is None:\n            continue\n        img0 = load_torch_image(fname1, device = device)\n\n        for key2 in rot_dict[key1]:\n            fname2 = next((f for f in img_fnames if os.path.basename(f) == key2), None)\n            if fname2 is None:\n                continue\n            rot = rot_dict[key1][key2]\n            # print(f\"{key1}-{key2}-rot{rot}\")\n            img1 = load_torch_image(fname2, device = device)\n            with torch.inference_mode():\n                pts0, pts1, matches, cache = matcher_pip(\n                    img0, img1,\n                    cache_args=[cache, key1, key2, rot],\n                    input_longside = 1216\n                )\n            print(f\"{key1}_{rot}-{key2}:{len(matches)}\")\n\n            # Save keypoints once per image per rotation\n            if key1 not in unique_kpts and len(pts0) > 0:\n                unique_kpts[key1] = {}\n            if rot not in unique_kpts[key1] and len(pts0) > 0:\n                unique_kpts[key1][rot] = pts0.astype(np.float32)\n            \n            if key2 not in unique_kpts and len(pts1) > 0:\n                unique_kpts[key2] = {}\n            if 0 not in unique_kpts[key2] and len(pts1) > 0:\n                unique_kpts[key2][0] = pts1.astype(np.float32)\n            \n            if len(matches) > 0:\n                if key1 not in out_match:\n                    out_match[key1] = {}\n                out_match[key1][key2] = {\n                    \"rot\": rot,\n                    \"matches\": matches}\n\n    unified_kp_path, remapped_matches_path = merge_and_save_keypoints_matches(\n        unique_kpts,\n        out_match,\n        rot_dict,\n        feature_dir)\n    return unified_kp_path, remapped_matches_path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T22:54:51.490463Z","iopub.execute_input":"2025-06-10T22:54:51.490762Z","iopub.status.idle":"2025-06-10T22:54:51.503585Z","shell.execute_reply.started":"2025-06-10T22:54:51.490735Z","shell.execute_reply":"2025-06-10T22:54:51.502942Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# Assume these are available from your environment or previous code\n# from .utils import load_torch_image # Assuming load_torch_image is defined elsewhere\n# from kornia.feature import ALIKED # Already in your detect_aliked\n# from kornia.feature import LightGlueMatcher as KF_LightGlueMatcher # Already in your match_with_lightglue\n# from kornia.geometry import laf_from_center_scale_ori # Already in your match_with_lightglue\n# from colmap_database import COLMAPDatabase, add_keypoints, add_matches # Already in your colmap_import\n\n\ndef convert_coord(r, w, h, rotk):\n    if rotk == 0:\n        return r\n    elif rotk == 1:\n        rx = w-1-r[:, 1]\n        ry = r[:, 0]\n        return torch.concat([rx[None], ry[None]], dim=0).T\n    elif rotk == 2:\n        rx = w-1-r[:, 0]\n        ry = h-1-r[:, 1]\n        return torch.concat([rx[None], ry[None]], dim=0).T\n    elif rotk == 3:\n        rx = r[:, 1]\n        ry = h-1-r[:, 0]\n        return torch.concat([rx[None], ry[None]], dim=0).T\n\ndef detect_common(img_fnames,\n                  model_name,\n                  rots,\n                  file_keypoints,\n                  feature_dir = '.featureout',\n                  num_features = 4096,\n                  resize_to = 1024,\n                  detection_threshold = 0.01,\n                  device=torch.device('cpu'),\n                  min_matches=15,verbose=VERBOSE\n                 ):\n    if not os.path.isdir(feature_dir):\n        os.makedirs(feature_dir)\n\n    #####################################################\n    # Extract keypoints and descriptions\n    #####################################################\n    dict_model = {\n        \"aliked\" : ALIKED,\n        \"superpoint\" : SuperPoint,\n        \"doghardnet\" : DoGHardNet,\n        \"disk\" : DISK,\n        \"sift\" : SIFT,\n    }\n    extractor_class = dict_model[model_name]\n    dtype = torch.float32 # ALIKED has issues with float16\n    # extractor = extractor_class(max_num_keypoints=num_features, detection_threshold=detection_threshold, \n    #                             resize=resize_to).eval().to(device, dtype)\n    if model_name == 'disk':\n        # print(\"dissskkkkkk\")\n        # extractor = DISK(\n        #     max_num_keypoints=num_features,\n        #     detection_threshold=detection_threshold,\n        #     resize=resize_to\n        # ).to(device).eval()\n        # checkpoint = torch.load(ckpt_path, map_location=device)\n        # extractor.load_state_dict(checkpoint['model'])\n        \n        extractor = DISK(\n            max_num_keypoints=num_features,\n            detection_threshold=detection_threshold,\n            resize=resize_to\n        ).eval().to(device)\n        \n        print(\"get extractor\")\n        \n    else:\n        extractor_class = dict_model[model_name]\n        extractor = extractor_class(\n            max_num_keypoints=num_features,\n            detection_threshold=detection_threshold,\n            resize=resize_to\n        ).to(device, dtype).eval()\n\n    \n    dict_kpts_cuda = {}\n    dict_descs_cuda = {}\n    for (img_path, rot_k) in zip(img_fnames, rots):\n        img_fname = img_path.split('/')[-1]\n        key = img_fname\n        with torch.inference_mode():\n            image0 = load_torch_image(img_path, device=device).to(dtype)\n            h, w = image0.shape[2], image0.shape[3]\n            image1 = torch.rot90(image0, rot_k, [2, 3])\n            feats0 = extractor.extract(image1)  # auto-resize the image, disable with resize=None\n            kpts = feats0['keypoints'].reshape(-1, 2).detach()\n            descs = feats0['descriptors'].reshape(len(kpts), -1).detach()\n            kpts = convert_coord(kpts, w, h, rot_k)\n            dict_kpts_cuda[f\"{key}\"] = kpts\n            dict_descs_cuda[f\"{key}\"] = descs\n            if verbose:\n                print(f\"{model_name} > rot_k={rot_k}, kpts.shape={kpts.shape}, descs.shape={descs.shape}\")\n    del extractor\n    gc.collect()\n\n    #####################################################\n    # Matching keypoints\n    #####################################################\n    # print(\"KF glue matcher\")\n    lg_matcher = KF.LightGlueMatcher(model_name, {\"width_confidence\": -1,\n                                            \"depth_confidence\": -1,\n                                             \"mp\": True if 'cuda' in str(device) else False}).eval().to(device)\n    \n    cnt_pairs = 0\n    with h5py.File(file_keypoints, mode='w') as f_match:\n        for pair_idx in tqdm(index_pairs):\n            idx1, idx2 = pair_idx\n            fname1, fname2 = img_fnames[idx1], img_fnames[idx2]\n            \n            key1, key2 = fname1.split('/')[-1], fname2.split('/')[-1]\n            \n            kp1 = dict_kpts_cuda[key1]\n            kp2 = dict_kpts_cuda[key2]\n            desc1 = dict_descs_cuda[key1]\n            desc2 = dict_descs_cuda[key2]\n            with torch.inference_mode():\n                dists, idxs = lg_matcher(desc1,\n                                     desc2,\n                                     KF.laf_from_center_scale_ori(kp1[None]),\n                                     KF.laf_from_center_scale_ori(kp2[None]))\n            if len(idxs)  == 0:\n                continue\n            n_matches = len(idxs)\n            kp1 = kp1[idxs[:,0], :].cpu().numpy().reshape(-1, 2).astype(np.float32)\n            kp2 = kp2[idxs[:,1], :].cpu().numpy().reshape(-1, 2).astype(np.float32)\n            group  = f_match.require_group(key1)\n            if n_matches >= min_matches:\n                group.create_dataset(key2, data=np.concatenate([kp1, kp2], axis=1))\n                cnt_pairs+=1\n                if verbose:\n                    print (f'{model_name}> {key1}-{key2}: {n_matches} matches @ {cnt_pairs}th pair({model_name}+lightglue)')            \n            else:\n                if verbose:\n                    print (f'{model_name}> {key1}-{key2}: {n_matches} matches --> skipped')\n    del lg_matcher\n    torch.cuda.empty_cache()\n    gc.collect()\n    return\n\ndef detect_lightglue_common(\n    img_fnames, model_name, index_pairs, feature_dir, device, file_keypoints, rots,\n    resize_to=1024,\n    detection_threshold=0.01, \n    num_features=4096, \n    min_matches=15,\n):\n    t=time()\n    detect_common(\n        img_fnames, model_name, rots, file_keypoints, feature_dir, \n        resize_to=resize_to,\n        num_features=num_features, \n        detection_threshold=detection_threshold, \n        device=device,\n        min_matches=min_matches,\n    )\n    gc.collect()\n    t=time() -t \n    print(f'Features matched in  {t:.4f} sec ({model_name}+LightGlue)')\n    return t","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T22:54:51.504317Z","iopub.execute_input":"2025-06-10T22:54:51.504549Z","iopub.status.idle":"2025-06-10T22:54:51.520533Z","shell.execute_reply.started":"2025-06-10T22:54:51.504517Z","shell.execute_reply":"2025-06-10T22:54:51.519753Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"def get_unique_idxs(A, dim=0):\n    # https://stackoverflow.com/questions/72001505/how-to-get-unique-elements-and-their-firstly-appeared-indices-of-a-pytorch-tenso\n    unique, idx, counts = torch.unique(A, dim=dim, sorted=True, return_inverse=True, return_counts=True)\n    _, ind_sorted = torch.sort(idx, stable=True)\n    cum_sum = counts.cumsum(0)\n    cum_sum = torch.cat((torch.tensor([0],device=cum_sum.device), cum_sum[:-1]))\n    first_indices = ind_sorted[cum_sum]\n    return first_indices\n\ndef get_keypoint_from_h5(fp, key1, key2):\n    rc = -1\n    try:\n        kpts = np.array(fp[key1][key2])\n        rc = 0\n        return (rc, kpts)\n    except:\n        return (rc, None)\n\ndef get_keypoint_from_multi_h5(fps, key1, key2):\n    list_mkpts = []\n    for fp in fps:\n        rc, mkpts = get_keypoint_from_h5(fp, key1, key2)\n        if rc == 0:\n            list_mkpts.append(mkpts)\n    if len(list_mkpts) > 0:\n        list_mkpts = np.concatenate(list_mkpts, axis=0)\n    else:\n        list_mkpts = None\n    return list_mkpts\n\ndef matches_merger(\n    img_fnames,\n    index_pairs,\n    files_keypoints,\n    save_file,\n    feature_dir = 'featureout',\n    filter_FundamentalMatrix = False,\n    filter_iterations = 10,\n    filter_threshold = 8,\n    verbose = VERBOSE\n):\n    # open h5 files\n    fps = [ h5py.File(file, mode=\"r\") for file in files_keypoints ]\n\n    with h5py.File(save_file, mode='w') as f_match:\n        counter = 0\n        for pair_idx in progress_bar(index_pairs):\n            idx1, idx2 = pair_idx\n            fname1, fname2 = img_fnames[idx1], img_fnames[idx2]\n            key1, key2 = fname1.split('/')[-1], fname2.split('/')[-1]\n\n            # extract keypoints\n            mkpts = get_keypoint_from_multi_h5(fps, key1, key2)\n            if mkpts is None:\n                if verbose:\n                    print(f\"skipped key1={key1}, key2={key2}\")\n                continue\n\n            ori_size = mkpts.shape[0]\n            if mkpts.shape[0] < CONFIG.MERGE_PARAMS[\"min_matches\"]:\n                continue\n            \n            if filter_FundamentalMatrix:\n                store_inliers = { idx:0 for idx in range(mkpts.shape[0]) }\n                idxs = np.array(range(mkpts.shape[0]))\n                for iter in range(filter_iterations):\n                    try:\n                        Fm, inliers = cv2.findFundamentalMat(\n                            mkpts[:,:2], mkpts[:,2:4], cv2.USAC_MAGSAC, 0.15, 0.9999, 20000)\n                        if Fm is not None:\n                            inliers = inliers > 0\n                            inlier_idxs = idxs[inliers[:, 0]]\n                            #print(inliers.shape, inlier_idxs[:5])\n                            for idx in inlier_idxs:\n                                store_inliers[idx] += 1\n                    except:\n                        print(f\"Failed to cv2.findFundamentalMat. mkpts.shape={mkpts.shape}\")\n                inliers = np.array([ count for (idx, count) in store_inliers.items() ]) >= filter_threshold\n                mkpts = mkpts[inliers]\n                if mkpts.shape[0] < 15:\n                    if verbose:\n                        print(f\"skipped key1={key1}, key2={key2}: mkpts.shape={mkpts.shape} after filtered.\")\n                    continue\n                #print(f\"filter_FundamentalMatrix: {len(store_inliers)} matches --> {mkpts.shape[0]} matches\")\n            \n            if verbose:\n                print (f'{key1}-{key2}: {ori_size} --> {mkpts.shape[0]} matches')            \n            # regist tmp file\n            group  = f_match.require_group(key1)\n            group.create_dataset(key2, data=mkpts)\n            counter += 1\n    print( f\"Ensembled pairs : {counter} pairs\" )\n    for fp in fps:\n        fp.close()\n\ndef keypoints_merger(\n    img_fnames,\n    index_pairs,\n    files_keypoints,\n    feature_dir = 'featureout',\n    filter_FundamentalMatrix = False,\n    filter_iterations = 10,\n    filter_threshold = 8,\n):\n    save_file = f'{feature_dir}/merge_tmp.h5'\n    !rm -rf {save_file}\n    matches_merger(\n        img_fnames,\n        index_pairs,\n        files_keypoints,\n        save_file,\n        feature_dir = feature_dir,\n        filter_FundamentalMatrix = filter_FundamentalMatrix,\n        filter_iterations = filter_iterations,\n        filter_threshold = filter_threshold,\n    )\n        \n    # Let's find unique loftr pixels and group them together.\n    kpts = defaultdict(list)\n    match_indexes = defaultdict(dict)\n    total_kpts=defaultdict(int)\n    with h5py.File(save_file, mode='r') as f_match:\n        for k1 in f_match.keys():\n            group  = f_match[k1]\n            for k2 in group.keys():\n                matches = group[k2][...]\n                total_kpts[k1]\n                kpts[k1].append(matches[:, :2])\n                kpts[k2].append(matches[:, 2:])\n                current_match = torch.arange(len(matches)).reshape(-1, 1).repeat(1, 2)\n                current_match[:, 0]+=total_kpts[k1]\n                current_match[:, 1]+=total_kpts[k2]\n                total_kpts[k1]+=len(matches)\n                total_kpts[k2]+=len(matches)\n                match_indexes[k1][k2]=current_match\n\n    for k in kpts.keys():\n        kpts[k] = np.round(np.concatenate(kpts[k], axis=0))\n    unique_kpts = {}\n    unique_match_idxs = {}\n    out_match = defaultdict(dict)\n    for k in kpts.keys():\n        uniq_kps, uniq_reverse_idxs = torch.unique(torch.from_numpy(kpts[k]),dim=0, return_inverse=True)\n        unique_match_idxs[k] = uniq_reverse_idxs\n        unique_kpts[k] = uniq_kps.numpy()\n    for k1, group in match_indexes.items():\n        for k2, m in group.items():\n            m2 = deepcopy(m)\n            m2[:,0] = unique_match_idxs[k1][m2[:,0]]\n            m2[:,1] = unique_match_idxs[k2][m2[:,1]]\n            mkpts = np.concatenate([unique_kpts[k1][ m2[:,0]],\n                                    unique_kpts[k2][  m2[:,1]],\n                                   ],\n                                   axis=1)\n            unique_idxs_current = get_unique_idxs(torch.from_numpy(mkpts), dim=0)\n            m2_semiclean = m2[unique_idxs_current]\n            unique_idxs_current1 = get_unique_idxs(m2_semiclean[:, 0], dim=0)\n            m2_semiclean = m2_semiclean[unique_idxs_current1]\n            unique_idxs_current2 = get_unique_idxs(m2_semiclean[:, 1], dim=0)\n            m2_semiclean2 = m2_semiclean[unique_idxs_current2]\n            out_match[k1][k2] = m2_semiclean2.numpy()\n    with h5py.File(f'{feature_dir}/keypoints.h5', mode='w') as f_kp:\n        for k, kpts1 in unique_kpts.items():\n            f_kp[k] = kpts1\n    \n    with h5py.File(f'{feature_dir}/matches.h5', mode='w') as f_match:\n        for k1, gr in out_match.items():\n            group  = f_match.require_group(k1)\n            for k2, match in gr.items():\n                group[k2] = match\n    return","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T22:54:51.521351Z","iopub.execute_input":"2025-06-10T22:54:51.521536Z","iopub.status.idle":"2025-06-10T22:54:51.552233Z","shell.execute_reply.started":"2025-06-10T22:54:51.521519Z","shell.execute_reply":"2025-06-10T22:54:51.551260Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"def get_img_pairs_exhaustive(img_fnames):\n    index_pairs = []\n    for i in range(len(img_fnames)):\n        for j in range(i+1, len(img_fnames)):\n            index_pairs.append((i,j))\n    return index_pairs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T22:54:51.555986Z","iopub.execute_input":"2025-06-10T22:54:51.556257Z","iopub.status.idle":"2025-06-10T22:54:51.567594Z","shell.execute_reply.started":"2025-06-10T22:54:51.556236Z","shell.execute_reply":"2025-06-10T22:54:51.566702Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# Must Use efficientnet global descriptor to get matching shortlists.\ndef get_global_desc(fnames, device = torch.device('cpu')):\n    processor = AutoImageProcessor.from_pretrained('/kaggle/input/dinov2/pytorch/base/1')\n    model = AutoModel.from_pretrained('/kaggle/input/dinov2/pytorch/base/1')\n    model = model.eval()\n    model = model.to(device)\n    global_descs_dinov2 = []\n    for i, img_fname_full in tqdm(enumerate(fnames),total= len(fnames)):\n        key = os.path.splitext(os.path.basename(img_fname_full))[0]\n        timg = load_torch_image(img_fname_full)\n        with torch.inference_mode():\n            inputs = processor(images=timg, return_tensors=\"pt\", do_rescale=False).to(device)\n            outputs = model(**inputs)\n            dino_mac = F.normalize(outputs.last_hidden_state[:,1:].max(dim=1)[0], dim=1, p=2)\n        global_descs_dinov2.append(dino_mac.detach().cpu())\n    global_descs_dinov2 = torch.cat(global_descs_dinov2, dim=0)\n    return global_descs_dinov2\n\n\ndef get_img_pairs_exhaustive(img_fnames):\n    index_pairs = []\n    for i in range(len(img_fnames)):\n        for j in range(i+1, len(img_fnames)):\n            index_pairs.append((i,j))\n    return index_pairs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T22:54:51.569226Z","iopub.execute_input":"2025-06-10T22:54:51.569548Z","iopub.status.idle":"2025-06-10T22:54:51.579921Z","shell.execute_reply.started":"2025-06-10T22:54:51.569520Z","shell.execute_reply":"2025-06-10T22:54:51.578978Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"def get_image_pairs_shortlist_org(fnames,\n                              sim_th = 0.6, # should be strict\n                              min_pairs = 60,\n                              exhaustive_if_less = 20,\n                              device=torch.device('cpu')):\n    num_imgs = len(fnames)\n    if num_imgs <= exhaustive_if_less:\n        return get_img_pairs_exhaustive(fnames)\n    descs = get_global_desc(fnames, device=device)\n    dm = torch.cdist(descs, descs, p=2).detach().cpu().numpy()\n\n    \n    mask = dm <= sim_th\n    total = 0\n    matching_list = []\n    ar = np.arange(num_imgs)\n    already_there_set = []\n    for st_idx in range(num_imgs-1):\n        mask_idx = mask[st_idx]\n        to_match = ar[mask_idx]\n        if len(to_match) < min_pairs:\n            to_match = np.argsort(dm[st_idx])[:min_pairs]  \n        for idx in to_match:\n            if st_idx == idx:\n                continue\n            if dm[st_idx, idx] < 10000:\n                matching_list.append(tuple(sorted((st_idx, idx.item()))))\n                total+=1\n    matching_list = sorted(list(set(matching_list)))\n    return matching_list","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T22:54:51.580857Z","iopub.execute_input":"2025-06-10T22:54:51.581142Z","iopub.status.idle":"2025-06-10T22:54:51.592755Z","shell.execute_reply.started":"2025-06-10T22:54:51.581108Z","shell.execute_reply":"2025-06-10T22:54:51.592060Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"def wrapper_keypoints(\n    img_fnames, index_pairs, feature_dir, device, timings, rots\n):\n    #############################################################\n    # get keypoints\n    #############################################################\n    files_keypoints = []\n    \n    if CONFIG.use_superglue:\n        for params_sg in CONFIG.params_sgs:\n            resize_to = params_sg[\"resize_to\"]\n            file_keypoints = f\"{feature_dir}/matches_superglue_{resize_to}pix.h5\"\n            !rm -rf {file_keypoints}\n            t = detect_superglue(\n                img_fnames, index_pairs, feature_dir, device, \n                params_sg[\"sg_config\"], file_keypoints, \n                resize_to=params_sg[\"resize_to\"], \n                min_matches=params_sg[\"min_matches\"],\n            )\n            gc.collect()\n            files_keypoints.append( file_keypoints )\n            timings['feature_matching'].append(t)\n\n    if CONFIG.use_aliked_lightglue:\n        model_name = \"aliked\"\n        file_keypoints = f'{feature_dir}/matches_lightglue_{model_name}.h5'\n        t = detect_lightglue_common(\n            img_fnames, model_name, index_pairs, feature_dir, device, file_keypoints, rots,\n            resize_to=CONFIG.params_aliked_lightglue[\"resize_to\"],\n            detection_threshold=CONFIG.params_aliked_lightglue[\"detection_threshold\"],\n            num_features=CONFIG.params_aliked_lightglue[\"num_features\"],\n            min_matches=CONFIG.params_aliked_lightglue[\"min_matches\"],\n        )\n        gc.collect()\n        files_keypoints.append(file_keypoints)\n        timings['feature_matching'].append(t)\n\n    if CONFIG.use_doghardnet_lightglue:\n        model_name = \"doghardnet\"\n        file_keypoints = f'{feature_dir}/matches_lightglue_{model_name}.h5'\n        t = detect_lightglue_common(\n            img_fnames, model_name, index_pairs, feature_dir, device, file_keypoints, rots,\n            resize_to=CONFIG.params_doghardnet_lightglue[\"resize_to\"],\n            detection_threshold=CONFIG.params_doghardnet_lightglue[\"detection_threshold\"],\n            num_features=CONFIG.params_doghardnet_lightglue[\"num_features\"],\n            min_matches=CONFIG.params_doghardnet_lightglue[\"min_matches\"],\n        )\n        gc.collect()\n        files_keypoints.append(file_keypoints)\n        timings['feature_matching'].append(t)\n\n    if CONFIG.use_superpoint_lightglue:\n        model_name = \"superpoint\"\n        file_keypoints = f'{feature_dir}/matches_lightglue_{model_name}.h5'\n        t = detect_lightglue_common(\n            img_fnames, model_name, index_pairs, feature_dir, device, file_keypoints, rots,\n            resize_to=CONFIG.params_superpoint_lightglue[\"resize_to\"],\n            detection_threshold=CONFIG.params_superpoint_lightglue[\"detection_threshold\"],\n            num_features=CONFIG.params_superpoint_lightglue[\"num_features\"],\n            min_matches=CONFIG.params_superpoint_lightglue[\"min_matches\"],\n        )\n        gc.collect()\n        files_keypoints.append(file_keypoints)\n        timings['feature_matching'].append(t)\n\n    if CONFIG.use_disk_lightglue:\n        model_name = \"disk\"\n        file_keypoints = f'{feature_dir}/matches_lightglue_{model_name}.h5'\n        t = detect_lightglue_common(\n            img_fnames, model_name, index_pairs, feature_dir, device, file_keypoints, rots,\n            resize_to=CONFIG.params_disk_lightglue[\"resize_to\"],\n            detection_threshold=CONFIG.params_disk_lightglue[\"detection_threshold\"],\n            num_features=CONFIG.params_disk_lightglue[\"num_features\"],\n            min_matches=CONFIG.params_disk_lightglue[\"min_matches\"],\n        )\n        gc.collect()\n        files_keypoints.append(file_keypoints)\n        timings['feature_matching'].append(t)\n\n    if CONFIG.use_sift_lightglue:\n        model_name = \"sift\"\n        file_keypoints = f'{feature_dir}/matches_lightglue_{model_name}.h5'\n        t = detect_lightglue_common(\n            img_fnames, model_name, index_pairs, feature_dir, device, file_keypoints, rots,\n            resize_to=CONFIG.params_sift_lightglue[\"resize_to\"],\n            detection_threshold=CONFIG.params_sift_lightglue[\"detection_threshold\"],\n            num_features=CONFIG.params_sift_lightglue[\"num_features\"],\n            min_matches=CONFIG.params_sift_lightglue[\"min_matches\"],\n        )\n        gc.collect()\n        files_keypoints.append(file_keypoints)\n        timings['feature_matching'].append(t)\n\n    if CONFIG.use_loftr:\n        file_keypoints = f'{feature_dir}/matches_loftr_{CONFIG.params_loftr[\"resize_small_edge_to\"]}pix.h5'\n        t = detect_loftr(\n            img_fnames, index_pairs, feature_dir, device, file_keypoints,\n            resize_small_edge_to=CONFIG.params_loftr[\"resize_small_edge_to\"],\n            min_matches=CONFIG.params_loftr[\"min_matches\"],\n        )\n        gc.collect()\n        files_keypoints.append( file_keypoints )\n        timings['feature_matching'].append(t)\n\n    if CONFIG.use_dkm:\n        file_keypoints = f'{feature_dir}/matches_dkm.h5'\n        t = detect_dkm(\n            img_fnames, index_pairs, feature_dir, device, file_keypoints,\n            resize_to=CONFIG.params_dkm[\"resize_to\"], \n            detection_threshold=CONFIG.params_dkm[\"detection_threshold\"], \n            num_features=CONFIG.params_dkm[\"num_features\"], \n            min_matches=CONFIG.params_dkm[\"min_matches\"]\n        )\n        gc.collect()\n        files_keypoints.append(file_keypoints)\n        timings['feature_matching'].append(t)\n\n    if CONFIG.use_matchformer:\n        file_keypoints = f'{feature_dir}/matches_matchformer_{CONFIG.params_matchformer[\"resize_to\"]}pix.h5'\n        t = detect_matchformer(\n            img_fnames, index_pairs, feature_dir, device, file_keypoints,\n            resize_to=CONFIG.params_matchformer[\"resize_to\"],\n            num_features=CONFIG.params_matchformer[\"num_features\"], \n            min_matches=CONFIG.params_matchformer[\"min_matches\"]\n        )\n        gc.collect()\n        files_keypoints.append( file_keypoints )\n        timings['feature_matching'].append(t)\n\n    #############################################################\n    # merge keypoints\n    #############################################################\n    keypoints_merger(\n        img_fnames,\n        index_pairs,\n        files_keypoints,\n        feature_dir = feature_dir,\n        filter_FundamentalMatrix = CONFIG.MERGE_PARAMS[\"filter_FundamentalMatrix\"],\n        filter_iterations = CONFIG.MERGE_PARAMS[\"filter_iterations\"],\n        filter_threshold = CONFIG.MERGE_PARAMS[\"filter_threshold\"],\n    )    \n    return timings\n\n\ndef import_into_colmap(img_dir, feature_dir ='.featureout', database_path = 'colmap.db'):\n    db = COLMAPDatabase.connect(database_path)\n    db.create_tables()\n    single_camera = False\n    fname_to_id = add_keypoints(db, feature_dir, img_dir, '', 'simple-pinhole', single_camera)\n    add_matches(\n        db,\n        feature_dir,\n        fname_to_id,\n    )\n    db.commit()\n    return","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T22:54:51.593579Z","iopub.execute_input":"2025-06-10T22:54:51.593891Z","iopub.status.idle":"2025-06-10T22:54:51.615948Z","shell.execute_reply.started":"2025-06-10T22:54:51.593856Z","shell.execute_reply":"2025-06-10T22:54:51.615012Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"def reconstruct_from_db(feature_dir, img_dir):\n    result = {}\n    local_timings = {'RANSAC': [], 'Reconstruction': []}\n    #############################################################\n    # regist keypoints from h5 into colmap db\n    #############################################################\n    database_path = f'{feature_dir}/colmap.db'\n    if os.path.isfile(database_path):\n        os.remove(database_path)\n    gc.collect()\n    import_into_colmap(img_dir, feature_dir=feature_dir, database_path=database_path)\n    output_path = f'{feature_dir}/colmap_rec'\n    os.makedirs(output_path, exist_ok=True)\n    print(\"colmap database\")\n    #############################################################\n    # Calculate fundamental matrix with colmap api\n    #############################################################\n    t=time()\n    # options = pycolmap.SiftMatchingOptions()\n    # options.confidence = 0.9999\n    # options.max_num_trials = 20000\n    # pycolmap.match_exhaustive(database_path, sift_options=options)\n    pycolmap.match_exhaustive(database_path)\n    # print(\"matching done!!!!\")\n    local_timings['RANSAC'].append(time() - t)\n    print(f'RANSAC in {local_timings[\"RANSAC\"][-1]:.4f} sec')\n\n    #############################################################\n    # Execute bundle adjustmnet with colmap api\n    # --> Bundle adjustment Calcs Camera matrix, R and t\n    #############################################################\n    t=time()\n    # By default colmap does not generate a reconstruction if less than 10 images are registered. Lower it to 3.\n    mapper_options = pycolmap.IncrementalPipelineOptions()\n    # mapper_options.mapper.filter_max_reproj_error\t = 10.0\n    mapper_options.min_model_size = 8\n    mapper_options.max_num_models = 25\n    maps = pycolmap.incremental_mapping(database_path=database_path, image_path=img_dir, \n                                        output_path=output_path, options=mapper_options)\n    print(maps)\n    for map_index, rec in maps.items():\n        result[map_index] = {}\n        for img_id, image in rec.images.items():\n            result[map_index][image.name] = {\n                'R': image.cam_from_world.rotation.matrix().tolist(),\n                't': image.cam_from_world.translation.tolist()\n            }\n    # clear_output(wait=False)\n    local_timings['Reconstruction'].append(time() - t)\n    print(f'Reconstruction done in {local_timings[\"Reconstruction\"][-1]:.4f} sec')\n\n    #############################################################\n    # Extract R,t from maps \n    #############################################################            \n    return result, local_timings","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T22:54:51.616833Z","iopub.execute_input":"2025-06-10T22:54:51.617091Z","iopub.status.idle":"2025-06-10T22:54:51.626905Z","shell.execute_reply.started":"2025-06-10T22:54:51.617070Z","shell.execute_reply":"2025-06-10T22:54:51.626049Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"# Collect vital info from the dataset\n\n@dataclasses.dataclass\nclass Prediction:\n    image_id: str | None  # A unique identifier for the row -- unused otherwise. Used only on the hidden test set.\n    dataset: str\n    filename: str\n    cluster_index: int | None = None\n    rotation: np.ndarray | None = None\n    translation: np.ndarray | None = None\n\n# Set is_train=True to run the notebook on the training data.\n# Set is_train=False if submitting an entry to the competition (test data is hidden, and different from what you see on the \"test\" folder).\nis_train = True\ndata_dir = '/kaggle/input/image-matching-challenge-2025'\nworkdir = '/kaggle/working/result/'\nos.makedirs(workdir, exist_ok=True)\n\nif is_train:\n    sample_submission_csv = os.path.join(data_dir, 'train_labels.csv')\nelse:\n    sample_submission_csv = os.path.join(data_dir, 'sample_submission.csv')\n\nsamples = {}\ncompetition_data = pd.read_csv(sample_submission_csv)\nfor _, row in competition_data.iterrows():\n    # Note: For the test data, the \"scene\" column has no meaning, and the rotation_matrix and translation_vector columns are random.\n    if row.dataset not in samples:\n        samples[row.dataset] = []\n    samples[row.dataset].append(\n        Prediction(\n            image_id=None if is_train else row.image_id,\n            dataset=row.dataset,\n            filename=row.image\n        )\n    )\n\nfor dataset in samples:\n    print(f'Dataset \"{dataset}\" -> num_images={len(samples[dataset])}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T22:54:51.627901Z","iopub.execute_input":"2025-06-10T22:54:51.628174Z","iopub.status.idle":"2025-06-10T22:54:51.792988Z","shell.execute_reply.started":"2025-06-10T22:54:51.628141Z","shell.execute_reply":"2025-06-10T22:54:51.792178Z"}},"outputs":[{"name":"stdout","text":"Dataset \"imc2023_haiper\" -> num_images=54\nDataset \"imc2023_heritage\" -> num_images=209\nDataset \"imc2023_theather_imc2024_church\" -> num_images=76\nDataset \"imc2024_dioscuri_baalshamin\" -> num_images=138\nDataset \"imc2024_lizard_pond\" -> num_images=214\nDataset \"pt_brandenburg_british_buckingham\" -> num_images=225\nDataset \"pt_piazzasanmarco_grandplace\" -> num_images=168\nDataset \"pt_sacrecoeur_trevi_tajmahal\" -> num_images=225\nDataset \"pt_stpeters_stpauls\" -> num_images=200\nDataset \"amy_gardens\" -> num_images=200\nDataset \"fbk_vineyard\" -> num_images=163\nDataset \"ETs\" -> num_images=22\nDataset \"stairs\" -> num_images=51\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"import cv2\nimport h5py\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n\n\ndef draw_keypoints_and_matches(images_input, unified_kp_path, remapped_matches_path, feature_dir='visualization_output'):\n    output_dir = os.path.join(feature_dir, 'visualization_output')\n    os.makedirs(output_dir, exist_ok=True)\n\n    # Load images and determine image_keys for HDF5 lookup\n    if isinstance(images_input[0], str):\n        loaded_images = [cv2.imread(img_path) for img_path in images_input]\n        image_keys = [os.path.basename(img_path) for img_path in images_input]\n    else:\n        loaded_images = images_input\n        # If images_input are already arrays, you need to provide the corresponding keys\n        # This part is crucial: image_keys MUST align with the HDF5 keys\n        image_keys = image_keys_in_h5 # Use the predefined list for the dummy case\n\n    # Load unified keypoints\n    keypoints_data = {}\n    with h5py.File(unified_kp_path, 'r') as f_kp:\n        for img_name_raw in f_kp.keys():\n            img_name = img_name_raw.decode('utf-8') if isinstance(img_name_raw, bytes) else img_name_raw\n            keypoints_data[img_name] = f_kp[img_name_raw][()] # Access with raw key if bytes\n\n    # Load remapped matches - CORRECTED LOGIC\n    # Store (img1_key, img2_key) directly with matches for robust iteration\n    matches_data_pairs = [] # Will store (img1_key, img2_key, matches_array)\n    with h5py.File(remapped_matches_path, 'r') as f_matches:\n        print(\"\\n--- Loading remapped matches from HDF5 ---\")\n        for img1_group_key_candidate in tqdm(f_matches.keys(), desc=\"Loading matches\"):\n            img1_key = img1_group_key_candidate.decode('utf-8') if isinstance(img1_group_key_candidate, bytes) else img1_group_key_candidate\n\n            img1_group = f_matches[img1_group_key_candidate] # Access with raw key\n\n            if isinstance(img1_group, h5py.Group):\n                for img2_dataset_key_candidate in img1_group.keys():\n                    img2_key = img2_dataset_key_candidate.decode('utf-8') if isinstance(img2_dataset_key_candidate, bytes) else img2_dataset_key_candidate\n\n                    try:\n                        matches_array = img1_group[img2_dataset_key_candidate][()]\n                        matches_data_pairs.append((img1_key, img2_key, matches_array))\n                    except Exception as e:\n                        print(f\"Error loading matches for pair ({img1_key}, {img2_key}): {e}\")\n            else:\n                print(f\"Warning: Expected '{img1_key}' to be a group, but found {type(img1_group)}. Skipping its contents.\")\n\n\n    # --- Drawing Keypoints ---\n    print(\"\\n--- Drawing Keypoints ---\")\n    for i, img_key in enumerate(image_keys):\n        if img_key in keypoints_data:\n            img = loaded_images[i].copy()\n            kpts = keypoints_data[img_key]\n\n            for kp in kpts:\n                x, y = int(kp[0]), int(kp[1])\n                cv2.circle(img, (x, y), 3, (0, 255, 0), -1) # Green circle for keypoint\n\n            output_kp_path = os.path.join(output_dir, f\"keypoints_{img_key}\")\n            if len(img.shape) == 2:\n                img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n            cv2.imwrite(output_kp_path, img)\n            print(f\"Keypoints drawn on {img_key}, saved to {output_kp_path}\")\n        else:\n            print(f\"No keypoints found for {img_key} in unified keypoints file.\")\n\n    # --- Drawing Matches ---\n    print(\"\\n--- Drawing Matches ---\")\n    # Iterate through the (img1_key, img2_key, matches) tuples directly\n    for img_name1, img_name2, matches in matches_data_pairs:\n        # We no longer need to split img_pair_key, as we have img_name1 and img_name2 directly\n\n        # Find the actual image objects and their keypoints using image_keys list\n        try:\n            img1_idx = image_keys.index(img_name1)\n            img2_idx = image_keys.index(img_name2)\n        except ValueError:\n            print(f\"Skipping matches for {img_name1}-{img_name2}: One or both image names not found in the provided 'images' list/keys.\")\n            continue\n\n        img1 = loaded_images[img1_idx].copy()\n        img2 = loaded_images[img2_idx].copy()\n\n        kpts1 = keypoints_data.get(img_name1)\n        kpts2 = keypoints_data.get(img_name2)\n\n        if kpts1 is None or kpts2 is None:\n            print(f\"Skipping matches for {img_name1}-{img_name2}: keypoints not found for one or both images in unified keypoints.\")\n            continue\n        if len(matches) == 0:\n            print(f\"No matches to draw for {img_name1}-{img_name2}.\")\n            continue\n\n        # Ensure images are 3 channels for drawing lines\n        if len(img1.shape) == 2:\n            img1 = cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR)\n        if len(img2.shape) == 2:\n            img2 = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n\n        # Create a concatenated image for drawing matches\n        h1, w1 = img1.shape[:2]\n        h2, w2 = img2.shape[:2]\n        max_h = max(h1, h2)\n        matched_img = np.zeros((max_h, w1 + w2, 3), dtype=np.uint8)\n        matched_img[0:h1, 0:w1] = img1\n        matched_img[0:h2, w1:w1+w2] = img2\n\n        num_matches_to_draw = min(len(matches), 200) # Draw up to 200 matches to avoid clutter, adjust as needed\n\n        for i in range(num_matches_to_draw):\n            match = matches[i]\n            kp1_idx, kp2_idx = int(match[0]), int(match[1])\n\n            # Bounds check for keypoint indices\n            if kp1_idx >= len(kpts1) or kp2_idx >= len(kpts2):\n                # print(f\"Warning: Match index out of bounds for {img_name1}-{img_name2}. Skipping match {kp1_idx}-{kp2_idx}.\")\n                continue\n\n            pt1 = tuple(map(int, kpts1[kp1_idx][:2]))\n            pt2 = tuple(map(int, kpts2[kp2_idx][:2]))\n\n            # Draw circles on the concatenated image\n            cv2.circle(matched_img, pt1, 5, (0, 0, 255), 2) # Red circle on img1 side\n            cv2.circle(matched_img, (pt2[0] + w1, pt2[1]), 5, (255, 0, 0), 2) # Blue circle on img2 side\n\n            # Draw a line connecting the matched keypoints\n            color = tuple(np.random.randint(0, 255, 3).tolist())\n            cv2.line(matched_img, pt1, (pt2[0] + w1, pt2[1]), color, 1)\n\n        output_match_path = os.path.join(output_dir, f\"matches_{img_name1}_{img_name2}.png\")\n        cv2.imwrite(output_match_path, matched_img)\n        print(f\"Matches drawn between {img_name1} and {img_name2}, saved to {output_match_path}\")\n\n\n# Example call (replace with your actual 'images' list)\n# If your 'images' are file paths:\n# images_file_paths = ['path/to/your/image1.jpg', 'path/to/your/image2.jpg', ...]\n# draw_keypoints_and_matches(images_file_paths, unified_kp_path, remapped_matches_path)\n\n# If your 'images' are loaded numpy arrays (as in the dummy example above):\n# draw_keypoints_and_matches(images, unified_kp_path, remapped_matches_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T22:54:51.793881Z","iopub.execute_input":"2025-06-10T22:54:51.794136Z","iopub.status.idle":"2025-06-10T22:54:51.811251Z","shell.execute_reply.started":"2025-06-10T22:54:51.794101Z","shell.execute_reply":"2025-06-10T22:54:51.810249Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"gc.collect()\n\nmax_images = None  # Used For debugging only. Set to None to disable.\ndatasets_to_process = None  # Not the best convention, but None means all datasets.\n\nif is_train:\n    # max_images = 5\n\n    # Note: When running on the training dataset, the notebook will hit the time limit and die. Use this filter to run on a few specific datasets.\n    datasets_to_process = [\n    \t# New data.\n    \t# 'amy_gardens',\n    \t'ETs',\n    \t# 'fbk_vineyard',\n    \t# 'stairs',\n    \t# Data from IMC 2023 and 2024.\n    \t# 'imc2024_dioscuri_baalshamin',\n    \t# 'imc2023_theather_imc2024_church',\n    \t# 'imc2023_heritage',\n    \t# 'imc2023_haiper',\n    \t# 'imc2024_lizard_pond',\n    \t# Crowdsourced PhotoTourism data.\n    \t# 'pt_stpeters_stpauls',\n    \t# 'pt_brandenburg_british_buckingham',\n    \t# 'pt_piazzasanmarco_grandplace',\n    \t# 'pt_sacrecoeur_trevi_tajmahal',\n    ]\n\ntimings = {\n    'rotation_detection':[],\n    \"shortlisting\":[],\n    \"feature_matching\":[],\n    \"RANSAC\": [],\n    \"Reconstruction\": [],\n}\nmapping_result_strs = []\n\n# Load DINOv2 model (for feature extraction, not global descriptor here)\nprint(\"Loading DINOv2 model for patch feature extraction...\")\ndino_processor = AutoImageProcessor.from_pretrained('/kaggle/input/dinov2/pytorch/base/1')\ndino_model = AutoModel.from_pretrained('/kaggle/input/dinov2/pytorch/base/1')\ndino_model = dino_model.eval().to(device)\nprint(\"DINOv2 model loaded.\")\n\nprint(f\"CONFIG.ROTATION_CORRECTION: {CONFIG.ROTATION_CORRECTION}\")\n\nwith concurrent.futures.ProcessPoolExecutor(max_workers=CONFIG.NUM_CORES) as executors:\n    # print (f\"Extracting on device {device}\")\n    for dataset, predictions in samples.items():\n        if datasets_to_process and dataset not in datasets_to_process:\n            print(f'Skipping \"{dataset}\"')\n            continue\n        \n        images_dir = os.path.join(data_dir, 'train' if is_train else 'test', dataset)\n        images = [os.path.join(images_dir, p.filename) for p in predictions]\n        if max_images is not None:\n            images = images[:max_images]\n    \n        print(f'\\nProcessing dataset \"{dataset}\": {len(images)} images')\n    \n        filename_to_index = {p.filename: idx for idx, p in enumerate(predictions)}\n    \n        feature_dir = os.path.join(workdir, 'featureout', dataset)\n        os.makedirs(feature_dir, exist_ok=True)\n    \n        # Wrap algos in try-except blocks so we can populate a submission even if one scene crashes.\n        try:\n            # --- Pipeline Execution ---\n            \n            #############################################################\n            # get image pairs\n            #############################################################\n            # 1. Detect ALIKED features and combine with DINO patch features\n            t = time()\n            index_pairs = get_image_pairs_shortlist_org(\n                images,\n                sim_th = 0.2, # should be strict\n                min_pairs = 60, # we should select at least min_pairs PER IMAGE with biggest similarity\n                exhaustive_if_less = 20,\n                device=device\n            )\n            timings['shortlisting'].append(time() - t)\n            print (f'Shortlisting. Number of pairs to match: {len(index_pairs)}. Done in {time() - t:.4f} sec')\n            gc.collect()\n\n            #############################################################\n            # get image rotations\n            #############################################################\n            t = time()\n\n            rotation_estimator = RotationEstimator(device=device)\n            rot_dict = rotation_estimator.run(images, index_pairs)\n            # print(rot_dict)\n\n            t = time()-t\n            timings['rotation_detection'].append(t)\n            print(f'rotation_detection for {len(images)} images : {t:.4f} sec')\n            gc.collect()\n\n            #############################################################\n            # get keypoints\n            #############################################################    \n            t=time()\n\n            lightglue_25groups_matcher_pipeline = LightGlueMatcherPipeline_sep(\n                extractor_cfg = {\"max_num_keypoints\": 4096, \"detection_threshold\":0.01}, \n                device= device)\n            # print(\"lightglue_25groups_matcher_pipeline initialization done\")            \n            unified_kp_path, remapped_matches_path = save_keypoints_and_matches_split(\n                img_fnames = images,\n                rot_dict = rot_dict,\n                matcher_pip = lightglue_25groups_matcher_pipeline,\n                feature_dir = feature_dir,\n                device = device)\n            \n            timings['feature_matching'].append(time() - t)\n            gc.collect()\n            print (f'Local feature extracting and matching. Done in {time() - t:.4f} sec')\n            draw_keypoints_and_matches(images, unified_kp_path, remapped_matches_path)\n            #############################################################\n            # kick COLMAP reconstruction\n            #############################################################            \n            future = executors.submit(\n                reconstruct_from_db, \n                feature_dir, images_dir)\n            maps, local_timings = future.result()\n            # 合并 timings（主进程里）\n            for k in local_timings:\n                timings[k].extend(local_timings[k])\n            # clear_output(wait=False)\n            print(maps)\n            registered = 0\n            for map_index, cur_map in maps.items():  # cur_map: image_name → {'R': list, 't': list}\n                for image_name, pose in cur_map.items():\n                    idx = filename_to_index[image_name]\n                    pred = predictions[idx]\n                    pred.cluster_index = map_index\n                    pred.rotation = np.array(pose['R'])  # convert back to np.ndarray\n                    pred.translation = np.array(pose['t'])\n                    registered += 1\n            mapping_result_str = f\"Dataset  {dataset} -> Registered {registered} / {len(images)} images with {len(maps)} clusters\"\n            mapping_result_strs.append(mapping_result_str)\n            print(mapping_result_str)\n\n            gc.collect()\n        except Exception as e:\n            print(e)\n            # raise e\n            mapping_result_str = f'Dataset \"{dataset}\" -> Failed!'\n            mapping_result_strs.append(mapping_result_str)\n            print(mapping_result_str)\n\nprint('\\nResults')\nfor s in mapping_result_strs:\n    print(s)\n\nprint('\\nTimings')\nfor k, v in timings.items():\n    print(f'{k} -> total={sum(v):.02f} sec.')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T22:54:51.812409Z","iopub.execute_input":"2025-06-10T22:54:51.812854Z","iopub.status.idle":"2025-06-10T22:58:38.597663Z","shell.execute_reply.started":"2025-06-10T22:54:51.812767Z","shell.execute_reply":"2025-06-10T22:58:38.596419Z"}},"outputs":[{"name":"stdout","text":"Loading DINOv2 model for patch feature extraction...\nDINOv2 model loaded.\nCONFIG.ROTATION_CORRECTION: True\nSkipping \"imc2023_haiper\"\nSkipping \"imc2023_heritage\"\nSkipping \"imc2023_theather_imc2024_church\"\nSkipping \"imc2024_dioscuri_baalshamin\"\nSkipping \"imc2024_lizard_pond\"\nSkipping \"pt_brandenburg_british_buckingham\"\nSkipping \"pt_piazzasanmarco_grandplace\"\nSkipping \"pt_sacrecoeur_trevi_tajmahal\"\nSkipping \"pt_stpeters_stpauls\"\nSkipping \"amy_gardens\"\nSkipping \"fbk_vineyard\"\n\nProcessing dataset \"ETs\": 22 images\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 22/22 [00:01<00:00, 12.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Shortlisting. Number of pairs to match: 231. Done in 2.0674 sec\n","output_type":"stream"},{"name":"stderr","text":"Finding valid rotations: 100%|██████████| 231/231 [00:48<00:00,  4.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"rotation_detection for 22 images : 49.5255 sec\n","output_type":"stream"},{"name":"stderr","text":"Matching and storing:   0%|          | 0/19 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"before ransac the original number of key1 outliers_out_et001.png, key2outliers_out_et002.png: 31649 and 43489,              matches len is 28: [2, 1, 1, 1, 2, 3, 1, 1, 2, 1, 1, 2, 1, 5, 2, 2]\nafter ransac the matches length is 14\noutliers_out_et001.png_0-outliers_out_et002.png:14\nSaved: tta_debug_vis/outliers_out_et001.png_vs_another_et_another_et002.png_TTA_3_3.jpg\nbefore ransac the original number of key1 outliers_out_et001.png, key2another_et_another_et002.png: 34122 and 21632,              matches len is 123: [3, 1, 2, 3, 3, 4, 12, 1, 9, 1, 2, 3, 63, 4, 7, 5]\nafter ransac the matches length is 78\noutliers_out_et001.png_0-another_et_another_et002.png:78\nbefore ransac the original number of key1 outliers_out_et001.png, key2another_et_another_et003.png: 45777 and 34327,              matches len is 76: [10, 1, 3, 3, 3, 1, 1, 1, 7, 13, 1, 3, 4, 8, 4, 1, 3, 1, 1, 1, 5, 1]\nafter ransac the matches length is 31\noutliers_out_et001.png_0-another_et_another_et003.png:31\nSaved: tta_debug_vis/outliers_out_et001.png_vs_another_et_another_et001.png_TTA_3_3.jpg\n","output_type":"stream"},{"name":"stderr","text":"Matching and storing:   5%|▌         | 1/19 [00:06<01:54,  6.37s/it]","output_type":"stream"},{"name":"stdout","text":"before ransac the original number of key1 outliers_out_et001.png, key2another_et_another_et001.png: 36270 and 24063,              matches len is 127: [4, 2, 4, 3, 4, 2, 3, 6, 3, 2, 1, 1, 74, 9, 4, 4, 1]\nafter ransac the matches length is 93\noutliers_out_et001.png_2-another_et_another_et001.png:93\n","output_type":"stream"},{"name":"stderr","text":"Matching and storing:  11%|█         | 2/19 [00:08<01:01,  3.59s/it]","output_type":"stream"},{"name":"stdout","text":"before ransac the original number of key1 outliers_out_et002.png, key2another_et_another_et004.png: 56070 and 30692,              matches len is 63: [1, 2, 5, 6, 3, 3, 3, 4, 15, 1, 1, 1, 1, 1, 2, 6, 1, 1, 2, 3, 1]\nafter ransac the matches length is 27\noutliers_out_et002.png_3-another_et_another_et004.png:27\nbefore ransac the original number of key1 et_et007.png, key2et_et003.png: 73340 and 60895,              matches len is 168: [2, 13, 6, 2, 16, 1, 12, 1, 2, 13, 3, 1, 31, 8, 6, 4, 1, 5, 5, 2, 2, 6, 9, 5, 12]\nafter ransac the matches length is 68\net_et007.png_0-et_et003.png:68\nSaved: tta_debug_vis/et_et007.png_vs_et_et006.png_TTA_0_0.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et006.png_TTA_0_1.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et006.png_TTA_0_4.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et006.png_TTA_1_1.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et006.png_TTA_1_4.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et006.png_TTA_2_2.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et006.png_TTA_2_3.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et006.png_TTA_2_4.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et006.png_TTA_3_1.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et006.png_TTA_3_3.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et006.png_TTA_3_4.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et006.png_TTA_4_0.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et006.png_TTA_4_1.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et006.png_TTA_4_2.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et006.png_TTA_4_3.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et006.png_TTA_4_4.jpg\nbefore ransac the original number of key1 et_et007.png, key2et_et006.png: 69244 and 69742,              matches len is 11115: [209, 83, 19, 1, 257, 1, 1058, 4, 10, 448, 4, 10, 1815, 163, 970, 3, 64, 1511, 486, 140, 557, 817, 499, 1986]\nafter ransac the matches length is 11055\net_et007.png_0-et_et006.png:11055\nSaved: tta_debug_vis/et_et007.png_vs_et_et001.png_TTA_1_0.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et001.png_TTA_2_2.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et001.png_TTA_2_3.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et001.png_TTA_2_4.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et001.png_TTA_4_0.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et001.png_TTA_4_3.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et001.png_TTA_4_4.jpg\nbefore ransac the original number of key1 et_et007.png, key2et_et001.png: 70371 and 70960,              matches len is 902: [5, 21, 3, 3, 24, 284, 12, 2, 10, 1, 7, 60, 90, 57, 8, 9, 10, 5, 2, 60, 24, 1, 86, 118]\nafter ransac the matches length is 817\net_et007.png_0-et_et001.png:817\nSaved: tta_debug_vis/et_et007.png_vs_et_et004.png_TTA_1_0.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et004.png_TTA_1_4.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et004.png_TTA_2_2.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et004.png_TTA_2_4.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et004.png_TTA_3_3.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et004.png_TTA_4_4.jpg\nbefore ransac the original number of key1 et_et007.png, key2et_et004.png: 68345 and 82525,              matches len is 1160: [8, 19, 3, 7, 215, 12, 21, 5, 132, 2, 7, 198, 47, 95, 2, 3, 103, 3, 28, 7, 26, 19, 198]\nafter ransac the matches length is 983\net_et007.png_0-et_et004.png:983\nSaved: tta_debug_vis/et_et007.png_vs_et_et002.png_TTA_1_0.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et002.png_TTA_1_4.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et002.png_TTA_2_2.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et002.png_TTA_2_3.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et002.png_TTA_2_4.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et002.png_TTA_3_3.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et002.png_TTA_4_0.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et002.png_TTA_4_1.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et002.png_TTA_4_3.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et002.png_TTA_4_4.jpg\nbefore ransac the original number of key1 et_et007.png, key2et_et002.png: 72441 and 76148,              matches len is 1758: [3, 37, 1, 21, 347, 19, 1, 4, 138, 3, 3, 157, 137, 113, 3, 2, 6, 73, 5, 185, 58, 33, 109, 300]\nafter ransac the matches length is 1678\net_et007.png_0-et_et002.png:1678\nSaved: tta_debug_vis/et_et007.png_vs_et_et008.png_TTA_0_0.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et008.png_TTA_0_4.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et008.png_TTA_1_0.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et008.png_TTA_1_1.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et008.png_TTA_1_4.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et008.png_TTA_2_0.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et008.png_TTA_2_2.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et008.png_TTA_2_4.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et008.png_TTA_3_2.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et008.png_TTA_3_3.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et008.png_TTA_3_4.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et008.png_TTA_4_0.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et008.png_TTA_4_1.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et008.png_TTA_4_2.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et008.png_TTA_4_3.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et008.png_TTA_4_4.jpg\nbefore ransac the original number of key1 et_et007.png, key2et_et008.png: 68573 and 76691,              matches len is 6245: [86, 2, 63, 170, 350, 2, 311, 351, 7, 782, 1, 473, 48, 30, 356, 320, 523, 431, 244, 454, 51, 1190]\nafter ransac the matches length is 6204\net_et007.png_0-et_et008.png:6204\nSaved: tta_debug_vis/et_et007.png_vs_et_et005.png_TTA_0_0.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et005.png_TTA_0_1.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et005.png_TTA_0_4.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et005.png_TTA_1_1.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et005.png_TTA_1_4.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et005.png_TTA_2_0.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et005.png_TTA_2_2.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et005.png_TTA_2_3.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et005.png_TTA_2_4.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et005.png_TTA_3_3.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et005.png_TTA_3_4.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et005.png_TTA_4_0.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et005.png_TTA_4_1.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et005.png_TTA_4_2.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et005.png_TTA_4_3.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et005.png_TTA_4_4.jpg\nbefore ransac the original number of key1 et_et007.png, key2et_et005.png: 61738 and 76652,              matches len is 10513: [278, 89, 4, 5, 201, 5, 867, 1, 1, 343, 375, 1613, 58, 1010, 46, 1251, 432, 409, 554, 620, 442, 1909]\nafter ransac the matches length is 10460\net_et007.png_0-et_et005.png:10460\nSaved: tta_debug_vis/et_et007.png_vs_et_et000.png_TTA_2_3.jpg\nSaved: tta_debug_vis/et_et007.png_vs_et_et000.png_TTA_2_4.jpg\nbefore ransac the original number of key1 et_et007.png, key2et_et000.png: 70046 and 69885,              matches len is 334: [20, 4, 8, 5, 14, 34, 21, 2, 3, 14, 1, 3, 16, 52, 69, 1, 6, 2, 1, 2, 3, 1, 22, 30]\nafter ransac the matches length is 222\net_et007.png_0-et_et000.png:222\n","output_type":"stream"},{"name":"stderr","text":"Matching and storing:  16%|█▌        | 3/19 [00:32<03:32, 13.25s/it]","output_type":"stream"},{"name":"stdout","text":"before ransac the original number of key1 et_et007.png, key2another_et_another_et002.png: 57545 and 28433,              matches len is 158: [3, 11, 8, 7, 6, 7, 8, 1, 11, 6, 6, 1, 1, 1, 36, 18, 2, 3, 3, 19]\nafter ransac the matches length is 81\net_et007.png_0-another_et_another_et002.png:81\nbefore ransac the original number of key1 et_et003.png, key2et_et006.png: 56330 and 67720,              matches len is 209: [1, 2, 10, 11, 10, 19, 9, 3, 17, 4, 1, 49, 15, 1, 3, 4, 4, 2, 20, 5, 5, 1, 13]\nafter ransac the matches length is 114\net_et003.png_0-et_et006.png:114\nSaved: tta_debug_vis/et_et003.png_vs_et_et001.png_TTA_0_0.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et001.png_TTA_0_1.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et001.png_TTA_0_4.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et001.png_TTA_1_0.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et001.png_TTA_1_1.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et001.png_TTA_1_4.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et001.png_TTA_2_2.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et001.png_TTA_2_4.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et001.png_TTA_3_3.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et001.png_TTA_3_4.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et001.png_TTA_4_0.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et001.png_TTA_4_1.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et001.png_TTA_4_2.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et001.png_TTA_4_3.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et001.png_TTA_4_4.jpg\nbefore ransac the original number of key1 et_et003.png, key2et_et001.png: 60895 and 73600,              matches len is 5954: [451, 395, 6, 5, 482, 76, 373, 4, 1, 235, 2, 2, 546, 14, 262, 3, 3, 2, 480, 197, 380, 445, 277, 252, 1061]\nafter ransac the matches length is 5910\net_et003.png_0-et_et001.png:5910\nSaved: tta_debug_vis/et_et003.png_vs_et_et004.png_TTA_0_0.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et004.png_TTA_0_1.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et004.png_TTA_0_4.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et004.png_TTA_1_1.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et004.png_TTA_1_4.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et004.png_TTA_2_2.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et004.png_TTA_2_4.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et004.png_TTA_3_3.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et004.png_TTA_3_4.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et004.png_TTA_4_0.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et004.png_TTA_4_1.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et004.png_TTA_4_2.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et004.png_TTA_4_3.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et004.png_TTA_4_4.jpg\nbefore ransac the original number of key1 et_et003.png, key2et_et004.png: 58844 and 84860,              matches len is 4727: [358, 287, 1, 4, 373, 1, 261, 9, 16, 252, 1, 574, 2, 309, 2, 5, 33, 284, 129, 227, 244, 291, 169, 895]\nafter ransac the matches length is 4636\net_et003.png_0-et_et004.png:4636\nSaved: tta_debug_vis/et_et003.png_vs_et_et002.png_TTA_0_1.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et002.png_TTA_0_4.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et002.png_TTA_1_0.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et002.png_TTA_1_1.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et002.png_TTA_1_4.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et002.png_TTA_2_2.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et002.png_TTA_2_4.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et002.png_TTA_3_3.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et002.png_TTA_3_4.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et002.png_TTA_4_0.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et002.png_TTA_4_1.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et002.png_TTA_4_2.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et002.png_TTA_4_3.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et002.png_TTA_4_4.jpg\nbefore ransac the original number of key1 et_et003.png, key2et_et002.png: 58381 and 76148,              matches len is 4065: [10, 581, 1, 256, 52, 252, 2, 1, 206, 2, 5, 402, 5, 182, 2, 3, 8, 347, 139, 51, 449, 211, 162, 736]\nafter ransac the matches length is 4016\net_et003.png_0-et_et002.png:4016\nbefore ransac the original number of key1 et_et003.png, key2et_et008.png: 51926 and 71062,              matches len is 86: [9, 1, 1, 5, 3, 5, 1, 2, 4, 6, 1, 1, 4, 10, 1, 1, 9, 2, 4, 2, 14]\nafter ransac the matches length is 38\net_et003.png_1-et_et008.png:38\nbefore ransac the original number of key1 et_et003.png, key2et_et005.png: 56028 and 79687,              matches len is 204: [3, 1, 7, 7, 8, 5, 2, 4, 6, 1, 7, 48, 1, 20, 2, 20, 2, 3, 23, 7, 6, 2, 19]\nafter ransac the matches length is 127\net_et003.png_0-et_et005.png:127\nSaved: tta_debug_vis/et_et003.png_vs_et_et000.png_TTA_0_0.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et000.png_TTA_0_1.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et000.png_TTA_0_4.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et000.png_TTA_1_1.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et000.png_TTA_1_4.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et000.png_TTA_2_2.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et000.png_TTA_2_3.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et000.png_TTA_2_4.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et000.png_TTA_3_1.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et000.png_TTA_3_3.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et000.png_TTA_3_4.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et000.png_TTA_4_0.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et000.png_TTA_4_1.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et000.png_TTA_4_2.jpg\n","output_type":"stream"},{"name":"stderr","text":"Matching and storing:  21%|██        | 4/19 [00:50<03:45, 15.02s/it]","output_type":"stream"},{"name":"stdout","text":"Saved: tta_debug_vis/et_et003.png_vs_et_et000.png_TTA_4_3.jpg\nSaved: tta_debug_vis/et_et003.png_vs_et_et000.png_TTA_4_4.jpg\nbefore ransac the original number of key1 et_et003.png, key2et_et000.png: 58830 and 69557,              matches len is 11445: [1370, 104, 9, 2, 907, 5, 887, 1, 401, 2, 2, 1055, 61, 477, 2, 83, 2, 1184, 518, 765, 576, 387, 524, 2121]\nafter ransac the matches length is 11412\net_et003.png_0-et_et000.png:11412\nSaved: tta_debug_vis/et_et006.png_vs_et_et001.png_TTA_1_0.jpg\nSaved: tta_debug_vis/et_et006.png_vs_et_et001.png_TTA_2_2.jpg\nSaved: tta_debug_vis/et_et006.png_vs_et_et001.png_TTA_2_4.jpg\nSaved: tta_debug_vis/et_et006.png_vs_et_et001.png_TTA_3_3.jpg\nSaved: tta_debug_vis/et_et006.png_vs_et_et001.png_TTA_4_0.jpg\nSaved: tta_debug_vis/et_et006.png_vs_et_et001.png_TTA_4_3.jpg\nSaved: tta_debug_vis/et_et006.png_vs_et_et001.png_TTA_4_4.jpg\nbefore ransac the original number of key1 et_et006.png, key2et_et001.png: 70827 and 66864,              matches len is 1318: [12, 8, 27, 329, 30, 2, 3, 8, 1, 13, 100, 44, 62, 1, 9, 6, 78, 8, 181, 29, 7, 142, 218]\nafter ransac the matches length is 1244\net_et006.png_0-et_et001.png:1244\nSaved: tta_debug_vis/et_et006.png_vs_et_et004.png_TTA_1_0.jpg\nSaved: tta_debug_vis/et_et006.png_vs_et_et004.png_TTA_1_4.jpg\nSaved: tta_debug_vis/et_et006.png_vs_et_et004.png_TTA_2_2.jpg\nSaved: tta_debug_vis/et_et006.png_vs_et_et004.png_TTA_2_4.jpg\nSaved: tta_debug_vis/et_et006.png_vs_et_et004.png_TTA_3_3.jpg\nSaved: tta_debug_vis/et_et006.png_vs_et_et004.png_TTA_4_2.jpg\nSaved: tta_debug_vis/et_et006.png_vs_et_et004.png_TTA_4_4.jpg\nbefore ransac the original number of key1 et_et006.png, key2et_et004.png: 64613 and 80764,              matches len is 1211: [2, 22, 1, 3, 19, 164, 10, 5, 5, 82, 1, 7, 264, 31, 102, 3, 127, 4, 2, 21, 111, 29, 196]\nafter ransac the matches length is 1120\net_et006.png_0-et_et004.png:1120\nSaved: tta_debug_vis/et_et006.png_vs_et_et002.png_TTA_1_0.jpg\nSaved: tta_debug_vis/et_et006.png_vs_et_et002.png_TTA_1_4.jpg\nSaved: tta_debug_vis/et_et006.png_vs_et_et002.png_TTA_2_2.jpg\nSaved: tta_debug_vis/et_et006.png_vs_et_et002.png_TTA_2_3.jpg\nSaved: tta_debug_vis/et_et006.png_vs_et_et002.png_TTA_2_4.jpg\nSaved: tta_debug_vis/et_et006.png_vs_et_et002.png_TTA_3_3.jpg\nSaved: tta_debug_vis/et_et006.png_vs_et_et002.png_TTA_4_0.jpg\nSaved: tta_debug_vis/et_et006.png_vs_et_et002.png_TTA_4_2.jpg\nSaved: tta_debug_vis/et_et006.png_vs_et_et002.png_TTA_4_3.jpg\nSaved: tta_debug_vis/et_et006.png_vs_et_et002.png_TTA_4_4.jpg\nbefore ransac the original number of key1 et_et006.png, key2et_et002.png: 68709 and 74864,              matches len is 2298: [5, 41, 3, 5, 29, 424, 49, 2, 3, 110, 1, 1, 195, 73, 116, 1, 2, 172, 22, 230, 29, 95, 235, 455]\nafter ransac the matches length is 2244\net_et006.png_0-et_et002.png:2244\nSaved: tta_debug_vis/et_et006.png_vs_et_et008.png_TTA_1_0.jpg\nSaved: tta_debug_vis/et_et006.png_vs_et_et008.png_TTA_1_4.jpg\nSaved: tta_debug_vis/et_et006.png_vs_et_et008.png_TTA_2_0.jpg\nSaved: tta_debug_vis/et_et006.png_vs_et_et008.png_TTA_2_2.jpg\nSaved: tta_debug_vis/et_et006.png_vs_et_et008.png_TTA_2_4.jpg\nSaved: tta_debug_vis/et_et006.png_vs_et_et008.png_TTA_3_2.jpg\nSaved: tta_debug_vis/et_et006.png_vs_et_et008.png_TTA_3_3.jpg\nSaved: tta_debug_vis/et_et006.png_vs_et_et008.png_TTA_3_4.jpg\nSaved: tta_debug_vis/et_et006.png_vs_et_et008.png_TTA_4_0.jpg\nSaved: tta_debug_vis/et_et006.png_vs_et_et008.png_TTA_4_2.jpg\nSaved: tta_debug_vis/et_et006.png_vs_et_et008.png_TTA_4_4.jpg\nbefore ransac the original number of key1 et_et006.png, key2et_et008.png: 65160 and 74217,              matches len is 4538: [4, 10, 9, 317, 50, 4, 293, 287, 19, 411, 267, 18, 9, 498, 98, 475, 377, 38, 350, 40, 964]\nafter ransac the matches length is 4445\net_et006.png_0-et_et008.png:4445\nSaved: tta_debug_vis/et_et006.png_vs_et_et005.png_TTA_0_0.jpg\nSaved: tta_debug_vis/et_et006.png_vs_et_et005.png_TTA_0_4.jpg\nSaved: tta_debug_vis/et_et006.png_vs_et_et005.png_TTA_1_1.jpg\nSaved: tta_debug_vis/et_et006.png_vs_et_et005.png_TTA_1_4.jpg\nSaved: tta_debug_vis/et_et006.png_vs_et_et005.png_TTA_2_0.jpg\nSaved: tta_debug_vis/et_et006.png_vs_et_et005.png_TTA_2_2.jpg\nSaved: tta_debug_vis/et_et006.png_vs_et_et005.png_TTA_2_4.jpg\nSaved: tta_debug_vis/et_et006.png_vs_et_et005.png_TTA_3_3.jpg\nSaved: tta_debug_vis/et_et006.png_vs_et_et005.png_TTA_3_4.jpg\nSaved: tta_debug_vis/et_et006.png_vs_et_et005.png_TTA_4_0.jpg\nSaved: tta_debug_vis/et_et006.png_vs_et_et005.png_TTA_4_1.jpg\nSaved: tta_debug_vis/et_et006.png_vs_et_et005.png_TTA_4_2.jpg\nSaved: tta_debug_vis/et_et006.png_vs_et_et005.png_TTA_4_3.jpg\nSaved: tta_debug_vis/et_et006.png_vs_et_et005.png_TTA_4_4.jpg\nbefore ransac the original number of key1 et_et006.png, key2et_et005.png: 68753 and 77383,              matches len is 10229: [215, 4, 1, 96, 1, 684, 1, 2, 430, 400, 2, 1441, 994, 3, 6, 4, 1475, 559, 474, 369, 671, 503, 1894]\nafter ransac the matches length is 10146\net_et006.png_0-et_et005.png:10146\nSaved: tta_debug_vis/et_et006.png_vs_et_et000.png_TTA_2_2.jpg\nSaved: tta_debug_vis/et_et006.png_vs_et_et000.png_TTA_4_3.jpg\nSaved: tta_debug_vis/et_et006.png_vs_et_et000.png_TTA_4_4.jpg\nbefore ransac the original number of key1 et_et006.png, key2et_et000.png: 70827 and 66987,              matches len is 447: [13, 4, 31, 11, 9, 6, 6, 7, 6, 3, 66, 43, 39, 3, 2, 3, 34, 5, 19, 4, 3, 55, 75]\nafter ransac the matches length is 347\net_et006.png_0-et_et000.png:347\n","output_type":"stream"},{"name":"stderr","text":"Matching and storing:  26%|██▋       | 5/19 [01:09<03:49, 16.39s/it]","output_type":"stream"},{"name":"stdout","text":"before ransac the original number of key1 et_et006.png, key2another_et_another_et004.png: 63668 and 30638,              matches len is 112: [1, 2, 5, 2, 6, 3, 2, 2, 4, 3, 2, 5, 1, 6, 12, 26, 2, 2, 7, 3, 16]\nafter ransac the matches length is 60\net_et006.png_0-another_et_another_et004.png:60\nSaved: tta_debug_vis/et_et001.png_vs_et_et004.png_TTA_0_0.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et004.png_TTA_0_4.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et004.png_TTA_1_1.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et004.png_TTA_1_4.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et004.png_TTA_2_0.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et004.png_TTA_2_2.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et004.png_TTA_2_4.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et004.png_TTA_3_1.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et004.png_TTA_3_2.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et004.png_TTA_3_3.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et004.png_TTA_3_4.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et004.png_TTA_4_0.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et004.png_TTA_4_1.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et004.png_TTA_4_2.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et004.png_TTA_4_3.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et004.png_TTA_4_4.jpg\nbefore ransac the original number of key1 et_et001.png, key2et_et004.png: 73600 and 88695,              matches len is 7081: [807, 39, 1, 8, 448, 7, 423, 6, 38, 267, 112, 4, 752, 6, 402, 1, 209, 98, 631, 457, 344, 303, 315, 194, 1209]\nafter ransac the matches length is 6989\net_et001.png_0-et_et004.png:6989\nSaved: tta_debug_vis/et_et001.png_vs_et_et002.png_TTA_0_0.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et002.png_TTA_0_1.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et002.png_TTA_0_4.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et002.png_TTA_1_1.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et002.png_TTA_1_3.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et002.png_TTA_1_4.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et002.png_TTA_2_2.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et002.png_TTA_2_4.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et002.png_TTA_3_2.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et002.png_TTA_3_3.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et002.png_TTA_3_4.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et002.png_TTA_4_0.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et002.png_TTA_4_1.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et002.png_TTA_4_2.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et002.png_TTA_4_3.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et002.png_TTA_4_4.jpg\nbefore ransac the original number of key1 et_et001.png, key2et_et002.png: 67276 and 72668,              matches len is 9901: [1230, 237, 2, 736, 1011, 1, 57, 509, 2, 2, 945, 1, 387, 1, 3, 69, 909, 367, 462, 598, 368, 338, 1666]\nafter ransac the matches length is 9860\net_et001.png_0-et_et002.png:9860\nSaved: tta_debug_vis/et_et001.png_vs_et_et008.png_TTA_3_2.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et008.png_TTA_3_4.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et008.png_TTA_4_4.jpg\nbefore ransac the original number of key1 et_et001.png, key2et_et008.png: 62217 and 75069,              matches len is 505: [2, 33, 3, 9, 5, 3, 3, 5, 4, 8, 1, 2, 3, 1, 1, 177, 3, 123, 20, 14, 1, 84]\nafter ransac the matches length is 428\net_et001.png_0-et_et008.png:428\nSaved: tta_debug_vis/et_et001.png_vs_et_et005.png_TTA_1_4.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et005.png_TTA_2_2.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et005.png_TTA_3_2.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et005.png_TTA_3_3.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et005.png_TTA_3_4.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et005.png_TTA_4_2.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et005.png_TTA_4_4.jpg\nbefore ransac the original number of key1 et_et001.png, key2et_et005.png: 70960 and 83783,              matches len is 977: [1, 9, 4, 1, 5, 11, 10, 2, 14, 52, 4, 103, 5, 34, 3, 3, 148, 122, 169, 15, 12, 70, 4, 176]\nafter ransac the matches length is 880\net_et001.png_0-et_et005.png:880\nSaved: tta_debug_vis/et_et001.png_vs_et_et000.png_TTA_0_0.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et000.png_TTA_0_1.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et000.png_TTA_0_4.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et000.png_TTA_1_0.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et000.png_TTA_1_1.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et000.png_TTA_1_4.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et000.png_TTA_2_2.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et000.png_TTA_2_4.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et000.png_TTA_3_3.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et000.png_TTA_3_4.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et000.png_TTA_4_0.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et000.png_TTA_4_1.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et000.png_TTA_4_2.jpg\nSaved: tta_debug_vis/et_et001.png_vs_et_et000.png_TTA_4_3.jpg\n","output_type":"stream"},{"name":"stderr","text":"Matching and storing:  32%|███▏      | 6/19 [01:23<03:25, 15.79s/it]","output_type":"stream"},{"name":"stdout","text":"Saved: tta_debug_vis/et_et001.png_vs_et_et000.png_TTA_4_4.jpg\nbefore ransac the original number of key1 et_et001.png, key2et_et000.png: 70960 and 69885,              matches len is 7681: [644, 80, 4, 2, 461, 283, 650, 2, 12, 475, 2, 878, 6, 450, 4, 1, 4, 713, 313, 506, 329, 270, 294, 1298]\nafter ransac the matches length is 7629\net_et001.png_0-et_et000.png:7629\nSaved: tta_debug_vis/et_et004.png_vs_et_et002.png_TTA_0_0.jpg\nSaved: tta_debug_vis/et_et004.png_vs_et_et002.png_TTA_0_2.jpg\nSaved: tta_debug_vis/et_et004.png_vs_et_et002.png_TTA_0_4.jpg\nSaved: tta_debug_vis/et_et004.png_vs_et_et002.png_TTA_1_1.jpg\nSaved: tta_debug_vis/et_et004.png_vs_et_et002.png_TTA_1_4.jpg\nSaved: tta_debug_vis/et_et004.png_vs_et_et002.png_TTA_2_2.jpg\nSaved: tta_debug_vis/et_et004.png_vs_et_et002.png_TTA_2_4.jpg\nSaved: tta_debug_vis/et_et004.png_vs_et_et002.png_TTA_3_3.jpg\nSaved: tta_debug_vis/et_et004.png_vs_et_et002.png_TTA_3_4.jpg\nSaved: tta_debug_vis/et_et004.png_vs_et_et002.png_TTA_4_0.jpg\nSaved: tta_debug_vis/et_et004.png_vs_et_et002.png_TTA_4_1.jpg\nSaved: tta_debug_vis/et_et004.png_vs_et_et002.png_TTA_4_2.jpg\nSaved: tta_debug_vis/et_et004.png_vs_et_et002.png_TTA_4_3.jpg\nSaved: tta_debug_vis/et_et004.png_vs_et_et002.png_TTA_4_4.jpg\nbefore ransac the original number of key1 et_et004.png, key2et_et002.png: 80764 and 72052,              matches len is 5447: [429, 3, 67, 195, 454, 2, 2, 201, 8, 6, 795, 35, 335, 1, 12, 6, 608, 224, 278, 279, 355, 225, 927]\nafter ransac the matches length is 5365\net_et004.png_0-et_et002.png:5365\nSaved: tta_debug_vis/et_et004.png_vs_et_et008.png_TTA_0_1.jpg\nSaved: tta_debug_vis/et_et004.png_vs_et_et008.png_TTA_2_2.jpg\nSaved: tta_debug_vis/et_et004.png_vs_et_et008.png_TTA_3_2.jpg\nSaved: tta_debug_vis/et_et004.png_vs_et_et008.png_TTA_3_4.jpg\nSaved: tta_debug_vis/et_et004.png_vs_et_et008.png_TTA_4_1.jpg\nSaved: tta_debug_vis/et_et004.png_vs_et_et008.png_TTA_4_4.jpg\nbefore ransac the original number of key1 et_et004.png, key2et_et008.png: 58471 and 59455,              matches len is 727: [1, 126, 10, 1, 9, 3, 54, 22, 4, 4, 129, 5, 137, 3, 66, 37, 116]\nafter ransac the matches length is 658\net_et004.png_0-et_et008.png:658\nSaved: tta_debug_vis/et_et004.png_vs_et_et005.png_TTA_0_1.jpg\nSaved: tta_debug_vis/et_et004.png_vs_et_et005.png_TTA_2_2.jpg\nSaved: tta_debug_vis/et_et004.png_vs_et_et005.png_TTA_2_4.jpg\nSaved: tta_debug_vis/et_et004.png_vs_et_et005.png_TTA_3_2.jpg\nSaved: tta_debug_vis/et_et004.png_vs_et_et005.png_TTA_3_3.jpg\nSaved: tta_debug_vis/et_et004.png_vs_et_et005.png_TTA_3_4.jpg\nSaved: tta_debug_vis/et_et004.png_vs_et_et005.png_TTA_4_2.jpg\nSaved: tta_debug_vis/et_et004.png_vs_et_et005.png_TTA_4_4.jpg\nbefore ransac the original number of key1 et_et004.png, key2et_et005.png: 81514 and 79687,              matches len is 1267: [3, 71, 5, 1, 36, 25, 1, 5, 19, 4, 327, 3, 82, 1, 4, 93, 157, 65, 27, 33, 109, 4, 192]\nafter ransac the matches length is 1200\net_et004.png_0-et_et005.png:1200\nSaved: tta_debug_vis/et_et004.png_vs_et_et000.png_TTA_0_0.jpg\nSaved: tta_debug_vis/et_et004.png_vs_et_et000.png_TTA_0_4.jpg\nSaved: tta_debug_vis/et_et004.png_vs_et_et000.png_TTA_1_0.jpg\nSaved: tta_debug_vis/et_et004.png_vs_et_et000.png_TTA_1_1.jpg\nSaved: tta_debug_vis/et_et004.png_vs_et_et000.png_TTA_1_4.jpg\nSaved: tta_debug_vis/et_et004.png_vs_et_et000.png_TTA_2_2.jpg\nSaved: tta_debug_vis/et_et004.png_vs_et_et000.png_TTA_2_3.jpg\nSaved: tta_debug_vis/et_et004.png_vs_et_et000.png_TTA_2_4.jpg\nSaved: tta_debug_vis/et_et004.png_vs_et_et000.png_TTA_3_3.jpg\nSaved: tta_debug_vis/et_et004.png_vs_et_et000.png_TTA_3_4.jpg\nSaved: tta_debug_vis/et_et004.png_vs_et_et000.png_TTA_4_0.jpg\nSaved: tta_debug_vis/et_et004.png_vs_et_et000.png_TTA_4_1.jpg\nSaved: tta_debug_vis/et_et004.png_vs_et_et000.png_TTA_4_2.jpg\nSaved: tta_debug_vis/et_et004.png_vs_et_et000.png_TTA_4_3.jpg\nSaved: tta_debug_vis/et_et004.png_vs_et_et000.png_TTA_4_4.jpg\nbefore ransac the original number of key1 et_et004.png, key2et_et000.png: 80764 and 66587,              matches len is 6285: [551, 1, 1, 284, 300, 471, 7, 321, 2, 2, 859, 156, 347, 10, 34, 7, 371, 186, 398, 348, 363, 222, 1044]\nafter ransac the matches length is 6208\net_et004.png_0-et_et000.png:6208\n","output_type":"stream"},{"name":"stderr","text":"Matching and storing:  37%|███▋      | 7/19 [01:38<03:05, 15.50s/it]","output_type":"stream"},{"name":"stdout","text":"before ransac the original number of key1 et_et004.png, key2another_et_another_et004.png: 70237 and 30206,              matches len is 73: [1, 1, 7, 6, 8, 2, 3, 3, 4, 2, 2, 2, 1, 1, 8, 9, 6, 2, 3, 2]\nafter ransac the matches length is 23\net_et004.png_2-another_et_another_et004.png:23\nSaved: tta_debug_vis/et_et002.png_vs_et_et008.png_TTA_3_2.jpg\nSaved: tta_debug_vis/et_et002.png_vs_et_et008.png_TTA_3_4.jpg\nSaved: tta_debug_vis/et_et002.png_vs_et_et008.png_TTA_4_4.jpg\nbefore ransac the original number of key1 et_et002.png, key2et_et008.png: 69856 and 75158,              matches len is 829: [4, 48, 2, 5, 15, 5, 2, 5, 4, 6, 12, 1, 2, 2, 261, 3, 246, 19, 41, 3, 3, 140]\nafter ransac the matches length is 722\net_et002.png_0-et_et008.png:722\nSaved: tta_debug_vis/et_et002.png_vs_et_et005.png_TTA_1_4.jpg\nSaved: tta_debug_vis/et_et002.png_vs_et_et005.png_TTA_2_2.jpg\nSaved: tta_debug_vis/et_et002.png_vs_et_et005.png_TTA_2_4.jpg\nSaved: tta_debug_vis/et_et002.png_vs_et_et005.png_TTA_3_2.jpg\nSaved: tta_debug_vis/et_et002.png_vs_et_et005.png_TTA_3_3.jpg\nSaved: tta_debug_vis/et_et002.png_vs_et_et005.png_TTA_3_4.jpg\nSaved: tta_debug_vis/et_et002.png_vs_et_et005.png_TTA_4_2.jpg\nSaved: tta_debug_vis/et_et002.png_vs_et_et005.png_TTA_4_4.jpg\nbefore ransac the original number of key1 et_et002.png, key2et_et005.png: 76148 and 83783,              matches len is 1550: [6, 38, 1, 1, 1, 17, 9, 6, 1, 110, 1, 1, 202, 1, 81, 5, 130, 193, 297, 26, 31, 68, 25, 299]\nafter ransac the matches length is 1460\net_et002.png_0-et_et005.png:1460\nSaved: tta_debug_vis/et_et002.png_vs_et_et000.png_TTA_0_0.jpg\nSaved: tta_debug_vis/et_et002.png_vs_et_et000.png_TTA_0_1.jpg\nSaved: tta_debug_vis/et_et002.png_vs_et_et000.png_TTA_0_4.jpg\nSaved: tta_debug_vis/et_et002.png_vs_et_et000.png_TTA_1_0.jpg\nSaved: tta_debug_vis/et_et002.png_vs_et_et000.png_TTA_1_1.jpg\nSaved: tta_debug_vis/et_et002.png_vs_et_et000.png_TTA_1_4.jpg\nSaved: tta_debug_vis/et_et002.png_vs_et_et000.png_TTA_2_2.jpg\nSaved: tta_debug_vis/et_et002.png_vs_et_et000.png_TTA_2_3.jpg\nSaved: tta_debug_vis/et_et002.png_vs_et_et000.png_TTA_2_4.jpg\nSaved: tta_debug_vis/et_et002.png_vs_et_et000.png_TTA_3_3.jpg\nSaved: tta_debug_vis/et_et002.png_vs_et_et000.png_TTA_3_4.jpg\nSaved: tta_debug_vis/et_et002.png_vs_et_et000.png_TTA_4_0.jpg\nSaved: tta_debug_vis/et_et002.png_vs_et_et000.png_TTA_4_1.jpg\nSaved: tta_debug_vis/et_et002.png_vs_et_et000.png_TTA_4_2.jpg\nSaved: tta_debug_vis/et_et002.png_vs_et_et000.png_TTA_4_3.jpg\n","output_type":"stream"},{"name":"stderr","text":"Matching and storing:  42%|████▏     | 8/19 [01:47<02:27, 13.37s/it]","output_type":"stream"},{"name":"stdout","text":"Saved: tta_debug_vis/et_et002.png_vs_et_et000.png_TTA_4_4.jpg\nbefore ransac the original number of key1 et_et002.png, key2et_et000.png: 68152 and 60883,              matches len is 5264: [102, 71, 4, 5, 112, 529, 404, 509, 4, 575, 69, 273, 10, 19, 489, 217, 281, 266, 211, 212, 902]\nafter ransac the matches length is 5208\net_et002.png_0-et_et000.png:5208\nSaved: tta_debug_vis/et_et008.png_vs_et_et005.png_TTA_0_0.jpg\nSaved: tta_debug_vis/et_et008.png_vs_et_et005.png_TTA_0_1.jpg\nSaved: tta_debug_vis/et_et008.png_vs_et_et005.png_TTA_0_4.jpg\nSaved: tta_debug_vis/et_et008.png_vs_et_et005.png_TTA_1_0.jpg\nSaved: tta_debug_vis/et_et008.png_vs_et_et005.png_TTA_1_1.jpg\nSaved: tta_debug_vis/et_et008.png_vs_et_et005.png_TTA_1_4.jpg\nSaved: tta_debug_vis/et_et008.png_vs_et_et005.png_TTA_2_2.jpg\nSaved: tta_debug_vis/et_et008.png_vs_et_et005.png_TTA_2_3.jpg\nSaved: tta_debug_vis/et_et008.png_vs_et_et005.png_TTA_2_4.jpg\nSaved: tta_debug_vis/et_et008.png_vs_et_et005.png_TTA_3_3.jpg\nSaved: tta_debug_vis/et_et008.png_vs_et_et005.png_TTA_4_0.jpg\nSaved: tta_debug_vis/et_et008.png_vs_et_et005.png_TTA_4_1.jpg\nSaved: tta_debug_vis/et_et008.png_vs_et_et005.png_TTA_4_2.jpg\nSaved: tta_debug_vis/et_et008.png_vs_et_et005.png_TTA_4_3.jpg\nSaved: tta_debug_vis/et_et008.png_vs_et_et005.png_TTA_4_4.jpg\nbefore ransac the original number of key1 et_et008.png, key2et_et005.png: 77543 and 80748,              matches len is 5998: [85, 311, 2, 30, 338, 107, 425, 5, 2, 286, 709, 453, 574, 3, 1, 1, 111, 50, 61, 417, 249, 480, 1298]\nafter ransac the matches length is 5950\net_et008.png_0-et_et005.png:5950\nSaved: tta_debug_vis/et_et008.png_vs_et_et000.png_TTA_2_3.jpg\nSaved: tta_debug_vis/et_et008.png_vs_et_et000.png_TTA_4_3.jpg\nbefore ransac the original number of key1 et_et008.png, key2et_et000.png: 75069 and 64181,              matches len is 358: [3, 3, 1, 3, 7, 10, 1, 1, 5, 5, 1, 1, 161, 3, 1, 2, 4, 2, 2, 3, 89, 50]\nafter ransac the matches length is 292\net_et008.png_0-et_et000.png:292\n","output_type":"stream"},{"name":"stderr","text":"Matching and storing:  47%|████▋     | 9/19 [01:55<01:57, 11.73s/it]","output_type":"stream"},{"name":"stdout","text":"before ransac the original number of key1 et_et008.png, key2another_et_another_et004.png: 61929 and 25966,              matches len is 100: [7, 5, 4, 7, 1, 4, 2, 3, 6, 1, 24, 2, 5, 3, 2, 3, 4, 17]\nafter ransac the matches length is 37\net_et008.png_0-another_et_another_et004.png:37\nSaved: tta_debug_vis/et_et005.png_vs_et_et000.png_TTA_2_2.jpg\nSaved: tta_debug_vis/et_et005.png_vs_et_et000.png_TTA_2_3.jpg\nSaved: tta_debug_vis/et_et005.png_vs_et_et000.png_TTA_4_3.jpg\nSaved: tta_debug_vis/et_et005.png_vs_et_et000.png_TTA_4_4.jpg\nbefore ransac the original number of key1 et_et005.png, key2et_et000.png: 77383 and 66166,              matches len is 516: [3, 11, 4, 3, 17, 2, 6, 8, 1, 6, 3, 9, 54, 105, 46, 1, 8, 45, 3, 9, 3, 95, 74]\nafter ransac the matches length is 422\net_et005.png_0-et_et000.png:422\nbefore ransac the original number of key1 et_et005.png, key2another_et_another_et006.png: 56172 and 22665,              matches len is 125: [2, 5, 2, 1, 3, 8, 6, 2, 4, 5, 4, 8, 23, 3, 11, 17, 21]\nafter ransac the matches length is 65\net_et005.png_0-another_et_another_et006.png:65\nbefore ransac the original number of key1 et_et005.png, key2another_et_another_et002.png: 69191 and 29031,              matches len is 126: [9, 3, 1, 1, 5, 13, 4, 3, 1, 3, 3, 1, 2, 2, 7, 2, 14, 9, 11, 5, 27]\nafter ransac the matches length is 61\net_et005.png_0-another_et_another_et002.png:61\n","output_type":"stream"},{"name":"stderr","text":"Matching and storing:  53%|█████▎    | 10/19 [02:04<01:37, 10.79s/it]","output_type":"stream"},{"name":"stdout","text":"before ransac the original number of key1 et_et005.png, key2another_et_another_et004.png: 71495 and 31204,              matches len is 131: [9, 12, 3, 4, 5, 4, 6, 4, 1, 3, 1, 1, 2, 2, 8, 19, 6, 3, 8, 1, 29]\nafter ransac the matches length is 56\net_et005.png_0-another_et_another_et004.png:56\n","output_type":"stream"},{"name":"stderr","text":"Matching and storing:  58%|█████▊    | 11/19 [02:06<01:04,  8.04s/it]","output_type":"stream"},{"name":"stdout","text":"before ransac the original number of key1 et_et000.png, key2another_et_another_et007.png: 51696 and 23878,              matches len is 56: [4, 1, 1, 3, 2, 4, 3, 2, 7, 1, 1, 5, 2, 2, 5, 9, 1, 3]\nafter ransac the matches length is 17\net_et000.png_0-another_et_another_et007.png:17\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et002.png_TTA_0_0.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et002.png_TTA_0_1.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et002.png_TTA_0_4.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et002.png_TTA_1_0.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et002.png_TTA_1_1.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et002.png_TTA_1_4.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et002.png_TTA_2_4.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et002.png_TTA_3_3.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et002.png_TTA_3_4.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et002.png_TTA_4_0.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et002.png_TTA_4_1.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et002.png_TTA_4_2.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et002.png_TTA_4_3.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et002.png_TTA_4_4.jpg\nbefore ransac the original number of key1 another_et_another_et006.png, key2another_et_another_et002.png: 28003 and 32091,              matches len is 2189: [96, 218, 7, 16, 102, 84, 187, 6, 2, 196, 7, 39, 1, 97, 6, 1, 2, 234, 140, 109, 110, 112, 75, 342]\nafter ransac the matches length is 1967\nanother_et_another_et006.png_0-another_et_another_et002.png:1967\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et004.png_TTA_0_0.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et004.png_TTA_0_4.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et004.png_TTA_1_0.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et004.png_TTA_1_1.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et004.png_TTA_1_3.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et004.png_TTA_1_4.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et004.png_TTA_2_2.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et004.png_TTA_2_4.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et004.png_TTA_3_3.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et004.png_TTA_3_4.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et004.png_TTA_4_0.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et004.png_TTA_4_1.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et004.png_TTA_4_2.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et004.png_TTA_4_3.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et004.png_TTA_4_4.jpg\nbefore ransac the original number of key1 another_et_another_et006.png, key2another_et_another_et004.png: 27133 and 33942,              matches len is 1953: [86, 29, 23, 18, 101, 94, 143, 15, 78, 269, 1, 108, 1, 103, 1, 5, 154, 128, 81, 53, 79, 76, 307]\nafter ransac the matches length is 1836\nanother_et_another_et006.png_0-another_et_another_et004.png:1836\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et007.png_TTA_0_0.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et007.png_TTA_0_1.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et007.png_TTA_0_4.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et007.png_TTA_1_1.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et007.png_TTA_1_4.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et007.png_TTA_2_2.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et007.png_TTA_2_4.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et007.png_TTA_3_3.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et007.png_TTA_3_4.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et007.png_TTA_4_0.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et007.png_TTA_4_1.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et007.png_TTA_4_2.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et007.png_TTA_4_3.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et007.png_TTA_4_4.jpg\nbefore ransac the original number of key1 another_et_another_et006.png, key2another_et_another_et007.png: 25030 and 29597,              matches len is 1912: [56, 121, 1, 118, 41, 291, 5, 97, 2, 3, 102, 1, 98, 1, 2, 160, 54, 52, 196, 68, 100, 343]\nafter ransac the matches length is 1836\nanother_et_another_et006.png_0-another_et_another_et007.png:1836\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et008.png_TTA_0_1.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et008.png_TTA_0_4.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et008.png_TTA_1_0.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et008.png_TTA_1_1.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et008.png_TTA_1_4.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et008.png_TTA_4_0.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et008.png_TTA_4_1.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et008.png_TTA_4_4.jpg\nbefore ransac the original number of key1 another_et_another_et006.png, key2another_et_another_et008.png: 23144 and 30621,              matches len is 1078: [16, 126, 84, 183, 59, 2, 131, 4, 37, 9, 1, 1, 1, 8, 1, 68, 125, 5, 8, 209]\nafter ransac the matches length is 1039\nanother_et_another_et006.png_0-another_et_another_et008.png:1039\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et003.png_TTA_0_0.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et003.png_TTA_0_1.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et003.png_TTA_0_4.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et003.png_TTA_1_0.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et003.png_TTA_1_1.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et003.png_TTA_1_3.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et003.png_TTA_1_4.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et003.png_TTA_2_4.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et003.png_TTA_3_3.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et003.png_TTA_4_0.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et003.png_TTA_4_1.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et003.png_TTA_4_4.jpg\nbefore ransac the original number of key1 another_et_another_et006.png, key2another_et_another_et003.png: 27133 and 36007,              matches len is 1530: [93, 143, 24, 4, 61, 104, 135, 2, 81, 253, 2, 26, 4, 55, 4, 1, 78, 2, 90, 67, 35, 43, 223]\nafter ransac the matches length is 1464\nanother_et_another_et006.png_0-another_et_another_et003.png:1464\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et005.png_TTA_0_0.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et005.png_TTA_0_1.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et005.png_TTA_0_4.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et005.png_TTA_1_0.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et005.png_TTA_1_1.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et005.png_TTA_1_4.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et005.png_TTA_2_2.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et005.png_TTA_2_4.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et005.png_TTA_3_3.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et005.png_TTA_3_4.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et005.png_TTA_4_0.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et005.png_TTA_4_1.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et005.png_TTA_4_4.jpg\nbefore ransac the original number of key1 another_et_another_et006.png, key2another_et_another_et005.png: 25058 and 26106,              matches len is 1977: [79, 315, 2, 7, 115, 122, 80, 25, 161, 10, 58, 69, 1, 1, 136, 136, 107, 195, 44, 46, 268]\nafter ransac the matches length is 1880\nanother_et_another_et006.png_0-another_et_another_et005.png:1880\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et001.png_TTA_0_0.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et001.png_TTA_0_1.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et001.png_TTA_0_4.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et001.png_TTA_1_0.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et001.png_TTA_1_1.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et001.png_TTA_1_4.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et001.png_TTA_2_4.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et001.png_TTA_3_3.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et001.png_TTA_3_4.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et001.png_TTA_4_0.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et001.png_TTA_4_1.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et001.png_TTA_4_2.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et001.png_TTA_4_3.jpg\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et001.png_TTA_4_4.jpg\nbefore ransac the original number of key1 another_et_another_et006.png, key2another_et_another_et001.png: 25552 and 30321,              matches len is 1931: [59, 326, 1, 10, 55, 87, 109, 1, 149, 17, 2, 36, 8, 70, 16, 150, 96, 127, 193, 64, 67, 288]\nafter ransac the matches length is 1808\nanother_et_another_et006.png_0-another_et_another_et001.png:1808\nSaved: tta_debug_vis/another_et_another_et006.png_vs_another_et_another_et009.png_TTA_0_1.jpg\n","output_type":"stream"},{"name":"stderr","text":"Matching and storing:  63%|██████▎   | 12/19 [02:14<00:57,  8.22s/it]","output_type":"stream"},{"name":"stdout","text":"before ransac the original number of key1 another_et_another_et006.png, key2another_et_another_et009.png: 23694 and 28347,              matches len is 239: [4, 64, 2, 2, 46, 22, 7, 3, 3, 9, 1, 5, 1, 1, 6, 32, 2, 3, 26]\nafter ransac the matches length is 164\nanother_et_another_et006.png_0-another_et_another_et009.png:164\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et004.png_TTA_0_0.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et004.png_TTA_0_4.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et004.png_TTA_1_1.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et004.png_TTA_1_3.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et004.png_TTA_1_4.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et004.png_TTA_2_2.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et004.png_TTA_2_4.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et004.png_TTA_3_3.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et004.png_TTA_3_4.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et004.png_TTA_4_0.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et004.png_TTA_4_1.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et004.png_TTA_4_2.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et004.png_TTA_4_3.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et004.png_TTA_4_4.jpg\nbefore ransac the original number of key1 another_et_another_et002.png, key2another_et_another_et004.png: 32630 and 35398,              matches len is 4918: [519, 4, 12, 2, 431, 4, 553, 2, 94, 374, 5, 382, 1, 239, 5, 1, 2, 308, 177, 323, 274, 160, 164, 882]\nafter ransac the matches length is 4860\nanother_et_another_et002.png_0-another_et_another_et004.png:4860\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et007.png_TTA_0_1.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et007.png_TTA_0_4.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et007.png_TTA_1_0.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et007.png_TTA_1_1.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et007.png_TTA_2_2.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et007.png_TTA_3_3.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et007.png_TTA_4_1.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et007.png_TTA_4_4.jpg\nbefore ransac the original number of key1 another_et_another_et002.png, key2another_et_another_et007.png: 31071 and 30101,              matches len is 1182: [4, 148, 4, 7, 101, 97, 102, 1, 26, 3, 70, 5, 37, 2, 1, 4, 119, 11, 15, 168, 38, 24, 195]\nafter ransac the matches length is 1128\nanother_et_another_et002.png_0-another_et_another_et007.png:1128\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et008.png_TTA_0_1.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et008.png_TTA_0_4.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et008.png_TTA_4_1.jpg\nbefore ransac the original number of key1 another_et_another_et002.png, key2another_et_another_et008.png: 24802 and 28569,              matches len is 304: [3, 101, 1, 54, 6, 15, 1, 9, 4, 2, 1, 3, 9, 7, 3, 65, 3, 17]\nafter ransac the matches length is 241\nanother_et_another_et002.png_0-another_et_another_et008.png:241\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et003.png_TTA_0_0.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et003.png_TTA_0_4.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et003.png_TTA_1_1.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et003.png_TTA_1_3.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et003.png_TTA_1_4.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et003.png_TTA_2_2.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et003.png_TTA_2_4.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et003.png_TTA_3_3.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et003.png_TTA_3_4.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et003.png_TTA_4_0.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et003.png_TTA_4_1.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et003.png_TTA_4_2.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et003.png_TTA_4_3.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et003.png_TTA_4_4.jpg\nbefore ransac the original number of key1 another_et_another_et002.png, key2another_et_another_et003.png: 28953 and 32760,              matches len is 3034: [368, 10, 16, 13, 228, 1, 300, 109, 238, 4, 283, 5, 173, 2, 168, 100, 174, 122, 96, 97, 527]\nafter ransac the matches length is 2970\nanother_et_another_et002.png_0-another_et_another_et003.png:2970\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et005.png_TTA_0_0.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et005.png_TTA_0_4.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et005.png_TTA_1_1.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et005.png_TTA_1_4.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et005.png_TTA_2_2.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et005.png_TTA_2_4.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et005.png_TTA_3_3.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et005.png_TTA_3_4.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et005.png_TTA_4_0.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et005.png_TTA_4_1.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et005.png_TTA_4_2.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et005.png_TTA_4_3.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et005.png_TTA_4_4.jpg\nbefore ransac the original number of key1 another_et_another_et002.png, key2another_et_another_et005.png: 29129 and 28398,              matches len is 4017: [378, 3, 236, 41, 525, 18, 294, 44, 1, 281, 6, 162, 7, 27, 2, 248, 185, 304, 261, 122, 129, 743]\nafter ransac the matches length is 3962\nanother_et_another_et002.png_0-another_et_another_et005.png:3962\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et001.png_TTA_0_0.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et001.png_TTA_0_4.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et001.png_TTA_1_1.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et001.png_TTA_1_4.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et001.png_TTA_2_2.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et001.png_TTA_2_4.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et001.png_TTA_3_3.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et001.png_TTA_3_4.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et001.png_TTA_4_0.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et001.png_TTA_4_1.jpg\n","output_type":"stream"},{"name":"stderr","text":"Matching and storing:  68%|██████▊   | 13/19 [02:21<00:46,  7.79s/it]","output_type":"stream"},{"name":"stdout","text":"Saved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et001.png_TTA_4_2.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et001.png_TTA_4_3.jpg\nSaved: tta_debug_vis/another_et_another_et002.png_vs_another_et_another_et001.png_TTA_4_4.jpg\nbefore ransac the original number of key1 another_et_another_et002.png, key2another_et_another_et001.png: 31071 and 30930,              matches len is 5848: [907, 31, 1, 4, 454, 31, 818, 4, 426, 41, 221, 7, 125, 8, 38, 1, 298, 132, 529, 445, 146, 154, 1027]\nafter ransac the matches length is 5762\nanother_et_another_et002.png_0-another_et_another_et001.png:5762\nSaved: tta_debug_vis/another_et_another_et010.png_vs_another_et_another_et007.png_TTA_0_1.jpg\nSaved: tta_debug_vis/another_et_another_et010.png_vs_another_et_another_et007.png_TTA_4_1.jpg\nSaved: tta_debug_vis/another_et_another_et010.png_vs_another_et_another_et007.png_TTA_4_4.jpg\nbefore ransac the original number of key1 another_et_another_et010.png, key2another_et_another_et007.png: 25702 and 30649,              matches len is 494: [8, 188, 2, 1, 20, 1, 3, 3, 9, 1, 3, 2, 7, 5, 1, 2, 3, 1, 8, 127, 1, 3, 95]\nafter ransac the matches length is 410\nanother_et_another_et010.png_0-another_et_another_et007.png:410\nSaved: tta_debug_vis/another_et_another_et010.png_vs_another_et_another_et008.png_TTA_0_1.jpg\nSaved: tta_debug_vis/another_et_another_et010.png_vs_another_et_another_et008.png_TTA_0_4.jpg\nSaved: tta_debug_vis/another_et_another_et010.png_vs_another_et_another_et008.png_TTA_1_1.jpg\nSaved: tta_debug_vis/another_et_another_et010.png_vs_another_et_another_et008.png_TTA_1_4.jpg\nSaved: tta_debug_vis/another_et_another_et010.png_vs_another_et_another_et008.png_TTA_4_1.jpg\nSaved: tta_debug_vis/another_et_another_et010.png_vs_another_et_another_et008.png_TTA_4_4.jpg\nbefore ransac the original number of key1 another_et_another_et010.png, key2another_et_another_et008.png: 20396 and 25988,              matches len is 980: [17, 306, 2, 130, 25, 68, 7, 84, 2, 2, 2, 7, 1, 1, 14, 168, 6, 138]\nafter ransac the matches length is 944\nanother_et_another_et010.png_0-another_et_another_et008.png:944\nSaved: tta_debug_vis/another_et_another_et010.png_vs_another_et_another_et009.png_TTA_0_1.jpg\nSaved: tta_debug_vis/another_et_another_et010.png_vs_another_et_another_et009.png_TTA_1_1.jpg\nSaved: tta_debug_vis/another_et_another_et010.png_vs_another_et_another_et009.png_TTA_1_4.jpg\nSaved: tta_debug_vis/another_et_another_et010.png_vs_another_et_another_et009.png_TTA_2_2.jpg\nSaved: tta_debug_vis/another_et_another_et010.png_vs_another_et_another_et009.png_TTA_3_3.jpg\nSaved: tta_debug_vis/another_et_another_et010.png_vs_another_et_another_et009.png_TTA_3_4.jpg\nSaved: tta_debug_vis/another_et_another_et010.png_vs_another_et_another_et009.png_TTA_4_1.jpg\n","output_type":"stream"},{"name":"stderr","text":"Matching and storing:  74%|███████▎  | 14/19 [02:24<00:31,  6.35s/it]","output_type":"stream"},{"name":"stdout","text":"Saved: tta_debug_vis/another_et_another_et010.png_vs_another_et_another_et009.png_TTA_4_4.jpg\nbefore ransac the original number of key1 another_et_another_et010.png, key2another_et_another_et009.png: 23459 and 30279,              matches len is 1371: [59, 3, 6, 6, 4, 343, 5, 185, 8, 3, 78, 24, 2, 14, 133, 103, 1, 138, 6, 40, 210]\nafter ransac the matches length is 1293\nanother_et_another_et010.png_0-another_et_another_et009.png:1293\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et007.png_TTA_0_1.jpg\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et007.png_TTA_0_4.jpg\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et007.png_TTA_1_1.jpg\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et007.png_TTA_3_3.jpg\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et007.png_TTA_4_1.jpg\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et007.png_TTA_4_4.jpg\nbefore ransac the original number of key1 another_et_another_et004.png, key2another_et_another_et007.png: 34188 and 30649,              matches len is 967: [1, 173, 2, 80, 4, 63, 1, 1, 4, 5, 6, 4, 16, 4, 45, 3, 68, 18, 8, 221, 28, 41, 171]\nafter ransac the matches length is 891\nanother_et_another_et004.png_0-another_et_another_et007.png:891\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et008.png_TTA_0_1.jpg\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et008.png_TTA_4_1.jpg\nbefore ransac the original number of key1 another_et_another_et004.png, key2another_et_another_et008.png: 23316 and 28691,              matches len is 307: [5, 109, 33, 2, 4, 3, 2, 5, 4, 6, 21, 1, 3, 6, 69, 34]\nafter ransac the matches length is 262\nanother_et_another_et004.png_0-another_et_another_et008.png:262\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et003.png_TTA_0_0.jpg\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et003.png_TTA_0_4.jpg\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et003.png_TTA_1_1.jpg\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et003.png_TTA_1_4.jpg\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et003.png_TTA_2_2.jpg\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et003.png_TTA_2_4.jpg\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et003.png_TTA_3_3.jpg\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et003.png_TTA_3_4.jpg\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et003.png_TTA_4_0.jpg\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et003.png_TTA_4_1.jpg\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et003.png_TTA_4_2.jpg\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et003.png_TTA_4_3.jpg\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et003.png_TTA_4_4.jpg\nbefore ransac the original number of key1 another_et_another_et004.png, key2another_et_another_et003.png: 33992 and 35821,              matches len is 3461: [367, 6, 6, 181, 4, 372, 9, 204, 10, 1, 401, 9, 182, 3, 3, 8, 282, 125, 173, 163, 170, 132, 650]\nafter ransac the matches length is 3403\nanother_et_another_et004.png_0-another_et_another_et003.png:3403\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et005.png_TTA_0_0.jpg\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et005.png_TTA_0_4.jpg\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et005.png_TTA_1_0.jpg\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et005.png_TTA_1_1.jpg\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et005.png_TTA_1_4.jpg\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et005.png_TTA_2_2.jpg\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et005.png_TTA_2_4.jpg\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et005.png_TTA_3_1.jpg\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et005.png_TTA_3_3.jpg\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et005.png_TTA_3_4.jpg\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et005.png_TTA_4_0.jpg\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et005.png_TTA_4_1.jpg\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et005.png_TTA_4_2.jpg\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et005.png_TTA_4_3.jpg\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et005.png_TTA_4_4.jpg\nbefore ransac the original number of key1 another_et_another_et004.png, key2another_et_another_et005.png: 29848 and 26855,              matches len is 4541: [573, 44, 313, 74, 435, 259, 49, 1, 244, 5, 153, 15, 109, 200, 162, 473, 285, 174, 129, 844]\nafter ransac the matches length is 4457\nanother_et_another_et004.png_0-another_et_another_et005.png:4457\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et001.png_TTA_0_0.jpg\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et001.png_TTA_0_4.jpg\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et001.png_TTA_1_1.jpg\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et001.png_TTA_1_4.jpg\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et001.png_TTA_2_0.jpg\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et001.png_TTA_2_2.jpg\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et001.png_TTA_2_4.jpg\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et001.png_TTA_3_1.jpg\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et001.png_TTA_3_3.jpg\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et001.png_TTA_3_4.jpg\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et001.png_TTA_4_0.jpg\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et001.png_TTA_4_1.jpg\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et001.png_TTA_4_2.jpg\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et001.png_TTA_4_3.jpg\nSaved: tta_debug_vis/another_et_another_et004.png_vs_another_et_another_et001.png_TTA_4_4.jpg\nbefore ransac the original number of key1 another_et_another_et004.png, key2another_et_another_et001.png: 31254 and 30710,              matches len is 4567: [596, 4, 2, 337, 28, 520, 270, 51, 1, 235, 3, 107, 11, 93, 209, 105, 518, 364, 163, 146, 804]\nafter ransac the matches length is 4535\nanother_et_another_et004.png_0-another_et_another_et001.png:4535\n","output_type":"stream"},{"name":"stderr","text":"Matching and storing:  79%|███████▉  | 15/19 [02:31<00:26,  6.54s/it]","output_type":"stream"},{"name":"stdout","text":"before ransac the original number of key1 another_et_another_et004.png, key2another_et_another_et009.png: 29640 and 28723,              matches len is 127: [4, 14, 1, 10, 2, 8, 8, 3, 8, 12, 8, 1, 7, 6, 9, 1, 5, 13, 1, 6]\nafter ransac the matches length is 45\nanother_et_another_et004.png_0-another_et_another_et009.png:45\nSaved: tta_debug_vis/another_et_another_et007.png_vs_another_et_another_et008.png_TTA_0_1.jpg\nSaved: tta_debug_vis/another_et_another_et007.png_vs_another_et_another_et008.png_TTA_0_4.jpg\nSaved: tta_debug_vis/another_et_another_et007.png_vs_another_et_another_et008.png_TTA_1_1.jpg\nSaved: tta_debug_vis/another_et_another_et007.png_vs_another_et_another_et008.png_TTA_1_4.jpg\nSaved: tta_debug_vis/another_et_another_et007.png_vs_another_et_another_et008.png_TTA_2_2.jpg\nSaved: tta_debug_vis/another_et_another_et007.png_vs_another_et_another_et008.png_TTA_2_3.jpg\nSaved: tta_debug_vis/another_et_another_et007.png_vs_another_et_another_et008.png_TTA_2_4.jpg\nSaved: tta_debug_vis/another_et_another_et007.png_vs_another_et_another_et008.png_TTA_3_3.jpg\nSaved: tta_debug_vis/another_et_another_et007.png_vs_another_et_another_et008.png_TTA_4_1.jpg\nSaved: tta_debug_vis/another_et_another_et007.png_vs_another_et_another_et008.png_TTA_4_2.jpg\nSaved: tta_debug_vis/another_et_another_et007.png_vs_another_et_another_et008.png_TTA_4_3.jpg\nSaved: tta_debug_vis/another_et_another_et007.png_vs_another_et_another_et008.png_TTA_4_4.jpg\nbefore ransac the original number of key1 another_et_another_et007.png, key2another_et_another_et008.png: 28753 and 32319,              matches len is 2206: [16, 72, 1, 2, 89, 15, 480, 1, 251, 2, 81, 74, 89, 1, 2, 79, 35, 41, 307, 59, 76, 433]\nafter ransac the matches length is 2095\nanother_et_another_et007.png_0-another_et_another_et008.png:2095\nSaved: tta_debug_vis/another_et_another_et007.png_vs_another_et_another_et003.png_TTA_1_0.jpg\nSaved: tta_debug_vis/another_et_another_et007.png_vs_another_et_another_et003.png_TTA_1_1.jpg\nSaved: tta_debug_vis/another_et_another_et007.png_vs_another_et_another_et003.png_TTA_1_4.jpg\nSaved: tta_debug_vis/another_et_another_et007.png_vs_another_et_another_et003.png_TTA_4_4.jpg\nbefore ransac the original number of key1 another_et_another_et007.png, key2another_et_another_et003.png: 29013 and 32370,              matches len is 823: [6, 3, 7, 7, 5, 174, 69, 4, 43, 265, 1, 3, 1, 10, 12, 5, 7, 13, 2, 41, 145]\nafter ransac the matches length is 751\nanother_et_another_et007.png_0-another_et_another_et003.png:751\nSaved: tta_debug_vis/another_et_another_et007.png_vs_another_et_another_et005.png_TTA_1_0.jpg\nSaved: tta_debug_vis/another_et_another_et007.png_vs_another_et_another_et005.png_TTA_1_4.jpg\nSaved: tta_debug_vis/another_et_another_et007.png_vs_another_et_another_et005.png_TTA_3_3.jpg\nSaved: tta_debug_vis/another_et_another_et007.png_vs_another_et_another_et005.png_TTA_3_4.jpg\nSaved: tta_debug_vis/another_et_another_et007.png_vs_another_et_another_et005.png_TTA_4_0.jpg\nSaved: tta_debug_vis/another_et_another_et007.png_vs_another_et_another_et005.png_TTA_4_4.jpg\nbefore ransac the original number of key1 another_et_another_et007.png, key2another_et_another_et005.png: 30649 and 29112,              matches len is 766: [8, 4, 1, 2, 4, 178, 43, 3, 16, 133, 2, 3, 17, 5, 2, 5, 68, 51, 89, 3, 1, 11, 117]\nafter ransac the matches length is 679\nanother_et_another_et007.png_0-another_et_another_et005.png:679\nSaved: tta_debug_vis/another_et_another_et007.png_vs_another_et_another_et001.png_TTA_0_1.jpg\nSaved: tta_debug_vis/another_et_another_et007.png_vs_another_et_another_et001.png_TTA_1_0.jpg\nSaved: tta_debug_vis/another_et_another_et007.png_vs_another_et_another_et001.png_TTA_1_4.jpg\nSaved: tta_debug_vis/another_et_another_et007.png_vs_another_et_another_et001.png_TTA_3_3.jpg\nSaved: tta_debug_vis/another_et_another_et007.png_vs_another_et_another_et001.png_TTA_4_0.jpg\nSaved: tta_debug_vis/another_et_another_et007.png_vs_another_et_another_et001.png_TTA_4_1.jpg\nSaved: tta_debug_vis/another_et_another_et007.png_vs_another_et_another_et001.png_TTA_4_4.jpg\nbefore ransac the original number of key1 another_et_another_et007.png, key2another_et_another_et001.png: 27490 and 29712,              matches len is 903: [5, 111, 11, 30, 132, 38, 2, 5, 117, 4, 2, 2, 16, 1, 3, 74, 24, 115, 56, 4, 151]\nafter ransac the matches length is 840\nanother_et_another_et007.png_0-another_et_another_et001.png:840\nSaved: tta_debug_vis/another_et_another_et007.png_vs_another_et_another_et009.png_TTA_0_1.jpg\nSaved: tta_debug_vis/another_et_another_et007.png_vs_another_et_another_et009.png_TTA_1_1.jpg\n","output_type":"stream"},{"name":"stderr","text":"Matching and storing:  84%|████████▍ | 16/19 [02:37<00:18,  6.19s/it]","output_type":"stream"},{"name":"stdout","text":"Saved: tta_debug_vis/another_et_another_et007.png_vs_another_et_another_et009.png_TTA_4_1.jpg\nSaved: tta_debug_vis/another_et_another_et007.png_vs_another_et_another_et009.png_TTA_4_4.jpg\nbefore ransac the original number of key1 another_et_another_et007.png, key2another_et_another_et009.png: 28465 and 30555,              matches len is 410: [9, 57, 2, 37, 16, 63, 3, 1, 17, 1, 12, 1, 3, 1, 2, 1, 6, 72, 10, 3, 93]\nafter ransac the matches length is 354\nanother_et_another_et007.png_0-another_et_another_et009.png:354\nSaved: tta_debug_vis/another_et_another_et008.png_vs_another_et_another_et003.png_TTA_1_0.jpg\nSaved: tta_debug_vis/another_et_another_et008.png_vs_another_et_another_et003.png_TTA_1_4.jpg\nbefore ransac the original number of key1 another_et_another_et008.png, key2another_et_another_et003.png: 30818 and 29182,              matches len is 279: [2, 13, 5, 19, 79, 7, 3, 13, 70, 2, 2, 1, 1, 6, 4, 3, 8, 6, 35]\nafter ransac the matches length is 215\nanother_et_another_et008.png_0-another_et_another_et003.png:215\nSaved: tta_debug_vis/another_et_another_et008.png_vs_another_et_another_et005.png_TTA_1_0.jpg\nSaved: tta_debug_vis/another_et_another_et008.png_vs_another_et_another_et005.png_TTA_1_4.jpg\nbefore ransac the original number of key1 another_et_another_et008.png, key2another_et_another_et005.png: 29785 and 23873,              matches len is 317: [2, 30, 3, 10, 3, 103, 16, 1, 59, 1, 1, 2, 3, 3, 35, 3, 1, 9, 32]\nafter ransac the matches length is 223\nanother_et_another_et008.png_0-another_et_another_et005.png:223\nSaved: tta_debug_vis/another_et_another_et008.png_vs_another_et_another_et001.png_TTA_1_0.jpg\nSaved: tta_debug_vis/another_et_another_et008.png_vs_another_et_another_et001.png_TTA_4_0.jpg\nSaved: tta_debug_vis/another_et_another_et008.png_vs_another_et_another_et001.png_TTA_4_4.jpg\nbefore ransac the original number of key1 another_et_another_et008.png, key2another_et_another_et001.png: 28386 and 22233,              matches len is 324: [15, 5, 5, 11, 81, 8, 3, 8, 47, 1, 1, 1, 2, 61, 21, 3, 51]\nafter ransac the matches length is 219\nanother_et_another_et008.png_0-another_et_another_et001.png:219\nSaved: tta_debug_vis/another_et_another_et008.png_vs_another_et_another_et009.png_TTA_0_1.jpg\nSaved: tta_debug_vis/another_et_another_et008.png_vs_another_et_another_et009.png_TTA_0_4.jpg\nSaved: tta_debug_vis/another_et_another_et008.png_vs_another_et_another_et009.png_TTA_1_1.jpg\nSaved: tta_debug_vis/another_et_another_et008.png_vs_another_et_another_et009.png_TTA_1_4.jpg\nSaved: tta_debug_vis/another_et_another_et008.png_vs_another_et_another_et009.png_TTA_2_2.jpg\nSaved: tta_debug_vis/another_et_another_et008.png_vs_another_et_another_et009.png_TTA_2_3.jpg\nSaved: tta_debug_vis/another_et_another_et008.png_vs_another_et_another_et009.png_TTA_2_4.jpg\n","output_type":"stream"},{"name":"stderr","text":"Matching and storing:  89%|████████▉ | 17/19 [02:41<00:11,  5.68s/it]","output_type":"stream"},{"name":"stdout","text":"Saved: tta_debug_vis/another_et_another_et008.png_vs_another_et_another_et009.png_TTA_4_1.jpg\nSaved: tta_debug_vis/another_et_another_et008.png_vs_another_et_another_et009.png_TTA_4_3.jpg\nSaved: tta_debug_vis/another_et_another_et008.png_vs_another_et_another_et009.png_TTA_4_4.jpg\nbefore ransac the original number of key1 another_et_another_et008.png, key2another_et_another_et009.png: 29663 and 30732,              matches len is 2125: [27, 57, 6, 1, 59, 6, 429, 271, 2, 90, 123, 107, 1, 1, 24, 2, 18, 331, 39, 87, 444]\nafter ransac the matches length is 2027\nanother_et_another_et008.png_0-another_et_another_et009.png:2027\nSaved: tta_debug_vis/another_et_another_et003.png_vs_another_et_another_et005.png_TTA_0_0.jpg\nSaved: tta_debug_vis/another_et_another_et003.png_vs_another_et_another_et005.png_TTA_0_4.jpg\nSaved: tta_debug_vis/another_et_another_et003.png_vs_another_et_another_et005.png_TTA_1_0.jpg\nSaved: tta_debug_vis/another_et_another_et003.png_vs_another_et_another_et005.png_TTA_1_1.jpg\nSaved: tta_debug_vis/another_et_another_et003.png_vs_another_et_another_et005.png_TTA_1_4.jpg\nSaved: tta_debug_vis/another_et_another_et003.png_vs_another_et_another_et005.png_TTA_2_2.jpg\nSaved: tta_debug_vis/another_et_another_et003.png_vs_another_et_another_et005.png_TTA_2_4.jpg\nSaved: tta_debug_vis/another_et_another_et003.png_vs_another_et_another_et005.png_TTA_3_1.jpg\nSaved: tta_debug_vis/another_et_another_et003.png_vs_another_et_another_et005.png_TTA_3_3.jpg\nSaved: tta_debug_vis/another_et_another_et003.png_vs_another_et_another_et005.png_TTA_3_4.jpg\nSaved: tta_debug_vis/another_et_another_et003.png_vs_another_et_another_et005.png_TTA_4_0.jpg\nSaved: tta_debug_vis/another_et_another_et003.png_vs_another_et_another_et005.png_TTA_4_1.jpg\nSaved: tta_debug_vis/another_et_another_et003.png_vs_another_et_another_et005.png_TTA_4_2.jpg\nSaved: tta_debug_vis/another_et_another_et003.png_vs_another_et_another_et005.png_TTA_4_4.jpg\nbefore ransac the original number of key1 another_et_another_et003.png, key2another_et_another_et005.png: 37560 and 29941,              matches len is 2335: [287, 1, 3, 3, 70, 51, 237, 1, 9, 142, 32, 3, 123, 11, 84, 6, 119, 88, 94, 207, 175, 73, 42, 474]\nafter ransac the matches length is 2272\nanother_et_another_et003.png_0-another_et_another_et005.png:2272\nSaved: tta_debug_vis/another_et_another_et003.png_vs_another_et_another_et001.png_TTA_0_0.jpg\nSaved: tta_debug_vis/another_et_another_et003.png_vs_another_et_another_et001.png_TTA_0_4.jpg\nSaved: tta_debug_vis/another_et_another_et003.png_vs_another_et_another_et001.png_TTA_1_1.jpg\nSaved: tta_debug_vis/another_et_another_et003.png_vs_another_et_another_et001.png_TTA_1_4.jpg\nSaved: tta_debug_vis/another_et_another_et003.png_vs_another_et_another_et001.png_TTA_2_2.jpg\nSaved: tta_debug_vis/another_et_another_et003.png_vs_another_et_another_et001.png_TTA_2_4.jpg\nSaved: tta_debug_vis/another_et_another_et003.png_vs_another_et_another_et001.png_TTA_3_1.jpg\nSaved: tta_debug_vis/another_et_another_et003.png_vs_another_et_another_et001.png_TTA_3_3.jpg\nSaved: tta_debug_vis/another_et_another_et003.png_vs_another_et_another_et001.png_TTA_3_4.jpg\nSaved: tta_debug_vis/another_et_another_et003.png_vs_another_et_another_et001.png_TTA_4_0.jpg\nSaved: tta_debug_vis/another_et_another_et003.png_vs_another_et_another_et001.png_TTA_4_1.jpg\nSaved: tta_debug_vis/another_et_another_et003.png_vs_another_et_another_et001.png_TTA_4_2.jpg\nSaved: tta_debug_vis/another_et_another_et003.png_vs_another_et_another_et001.png_TTA_4_4.jpg\nbefore ransac the original number of key1 another_et_another_et003.png, key2another_et_another_et001.png: 34717 and 31518,              matches len is 2678: [458, 1, 2, 218, 20, 261, 6, 117, 31, 7, 125, 1, 52, 4, 83, 81, 60, 313, 256, 96, 46, 440]\nafter ransac the matches length is 2627\nanother_et_another_et003.png_0-another_et_another_et001.png:2627\n","output_type":"stream"},{"name":"stderr","text":"Matching and storing:  95%|█████████▍| 18/19 [02:45<00:05,  5.02s/it]","output_type":"stream"},{"name":"stdout","text":"before ransac the original number of key1 another_et_another_et003.png, key2another_et_another_et009.png: 25484 and 24944,              matches len is 130: [2, 24, 11, 6, 10, 8, 7, 5, 1, 4, 7, 15, 7, 4, 1, 18]\nafter ransac the matches length is 47\nanother_et_another_et003.png_0-another_et_another_et009.png:47\nSaved: tta_debug_vis/another_et_another_et005.png_vs_another_et_another_et001.png_TTA_0_0.jpg\nSaved: tta_debug_vis/another_et_another_et005.png_vs_another_et_another_et001.png_TTA_0_4.jpg\nSaved: tta_debug_vis/another_et_another_et005.png_vs_another_et_another_et001.png_TTA_1_1.jpg\nSaved: tta_debug_vis/another_et_another_et005.png_vs_another_et_another_et001.png_TTA_1_4.jpg\nSaved: tta_debug_vis/another_et_another_et005.png_vs_another_et_another_et001.png_TTA_2_2.jpg\nSaved: tta_debug_vis/another_et_another_et005.png_vs_another_et_another_et001.png_TTA_2_4.jpg\nSaved: tta_debug_vis/another_et_another_et005.png_vs_another_et_another_et001.png_TTA_3_3.jpg\nSaved: tta_debug_vis/another_et_another_et005.png_vs_another_et_another_et001.png_TTA_3_4.jpg\nSaved: tta_debug_vis/another_et_another_et005.png_vs_another_et_another_et001.png_TTA_4_0.jpg\nSaved: tta_debug_vis/another_et_another_et005.png_vs_another_et_another_et001.png_TTA_4_1.jpg\n","output_type":"stream"},{"name":"stderr","text":"Matching and storing: 100%|██████████| 19/19 [02:46<00:00,  8.75s/it]","output_type":"stream"},{"name":"stdout","text":"Saved: tta_debug_vis/another_et_another_et005.png_vs_another_et_another_et001.png_TTA_4_2.jpg\nSaved: tta_debug_vis/another_et_another_et005.png_vs_another_et_another_et001.png_TTA_4_3.jpg\nSaved: tta_debug_vis/another_et_another_et005.png_vs_another_et_another_et001.png_TTA_4_4.jpg\nbefore ransac the original number of key1 another_et_another_et005.png, key2another_et_another_et001.png: 25392 and 27883,              matches len is 4539: [520, 14, 5, 302, 3, 692, 4, 337, 222, 3, 99, 3, 2, 348, 125, 336, 392, 157, 186, 789]\nafter ransac the matches length is 4498\nanother_et_another_et005.png_0-another_et_another_et001.png:4498\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Local feature extracting and matching. Done in 166.7604 sec\n\n--- Loading remapped matches from HDF5 ---\n","output_type":"stream"},{"name":"stderr","text":"Loading matches: 100%|██████████| 19/19 [00:00<00:00, 1267.60it/s]","output_type":"stream"},{"name":"stdout","text":"\n--- Drawing Keypoints ---\nKeypoints drawn on outliers_out_et001.png, saved to visualization_output/visualization_output/keypoints_outliers_out_et001.png\nNo keypoints found for outliers_out_et003.png in unified keypoints file.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Keypoints drawn on outliers_out_et002.png, saved to visualization_output/visualization_output/keypoints_outliers_out_et002.png\nKeypoints drawn on et_et007.png, saved to visualization_output/visualization_output/keypoints_et_et007.png\nKeypoints drawn on et_et003.png, saved to visualization_output/visualization_output/keypoints_et_et003.png\nKeypoints drawn on et_et006.png, saved to visualization_output/visualization_output/keypoints_et_et006.png\nKeypoints drawn on et_et001.png, saved to visualization_output/visualization_output/keypoints_et_et001.png\nKeypoints drawn on et_et004.png, saved to visualization_output/visualization_output/keypoints_et_et004.png\nKeypoints drawn on et_et002.png, saved to visualization_output/visualization_output/keypoints_et_et002.png\nKeypoints drawn on et_et008.png, saved to visualization_output/visualization_output/keypoints_et_et008.png\nKeypoints drawn on et_et005.png, saved to visualization_output/visualization_output/keypoints_et_et005.png\nKeypoints drawn on et_et000.png, saved to visualization_output/visualization_output/keypoints_et_et000.png\nKeypoints drawn on another_et_another_et006.png, saved to visualization_output/visualization_output/keypoints_another_et_another_et006.png\nKeypoints drawn on another_et_another_et002.png, saved to visualization_output/visualization_output/keypoints_another_et_another_et002.png\nKeypoints drawn on another_et_another_et010.png, saved to visualization_output/visualization_output/keypoints_another_et_another_et010.png\nKeypoints drawn on another_et_another_et004.png, saved to visualization_output/visualization_output/keypoints_another_et_another_et004.png\nKeypoints drawn on another_et_another_et007.png, saved to visualization_output/visualization_output/keypoints_another_et_another_et007.png\nKeypoints drawn on another_et_another_et008.png, saved to visualization_output/visualization_output/keypoints_another_et_another_et008.png\nKeypoints drawn on another_et_another_et003.png, saved to visualization_output/visualization_output/keypoints_another_et_another_et003.png\nKeypoints drawn on another_et_another_et005.png, saved to visualization_output/visualization_output/keypoints_another_et_another_et005.png\nKeypoints drawn on another_et_another_et001.png, saved to visualization_output/visualization_output/keypoints_another_et_another_et001.png\nKeypoints drawn on another_et_another_et009.png, saved to visualization_output/visualization_output/keypoints_another_et_another_et009.png\n\n--- Drawing Matches ---\nMatches drawn between another_et_another_et002.png and another_et_another_et001.png, saved to visualization_output/visualization_output/matches_another_et_another_et002.png_another_et_another_et001.png.png\nMatches drawn between another_et_another_et002.png and another_et_another_et003.png, saved to visualization_output/visualization_output/matches_another_et_another_et002.png_another_et_another_et003.png.png\nMatches drawn between another_et_another_et002.png and another_et_another_et004.png, saved to visualization_output/visualization_output/matches_another_et_another_et002.png_another_et_another_et004.png.png\nMatches drawn between another_et_another_et002.png and another_et_another_et005.png, saved to visualization_output/visualization_output/matches_another_et_another_et002.png_another_et_another_et005.png.png\nMatches drawn between another_et_another_et002.png and another_et_another_et007.png, saved to visualization_output/visualization_output/matches_another_et_another_et002.png_another_et_another_et007.png.png\nMatches drawn between another_et_another_et002.png and another_et_another_et008.png, saved to visualization_output/visualization_output/matches_another_et_another_et002.png_another_et_another_et008.png.png\nMatches drawn between another_et_another_et003.png and another_et_another_et001.png, saved to visualization_output/visualization_output/matches_another_et_another_et003.png_another_et_another_et001.png.png\nMatches drawn between another_et_another_et003.png and another_et_another_et005.png, saved to visualization_output/visualization_output/matches_another_et_another_et003.png_another_et_another_et005.png.png\nMatches drawn between another_et_another_et003.png and another_et_another_et009.png, saved to visualization_output/visualization_output/matches_another_et_another_et003.png_another_et_another_et009.png.png\nMatches drawn between another_et_another_et004.png and another_et_another_et001.png, saved to visualization_output/visualization_output/matches_another_et_another_et004.png_another_et_another_et001.png.png\nMatches drawn between another_et_another_et004.png and another_et_another_et003.png, saved to visualization_output/visualization_output/matches_another_et_another_et004.png_another_et_another_et003.png.png\nMatches drawn between another_et_another_et004.png and another_et_another_et005.png, saved to visualization_output/visualization_output/matches_another_et_another_et004.png_another_et_another_et005.png.png\nMatches drawn between another_et_another_et004.png and another_et_another_et007.png, saved to visualization_output/visualization_output/matches_another_et_another_et004.png_another_et_another_et007.png.png\nMatches drawn between another_et_another_et004.png and another_et_another_et008.png, saved to visualization_output/visualization_output/matches_another_et_another_et004.png_another_et_another_et008.png.png\nMatches drawn between another_et_another_et004.png and another_et_another_et009.png, saved to visualization_output/visualization_output/matches_another_et_another_et004.png_another_et_another_et009.png.png\nMatches drawn between another_et_another_et005.png and another_et_another_et001.png, saved to visualization_output/visualization_output/matches_another_et_another_et005.png_another_et_another_et001.png.png\nMatches drawn between another_et_another_et006.png and another_et_another_et001.png, saved to visualization_output/visualization_output/matches_another_et_another_et006.png_another_et_another_et001.png.png\nMatches drawn between another_et_another_et006.png and another_et_another_et002.png, saved to visualization_output/visualization_output/matches_another_et_another_et006.png_another_et_another_et002.png.png\nMatches drawn between another_et_another_et006.png and another_et_another_et003.png, saved to visualization_output/visualization_output/matches_another_et_another_et006.png_another_et_another_et003.png.png\nMatches drawn between another_et_another_et006.png and another_et_another_et004.png, saved to visualization_output/visualization_output/matches_another_et_another_et006.png_another_et_another_et004.png.png\nMatches drawn between another_et_another_et006.png and another_et_another_et005.png, saved to visualization_output/visualization_output/matches_another_et_another_et006.png_another_et_another_et005.png.png\nMatches drawn between another_et_another_et006.png and another_et_another_et007.png, saved to visualization_output/visualization_output/matches_another_et_another_et006.png_another_et_another_et007.png.png\nMatches drawn between another_et_another_et006.png and another_et_another_et008.png, saved to visualization_output/visualization_output/matches_another_et_another_et006.png_another_et_another_et008.png.png\nMatches drawn between another_et_another_et006.png and another_et_another_et009.png, saved to visualization_output/visualization_output/matches_another_et_another_et006.png_another_et_another_et009.png.png\nMatches drawn between another_et_another_et007.png and another_et_another_et001.png, saved to visualization_output/visualization_output/matches_another_et_another_et007.png_another_et_another_et001.png.png\nMatches drawn between another_et_another_et007.png and another_et_another_et003.png, saved to visualization_output/visualization_output/matches_another_et_another_et007.png_another_et_another_et003.png.png\nMatches drawn between another_et_another_et007.png and another_et_another_et005.png, saved to visualization_output/visualization_output/matches_another_et_another_et007.png_another_et_another_et005.png.png\nMatches drawn between another_et_another_et007.png and another_et_another_et008.png, saved to visualization_output/visualization_output/matches_another_et_another_et007.png_another_et_another_et008.png.png\nMatches drawn between another_et_another_et007.png and another_et_another_et009.png, saved to visualization_output/visualization_output/matches_another_et_another_et007.png_another_et_another_et009.png.png\nMatches drawn between another_et_another_et008.png and another_et_another_et001.png, saved to visualization_output/visualization_output/matches_another_et_another_et008.png_another_et_another_et001.png.png\nMatches drawn between another_et_another_et008.png and another_et_another_et003.png, saved to visualization_output/visualization_output/matches_another_et_another_et008.png_another_et_another_et003.png.png\nMatches drawn between another_et_another_et008.png and another_et_another_et005.png, saved to visualization_output/visualization_output/matches_another_et_another_et008.png_another_et_another_et005.png.png\nMatches drawn between another_et_another_et008.png and another_et_another_et009.png, saved to visualization_output/visualization_output/matches_another_et_another_et008.png_another_et_another_et009.png.png\nMatches drawn between another_et_another_et010.png and another_et_another_et007.png, saved to visualization_output/visualization_output/matches_another_et_another_et010.png_another_et_another_et007.png.png\nMatches drawn between another_et_another_et010.png and another_et_another_et008.png, saved to visualization_output/visualization_output/matches_another_et_another_et010.png_another_et_another_et008.png.png\nMatches drawn between another_et_another_et010.png and another_et_another_et009.png, saved to visualization_output/visualization_output/matches_another_et_another_et010.png_another_et_another_et009.png.png\nMatches drawn between et_et000.png and another_et_another_et007.png, saved to visualization_output/visualization_output/matches_et_et000.png_another_et_another_et007.png.png\nMatches drawn between et_et001.png and et_et000.png, saved to visualization_output/visualization_output/matches_et_et001.png_et_et000.png.png\nMatches drawn between et_et001.png and et_et002.png, saved to visualization_output/visualization_output/matches_et_et001.png_et_et002.png.png\nMatches drawn between et_et001.png and et_et004.png, saved to visualization_output/visualization_output/matches_et_et001.png_et_et004.png.png\nMatches drawn between et_et001.png and et_et005.png, saved to visualization_output/visualization_output/matches_et_et001.png_et_et005.png.png\nMatches drawn between et_et001.png and et_et008.png, saved to visualization_output/visualization_output/matches_et_et001.png_et_et008.png.png\nMatches drawn between et_et002.png and et_et000.png, saved to visualization_output/visualization_output/matches_et_et002.png_et_et000.png.png\nMatches drawn between et_et002.png and et_et005.png, saved to visualization_output/visualization_output/matches_et_et002.png_et_et005.png.png\nMatches drawn between et_et002.png and et_et008.png, saved to visualization_output/visualization_output/matches_et_et002.png_et_et008.png.png\nMatches drawn between et_et003.png and et_et000.png, saved to visualization_output/visualization_output/matches_et_et003.png_et_et000.png.png\nMatches drawn between et_et003.png and et_et001.png, saved to visualization_output/visualization_output/matches_et_et003.png_et_et001.png.png\nMatches drawn between et_et003.png and et_et002.png, saved to visualization_output/visualization_output/matches_et_et003.png_et_et002.png.png\nMatches drawn between et_et003.png and et_et004.png, saved to visualization_output/visualization_output/matches_et_et003.png_et_et004.png.png\nMatches drawn between et_et003.png and et_et005.png, saved to visualization_output/visualization_output/matches_et_et003.png_et_et005.png.png\nMatches drawn between et_et003.png and et_et006.png, saved to visualization_output/visualization_output/matches_et_et003.png_et_et006.png.png\nMatches drawn between et_et003.png and et_et008.png, saved to visualization_output/visualization_output/matches_et_et003.png_et_et008.png.png\nMatches drawn between et_et004.png and another_et_another_et004.png, saved to visualization_output/visualization_output/matches_et_et004.png_another_et_another_et004.png.png\nMatches drawn between et_et004.png and et_et000.png, saved to visualization_output/visualization_output/matches_et_et004.png_et_et000.png.png\nMatches drawn between et_et004.png and et_et002.png, saved to visualization_output/visualization_output/matches_et_et004.png_et_et002.png.png\nMatches drawn between et_et004.png and et_et005.png, saved to visualization_output/visualization_output/matches_et_et004.png_et_et005.png.png\nMatches drawn between et_et004.png and et_et008.png, saved to visualization_output/visualization_output/matches_et_et004.png_et_et008.png.png\nMatches drawn between et_et005.png and another_et_another_et002.png, saved to visualization_output/visualization_output/matches_et_et005.png_another_et_another_et002.png.png\nMatches drawn between et_et005.png and another_et_another_et004.png, saved to visualization_output/visualization_output/matches_et_et005.png_another_et_another_et004.png.png\nMatches drawn between et_et005.png and another_et_another_et006.png, saved to visualization_output/visualization_output/matches_et_et005.png_another_et_another_et006.png.png\nMatches drawn between et_et005.png and et_et000.png, saved to visualization_output/visualization_output/matches_et_et005.png_et_et000.png.png\nMatches drawn between et_et006.png and another_et_another_et004.png, saved to visualization_output/visualization_output/matches_et_et006.png_another_et_another_et004.png.png\nMatches drawn between et_et006.png and et_et000.png, saved to visualization_output/visualization_output/matches_et_et006.png_et_et000.png.png\nMatches drawn between et_et006.png and et_et001.png, saved to visualization_output/visualization_output/matches_et_et006.png_et_et001.png.png\nMatches drawn between et_et006.png and et_et002.png, saved to visualization_output/visualization_output/matches_et_et006.png_et_et002.png.png\nMatches drawn between et_et006.png and et_et004.png, saved to visualization_output/visualization_output/matches_et_et006.png_et_et004.png.png\nMatches drawn between et_et006.png and et_et005.png, saved to visualization_output/visualization_output/matches_et_et006.png_et_et005.png.png\nMatches drawn between et_et006.png and et_et008.png, saved to visualization_output/visualization_output/matches_et_et006.png_et_et008.png.png\nMatches drawn between et_et007.png and another_et_another_et002.png, saved to visualization_output/visualization_output/matches_et_et007.png_another_et_another_et002.png.png\nMatches drawn between et_et007.png and et_et000.png, saved to visualization_output/visualization_output/matches_et_et007.png_et_et000.png.png\nMatches drawn between et_et007.png and et_et001.png, saved to visualization_output/visualization_output/matches_et_et007.png_et_et001.png.png\nMatches drawn between et_et007.png and et_et002.png, saved to visualization_output/visualization_output/matches_et_et007.png_et_et002.png.png\nMatches drawn between et_et007.png and et_et003.png, saved to visualization_output/visualization_output/matches_et_et007.png_et_et003.png.png\nMatches drawn between et_et007.png and et_et004.png, saved to visualization_output/visualization_output/matches_et_et007.png_et_et004.png.png\nMatches drawn between et_et007.png and et_et005.png, saved to visualization_output/visualization_output/matches_et_et007.png_et_et005.png.png\nMatches drawn between et_et007.png and et_et006.png, saved to visualization_output/visualization_output/matches_et_et007.png_et_et006.png.png\nMatches drawn between et_et007.png and et_et008.png, saved to visualization_output/visualization_output/matches_et_et007.png_et_et008.png.png\nMatches drawn between et_et008.png and another_et_another_et004.png, saved to visualization_output/visualization_output/matches_et_et008.png_another_et_another_et004.png.png\nMatches drawn between et_et008.png and et_et000.png, saved to visualization_output/visualization_output/matches_et_et008.png_et_et000.png.png\nMatches drawn between et_et008.png and et_et005.png, saved to visualization_output/visualization_output/matches_et_et008.png_et_et005.png.png\nMatches drawn between outliers_out_et001.png and another_et_another_et001.png, saved to visualization_output/visualization_output/matches_outliers_out_et001.png_another_et_another_et001.png.png\nMatches drawn between outliers_out_et001.png and another_et_another_et002.png, saved to visualization_output/visualization_output/matches_outliers_out_et001.png_another_et_another_et002.png.png\nMatches drawn between outliers_out_et001.png and another_et_another_et003.png, saved to visualization_output/visualization_output/matches_outliers_out_et001.png_another_et_another_et003.png.png\nMatches drawn between outliers_out_et001.png and outliers_out_et002.png, saved to visualization_output/visualization_output/matches_outliers_out_et001.png_outliers_out_et002.png.png\nMatches drawn between outliers_out_et002.png and another_et_another_et004.png, saved to visualization_output/visualization_output/matches_outliers_out_et002.png_another_et_another_et004.png.png\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 21/21 [00:00<00:00, 62.46it/s]\n 50%|████▉     | 85/171 [00:00<00:00, 2880.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"colmap database\nA process in the process pool was terminated abruptly while the future was running or pending.\nDataset \"ETs\" -> Failed!\nSkipping \"stairs\"\n\nResults\nDataset \"ETs\" -> Failed!\n\nTimings\nrotation_detection -> total=49.53 sec.\nshortlisting -> total=2.07 sec.\nfeature_matching -> total=166.47 sec.\nRANSAC -> total=0.00 sec.\nReconstruction -> total=0.00 sec.\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"# Helpers\narray_to_str = lambda array: ';'.join([f\"{x:.09f}\" for x in array])\nnone_to_str = lambda n: ';'.join(['nan'] * n)\n\nsubmission_file = '/kaggle/working/submission.csv'\nwith open(submission_file, 'w') as f:\n    if is_train:\n        f.write('dataset,scene,image,rotation_matrix,translation_vector\\n')\n        for dataset, predictions in samples.items():\n            for prediction in predictions:\n                cluster_name = 'outliers' if prediction.cluster_index is None else f'cluster{prediction.cluster_index}'\n\n                # ✅ `rotation` is a list of lists, flatten it\n                if prediction.rotation is None:\n                    rotation_str = none_to_str(9)\n                else:\n                    rotation_flat =  prediction.rotation.flatten()  # flatten 3x3 list -> 9 elems\n                    rotation_str = array_to_str(rotation_flat)\n\n                # ✅ `translation` is a flat list\n                if prediction.translation is None:\n                    translation_str = none_to_str(3)\n                else:\n                    translation_str = array_to_str(prediction.translation)\n\n                f.write(f'{prediction.dataset},{cluster_name},{prediction.filename},{rotation_str},{translation_str}\\n')\n    else:\n        f.write('image_id,dataset,scene,image,rotation_matrix,translation_vector\\n')\n        for dataset, predictions in samples.items():\n            for prediction in predictions:\n                cluster_name = 'outliers' if prediction.cluster_index is None else f'cluster{prediction.cluster_index}'\n\n                if prediction.rotation is None:\n                    rotation_str = none_to_str(9)\n                else:\n                    rotation_flat =  prediction.rotation.flatten()\n                    rotation_str = array_to_str(rotation_flat)\n\n                if prediction.translation is None:\n                    translation_str = none_to_str(3)\n                else:\n                    translation_str = array_to_str(prediction.translation)\n\n                f.write(f'{prediction.image_id},{prediction.dataset},{cluster_name},{prediction.filename},{rotation_str},{translation_str}\\n')\n\n# Preview the output\n!head {submission_file}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T22:58:38.599321Z","iopub.execute_input":"2025-06-10T22:58:38.599771Z","iopub.status.idle":"2025-06-10T22:58:38.776300Z","shell.execute_reply.started":"2025-06-10T22:58:38.599726Z","shell.execute_reply":"2025-06-10T22:58:38.775248Z"}},"outputs":[{"name":"stdout","text":"dataset,scene,image,rotation_matrix,translation_vector\nimc2023_haiper,outliers,fountain_image_116.png,nan;nan;nan;nan;nan;nan;nan;nan;nan,nan;nan;nan\nimc2023_haiper,outliers,fountain_image_108.png,nan;nan;nan;nan;nan;nan;nan;nan;nan,nan;nan;nan\nimc2023_haiper,outliers,fountain_image_101.png,nan;nan;nan;nan;nan;nan;nan;nan;nan,nan;nan;nan\nimc2023_haiper,outliers,fountain_image_082.png,nan;nan;nan;nan;nan;nan;nan;nan;nan,nan;nan;nan\nimc2023_haiper,outliers,fountain_image_071.png,nan;nan;nan;nan;nan;nan;nan;nan;nan,nan;nan;nan\nimc2023_haiper,outliers,fountain_image_025.png,nan;nan;nan;nan;nan;nan;nan;nan;nan,nan;nan;nan\nimc2023_haiper,outliers,fountain_image_000.png,nan;nan;nan;nan;nan;nan;nan;nan;nan,nan;nan;nan\nimc2023_haiper,outliers,fountain_image_007.png,nan;nan;nan;nan;nan;nan;nan;nan;nan,nan;nan;nan\nimc2023_haiper,outliers,fountain_image_012.png,nan;nan;nan;nan;nan;nan;nan;nan;nan,nan;nan;nan\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"# Definitely Compute results if running on the training set.\n# Do not do this when submitting a notebook for scoring. All you have to do is save your submission to /kaggle/working/submission.csv.\n\nif is_train:\n    t = time()\n    final_score, dataset_scores = metric.score(\n        gt_csv='/kaggle/input/image-matching-challenge-2025/train_labels.csv',\n        user_csv=submission_file,\n        thresholds_csv='/kaggle/input/image-matching-challenge-2025/train_thresholds.csv',\n        mask_csv=None if is_train else os.path.join(data_dir, 'mask.csv'),\n        inl_cf=0,\n        strict_cf=-1,\n        verbose=True,\n    )\n    print(f'Computed metric in: {time() - t:.02f} sec.')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T22:58:38.777331Z","iopub.execute_input":"2025-06-10T22:58:38.777622Z","iopub.status.idle":"2025-06-10T22:58:38.851157Z","shell.execute_reply.started":"2025-06-10T22:58:38.777585Z","shell.execute_reply":"2025-06-10T22:58:38.850399Z"}},"outputs":[{"name":"stdout","text":"imc2023_haiper: score=0.00% (mAA=0.00%, clusterness=100.00%)\nimc2023_heritage: score=0.00% (mAA=0.00%, clusterness=100.00%)\nimc2023_theather_imc2024_church: score=0.00% (mAA=0.00%, clusterness=100.00%)\nimc2024_dioscuri_baalshamin: score=0.00% (mAA=0.00%, clusterness=100.00%)\nimc2024_lizard_pond: score=0.00% (mAA=0.00%, clusterness=100.00%)\npt_brandenburg_british_buckingham: score=0.00% (mAA=0.00%, clusterness=100.00%)\npt_piazzasanmarco_grandplace: score=0.00% (mAA=0.00%, clusterness=100.00%)\npt_sacrecoeur_trevi_tajmahal: score=0.00% (mAA=0.00%, clusterness=100.00%)\npt_stpeters_stpauls: score=0.00% (mAA=0.00%, clusterness=100.00%)\namy_gardens: score=0.00% (mAA=0.00%, clusterness=100.00%)\nfbk_vineyard: score=0.00% (mAA=0.00%, clusterness=100.00%)\nETs: score=0.00% (mAA=0.00%, clusterness=100.00%)\nstairs: score=0.00% (mAA=0.00%, clusterness=100.00%)\nAverage over all datasets: score=0.00% (mAA=0.00%, clusterness=100.00%)\nComputed metric in: 0.07 sec.\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}