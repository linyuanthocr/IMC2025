{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c0fe2cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T07:29:04.402893Z",
     "iopub.status.busy": "2025-06-04T07:29:04.402578Z",
     "iopub.status.idle": "2025-06-04T07:29:16.642211Z",
     "shell.execute_reply": "2025-06-04T07:29:16.640958Z"
    },
    "papermill": {
     "duration": 12.247825,
     "end_time": "2025-06-04T07:29:16.643936",
     "exception": false,
     "start_time": "2025-06-04T07:29:04.396111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/imc2024-packages-lightglue-rerun-kornia/kornia-0.7.2-py2.py3-none-any.whl\r\n",
      "Processing /kaggle/input/imc2024-packages-lightglue-rerun-kornia/kornia_moons-0.2.9-py3-none-any.whl\r\n",
      "Processing /kaggle/input/imc2024-packages-lightglue-rerun-kornia/kornia_rs-0.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Processing /kaggle/input/imc2024-packages-lightglue-rerun-kornia/lightglue-0.0-py3-none-any.whl\r\n",
      "Processing /kaggle/input/imc2024-packages-lightglue-rerun-kornia/pycolmap-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Processing /kaggle/input/imc2024-packages-lightglue-rerun-kornia/rerun_sdk-0.15.0a2-cp38-abi3-manylinux_2_31_x86_64.whl\r\n",
      "Installing collected packages: rerun-sdk, pycolmap, lightglue, kornia-rs, kornia-moons, kornia\r\n",
      "  Attempting uninstall: kornia-rs\r\n",
      "    Found existing installation: kornia_rs 0.1.8\r\n",
      "    Uninstalling kornia_rs-0.1.8:\r\n",
      "      Successfully uninstalled kornia_rs-0.1.8\r\n",
      "  Attempting uninstall: kornia\r\n",
      "    Found existing installation: kornia 0.8.0\r\n",
      "    Uninstalling kornia-0.8.0:\r\n",
      "      Successfully uninstalled kornia-0.8.0\r\n",
      "Successfully installed kornia-0.7.2 kornia-moons-0.2.9 kornia-rs-0.1.2 lightglue-0.0 pycolmap-0.6.1 rerun-sdk-0.15.0a2\r\n",
      "Processing /kaggle/input/imc2025-deps/imc2025-deps/yacs-0.1.8-py3-none-any.whl\r\n",
      "Installing collected packages: yacs\r\n",
      "Successfully installed yacs-0.1.8\r\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT \n",
    "#Install dependencies and copy model weights to run the notebook without internet access when submitting to the competition.\n",
    "\n",
    "!pip install --no-index /kaggle/input/imc2024-packages-lightglue-rerun-kornia/* --no-deps\n",
    "!pip install --no-index /kaggle/input/imc2025-deps/imc2025-deps/* --no-deps\n",
    "!mkdir -p /root/.cache/torch/hub/checkpoints\n",
    "!cp /kaggle/input/resnet60/pytorch/default/1/resnet50-0676ba61.pth /root/.cache/torch/hub/checkpoints/\n",
    "!cp /kaggle/input/superpoint/pytorch/default/1/superpoint_v1.pth /root/.cache/torch/hub/checkpoints/\n",
    "!cp /kaggle/input/aliked/pytorch/aliked-n16/1/aliked-n16.pth /root/.cache/torch/hub/checkpoints/\n",
    "!mkdir -p /root/.cache/torch/hub/netvlad/netvlad\n",
    "!cp /kaggle/input/netvlad/other/default/1/Pitts30K_struct.mat /root/.cache/torch/hub/netvlad/VGG16-NetVLAD-Pitts30K.mat\n",
    "!cp /kaggle/input/lightglue/pytorch/aliked/1/aliked_lightglue.pth /root/.cache/torch/hub/checkpoints/\n",
    "!cp /kaggle/input/lightglue/pytorch/aliked/1/aliked_lightglue.pth /root/.cache/torch/hub/checkpoints/aliked_lightglue_v0-1_arxiv.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29a3fde0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T07:29:16.655023Z",
     "iopub.status.busy": "2025-06-04T07:29:16.654750Z",
     "iopub.status.idle": "2025-06-04T07:29:25.985901Z",
     "shell.execute_reply": "2025-06-04T07:29:25.984850Z"
    },
    "papermill": {
     "duration": 9.338365,
     "end_time": "2025-06-04T07:29:25.987632",
     "exception": false,
     "start_time": "2025-06-04T07:29:16.649267",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python -m pip install --no-index --find-links=/kaggle/input/pkg-check-orientation/ check_orientation==0.0.5 > /dev/null\n",
    "!cp /kaggle/input/pkg-check-orientation/2020-11-16_resnext50_32x4d.zip /root/.cache/torch/hub/checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "423b3aac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T07:29:25.998631Z",
     "iopub.status.busy": "2025-06-04T07:29:25.998338Z",
     "iopub.status.idle": "2025-06-04T07:29:26.835399Z",
     "shell.execute_reply": "2025-06-04T07:29:26.834273Z"
    },
    "papermill": {
     "duration": 0.844384,
     "end_time": "2025-06-04T07:29:26.837194",
     "exception": false,
     "start_time": "2025-06-04T07:29:25.992810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: lightglue 0.0\r\n",
      "Uninstalling lightglue-0.0:\r\n",
      "  Successfully uninstalled lightglue-0.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y lightglue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21798448",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T07:29:26.855871Z",
     "iopub.status.busy": "2025-06-04T07:29:26.855415Z",
     "iopub.status.idle": "2025-06-04T07:29:39.966292Z",
     "shell.execute_reply": "2025-06-04T07:29:39.965448Z"
    },
    "papermill": {
     "duration": 13.122597,
     "end_time": "2025-06-04T07:29:39.968088",
     "exception": false,
     "start_time": "2025-06-04T07:29:26.845491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///root/Hierarchical-Localization\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.10/dist-packages (from hloc==1.5) (2.5.1+cu121)\r\n",
      "Requirement already satisfied: torchvision>=0.3 in /usr/local/lib/python3.10/dist-packages (from hloc==1.5) (0.20.1+cu121)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from hloc==1.5) (1.26.4)\r\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from hloc==1.5) (4.10.0.84)\r\n",
      "Requirement already satisfied: tqdm>=4.36.0 in /usr/local/lib/python3.10/dist-packages (from hloc==1.5) (4.67.1)\r\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from hloc==1.5) (3.7.5)\r\n",
      "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from hloc==1.5) (5.24.1)\r\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from hloc==1.5) (1.13.1)\r\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from hloc==1.5) (3.12.1)\r\n",
      "Requirement already satisfied: pycolmap>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from hloc==1.5) (0.6.1)\r\n",
      "Requirement already satisfied: kornia>=0.6.11 in /usr/local/lib/python3.10/dist-packages (from hloc==1.5) (0.7.2)\r\n",
      "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (from hloc==1.5) (5.2.0)\r\n",
      "Requirement already satisfied: kornia-rs>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from kornia>=0.6.11->hloc==1.5) (0.1.2)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from kornia>=0.6.11->hloc==1.5) (24.2)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->hloc==1.5) (3.17.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->hloc==1.5) (4.12.2)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->hloc==1.5) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->hloc==1.5) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->hloc==1.5) (2024.12.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->hloc==1.5) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.1->hloc==1.5) (1.3.0)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.3->hloc==1.5) (11.0.0)\r\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown->hloc==1.5) (4.12.3)\r\n",
      "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown->hloc==1.5) (2.32.3)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->hloc==1.5) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->hloc==1.5) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->hloc==1.5) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->hloc==1.5) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->hloc==1.5) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->hloc==1.5) (2.4.1)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->hloc==1.5) (1.3.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->hloc==1.5) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->hloc==1.5) (4.55.3)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->hloc==1.5) (1.4.7)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->hloc==1.5) (3.2.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->hloc==1.5) (2.9.0.post0)\r\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->hloc==1.5) (9.0.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->hloc==1.5) (1.17.0)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown->hloc==1.5) (2.6)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.1->hloc==1.5) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->hloc==1.5) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->hloc==1.5) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->hloc==1.5) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->hloc==1.5) (2024.2.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->hloc==1.5) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->hloc==1.5) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->hloc==1.5) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->hloc==1.5) (2025.1.31)\r\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->hloc==1.5) (1.7.1)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->hloc==1.5) (2024.2.0)\r\n",
      "Installing collected packages: hloc\r\n",
      "  Running setup.py develop for hloc\r\n",
      "Successfully installed hloc-1.5\r\n"
     ]
    }
   ],
   "source": [
    "!cp -r /kaggle/input/hloc-with-rdd/pytorch/default/22/Hierarchical-Localization /root/\n",
    "!cd /root/Hierarchical-Localization && python -m pip install -e .\n",
    "import sys\n",
    "sys.path.append('/root/Hierarchical-Localization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0affb77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T07:29:39.980079Z",
     "iopub.status.busy": "2025-06-04T07:29:39.979835Z",
     "iopub.status.idle": "2025-06-04T07:30:30.037164Z",
     "shell.execute_reply": "2025-06-04T07:30:30.035968Z"
    },
    "papermill": {
     "duration": 50.065191,
     "end_time": "2025-06-04T07:30:30.038969",
     "exception": false,
     "start_time": "2025-06-04T07:29:39.973778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///root/Hierarchical-Localization/third_party/rdd/RDD/models/ops\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Installing collected packages: MultiScaleDeformableAttention\r\n",
      "  Running setup.py develop for MultiScaleDeformableAttention\r\n",
      "Successfully installed MultiScaleDeformableAttention-1.0\r\n"
     ]
    }
   ],
   "source": [
    "! cd /root/Hierarchical-Localization/third_party/rdd/RDD/models/ops && python -m pip install -e .\n",
    "sys.path.append('/root/Hierarchical-Localization/third_party/rdd/RDD/models/ops')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75d15c2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T07:30:30.051520Z",
     "iopub.status.busy": "2025-06-04T07:30:30.051236Z",
     "iopub.status.idle": "2025-06-04T07:30:36.073143Z",
     "shell.execute_reply": "2025-06-04T07:30:36.072464Z"
    },
    "papermill": {
     "duration": 6.029709,
     "end_time": "2025-06-04T07:30:36.074684",
     "exception": false,
     "start_time": "2025-06-04T07:30:30.044975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/kornia/feature/lightglue.py:44: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from time import time, sleep\n",
    "import gc\n",
    "import numpy as np\n",
    "import h5py\n",
    "import dataclasses\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import kornia as K\n",
    "import kornia.feature as KF\n",
    "\n",
    "# IMPORTANT Utilities: importing data into colmap and competition metric\n",
    "import pycolmap\n",
    "sys.path.append('/kaggle/input/imc25-utils')\n",
    "from database import *\n",
    "from h5_to_db import *\n",
    "import metric\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from torch.backends import cudnn\n",
    "import importlib\n",
    "import shutil\n",
    "from hloc import (\n",
    "    extract_features,\n",
    "    match_features,\n",
    "    reconstruction,\n",
    "    visualization,\n",
    "    pairs_from_retrieval,\n",
    "    pairs_from_exhaustive\n",
    ")\n",
    "from hloc.reconstruction import *\n",
    "from hloc.utils.parsers import names_to_pair, names_to_pair_old, parse_retrieval\n",
    "from torch.utils.data import Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5098a794",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T07:30:36.087482Z",
     "iopub.status.busy": "2025-06-04T07:30:36.087045Z",
     "iopub.status.idle": "2025-06-04T07:30:36.133014Z",
     "shell.execute_reply": "2025-06-04T07:30:36.132049Z"
    },
    "papermill": {
     "duration": 0.053534,
     "end_time": "2025-06-04T07:30:36.134449",
     "exception": false,
     "start_time": "2025-06-04T07:30:36.080915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device=device(type='cuda', index=0)\n"
     ]
    }
   ],
   "source": [
    "# Do not forget to select an accelerator on the sidebar to the right.\n",
    "device = K.utils.get_cuda_device_if_available(0)\n",
    "print(f'{device=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa532f16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T07:30:36.147460Z",
     "iopub.status.busy": "2025-06-04T07:30:36.147169Z",
     "iopub.status.idle": "2025-06-04T07:30:36.314115Z",
     "shell.execute_reply": "2025-06-04T07:30:36.313398Z"
    },
    "papermill": {
     "duration": 0.174966,
     "end_time": "2025-06-04T07:30:36.315646",
     "exception": false,
     "start_time": "2025-06-04T07:30:36.140680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset \"ETs\" -> num_images=22\n",
      "Dataset \"amy_gardens\" -> num_images=200\n",
      "Dataset \"fbk_vineyard\" -> num_images=163\n",
      "Dataset \"imc2023_haiper\" -> num_images=54\n",
      "Dataset \"imc2023_heritage\" -> num_images=209\n",
      "Dataset \"imc2023_theather_imc2024_church\" -> num_images=76\n",
      "Dataset \"imc2024_dioscuri_baalshamin\" -> num_images=138\n",
      "Dataset \"imc2024_lizard_pond\" -> num_images=214\n",
      "Dataset \"pt_brandenburg_british_buckingham\" -> num_images=225\n",
      "Dataset \"pt_piazzasanmarco_grandplace\" -> num_images=168\n",
      "Dataset \"pt_sacrecoeur_trevi_tajmahal\" -> num_images=225\n",
      "Dataset \"pt_stpeters_stpauls\" -> num_images=200\n",
      "Dataset \"stairs\" -> num_images=51\n"
     ]
    }
   ],
   "source": [
    "# Collect vital info from the dataset\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class Prediction:\n",
    "    image_id: str | None  # A unique identifier for the row -- unused otherwise. Used only on the hidden test set.\n",
    "    dataset: str\n",
    "    filename: str\n",
    "    cluster_index: int | None = None\n",
    "    rotation: np.ndarray | None = None\n",
    "    translation: np.ndarray | None = None\n",
    "\n",
    "# Set is_train=True to run the notebook on the training data.\n",
    "# Set is_train=False if submitting an entry to the competition (test data is hidden, and different from what you see on the \"test\" folder).\n",
    "is_train = False\n",
    "data_dir = '/kaggle/input/image-matching-challenge-2025'\n",
    "workdir = '/kaggle/working/result/'\n",
    "os.makedirs(workdir, exist_ok=True)\n",
    "\n",
    "if is_train:\n",
    "    sample_submission_csv = os.path.join(data_dir, 'train_labels.csv')\n",
    "else:\n",
    "    sample_submission_csv = os.path.join(data_dir, 'sample_submission.csv')\n",
    "\n",
    "samples = {}\n",
    "competition_data = pd.read_csv(sample_submission_csv)\n",
    "for _, row in competition_data.iterrows():\n",
    "    # Note: For the test data, the \"scene\" column has no meaning, and the rotation_matrix and translation_vector columns are random.\n",
    "    if row.dataset not in samples:\n",
    "        samples[row.dataset] = []\n",
    "    samples[row.dataset].append(\n",
    "        Prediction(\n",
    "            image_id=None if is_train else row.image_id,\n",
    "            dataset=row.dataset,\n",
    "            filename=row.image\n",
    "        )\n",
    "    )\n",
    "\n",
    "for dataset in samples:\n",
    "    print(f'Dataset \"{dataset}\" -> num_images={len(samples[dataset])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42667f24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T07:30:36.328553Z",
     "iopub.status.busy": "2025-06-04T07:30:36.328260Z",
     "iopub.status.idle": "2025-06-04T07:30:36.332553Z",
     "shell.execute_reply": "2025-06-04T07:30:36.331937Z"
    },
    "papermill": {
     "duration": 0.012239,
     "end_time": "2025-06-04T07:30:36.333889",
     "exception": false,
     "start_time": "2025-06-04T07:30:36.321650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_duplicate_pairs(pairs_path):\n",
    "    pairs = parse_retrieval(pairs_path)\n",
    "    pairs = [(q, r) for q, rs in pairs.items() for r in rs]\n",
    "    pairs = match_features.find_unique_new_pairs(pairs, None)\n",
    "    os.system(f'rm -rf {str(pairs_path)}')\n",
    "    with open(pairs_path, 'w') as f:\n",
    "        f.write(\"\\n\".join(\" \".join([i, j]) for i, j in pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8799de4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T07:30:36.346492Z",
     "iopub.status.busy": "2025-06-04T07:30:36.346233Z",
     "iopub.status.idle": "2025-06-04T07:30:36.352775Z",
     "shell.execute_reply": "2025-06-04T07:30:36.352083Z"
    },
    "papermill": {
     "duration": 0.014007,
     "end_time": "2025-06-04T07:30:36.353897",
     "exception": false,
     "start_time": "2025-06-04T07:30:36.339890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_pairs(path):\n",
    "    path = Path(path)\n",
    "    with open(path, 'r') as f:\n",
    "        lines = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "    mid = len(lines) // 2\n",
    "    pairs_split1 = lines[:mid]\n",
    "    pairs_split2 = lines[mid:]\n",
    "\n",
    "    # Define output file paths\n",
    "    output1 = path.parent / (path.stem + '_1.txt')\n",
    "    output2 = path.parent / (path.stem + '_2.txt')\n",
    "\n",
    "    # Write each half to its own file\n",
    "    with open(output1, 'w') as f:\n",
    "        f.write('\\n'.join(pairs_split1) + '\\n')\n",
    "    with open(output2, 'w') as f:\n",
    "        f.write('\\n'.join(pairs_split2) + '\\n')\n",
    "\n",
    "    return output1, output2\n",
    "\n",
    "\n",
    "def combine_pairs(path1, path2, output_path):\n",
    "    path1 = Path(path1)\n",
    "    path2 = Path(path2)\n",
    "    output_path = Path(output_path)\n",
    "\n",
    "    # Read lines from both input files\n",
    "    with open(path1, 'r') as f1:\n",
    "        lines1 = [line.strip() for line in f1 if line.strip()]\n",
    "\n",
    "    with open(path2, 'r') as f2:\n",
    "        lines2 = [line.strip() for line in f2 if line.strip()]\n",
    "\n",
    "    # Combine the lines\n",
    "    combined_lines = lines1 + lines2\n",
    "\n",
    "    # Write to output file\n",
    "    with open(output_path, 'w') as out_f:\n",
    "        out_f.write('\\n'.join(combined_lines) + '\\n')\n",
    "\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552a09ed",
   "metadata": {
    "papermill": {
     "duration": 0.005355,
     "end_time": "2025-06-04T07:30:36.365202",
     "exception": false,
     "start_time": "2025-06-04T07:30:36.359847",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "684f08c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T07:30:36.377845Z",
     "iopub.status.busy": "2025-06-04T07:30:36.377609Z",
     "iopub.status.idle": "2025-06-04T07:30:36.407202Z",
     "shell.execute_reply": "2025-06-04T07:30:36.406331Z"
    },
    "papermill": {
     "duration": 0.037506,
     "end_time": "2025-06-04T07:30:36.408694",
     "exception": false,
     "start_time": "2025-06-04T07:30:36.371188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"d_model\": 256,\n",
    "    \"nhead\": 8,\n",
    "    \"layer_names\": [\"self\", \"cross\"] * 4,\n",
    "    \"attention\": \"linear\",\n",
    "    \"input_dim\": 768,\n",
    "}\n",
    "sys.path.append('/kaggle/input/kaggle-classifier/kaggle-classifier')\n",
    "from model.transformer import LocalFeatureTransformer\n",
    "\n",
    "def get_descriptors(path: Path, name: str) -> np.ndarray:\n",
    "    with h5py.File(str(path), \"r\", libver=\"latest\") as hfile:\n",
    "        dset = hfile[name][\"descriptors\"]\n",
    "        return dset[:]\n",
    "        \n",
    "def exec_pair_classification(sfm_pairs, device, feature_path, output_path):\n",
    "    model = LocalFeatureTransformer(config)\n",
    "    model.load_state_dict(torch.load('/kaggle/input/kaggle-classifier/kaggle-classifier/checkpoints/checkpoint_epoch_16.pth')['model_state_dict'])\n",
    "    model.eval().to(device)\n",
    "    pairs = parse_retrieval(sfm_pairs)\n",
    "    pairs = [(q, r) for q, rs in pairs.items() for r in rs]\n",
    "    pairs = match_features.find_unique_new_pairs(pairs, None)\n",
    "    new_pairs = []\n",
    "    with torch.no_grad():\n",
    "        for i, (q, r) in tqdm(enumerate(pairs)):\n",
    "            desc_q = get_descriptors(feature_path, q)\n",
    "            desc_r = get_descriptors(feature_path, r)\n",
    "            desc_q = torch.from_numpy(desc_q).to(device)\n",
    "            desc_r = torch.from_numpy(desc_r).to(device)\n",
    "            desc_q = desc_q.unsqueeze(0).to(torch.float32)\n",
    "            desc_r = desc_r.unsqueeze(0).to(torch.float32)\n",
    "            out = model(desc_q, desc_r)\n",
    "            if out[0][0] >= 0.6:\n",
    "                new_pairs.append((q, r))\n",
    "    \n",
    "    with open(output_path, 'w') as f:\n",
    "        f.write(\"\\n\".join(\" \".join([i, j]) for i, j in new_pairs))\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c055b2c",
   "metadata": {
    "papermill": {
     "duration": 0.00531,
     "end_time": "2025-06-04T07:30:36.420196",
     "exception": false,
     "start_time": "2025-06-04T07:30:36.414886",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ca04992",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T07:30:36.432700Z",
     "iopub.status.busy": "2025-06-04T07:30:36.432422Z",
     "iopub.status.idle": "2025-06-04T07:30:41.745676Z",
     "shell.execute_reply": "2025-06-04T07:30:41.744898Z"
    },
    "papermill": {
     "duration": 5.321101,
     "end_time": "2025-06-04T07:30:41.747272",
     "exception": false,
     "start_time": "2025-06-04T07:30:36.426171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name swsl_resnext50_32x4d to current resnext50_32x4d.fb_swsl_ig1b_ft_in1k.\n",
      "  model = create_fn(\n"
     ]
    }
   ],
   "source": [
    "from torchvision.io import read_image as T_read_image\n",
    "from torchvision.io import ImageReadMode\n",
    "from torchvision import transforms as T\n",
    "from check_orientation.pre_trained_models import create_model\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "def convert_rot_k(index):\n",
    "    if index == 0:\n",
    "        return 0\n",
    "    elif index == 1:\n",
    "        return 3\n",
    "    elif index == 2:\n",
    "        return 2\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "class CheckRotationDataset(Dataset):\n",
    "    def __init__(self, files, transform=None):\n",
    "        self.transform = transform\n",
    "        self.files = files\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        imgPath = self.files[idx]\n",
    "        image = T_read_image(imgPath, mode=ImageReadMode.RGB)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "def get_CheckRotation_dataloader_crop(images, batch_size=1):\n",
    "    transform = T.Compose([\n",
    "        T.Resize((224, 224)),\n",
    "        T.ConvertImageDtype(torch.float),\n",
    "        T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "    ])\n",
    "\n",
    "    dataset = CheckRotationDataset(images, transform=transform)\n",
    "    dataloader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size,\n",
    "        pin_memory=True,\n",
    "        num_workers=2,\n",
    "        drop_last=False\n",
    "    )\n",
    "    return dataloader\n",
    "\n",
    "def exec_rotation_detection(img_files, device):\n",
    "    model = create_model(\"swsl_resnext50_32x4d\")\n",
    "    model.eval().to(device);\n",
    "    \n",
    "    dataloader = get_CheckRotation_dataloader_crop(img_files)\n",
    "    \n",
    "    rots = []\n",
    "    for idx, image in enumerate(dataloader):\n",
    "        image = image.to(torch.float32).to(device)\n",
    "        with torch.no_grad():\n",
    "            prediction = model(image).detach().cpu().numpy()\n",
    "            detected_rot = prediction[0].argmax()\n",
    "            if prediction[0][detected_rot] > 0.9:\n",
    "                rot_k = convert_rot_k(detected_rot)\n",
    "            else:\n",
    "                rot_k = 0\n",
    "            rots.append(rot_k)\n",
    "            print(f\"{os.path.basename(img_files[idx])} > rot_k={rot_k}\")\n",
    "    return rots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "895c2f13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T07:30:41.760437Z",
     "iopub.status.busy": "2025-06-04T07:30:41.760112Z",
     "iopub.status.idle": "2025-06-04T07:30:41.766704Z",
     "shell.execute_reply": "2025-06-04T07:30:41.766005Z"
    },
    "papermill": {
     "duration": 0.014435,
     "end_time": "2025-06-04T07:30:41.767898",
     "exception": false,
     "start_time": "2025-06-04T07:30:41.753463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def output_rot_images(\n",
    "    paths,\n",
    "    output_dir,\n",
    "    rots,\n",
    "):\n",
    "    corrected_image_paths = []\n",
    "    for rot, path in tqdm(zip(rots, paths), total=len(paths), desc=f\"Rotating images\", dynamic_ncols=True):\n",
    "        try:\n",
    "            img = cv2.imread(str(path))\n",
    "    \n",
    "            if rot == 1:\n",
    "                img = cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "            elif rot == 2:\n",
    "                img = cv2.rotate(img, cv2.ROTATE_180)\n",
    "            elif rot == 3:\n",
    "                img = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
    "    \n",
    "            cv2.imwrite(str(output_dir / path.name), img)\n",
    "        except:\n",
    "            shutil.copy(str(path), str(output_dir / path.name))\n",
    "        \n",
    "        corrected_image_paths.append(output_dir / path.name)\n",
    "\n",
    "    return corrected_image_paths\n",
    "\n",
    "def exec_rotation_correction(paths, output_dir):\n",
    "\n",
    "    rots = exec_rotation_detection(paths, device)\n",
    "\n",
    "    corrected_image_paths = []\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = executor.map(\n",
    "            output_rot_images,\n",
    "            np.array_split(paths, 2),\n",
    "            itertools.repeat(output_dir),\n",
    "            np.array_split(rots, 2),\n",
    "        )\n",
    "        for data in results:\n",
    "            corrected_image_paths.append(data)\n",
    "\n",
    "    corrected_image_paths = list(itertools.chain.from_iterable(corrected_image_paths))\n",
    "    gc.collect()\n",
    "\n",
    "    return corrected_image_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cbc820",
   "metadata": {
    "papermill": {
     "duration": 0.005427,
     "end_time": "2025-06-04T07:30:41.779299",
     "exception": false,
     "start_time": "2025-06-04T07:30:41.773872",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Run All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f414a04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T07:30:41.791242Z",
     "iopub.status.busy": "2025-06-04T07:30:41.791010Z",
     "iopub.status.idle": "2025-06-04T07:30:41.802015Z",
     "shell.execute_reply": "2025-06-04T07:30:41.801262Z"
    },
    "papermill": {
     "duration": 0.01839,
     "end_time": "2025-06-04T07:30:41.803270",
     "exception": false,
     "start_time": "2025-06-04T07:30:41.784880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from hloc.utils.io import get_keypoints, get_matches, names_to_pair\n",
    "\n",
    "def merge_keypoints(image_list, feature_path1, feature_path2, save_name='feats-merged.h5'):\n",
    "    output = feature_path1.parent / save_name\n",
    "    with h5py.File(str(output), \"a\", libver=\"latest\") as fd:\n",
    "        for name in image_list:\n",
    "            try:\n",
    "                if name in fd:\n",
    "                    del fd[name]\n",
    "                grp = fd.create_group(name)\n",
    "                kpts1 = get_keypoints(feature_path1, name)\n",
    "                if isinstance(feature_path2, list):\n",
    "                    try:\n",
    "                        kpts2 = get_keypoints(feature_path2[0], name)\n",
    "                    except:\n",
    "                        kpts2 = get_keypoints(feature_path2[1], name)\n",
    "                else:\n",
    "                    kpts2 = get_keypoints(feature_path2, name)\n",
    "                kpts = np.concatenate((kpts1, kpts2), axis=0)\n",
    "                len1 = kpts1.shape[0]\n",
    "                grp.create_dataset('keypoints', data=kpts)\n",
    "                grp.create_dataset('length', data=len1)\n",
    "                \n",
    "            except OSError as error:\n",
    "                if \"No space left on device\" in error.args[0]:\n",
    "                    logger.error(\n",
    "                        \"Out of disk space: storing features on disk can take \"\n",
    "                        \"significant space, did you enable the as_half flag?\"\n",
    "                    )\n",
    "                    del grp, fd[name]\n",
    "                raise error\n",
    "    return output\n",
    "\n",
    "def get_length(feature_path, name):\n",
    "    with h5py.File(str(feature_path), \"r\", libver=\"latest\") as fd:\n",
    "        length = fd[name]['length'][()]\n",
    "    return length\n",
    "\n",
    "def merge_matches(matches_path, matches_path_sg, pairs_path, merge_keypoints, save_name='matches-merged.h5'):\n",
    "    output = matches_path.parent / save_name\n",
    "    with open(str(pairs_path), \"r\") as f:\n",
    "        pairs = [p.split() for p in f.readlines()]\n",
    "    \n",
    "    with h5py.File(str(output), \"a\", libver=\"latest\") as fd:\n",
    "        for name0, name1 in tqdm(pairs):\n",
    "            pair = names_to_pair(name0, name1)\n",
    "            \n",
    "            try:\n",
    "                out1 = get_matches(matches_path, name0, name1)\n",
    "                    \n",
    "                matches1 = out1[0]\n",
    "                scores1 = out1[1]\n",
    "\n",
    "                out2 = get_matches(matches_path_sg, name0, name1)\n",
    "                matches2 = out2[0]\n",
    "                scores2 = out2[1]\n",
    "\n",
    "                length1 = get_length(merge_keypoints, name0)\n",
    "                length2 = get_length(merge_keypoints, name1)\n",
    "                \n",
    "                # add length to matches2\n",
    "                matches2[:, 0] += length1\n",
    "                matches2[:, 1] += length2\n",
    "                \n",
    "                matches = np.concatenate((matches1, matches2), axis=0)\n",
    "            \n",
    "                scores = np.concatenate((scores1, scores2), axis=0)\n",
    "\n",
    "                with h5py.File(str(output), \"a\", libver=\"latest\") as fd:\n",
    "                    if pair in fd:\n",
    "                        del fd[pair]\n",
    "                    grp = fd.create_group(pair)\n",
    "                    grp.create_dataset(\"matches0\", data=matches)\n",
    "                    grp.create_dataset(\"matching_scores0\", data=scores)\n",
    "            except OSError as error:\n",
    "                if \"No space left on device\" in error.args[0]:\n",
    "                    logger.error(\n",
    "                        \"Out of disk space: storing features on disk can take \"\n",
    "                        \"significant space, did you enable the as_half flag?\"\n",
    "                    )\n",
    "                    del grp, fd[pair]\n",
    "                raise error\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "889ab1c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T07:30:41.815558Z",
     "iopub.status.busy": "2025-06-04T07:30:41.815218Z",
     "iopub.status.idle": "2025-06-04T07:40:38.049510Z",
     "shell.execute_reply": "2025-06-04T07:40:38.048462Z"
    },
    "papermill": {
     "duration": 596.242215,
     "end_time": "2025-06-04T07:40:38.051060",
     "exception": false,
     "start_time": "2025-06-04T07:30:41.808845",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset \"stairs\" -> Registered 9 / 52 images with 2 clusters\n",
      "\n",
      "Results\n",
      "Dataset \"ETs\" -> Registered 21 / 23 images with 2 clusters\n",
      "Dataset \"stairs\" -> Registered 9 / 52 images with 2 clusters\n",
      "\n",
      "Timings\n",
      "shortlisting -> total=0.00 sec.\n",
      "feature_detection -> total=0.00 sec.\n",
      "feature_matching -> total=0.00 sec.\n",
      "RANSAC -> total=0.00 sec.\n",
      "Reconstruction -> total=0.00 sec.\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "\n",
    "max_images = None  # Used For debugging only. Set to None to disable.\n",
    "datasets_to_process = None  # Not the best convention, but None means all datasets.\n",
    "\n",
    "if is_train:\n",
    "    # max_images = 5\n",
    "\n",
    "    # Note: When running on the training dataset, the notebook will hit the time limit and die. Use this filter to run on a few specific datasets.\n",
    "    datasets_to_process = [\n",
    "    \t# New data.\n",
    "    \t#'amy_gardens',\n",
    "    \t'ETs',\n",
    "    \t#'fbk_vineyard',\n",
    "    \t'stairs',\n",
    "    \t#Data from IMC 2023 and 2024.\n",
    "    \t#'imc2024_dioscuri_baalshamin',\n",
    "    \t#'imc2023_theather_imc2024_church',\n",
    "    \t#'imc2023_heritage',\n",
    "    \t#'imc2023_haiper',\n",
    "    \t#'imc2024_lizard_pond',\n",
    "    \t# Crowdsourced PhotoTourism data.\n",
    "    \t#'pt_stpeters_stpauls',\n",
    "    \t#'pt_brandenburg_british_buckingham',\n",
    "    \t#'pt_piazzasanmarco_grandplace',\n",
    "    \t#'pt_sacrecoeur_trevi_tajmahal',\n",
    "    ]\n",
    "\n",
    "timings = {\n",
    "    \"shortlisting\":[],\n",
    "    \"feature_detection\": [],\n",
    "    \"feature_matching\":[],\n",
    "    \"RANSAC\": [],\n",
    "    \"Reconstruction\": [],\n",
    "}\n",
    "mapping_result_strs = []\n",
    "\n",
    "\n",
    "print (f\"Extracting on device {device}\")\n",
    "for dataset, predictions in samples.items():\n",
    "    if datasets_to_process and dataset not in datasets_to_process:\n",
    "        print(f'Skipping \"{dataset}\"')\n",
    "        continue\n",
    "\n",
    "    images_dir = Path(os.path.join(data_dir, 'train' if is_train else 'test', dataset))\n",
    "    image_paths = list(images_dir.glob('**/*.[pjJP][npNP][gG]'))  # Matches .jpg, .png, .JPG, .PNG, etc.\n",
    "\n",
    "    if not images_dir.exists():\n",
    "        continue\n",
    "    \n",
    "    images = os.listdir(images_dir)\n",
    "    images = [image for image in images if image.endswith('.jpg') or image.endswith('.png')]\n",
    "    images_path = [images_dir / image for image in images]\n",
    "\n",
    "    mid = len(images) // 2\n",
    "    images_split1 = images[:mid]\n",
    "    images_split2 = images[mid:]\n",
    "    \n",
    "    feature_dir = os.path.join(workdir, 'featureout', dataset)\n",
    "    os.makedirs(feature_dir, exist_ok=True)\n",
    "\n",
    "    outputs = Path(feature_dir)\n",
    "        \n",
    "    # check for rotation\n",
    "    \n",
    "    corrected_images_dir = outputs / \"corrected_images\"\n",
    "    corrected_images_dir.mkdir(parents=True, exist_ok=True)\n",
    "    exec_rotation_correction(image_paths, corrected_images_dir)\n",
    "    corrected_images_paths = list(corrected_images_dir.glob('**/*.[pjJP][npNP][gG]'))\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    sfm_pairs = outputs / \"pairs-all.txt\"\n",
    "    sfm_pairs_retrival = outputs / \"pairs-netvlad.txt\"\n",
    "    sfm_dir = outputs / \"sfm_rdd+lightglue\"\n",
    "    \n",
    "    ##### rdd+lightglue\n",
    "    \n",
    "    feature_conf1 = {'model': {'combine': False, 'max_keypoints': 8192, 'name': 'rdd'},\n",
    "     'output': 'feats-rdd-r1024',\n",
    "     'preprocessing': {'grayscale': False, 'resize_max': 1024, 'resize_force': True}}\n",
    "    feature_conf2 = {'model': {'combine': False, 'max_keypoints': 8192, 'name': 'rdd'},\n",
    "     'output': 'feats-rdd-r1280',\n",
    "     'preprocessing': {'grayscale': False, 'resize_max': 1280, 'resize_force': True}}\n",
    "    \n",
    "    matcher_conf = {'model': {'depth_confidence': -1,\n",
    "                               'features': 'rdd',\n",
    "                               'mp': True,\n",
    "                               'name': 'lightglue',\n",
    "                               'width_confidence': 0.99},\n",
    "                     'output': 'matches-rdd-lightglue'}\n",
    "\n",
    "    matcher_conf2 = {'model': {'depth_confidence': -1,\n",
    "                               'features': 'rdd',\n",
    "                               'mp': True,\n",
    "                               'name': 'lightglue',\n",
    "                               'width_confidence': 0.99},\n",
    "                     'output': 'matches-rdd-lightglue'}\n",
    "    \n",
    "    print(f'\\nProcessing dataset \"{dataset}\": {len(os.listdir(corrected_images_dir))} images')\n",
    "    filename_to_index = {p.filename: idx for idx, p in enumerate(predictions)}\n",
    "    \n",
    "    pairs_from_exhaustive.main(sfm_pairs, images)\n",
    "    retrieval_conf = extract_features.confs[\"netvlad\"]\n",
    "    retrieval_path = extract_features.main(retrieval_conf, corrected_images_dir, outputs, device='0')\n",
    "    num_matched = max(20, int(0.12 * len(images)))\n",
    "    pairs_from_retrieval.main(retrieval_path, sfm_pairs_retrival, num_matched=num_matched)\n",
    "\n",
    "    dino_conf = {\n",
    "        \"output\": \"global-feats-dino\",\n",
    "        \"model\": {\"name\": \"dino\", \"model_path\": \"/kaggle/input/dinov2/pytorch/base/1\"},\n",
    "        \"preprocessing\": {\"resize_max\": 1024, \"grayscale\": False},\n",
    "    }\n",
    "    dino_path = extract_features.main(dino_conf, corrected_images_dir, outputs, device='0', overwrite=True)\n",
    "    \n",
    "    # remove_duplicate_pairs(sfm_pairs)\n",
    "    sfm_pairs1, sfm_pairs2 = split_pairs(sfm_pairs)\n",
    "\n",
    "    sfm_pairs1_new = sfm_pairs1.parent / (sfm_pairs1.stem + '_new.txt')\n",
    "    sfm_pairs2_new = sfm_pairs2.parent / (sfm_pairs2.stem + '_new.txt')\n",
    "    \n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        sfm_pairs_list = list(executor.map(\n",
    "            exec_pair_classification,\n",
    "            [sfm_pairs1, sfm_pairs2],\n",
    "            ['cuda:0', 'cuda:1'],\n",
    "            [dino_path, dino_path],\n",
    "            [sfm_pairs1_new, sfm_pairs2_new]\n",
    "        ))\n",
    "\n",
    "\n",
    "    sfm_pairs_new = sfm_pairs.parent / (sfm_pairs.stem + '_new.txt')\n",
    "    combine_pairs(sfm_pairs1_new, sfm_pairs2_new, sfm_pairs_new)\n",
    "\n",
    "    sfm_pairs_combine = sfm_pairs.parent / (sfm_pairs.stem + '_final.txt')\n",
    "    combine_pairs(sfm_pairs_new, sfm_pairs_retrival, sfm_pairs_combine)\n",
    "\n",
    "    remove_duplicate_pairs(sfm_pairs_combine)\n",
    "\n",
    "    print('feature_conf1', feature_conf1)\n",
    "    print('feature_conf2', feature_conf2)\n",
    "    feature_path1 = extract_features.main(feature_conf1, corrected_images_dir, outputs, device='0', overwrite=True)\n",
    "    feature_path2 = extract_features.main(feature_conf2, corrected_images_dir, outputs, device='0', overwrite=True)\n",
    "    \n",
    "    # remove_duplicate_pairs(sfm_pairs)\n",
    "    \n",
    "    # sfm_pairs1, sfm_pairs2 = split_pairs(sfm_pairs)\n",
    "    \n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        match_paths = list(executor.map(\n",
    "            match_features.main,\n",
    "            [matcher_conf, matcher_conf2],\n",
    "            [sfm_pairs_combine, sfm_pairs_combine],\n",
    "            [feature_conf1[\"output\"], feature_conf2[\"output\"]],\n",
    "            [outputs, outputs],\n",
    "            [None, None],\n",
    "            [None, None],\n",
    "            [True, True],\n",
    "            ['0', '1'],\n",
    "            [0, 0]\n",
    "        ))\n",
    "\n",
    "    \"\"\"sfm_pairs_new = sfm_pairs.parent / (sfm_pairs.stem + '_new.txt')\n",
    "    combine_pairs(sfm_pairs1_new, sfm_pairs2_new, sfm_pairs_new)\"\"\"\n",
    "\n",
    "    merged_features_path = merge_keypoints(images, feature_path1, feature_path2)\n",
    "    merged_match_path = merge_matches(match_paths[0], match_paths[1], sfm_pairs_combine, merged_features_path, save_name='matches-merged.h5')\n",
    "    \n",
    "    sfm_dir.mkdir(parents=True, exist_ok=True)\n",
    "    database = sfm_dir / \"database.db\"\n",
    "    models_path = sfm_dir / \"models\"\n",
    "    camera_mode = pycolmap.CameraMode.AUTO\n",
    "    models_path.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    create_empty_db(database)\n",
    "    import_images(corrected_images_dir, database, camera_mode, None, None)\n",
    "    image_ids = get_image_ids(database)\n",
    "    import_features(image_ids, database, merged_features_path)\n",
    "    \n",
    "    import_matches(\n",
    "        image_ids,\n",
    "        database,\n",
    "        sfm_pairs_combine,\n",
    "        merged_match_path,\n",
    "        0.2,\n",
    "        False,\n",
    "    )\n",
    "    \n",
    "    estimation_and_geometric_verification(database, sfm_pairs_combine, False)\n",
    "    \n",
    "    os.makedirs(models_path, exist_ok=True)\n",
    "    t = time()\n",
    "    \n",
    "    # Run the mapping\n",
    "    \n",
    "    new_database_path = database\n",
    "    \n",
    "    mapper_options = pycolmap.IncrementalPipelineOptions()\n",
    "    mapper_options.min_model_size = 3\n",
    "    mapper_options.max_num_models = 5\n",
    "    \n",
    "    maps = pycolmap.incremental_mapping(\n",
    "        database_path=new_database_path, \n",
    "        image_path=corrected_images_dir,\n",
    "        output_path=models_path,\n",
    "        options=mapper_options)\n",
    "    \n",
    "    clear_output(wait=False)\n",
    "\n",
    "    registered = 0\n",
    "    for map_index, cur_map in maps.items():\n",
    "        for index, image in cur_map.images.items():\n",
    "            prediction_index = filename_to_index[image.name]\n",
    "            predictions[prediction_index].cluster_index = map_index\n",
    "            predictions[prediction_index].rotation = deepcopy(image.cam_from_world.rotation.matrix())\n",
    "            predictions[prediction_index].translation = deepcopy(image.cam_from_world.translation)\n",
    "            registered += 1\n",
    "    mapping_result_str = f'Dataset \"{dataset}\" -> Registered {registered} / {len(os.listdir(images_dir))} images with {len(maps)} clusters'\n",
    "    mapping_result_strs.append(mapping_result_str)\n",
    "    print(mapping_result_str)\n",
    "    gc.collect()\n",
    "    os.system(f'rm -rf {str(corrected_images_dir)}')\n",
    "\n",
    "print('\\nResults')\n",
    "for s in mapping_result_strs:\n",
    "    print(s)\n",
    "\n",
    "print('\\nTimings')\n",
    "for k, v in timings.items():\n",
    "    print(f'{k} -> total={sum(v):.02f} sec.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de22b8a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T07:40:38.064642Z",
     "iopub.status.busy": "2025-06-04T07:40:38.064026Z",
     "iopub.status.idle": "2025-06-04T07:40:38.320604Z",
     "shell.execute_reply": "2025-06-04T07:40:38.319621Z"
    },
    "papermill": {
     "duration": 0.264923,
     "end_time": "2025-06-04T07:40:38.322263",
     "exception": false,
     "start_time": "2025-06-04T07:40:38.057340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_id,dataset,scene,image,rotation_matrix,translation_vector\r\n",
      "ETs_another_et_another_et001.png_public,ETs,cluster1,another_et_another_et001.png,0.999916621;-0.004184967;0.012216266;0.003881384;0.999685654;0.024769510;-0.012316085;-0.024720029;0.999618544,-2.686391945;-1.911350527;3.649016461\r\n",
      "ETs_another_et_another_et002.png_public,ETs,cluster1,another_et_another_et002.png,0.999993768;-0.001928512;-0.002957279;0.001926209;0.999997840;-0.000781393;0.002958780;0.000775691;0.999995322,-2.511561487;-1.006329969;1.827922478\r\n",
      "ETs_another_et_another_et003.png_public,ETs,cluster1,another_et_another_et003.png,0.998005220;-0.041333618;0.047719112;0.044293194;0.997047377;-0.062726719;-0.044985493;0.064715225;0.996889284,-2.752199578;0.773408425;-0.293995558\r\n",
      "ETs_another_et_another_et004.png_public,ETs,cluster1,another_et_another_et004.png,0.999366128;-0.011534478;0.033679356;0.007007487;0.991283304;0.131561035;-0.034903271;-0.131241634;0.990735785,-2.635643651;-1.271348738;0.178377702\r\n",
      "ETs_another_et_another_et005.png_public,ETs,cluster1,another_et_another_et005.png,0.995549411;0.002313664;0.094212621;-0.008753685;0.997646883;0.068000507;-0.093833597;-0.068522572;0.993227020,-3.228712417;-2.118762360;1.895081794\r\n",
      "ETs_another_et_another_et006.png_public,ETs,cluster1,another_et_another_et006.png,0.919777214;0.193244849;-0.341564495;-0.218644864;0.975099014;-0.037099001;0.325890012;0.108804138;0.939125849,-0.179428351;-0.652957093;1.899359481\r\n",
      "ETs_another_et_another_et007.png_public,ETs,cluster1,another_et_another_et007.png,0.779284683;0.264599201;-0.568069226;-0.310411696;0.950452311;0.016881467;0.544389531;0.163179864;0.822807614,1.679431082;-0.352429717;1.459344323\r\n",
      "ETs_another_et_another_et008.png_public,ETs,cluster1,another_et_another_et008.png,0.565743555;0.311234754;-0.763588343;-0.392619185;0.915996688;0.082463582;0.725109926;0.253146193;0.640415959,3.484061704;-0.764270153;2.468266412\r\n",
      "ETs_another_et_another_et009.png_public,ETs,cluster1,another_et_another_et009.png,0.314747139;0.345195597;-0.884179981;-0.487659012;0.857989869;0.161375568;0.814323601;0.380385837;0.438387600,5.239226750;-1.195599824;3.270734355\r\n"
     ]
    }
   ],
   "source": [
    "# Must Create a submission file.\n",
    "array_to_str = lambda array: ';'.join([f\"{x:.09f}\" for x in array])\n",
    "none_to_str = lambda n: ';'.join(['nan'] * n)\n",
    "\n",
    "submission_file = '/kaggle/working/submission.csv' \n",
    "with open(submission_file, 'w') as f:\n",
    "    if is_train:\n",
    "        f.write('dataset,scene,image,rotation_matrix,translation_vector\\n')\n",
    "        for dataset in samples:\n",
    "            for prediction in samples[dataset]:\n",
    "                cluster_name = 'outliers' if prediction.cluster_index is None else f'cluster{prediction.cluster_index}'\n",
    "                rotation = none_to_str(9) if prediction.rotation is None else array_to_str(prediction.rotation.flatten())\n",
    "                translation = none_to_str(3) if prediction.translation is None else array_to_str(prediction.translation)\n",
    "                f.write(f'{prediction.dataset},{cluster_name},{prediction.filename},{rotation},{translation}\\n')\n",
    "    else:\n",
    "        f.write('image_id,dataset,scene,image,rotation_matrix,translation_vector\\n')\n",
    "        for dataset in samples:\n",
    "            for prediction in samples[dataset]:\n",
    "                cluster_name = 'outliers' if prediction.cluster_index is None else f'cluster{prediction.cluster_index}'\n",
    "                rotation = none_to_str(9) if prediction.rotation is None else array_to_str(prediction.rotation.flatten())\n",
    "                translation = none_to_str(3) if prediction.translation is None else array_to_str(prediction.translation)\n",
    "                f.write(f'{prediction.image_id},{prediction.dataset},{cluster_name},{prediction.filename},{rotation},{translation}\\n')\n",
    "\n",
    "!head {submission_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "983ca02c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T07:40:38.335285Z",
     "iopub.status.busy": "2025-06-04T07:40:38.334979Z",
     "iopub.status.idle": "2025-06-04T07:40:38.339911Z",
     "shell.execute_reply": "2025-06-04T07:40:38.339043Z"
    },
    "papermill": {
     "duration": 0.012608,
     "end_time": "2025-06-04T07:40:38.341073",
     "exception": false,
     "start_time": "2025-06-04T07:40:38.328465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Definitely Compute results if running on the training set.\n",
    "# Do not do this when submitting a notebook for scoring. All you have to do is save your submission to /kaggle/working/submission.csv.\n",
    "\n",
    "if is_train:\n",
    "    t = time()\n",
    "    final_score, dataset_scores = metric.score(\n",
    "        gt_csv='/kaggle/input/image-matching-challenge-2025/train_labels.csv',\n",
    "        user_csv=submission_file,\n",
    "        thresholds_csv='/kaggle/input/image-matching-challenge-2025/train_thresholds.csv',\n",
    "        mask_csv=None if is_train else os.path.join(data_dir, 'mask.csv'),\n",
    "        inl_cf=0,\n",
    "        strict_cf=-1,\n",
    "        verbose=True,\n",
    "    )\n",
    "    print(f'Computed metric in: {time() - t:.02f} sec.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2bd716",
   "metadata": {
    "papermill": {
     "duration": 0.005531,
     "end_time": "2025-06-04T07:40:38.352397",
     "exception": false,
     "start_time": "2025-06-04T07:40:38.346866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11655853,
     "sourceId": 91498,
     "sourceType": "competition"
    },
    {
     "datasetId": 4628051,
     "sourceId": 7884485,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7226273,
     "sourceId": 11522248,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6988459,
     "sourceId": 11924468,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7587137,
     "sourceId": 12055258,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 174014325,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 176463227,
     "sourceType": "kernelVersion"
    },
    {
     "modelId": 322,
     "modelInstanceId": 2742,
     "sourceId": 3840,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 986,
     "modelInstanceId": 3326,
     "sourceId": 4534,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 21716,
     "modelInstanceId": 14317,
     "sourceId": 17191,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 22086,
     "modelInstanceId": 14611,
     "sourceId": 17555,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 304753,
     "modelInstanceId": 283910,
     "sourceId": 339504,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 304784,
     "modelInstanceId": 283941,
     "sourceId": 339540,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 304812,
     "modelInstanceId": 283969,
     "sourceId": 339573,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 310167,
     "modelInstanceId": 289429,
     "sourceId": 417630,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 700.170018,
   "end_time": "2025-06-04T07:40:41.939041",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-04T07:29:01.769023",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
